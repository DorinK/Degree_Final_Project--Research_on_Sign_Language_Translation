2021-12-27 01:48:02,646 Hello! This is Joey-NMT.
2021-12-27 01:48:02,707 Total params: 27927304
2021-12-27 01:48:02,711 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.output_layer.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'image_encoder.classifier.0.bias', 'image_encoder.classifier.0.weight', 'image_encoder.classifier.3.bias', 'image_encoder.classifier.3.weight', 'image_encoder.features.0.0.weight', 'image_encoder.features.0.1.bias', 'image_encoder.features.0.1.weight', 'image_encoder.features.1.block.0.0.weight', 'image_encoder.features.1.block.0.1.bias', 'image_encoder.features.1.block.0.1.weight', 'image_encoder.features.1.block.1.fc1.bias', 'image_encoder.features.1.block.1.fc1.weight', 'image_encoder.features.1.block.1.fc2.bias', 'image_encoder.features.1.block.1.fc2.weight', 'image_encoder.features.1.block.2.0.weight', 'image_encoder.features.1.block.2.1.bias', 'image_encoder.features.1.block.2.1.weight', 'image_encoder.features.10.block.0.0.weight', 'image_encoder.features.10.block.0.1.bias', 'image_encoder.features.10.block.0.1.weight', 'image_encoder.features.10.block.1.0.weight', 'image_encoder.features.10.block.1.1.bias', 'image_encoder.features.10.block.1.1.weight', 'image_encoder.features.10.block.2.fc1.bias', 'image_encoder.features.10.block.2.fc1.weight', 'image_encoder.features.10.block.2.fc2.bias', 'image_encoder.features.10.block.2.fc2.weight', 'image_encoder.features.10.block.3.0.weight', 'image_encoder.features.10.block.3.1.bias', 'image_encoder.features.10.block.3.1.weight', 'image_encoder.features.11.block.0.0.weight', 'image_encoder.features.11.block.0.1.bias', 'image_encoder.features.11.block.0.1.weight', 'image_encoder.features.11.block.1.0.weight', 'image_encoder.features.11.block.1.1.bias', 'image_encoder.features.11.block.1.1.weight', 'image_encoder.features.11.block.2.fc1.bias', 'image_encoder.features.11.block.2.fc1.weight', 'image_encoder.features.11.block.2.fc2.bias', 'image_encoder.features.11.block.2.fc2.weight', 'image_encoder.features.11.block.3.0.weight', 'image_encoder.features.11.block.3.1.bias', 'image_encoder.features.11.block.3.1.weight', 'image_encoder.features.12.0.weight', 'image_encoder.features.12.1.bias', 'image_encoder.features.12.1.weight', 'image_encoder.features.2.block.0.0.weight', 'image_encoder.features.2.block.0.1.bias', 'image_encoder.features.2.block.0.1.weight', 'image_encoder.features.2.block.1.0.weight', 'image_encoder.features.2.block.1.1.bias', 'image_encoder.features.2.block.1.1.weight', 'image_encoder.features.2.block.2.0.weight', 'image_encoder.features.2.block.2.1.bias', 'image_encoder.features.2.block.2.1.weight', 'image_encoder.features.3.block.0.0.weight', 'image_encoder.features.3.block.0.1.bias', 'image_encoder.features.3.block.0.1.weight', 'image_encoder.features.3.block.1.0.weight', 'image_encoder.features.3.block.1.1.bias', 'image_encoder.features.3.block.1.1.weight', 'image_encoder.features.3.block.2.0.weight', 'image_encoder.features.3.block.2.1.bias', 'image_encoder.features.3.block.2.1.weight', 'image_encoder.features.4.block.0.0.weight', 'image_encoder.features.4.block.0.1.bias', 'image_encoder.features.4.block.0.1.weight', 'image_encoder.features.4.block.1.0.weight', 'image_encoder.features.4.block.1.1.bias', 'image_encoder.features.4.block.1.1.weight', 'image_encoder.features.4.block.2.fc1.bias', 'image_encoder.features.4.block.2.fc1.weight', 'image_encoder.features.4.block.2.fc2.bias', 'image_encoder.features.4.block.2.fc2.weight', 'image_encoder.features.4.block.3.0.weight', 'image_encoder.features.4.block.3.1.bias', 'image_encoder.features.4.block.3.1.weight', 'image_encoder.features.5.block.0.0.weight', 'image_encoder.features.5.block.0.1.bias', 'image_encoder.features.5.block.0.1.weight', 'image_encoder.features.5.block.1.0.weight', 'image_encoder.features.5.block.1.1.bias', 'image_encoder.features.5.block.1.1.weight', 'image_encoder.features.5.block.2.fc1.bias', 'image_encoder.features.5.block.2.fc1.weight', 'image_encoder.features.5.block.2.fc2.bias', 'image_encoder.features.5.block.2.fc2.weight', 'image_encoder.features.5.block.3.0.weight', 'image_encoder.features.5.block.3.1.bias', 'image_encoder.features.5.block.3.1.weight', 'image_encoder.features.6.block.0.0.weight', 'image_encoder.features.6.block.0.1.bias', 'image_encoder.features.6.block.0.1.weight', 'image_encoder.features.6.block.1.0.weight', 'image_encoder.features.6.block.1.1.bias', 'image_encoder.features.6.block.1.1.weight', 'image_encoder.features.6.block.2.fc1.bias', 'image_encoder.features.6.block.2.fc1.weight', 'image_encoder.features.6.block.2.fc2.bias', 'image_encoder.features.6.block.2.fc2.weight', 'image_encoder.features.6.block.3.0.weight', 'image_encoder.features.6.block.3.1.bias', 'image_encoder.features.6.block.3.1.weight', 'image_encoder.features.7.block.0.0.weight', 'image_encoder.features.7.block.0.1.bias', 'image_encoder.features.7.block.0.1.weight', 'image_encoder.features.7.block.1.0.weight', 'image_encoder.features.7.block.1.1.bias', 'image_encoder.features.7.block.1.1.weight', 'image_encoder.features.7.block.2.fc1.bias', 'image_encoder.features.7.block.2.fc1.weight', 'image_encoder.features.7.block.2.fc2.bias', 'image_encoder.features.7.block.2.fc2.weight', 'image_encoder.features.7.block.3.0.weight', 'image_encoder.features.7.block.3.1.bias', 'image_encoder.features.7.block.3.1.weight', 'image_encoder.features.8.block.0.0.weight', 'image_encoder.features.8.block.0.1.bias', 'image_encoder.features.8.block.0.1.weight', 'image_encoder.features.8.block.1.0.weight', 'image_encoder.features.8.block.1.1.bias', 'image_encoder.features.8.block.1.1.weight', 'image_encoder.features.8.block.2.fc1.bias', 'image_encoder.features.8.block.2.fc1.weight', 'image_encoder.features.8.block.2.fc2.bias', 'image_encoder.features.8.block.2.fc2.weight', 'image_encoder.features.8.block.3.0.weight', 'image_encoder.features.8.block.3.1.bias', 'image_encoder.features.8.block.3.1.weight', 'image_encoder.features.9.block.0.0.weight', 'image_encoder.features.9.block.0.1.bias', 'image_encoder.features.9.block.0.1.weight', 'image_encoder.features.9.block.1.0.weight', 'image_encoder.features.9.block.1.1.bias', 'image_encoder.features.9.block.1.1.weight', 'image_encoder.features.9.block.2.fc1.bias', 'image_encoder.features.9.block.2.fc1.weight', 'image_encoder.features.9.block.2.fc2.bias', 'image_encoder.features.9.block.2.fc2.weight', 'image_encoder.features.9.block.3.0.weight', 'image_encoder.features.9.block.3.1.bias', 'image_encoder.features.9.block.3.1.weight', 'sgn_embed.ln.bias', 'sgn_embed.ln.weight', 'sgn_embed.norm.norm.bias', 'sgn_embed.norm.norm.weight', 'txt_embed.lut.weight', 'txt_embed.norm.norm.bias', 'txt_embed.norm.norm.weight']
2021-12-27 01:48:23,953 cfg.name                           : ChicagoFSWild Experiment
2021-12-27 01:48:23,954 cfg.data.data_path                 : ./data/
2021-12-27 01:48:23,954 cfg.data.version                   : ChicagoFSWild
2021-12-27 01:48:23,955 cfg.data.sgn                       : sign
2021-12-27 01:48:23,955 cfg.data.gls                       : gloss
2021-12-27 01:48:23,956 cfg.data.feature_size              : 1000
2021-12-27 01:48:23,956 cfg.data.level                     : word
2021-12-27 01:48:23,956 cfg.data.max_sent_length           : 400
2021-12-27 01:48:23,957 cfg.data.random_train_subset       : -1
2021-12-27 01:48:23,957 cfg.data.random_dev_subset         : -1
2021-12-27 01:48:23,957 cfg.testing.recognition_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2021-12-27 01:48:23,958 cfg.testing.translation_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2021-12-27 01:48:23,958 cfg.testing.translation_beam_alphas : [-1, 0, 1, 2, 3, 4, 5]
2021-12-27 01:48:23,958 cfg.training.reset_best_ckpt       : False
2021-12-27 01:48:23,958 cfg.training.reset_scheduler       : False
2021-12-27 01:48:23,958 cfg.training.reset_optimizer       : False
2021-12-27 01:48:23,958 cfg.training.random_seed           : 42
2021-12-27 01:48:23,958 cfg.training.model_dir             : ./ChicagoFSWild Experiments/ChicagoFSWild_experiment_13
2021-12-27 01:48:23,958 cfg.training.recognition_loss_weight : 0.0
2021-12-27 01:48:23,958 cfg.training.translation_loss_weight : 1.0
2021-12-27 01:48:23,958 cfg.training.eval_metric           : bleu
2021-12-27 01:48:23,959 cfg.training.optimizer             : adam
2021-12-27 01:48:23,959 cfg.training.learning_rate         : 0.001
2021-12-27 01:48:23,959 cfg.training.batch_size            : 32
2021-12-27 01:48:23,959 cfg.training.num_valid_log         : 5
2021-12-27 01:48:23,959 cfg.training.epochs                : 5000000
2021-12-27 01:48:23,959 cfg.training.early_stopping_metric : eval_metric
2021-12-27 01:48:23,959 cfg.training.batch_type            : token
2021-12-27 01:48:23,959 cfg.training.translation_normalization : batch
2021-12-27 01:48:23,959 cfg.training.eval_recognition_beam_size : 9
2021-12-27 01:48:23,959 cfg.training.eval_translation_beam_size : 9
2021-12-27 01:48:23,959 cfg.training.eval_translation_beam_alpha : 1
2021-12-27 01:48:23,960 cfg.training.overwrite             : True
2021-12-27 01:48:23,960 cfg.training.shuffle               : True
2021-12-27 01:48:23,960 cfg.training.use_cuda              : True
2021-12-27 01:48:23,960 cfg.training.translation_max_output_length : 5
2021-12-27 01:48:23,960 cfg.training.keep_last_ckpts       : 1
2021-12-27 01:48:23,960 cfg.training.batch_multiplier      : 1
2021-12-27 01:48:23,960 cfg.training.logging_freq          : 1
2021-12-27 01:48:23,960 cfg.training.validation_freq       : 100
2021-12-27 01:48:23,960 cfg.training.betas                 : [0.9, 0.998]
2021-12-27 01:48:23,960 cfg.training.scheduling            : plateau
2021-12-27 01:48:23,960 cfg.training.learning_rate_min     : 1e-06
2021-12-27 01:48:23,960 cfg.training.weight_decay          : 0.001
2021-12-27 01:48:23,961 cfg.training.patience              : 8
2021-12-27 01:48:23,961 cfg.training.decrease_factor       : 0.7
2021-12-27 01:48:23,961 cfg.training.label_smoothing       : 0.0
2021-12-27 01:48:23,961 cfg.model.initializer              : xavier
2021-12-27 01:48:23,961 cfg.model.bias_initializer         : zeros
2021-12-27 01:48:23,961 cfg.model.init_gain                : 1.0
2021-12-27 01:48:23,961 cfg.model.embed_initializer        : xavier
2021-12-27 01:48:23,961 cfg.model.embed_init_gain          : 1.0
2021-12-27 01:48:23,961 cfg.model.tied_softmax             : False
2021-12-27 01:48:23,961 cfg.model.encoder.type             : transformer
2021-12-27 01:48:23,961 cfg.model.encoder.num_layers       : 3
2021-12-27 01:48:23,962 cfg.model.encoder.num_heads        : 8
2021-12-27 01:48:23,962 cfg.model.encoder.embeddings.embedding_dim : 512
2021-12-27 01:48:23,962 cfg.model.encoder.embeddings.scale : False
2021-12-27 01:48:23,962 cfg.model.encoder.embeddings.dropout : 0.1
2021-12-27 01:48:23,962 cfg.model.encoder.embeddings.norm_type : batch
2021-12-27 01:48:23,962 cfg.model.encoder.embeddings.activation_type : softsign
2021-12-27 01:48:23,962 cfg.model.encoder.hidden_size      : 512
2021-12-27 01:48:23,962 cfg.model.encoder.ff_size          : 2048
2021-12-27 01:48:23,962 cfg.model.encoder.dropout          : 0.1
2021-12-27 01:48:23,962 cfg.model.decoder.type             : transformer
2021-12-27 01:48:23,962 cfg.model.decoder.num_layers       : 3
2021-12-27 01:48:23,963 cfg.model.decoder.num_heads        : 8
2021-12-27 01:48:23,963 cfg.model.decoder.embeddings.embedding_dim : 512
2021-12-27 01:48:23,963 cfg.model.decoder.embeddings.scale : False
2021-12-27 01:48:23,963 cfg.model.decoder.embeddings.dropout : 0.1
2021-12-27 01:48:23,963 cfg.model.decoder.embeddings.norm_type : batch
2021-12-27 01:48:23,963 cfg.model.decoder.embeddings.activation_type : softsign
2021-12-27 01:48:23,963 cfg.model.decoder.hidden_size      : 512
2021-12-27 01:48:23,963 cfg.model.decoder.ff_size          : 2048
2021-12-27 01:48:23,963 cfg.model.decoder.dropout          : 0.1
2021-12-27 01:48:23,964 SignModel(
	encoder=TransformerEncoder(num_layers=3, num_heads=8),
	decoder=TransformerDecoder(num_layers=3, num_heads=8),
	sgn_embed=SpatialEmbeddings(embedding_dim=512, input_size=1000),
	txt_embed=Embeddings(embedding_dim=512, vocab_size=2733))
2021-12-27 01:48:23,977 EPOCH 1
2021-12-27 01:48:52,122 [Epoch: 001 Step: 00000001] Batch Translation Loss:   8.118832 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 01:49:20,779 [Epoch: 001 Step: 00000002] Batch Translation Loss:   8.151172 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 01:49:48,692 [Epoch: 001 Step: 00000003] Batch Translation Loss:   7.842789 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 01:50:15,999 [Epoch: 001 Step: 00000004] Batch Translation Loss:   7.755487 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 01:50:48,727 [Epoch: 001 Step: 00000005] Batch Translation Loss:   8.073674 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 01:51:17,728 [Epoch: 001 Step: 00000006] Batch Translation Loss:   8.315192 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 01:51:52,596 [Epoch: 001 Step: 00000007] Batch Translation Loss:   7.825822 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 01:52:15,800 [Epoch: 001 Step: 00000008] Batch Translation Loss:   8.305512 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 01:52:42,381 [Epoch: 001 Step: 00000009] Batch Translation Loss:   7.887574 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 01:53:08,513 [Epoch: 001 Step: 00000010] Batch Translation Loss:   8.097235 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 01:53:46,611 [Epoch: 001 Step: 00000011] Batch Translation Loss:   8.319373 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 01:54:25,953 [Epoch: 001 Step: 00000012] Batch Translation Loss:   8.049815 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 01:54:56,243 [Epoch: 001 Step: 00000013] Batch Translation Loss:   8.222323 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 01:55:36,029 [Epoch: 001 Step: 00000014] Batch Translation Loss:   7.840301 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 01:56:10,373 [Epoch: 001 Step: 00000015] Batch Translation Loss:   8.243297 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 01:56:35,339 [Epoch: 001 Step: 00000016] Batch Translation Loss:   7.890227 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 01:57:02,104 [Epoch: 001 Step: 00000017] Batch Translation Loss:   7.652782 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 01:57:30,390 [Epoch: 001 Step: 00000018] Batch Translation Loss:   7.463319 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 01:58:05,061 [Epoch: 001 Step: 00000019] Batch Translation Loss:   8.156219 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 01:58:52,168 [Epoch: 001 Step: 00000020] Batch Translation Loss:   8.177882 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 01:59:30,748 [Epoch: 001 Step: 00000021] Batch Translation Loss:   7.999519 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:00:18,344 [Epoch: 001 Step: 00000022] Batch Translation Loss:   7.291662 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:00:58,155 [Epoch: 001 Step: 00000023] Batch Translation Loss:   7.885445 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:01:32,440 [Epoch: 001 Step: 00000024] Batch Translation Loss:   7.688964 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:02:09,582 [Epoch: 001 Step: 00000025] Batch Translation Loss:   7.670313 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:02:33,039 [Epoch: 001 Step: 00000026] Batch Translation Loss:   7.829965 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:03:05,080 [Epoch: 001 Step: 00000027] Batch Translation Loss:   6.809216 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:03:38,941 [Epoch: 001 Step: 00000028] Batch Translation Loss:   7.481051 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:04:06,184 [Epoch: 001 Step: 00000029] Batch Translation Loss:   7.742773 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:04:40,543 [Epoch: 001 Step: 00000030] Batch Translation Loss:   7.381332 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:05:28,260 [Epoch: 001 Step: 00000031] Batch Translation Loss:   7.441849 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:06:19,347 [Epoch: 001 Step: 00000032] Batch Translation Loss:   8.071734 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:06:54,691 [Epoch: 001 Step: 00000033] Batch Translation Loss:   7.796351 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:07:32,697 [Epoch: 001 Step: 00000034] Batch Translation Loss:   7.539833 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:08:08,225 [Epoch: 001 Step: 00000035] Batch Translation Loss:   7.752213 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:08:45,885 [Epoch: 001 Step: 00000036] Batch Translation Loss:   7.692181 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:09:23,248 [Epoch: 001 Step: 00000037] Batch Translation Loss:   7.274260 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:10:15,668 [Epoch: 001 Step: 00000038] Batch Translation Loss:   7.105134 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:10:48,924 [Epoch: 001 Step: 00000039] Batch Translation Loss:   7.073411 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:11:44,581 [Epoch: 001 Step: 00000040] Batch Translation Loss:   7.594705 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:12:43,844 [Epoch: 001 Step: 00000041] Batch Translation Loss:   7.837032 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:13:21,956 [Epoch: 001 Step: 00000042] Batch Translation Loss:   6.861259 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:13:58,631 [Epoch: 001 Step: 00000043] Batch Translation Loss:   7.595701 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:14:40,003 [Epoch: 001 Step: 00000044] Batch Translation Loss:   8.590553 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:15:15,869 [Epoch: 001 Step: 00000045] Batch Translation Loss:   7.024837 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:15:55,412 [Epoch: 001 Step: 00000046] Batch Translation Loss:   7.819602 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:16:36,383 [Epoch: 001 Step: 00000047] Batch Translation Loss:   8.334743 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:17:14,149 [Epoch: 001 Step: 00000048] Batch Translation Loss:   7.709513 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:18:12,892 [Epoch: 001 Step: 00000049] Batch Translation Loss:   7.847338 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:19:08,646 [Epoch: 001 Step: 00000050] Batch Translation Loss:   8.533114 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:19:41,952 [Epoch: 001 Step: 00000051] Batch Translation Loss:   8.097237 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:20:21,794 [Epoch: 001 Step: 00000052] Batch Translation Loss:   8.250480 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:21:34,661 [Epoch: 001 Step: 00000053] Batch Translation Loss:   8.128274 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 02:22:30,233 [Epoch: 001 Step: 00000054] Batch Translation Loss:   7.621644 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:23:11,040 [Epoch: 001 Step: 00000055] Batch Translation Loss:   8.105804 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:23:55,720 [Epoch: 001 Step: 00000056] Batch Translation Loss:   8.248470 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:24:52,301 [Epoch: 001 Step: 00000057] Batch Translation Loss:   7.058488 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:25:28,954 [Epoch: 001 Step: 00000058] Batch Translation Loss:   7.828161 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:26:09,063 [Epoch: 001 Step: 00000059] Batch Translation Loss:   7.254006 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:27:06,338 [Epoch: 001 Step: 00000060] Batch Translation Loss:   7.673277 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:27:45,048 [Epoch: 001 Step: 00000061] Batch Translation Loss:   7.695973 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:28:23,575 [Epoch: 001 Step: 00000062] Batch Translation Loss:   7.655858 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:29:47,473 [Epoch: 001 Step: 00000063] Batch Translation Loss:   7.852979 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 02:30:30,254 [Epoch: 001 Step: 00000064] Batch Translation Loss:   7.417474 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:31:57,903 [Epoch: 001 Step: 00000065] Batch Translation Loss:   7.704868 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 02:32:54,108 [Epoch: 001 Step: 00000066] Batch Translation Loss:   7.788415 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:34:26,175 [Epoch: 001 Step: 00000067] Batch Translation Loss:   7.804728 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 02:35:25,213 [Epoch: 001 Step: 00000068] Batch Translation Loss:   7.482073 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:36:20,233 [Epoch: 001 Step: 00000069] Batch Translation Loss:   8.014314 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:37:06,238 [Epoch: 001 Step: 00000070] Batch Translation Loss:   8.018032 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:37:48,639 [Epoch: 001 Step: 00000071] Batch Translation Loss:   7.545169 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:38:40,483 [Epoch: 001 Step: 00000072] Batch Translation Loss:   7.181304 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:39:20,881 [Epoch: 001 Step: 00000073] Batch Translation Loss:   7.664511 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:40:07,700 [Epoch: 001 Step: 00000074] Batch Translation Loss:   7.716413 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:41:49,226 [Epoch: 001 Step: 00000075] Batch Translation Loss:   8.376765 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 02:42:48,264 [Epoch: 001 Step: 00000076] Batch Translation Loss:   7.588837 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:43:35,358 [Epoch: 001 Step: 00000077] Batch Translation Loss:   7.006534 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:44:34,004 [Epoch: 001 Step: 00000078] Batch Translation Loss:   7.506618 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:45:26,999 [Epoch: 001 Step: 00000079] Batch Translation Loss:   7.747993 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:46:18,316 [Epoch: 001 Step: 00000080] Batch Translation Loss:   7.433509 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:47:54,987 [Epoch: 001 Step: 00000081] Batch Translation Loss:   7.730015 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 02:48:48,761 [Epoch: 001 Step: 00000082] Batch Translation Loss:   7.570457 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:50:21,645 [Epoch: 001 Step: 00000083] Batch Translation Loss:   7.438837 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 02:51:19,342 [Epoch: 001 Step: 00000084] Batch Translation Loss:   6.671218 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:52:16,528 [Epoch: 001 Step: 00000085] Batch Translation Loss:   7.949939 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:53:14,664 [Epoch: 001 Step: 00000086] Batch Translation Loss:   8.031384 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:54:13,240 [Epoch: 001 Step: 00000087] Batch Translation Loss:   7.323698 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:55:53,998 [Epoch: 001 Step: 00000088] Batch Translation Loss:   7.861881 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 02:56:46,564 [Epoch: 001 Step: 00000089] Batch Translation Loss:   7.193537 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 02:58:22,236 [Epoch: 001 Step: 00000090] Batch Translation Loss:   7.391947 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 02:59:06,865 [Epoch: 001 Step: 00000091] Batch Translation Loss:   7.198679 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 03:00:04,792 [Epoch: 001 Step: 00000092] Batch Translation Loss:   7.591041 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 03:01:00,876 [Epoch: 001 Step: 00000093] Batch Translation Loss:   7.208814 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 03:01:54,714 [Epoch: 001 Step: 00000094] Batch Translation Loss:   7.213814 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 03:02:59,905 [Epoch: 001 Step: 00000095] Batch Translation Loss:   7.983769 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 03:04:04,204 [Epoch: 001 Step: 00000096] Batch Translation Loss:   7.215735 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 03:05:01,886 [Epoch: 001 Step: 00000097] Batch Translation Loss:   7.347818 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 03:07:05,205 [Epoch: 001 Step: 00000098] Batch Translation Loss:   7.348352 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 03:09:24,928 [Epoch: 001 Step: 00000099] Batch Translation Loss:   7.170366 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 03:10:32,511 [Epoch: 001 Step: 00000100] Batch Translation Loss:   7.640428 => Txt Tokens per Sec:        0 || Lr: 0.001000
