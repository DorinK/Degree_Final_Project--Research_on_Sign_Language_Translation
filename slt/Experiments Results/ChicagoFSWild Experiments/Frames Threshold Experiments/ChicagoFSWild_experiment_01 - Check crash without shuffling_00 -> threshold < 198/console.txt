ssh://dorink@nlp15:22/home/nlp/dorink/anaconda3/envs/slt_env/bin/python3 -u /home/nlp/dorink/project/slt/signjoey/__main__.py train /home/nlp/dorink/project/slt/configs/sign_ChicagoFSWild.yaml
2021-12-23 18:56:30.054959: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2021-12-23 19:06:06.271575: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
2021-12-23 19:06:06.948252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
pciBusID: 0000:3b:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2021-12-23 19:06:06.949492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties:
pciBusID: 0000:5e:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2021-12-23 19:06:06.950650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 2 with properties:
pciBusID: 0000:86:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2021-12-23 19:06:06.952534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 3 with properties:
pciBusID: 0000:af:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2021-12-23 19:06:06.952677: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2021-12-23 19:06:06.952776: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
2021-12-23 19:06:06.952854: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
2021-12-23 19:06:06.952903: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
2021-12-23 19:06:06.952949: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
2021-12-23 19:06:06.952998: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
2021-12-23 19:06:06.953042: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
2021-12-23 19:06:07.504990: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
2021-12-23 19:06:07.520516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1, 2, 3
WARNING:absl:Using custom data configuration new-setup
2021-12-23 19:11:47.653372: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-23 19:11:47.961971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-23 19:11:47.962070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]
2021-12-23 19:11:49.150043: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
2021-12-23 19:11:49.151222: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2100000000 Hz
INFO:slt.signjoey.helpers:Hello! This is Joey-NMT.
2021-12-23 19:15:08,986 Hello! This is Joey-NMT.
INFO:slt.signjoey.helpers:Total params: 27927304
2021-12-23 19:15:09,881 Total params: 27927304
INFO:slt.signjoey.helpers:Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.output_layer.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'image_encoder.classifier.0.bias', 'image_encoder.classifier.0.weight', 'image_encoder.classifier.3.bias', 'image_encoder.classifier.3.weight', 'image_encoder.features.0.0.weight', 'image_encoder.features.0.1.bias', 'image_encoder.features.0.1.weight', 'image_encoder.features.1.block.0.0.weight', 'image_encoder.features.1.block.0.1.bias', 'image_encoder.features.1.block.0.1.weight', 'image_encoder.features.1.block.1.fc1.bias', 'image_encoder.features.1.block.1.fc1.weight', 'image_encoder.features.1.block.1.fc2.bias', 'image_encoder.features.1.block.1.fc2.weight', 'image_encoder.features.1.block.2.0.weight', 'image_encoder.features.1.block.2.1.bias', 'image_encoder.features.1.block.2.1.weight', 'image_encoder.features.10.block.0.0.weight', 'image_encoder.features.10.block.0.1.bias', 'image_encoder.features.10.block.0.1.weight', 'image_encoder.features.10.block.1.0.weight', 'image_encoder.features.10.block.1.1.bias', 'image_encoder.features.10.block.1.1.weight', 'image_encoder.features.10.block.2.fc1.bias', 'image_encoder.features.10.block.2.fc1.weight', 'image_encoder.features.10.block.2.fc2.bias', 'image_encoder.features.10.block.2.fc2.weight', 'image_encoder.features.10.block.3.0.weight', 'image_encoder.features.10.block.3.1.bias', 'image_encoder.features.10.block.3.1.weight', 'image_encoder.features.11.block.0.0.weight', 'image_encoder.features.11.block.0.1.bias', 'image_encoder.features.11.block.0.1.weight', 'image_encoder.features.11.block.1.0.weight', 'image_encoder.features.11.block.1.1.bias', 'image_encoder.features.11.block.1.1.weight', 'image_encoder.features.11.block.2.fc1.bias', 'image_encoder.features.11.block.2.fc1.weight', 'image_encoder.features.11.block.2.fc2.bias', 'image_encoder.features.11.block.2.fc2.weight', 'image_encoder.features.11.block.3.0.weight', 'image_encoder.features.11.block.3.1.bias', 'image_encoder.features.11.block.3.1.weight', 'image_encoder.features.12.0.weight', 'image_encoder.features.12.1.bias', 'image_encoder.features.12.1.weight', 'image_encoder.features.2.block.0.0.weight', 'image_encoder.features.2.block.0.1.bias', 'image_encoder.features.2.block.0.1.weight', 'image_encoder.features.2.block.1.0.weight', 'image_encoder.features.2.block.1.1.bias', 'image_encoder.features.2.block.1.1.weight', 'image_encoder.features.2.block.2.0.weight', 'image_encoder.features.2.block.2.1.bias', 'image_encoder.features.2.block.2.1.weight', 'image_encoder.features.3.block.0.0.weight', 'image_encoder.features.3.block.0.1.bias', 'image_encoder.features.3.block.0.1.weight', 'image_encoder.features.3.block.1.0.weight', 'image_encoder.features.3.block.1.1.bias', 'image_encoder.features.3.block.1.1.weight', 'image_encoder.features.3.block.2.0.weight', 'image_encoder.features.3.block.2.1.bias', 'image_encoder.features.3.block.2.1.weight', 'image_encoder.features.4.block.0.0.weight', 'image_encoder.features.4.block.0.1.bias', 'image_encoder.features.4.block.0.1.weight', 'image_encoder.features.4.block.1.0.weight', 'image_encoder.features.4.block.1.1.bias', 'image_encoder.features.4.block.1.1.weight', 'image_encoder.features.4.block.2.fc1.bias', 'image_encoder.features.4.block.2.fc1.weight', 'image_encoder.features.4.block.2.fc2.bias', 'image_encoder.features.4.block.2.fc2.weight', 'image_encoder.features.4.block.3.0.weight', 'image_encoder.features.4.block.3.1.bias', 'image_encoder.features.4.block.3.1.weight', 'image_encoder.features.5.block.0.0.weight', 'image_encoder.features.5.block.0.1.bias', 'image_encoder.features.5.block.0.1.weight', 'image_encoder.features.5.block.1.0.weight', 'image_encoder.features.5.block.1.1.bias', 'image_encoder.features.5.block.1.1.weight', 'image_encoder.features.5.block.2.fc1.bias', 'image_encoder.features.5.block.2.fc1.weight', 'image_encoder.features.5.block.2.fc2.bias', 'image_encoder.features.5.block.2.fc2.weight', 'image_encoder.features.5.block.3.0.weight', 'image_encoder.features.5.block.3.1.bias', 'image_encoder.features.5.block.3.1.weight', 'image_encoder.features.6.block.0.0.weight', 'image_encoder.features.6.block.0.1.bias', 'image_encoder.features.6.block.0.1.weight', 'image_encoder.features.6.block.1.0.weight', 'image_encoder.features.6.block.1.1.bias', 'image_encoder.features.6.block.1.1.weight', 'image_encoder.features.6.block.2.fc1.bias', 'image_encoder.features.6.block.2.fc1.weight', 'image_encoder.features.6.block.2.fc2.bias', 'image_encoder.features.6.block.2.fc2.weight', 'image_encoder.features.6.block.3.0.weight', 'image_encoder.features.6.block.3.1.bias', 'image_encoder.features.6.block.3.1.weight', 'image_encoder.features.7.block.0.0.weight', 'image_encoder.features.7.block.0.1.bias', 'image_encoder.features.7.block.0.1.weight', 'image_encoder.features.7.block.1.0.weight', 'image_encoder.features.7.block.1.1.bias', 'image_encoder.features.7.block.1.1.weight', 'image_encoder.features.7.block.2.fc1.bias', 'image_encoder.features.7.block.2.fc1.weight', 'image_encoder.features.7.block.2.fc2.bias', 'image_encoder.features.7.block.2.fc2.weight', 'image_encoder.features.7.block.3.0.weight', 'image_encoder.features.7.block.3.1.bias', 'image_encoder.features.7.block.3.1.weight', 'image_encoder.features.8.block.0.0.weight', 'image_encoder.features.8.block.0.1.bias', 'image_encoder.features.8.block.0.1.weight', 'image_encoder.features.8.block.1.0.weight', 'image_encoder.features.8.block.1.1.bias', 'image_encoder.features.8.block.1.1.weight', 'image_encoder.features.8.block.2.fc1.bias', 'image_encoder.features.8.block.2.fc1.weight', 'image_encoder.features.8.block.2.fc2.bias', 'image_encoder.features.8.block.2.fc2.weight', 'image_encoder.features.8.block.3.0.weight', 'image_encoder.features.8.block.3.1.bias', 'image_encoder.features.8.block.3.1.weight', 'image_encoder.features.9.block.0.0.weight', 'image_encoder.features.9.block.0.1.bias', 'image_encoder.features.9.block.0.1.weight', 'image_encoder.features.9.block.1.0.weight', 'image_encoder.features.9.block.1.1.bias', 'image_encoder.features.9.block.1.1.weight', 'image_encoder.features.9.block.2.fc1.bias', 'image_encoder.features.9.block.2.fc1.weight', 'image_encoder.features.9.block.2.fc2.bias', 'image_encoder.features.9.block.2.fc2.weight', 'image_encoder.features.9.block.3.0.weight', 'image_encoder.features.9.block.3.1.bias', 'image_encoder.features.9.block.3.1.weight', 'sgn_embed.ln.bias', 'sgn_embed.ln.weight', 'sgn_embed.norm.norm.bias', 'sgn_embed.norm.norm.weight', 'txt_embed.lut.weight', 'txt_embed.norm.norm.bias', 'txt_embed.norm.norm.weight']
2021-12-23 19:15:09,885 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.output_layer.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'image_encoder.classifier.0.bias', 'image_encoder.classifier.0.weight', 'image_encoder.classifier.3.bias', 'image_encoder.classifier.3.weight', 'image_encoder.features.0.0.weight', 'image_encoder.features.0.1.bias', 'image_encoder.features.0.1.weight', 'image_encoder.features.1.block.0.0.weight', 'image_encoder.features.1.block.0.1.bias', 'image_encoder.features.1.block.0.1.weight', 'image_encoder.features.1.block.1.fc1.bias', 'image_encoder.features.1.block.1.fc1.weight', 'image_encoder.features.1.block.1.fc2.bias', 'image_encoder.features.1.block.1.fc2.weight', 'image_encoder.features.1.block.2.0.weight', 'image_encoder.features.1.block.2.1.bias', 'image_encoder.features.1.block.2.1.weight', 'image_encoder.features.10.block.0.0.weight', 'image_encoder.features.10.block.0.1.bias', 'image_encoder.features.10.block.0.1.weight', 'image_encoder.features.10.block.1.0.weight', 'image_encoder.features.10.block.1.1.bias', 'image_encoder.features.10.block.1.1.weight', 'image_encoder.features.10.block.2.fc1.bias', 'image_encoder.features.10.block.2.fc1.weight', 'image_encoder.features.10.block.2.fc2.bias', 'image_encoder.features.10.block.2.fc2.weight', 'image_encoder.features.10.block.3.0.weight', 'image_encoder.features.10.block.3.1.bias', 'image_encoder.features.10.block.3.1.weight', 'image_encoder.features.11.block.0.0.weight', 'image_encoder.features.11.block.0.1.bias', 'image_encoder.features.11.block.0.1.weight', 'image_encoder.features.11.block.1.0.weight', 'image_encoder.features.11.block.1.1.bias', 'image_encoder.features.11.block.1.1.weight', 'image_encoder.features.11.block.2.fc1.bias', 'image_encoder.features.11.block.2.fc1.weight', 'image_encoder.features.11.block.2.fc2.bias', 'image_encoder.features.11.block.2.fc2.weight', 'image_encoder.features.11.block.3.0.weight', 'image_encoder.features.11.block.3.1.bias', 'image_encoder.features.11.block.3.1.weight', 'image_encoder.features.12.0.weight', 'image_encoder.features.12.1.bias', 'image_encoder.features.12.1.weight', 'image_encoder.features.2.block.0.0.weight', 'image_encoder.features.2.block.0.1.bias', 'image_encoder.features.2.block.0.1.weight', 'image_encoder.features.2.block.1.0.weight', 'image_encoder.features.2.block.1.1.bias', 'image_encoder.features.2.block.1.1.weight', 'image_encoder.features.2.block.2.0.weight', 'image_encoder.features.2.block.2.1.bias', 'image_encoder.features.2.block.2.1.weight', 'image_encoder.features.3.block.0.0.weight', 'image_encoder.features.3.block.0.1.bias', 'image_encoder.features.3.block.0.1.weight', 'image_encoder.features.3.block.1.0.weight', 'image_encoder.features.3.block.1.1.bias', 'image_encoder.features.3.block.1.1.weight', 'image_encoder.features.3.block.2.0.weight', 'image_encoder.features.3.block.2.1.bias', 'image_encoder.features.3.block.2.1.weight', 'image_encoder.features.4.block.0.0.weight', 'image_encoder.features.4.block.0.1.bias', 'image_encoder.features.4.block.0.1.weight', 'image_encoder.features.4.block.1.0.weight', 'image_encoder.features.4.block.1.1.bias', 'image_encoder.features.4.block.1.1.weight', 'image_encoder.features.4.block.2.fc1.bias', 'image_encoder.features.4.block.2.fc1.weight', 'image_encoder.features.4.block.2.fc2.bias', 'image_encoder.features.4.block.2.fc2.weight', 'image_encoder.features.4.block.3.0.weight', 'image_encoder.features.4.block.3.1.bias', 'image_encoder.features.4.block.3.1.weight', 'image_encoder.features.5.block.0.0.weight', 'image_encoder.features.5.block.0.1.bias', 'image_encoder.features.5.block.0.1.weight', 'image_encoder.features.5.block.1.0.weight', 'image_encoder.features.5.block.1.1.bias', 'image_encoder.features.5.block.1.1.weight', 'image_encoder.features.5.block.2.fc1.bias', 'image_encoder.features.5.block.2.fc1.weight', 'image_encoder.features.5.block.2.fc2.bias', 'image_encoder.features.5.block.2.fc2.weight', 'image_encoder.features.5.block.3.0.weight', 'image_encoder.features.5.block.3.1.bias', 'image_encoder.features.5.block.3.1.weight', 'image_encoder.features.6.block.0.0.weight', 'image_encoder.features.6.block.0.1.bias', 'image_encoder.features.6.block.0.1.weight', 'image_encoder.features.6.block.1.0.weight', 'image_encoder.features.6.block.1.1.bias', 'image_encoder.features.6.block.1.1.weight', 'image_encoder.features.6.block.2.fc1.bias', 'image_encoder.features.6.block.2.fc1.weight', 'image_encoder.features.6.block.2.fc2.bias', 'image_encoder.features.6.block.2.fc2.weight', 'image_encoder.features.6.block.3.0.weight', 'image_encoder.features.6.block.3.1.bias', 'image_encoder.features.6.block.3.1.weight', 'image_encoder.features.7.block.0.0.weight', 'image_encoder.features.7.block.0.1.bias', 'image_encoder.features.7.block.0.1.weight', 'image_encoder.features.7.block.1.0.weight', 'image_encoder.features.7.block.1.1.bias', 'image_encoder.features.7.block.1.1.weight', 'image_encoder.features.7.block.2.fc1.bias', 'image_encoder.features.7.block.2.fc1.weight', 'image_encoder.features.7.block.2.fc2.bias', 'image_encoder.features.7.block.2.fc2.weight', 'image_encoder.features.7.block.3.0.weight', 'image_encoder.features.7.block.3.1.bias', 'image_encoder.features.7.block.3.1.weight', 'image_encoder.features.8.block.0.0.weight', 'image_encoder.features.8.block.0.1.bias', 'image_encoder.features.8.block.0.1.weight', 'image_encoder.features.8.block.1.0.weight', 'image_encoder.features.8.block.1.1.bias', 'image_encoder.features.8.block.1.1.weight', 'image_encoder.features.8.block.2.fc1.bias', 'image_encoder.features.8.block.2.fc1.weight', 'image_encoder.features.8.block.2.fc2.bias', 'image_encoder.features.8.block.2.fc2.weight', 'image_encoder.features.8.block.3.0.weight', 'image_encoder.features.8.block.3.1.bias', 'image_encoder.features.8.block.3.1.weight', 'image_encoder.features.9.block.0.0.weight', 'image_encoder.features.9.block.0.1.bias', 'image_encoder.features.9.block.0.1.weight', 'image_encoder.features.9.block.1.0.weight', 'image_encoder.features.9.block.1.1.bias', 'image_encoder.features.9.block.1.1.weight', 'image_encoder.features.9.block.2.fc1.bias', 'image_encoder.features.9.block.2.fc1.weight', 'image_encoder.features.9.block.2.fc2.bias', 'image_encoder.features.9.block.2.fc2.weight', 'image_encoder.features.9.block.3.0.weight', 'image_encoder.features.9.block.3.1.bias', 'image_encoder.features.9.block.3.1.weight', 'sgn_embed.ln.bias', 'sgn_embed.ln.weight', 'sgn_embed.norm.norm.bias', 'sgn_embed.norm.norm.weight', 'txt_embed.lut.weight', 'txt_embed.norm.norm.bias', 'txt_embed.norm.norm.weight']
INFO:slt.signjoey.helpers:cfg.name                           : sign_experiment
2021-12-23 19:15:35,870 cfg.name                           : sign_experiment
INFO:slt.signjoey.helpers:cfg.data.data_path                 : ./data/
2021-12-23 19:15:35,920 cfg.data.data_path                 : ./data/
INFO:slt.signjoey.helpers:cfg.data.version                   : ChicagoFSWild
2021-12-23 19:15:35,920 cfg.data.version                   : ChicagoFSWild
INFO:slt.signjoey.helpers:cfg.data.sgn                       : sign
2021-12-23 19:15:35,920 cfg.data.sgn                       : sign
INFO:slt.signjoey.helpers:cfg.data.gls                       : gloss
2021-12-23 19:15:35,920 cfg.data.gls                       : gloss
INFO:slt.signjoey.helpers:cfg.data.feature_size              : 1000
2021-12-23 19:15:35,920 cfg.data.feature_size              : 1000
INFO:slt.signjoey.helpers:cfg.data.level                     : word
2021-12-23 19:15:35,920 cfg.data.level                     : word
INFO:slt.signjoey.helpers:cfg.data.max_sent_length           : 400
2021-12-23 19:15:35,920 cfg.data.max_sent_length           : 400
INFO:slt.signjoey.helpers:cfg.data.random_train_subset       : -1
2021-12-23 19:15:35,920 cfg.data.random_train_subset       : -1
INFO:slt.signjoey.helpers:cfg.data.random_dev_subset         : -1
2021-12-23 19:15:35,920 cfg.data.random_dev_subset         : -1
INFO:slt.signjoey.helpers:cfg.testing.recognition_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2021-12-23 19:15:35,920 cfg.testing.recognition_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
INFO:slt.signjoey.helpers:cfg.testing.translation_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2021-12-23 19:15:35,921 cfg.testing.translation_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
INFO:slt.signjoey.helpers:cfg.testing.translation_beam_alphas : [-1, 0, 1, 2, 3, 4, 5]
2021-12-23 19:15:35,921 cfg.testing.translation_beam_alphas : [-1, 0, 1, 2, 3, 4, 5]
INFO:slt.signjoey.helpers:cfg.training.reset_best_ckpt       : False
2021-12-23 19:15:35,921 cfg.training.reset_best_ckpt       : False
INFO:slt.signjoey.helpers:cfg.training.reset_scheduler       : False
2021-12-23 19:15:35,921 cfg.training.reset_scheduler       : False
INFO:slt.signjoey.helpers:cfg.training.reset_optimizer       : False
2021-12-23 19:15:35,921 cfg.training.reset_optimizer       : False
INFO:slt.signjoey.helpers:cfg.training.random_seed           : 42
2021-12-23 19:15:35,921 cfg.training.random_seed           : 42
INFO:slt.signjoey.helpers:cfg.training.model_dir             : ./ChicagoFSWild_model__00
2021-12-23 19:15:35,921 cfg.training.model_dir             : ./ChicagoFSWild_model__00
INFO:slt.signjoey.helpers:cfg.training.recognition_loss_weight : 0.0
2021-12-23 19:15:35,921 cfg.training.recognition_loss_weight : 0.0
INFO:slt.signjoey.helpers:cfg.training.translation_loss_weight : 1.0
2021-12-23 19:15:35,921 cfg.training.translation_loss_weight : 1.0
INFO:slt.signjoey.helpers:cfg.training.eval_metric           : bleu
2021-12-23 19:15:35,921 cfg.training.eval_metric           : bleu
INFO:slt.signjoey.helpers:cfg.training.optimizer             : adam
2021-12-23 19:15:35,921 cfg.training.optimizer             : adam
INFO:slt.signjoey.helpers:cfg.training.learning_rate         : 0.001
2021-12-23 19:15:35,921 cfg.training.learning_rate         : 0.001
INFO:slt.signjoey.helpers:cfg.training.batch_size            : 32
2021-12-23 19:15:35,921 cfg.training.batch_size            : 32
INFO:slt.signjoey.helpers:cfg.training.num_valid_log         : 5
2021-12-23 19:15:35,922 cfg.training.num_valid_log         : 5
INFO:slt.signjoey.helpers:cfg.training.epochs                : 5000000
2021-12-23 19:15:35,922 cfg.training.epochs                : 5000000
INFO:slt.signjoey.helpers:cfg.training.early_stopping_metric : eval_metric
2021-12-23 19:15:35,922 cfg.training.early_stopping_metric : eval_metric
INFO:slt.signjoey.helpers:cfg.training.batch_type            : token
2021-12-23 19:15:35,922 cfg.training.batch_type            : token
INFO:slt.signjoey.helpers:cfg.training.translation_normalization : batch
2021-12-23 19:15:35,922 cfg.training.translation_normalization : batch
INFO:slt.signjoey.helpers:cfg.training.eval_recognition_beam_size : 9
2021-12-23 19:15:35,922 cfg.training.eval_recognition_beam_size : 9
INFO:slt.signjoey.helpers:cfg.training.eval_translation_beam_size : 9
2021-12-23 19:15:35,923 cfg.training.eval_translation_beam_size : 9
INFO:slt.signjoey.helpers:cfg.training.eval_translation_beam_alpha : 1
2021-12-23 19:15:35,923 cfg.training.eval_translation_beam_alpha : 1
INFO:slt.signjoey.helpers:cfg.training.overwrite             : True
2021-12-23 19:15:35,923 cfg.training.overwrite             : True
INFO:slt.signjoey.helpers:cfg.training.shuffle               : True
2021-12-23 19:15:35,923 cfg.training.shuffle               : True
INFO:slt.signjoey.helpers:cfg.training.use_cuda              : True
2021-12-23 19:15:35,923 cfg.training.use_cuda              : True
INFO:slt.signjoey.helpers:cfg.training.translation_max_output_length : 5
2021-12-23 19:15:35,924 cfg.training.translation_max_output_length : 5
INFO:slt.signjoey.helpers:cfg.training.keep_last_ckpts       : 1
2021-12-23 19:15:35,924 cfg.training.keep_last_ckpts       : 1
INFO:slt.signjoey.helpers:cfg.training.batch_multiplier      : 1
2021-12-23 19:15:35,924 cfg.training.batch_multiplier      : 1
INFO:slt.signjoey.helpers:cfg.training.logging_freq          : 1
2021-12-23 19:15:35,924 cfg.training.logging_freq          : 1
INFO:slt.signjoey.helpers:cfg.training.validation_freq       : 200
2021-12-23 19:15:35,924 cfg.training.validation_freq       : 200
INFO:slt.signjoey.helpers:cfg.training.betas                 : [0.9, 0.998]
2021-12-23 19:15:35,925 cfg.training.betas                 : [0.9, 0.998]
INFO:slt.signjoey.helpers:cfg.training.scheduling            : plateau
2021-12-23 19:15:35,925 cfg.training.scheduling            : plateau
INFO:slt.signjoey.helpers:cfg.training.learning_rate_min     : 1e-06
2021-12-23 19:15:35,925 cfg.training.learning_rate_min     : 1e-06
INFO:slt.signjoey.helpers:cfg.training.weight_decay          : 0.001
2021-12-23 19:15:35,925 cfg.training.weight_decay          : 0.001
INFO:slt.signjoey.helpers:cfg.training.patience              : 8
2021-12-23 19:15:35,925 cfg.training.patience              : 8
INFO:slt.signjoey.helpers:cfg.training.decrease_factor       : 0.7
2021-12-23 19:15:35,925 cfg.training.decrease_factor       : 0.7
INFO:slt.signjoey.helpers:cfg.training.label_smoothing       : 0.0
2021-12-23 19:15:35,926 cfg.training.label_smoothing       : 0.0
INFO:slt.signjoey.helpers:cfg.model.initializer              : xavier
2021-12-23 19:15:35,926 cfg.model.initializer              : xavier
INFO:slt.signjoey.helpers:cfg.model.bias_initializer         : zeros
2021-12-23 19:15:35,926 cfg.model.bias_initializer         : zeros
INFO:slt.signjoey.helpers:cfg.model.init_gain                : 1.0
2021-12-23 19:15:35,926 cfg.model.init_gain                : 1.0
INFO:slt.signjoey.helpers:cfg.model.embed_initializer        : xavier
2021-12-23 19:15:35,926 cfg.model.embed_initializer        : xavier
INFO:slt.signjoey.helpers:cfg.model.embed_init_gain          : 1.0
2021-12-23 19:15:35,927 cfg.model.embed_init_gain          : 1.0
INFO:slt.signjoey.helpers:cfg.model.tied_softmax             : False
2021-12-23 19:15:35,927 cfg.model.tied_softmax             : False
INFO:slt.signjoey.helpers:cfg.model.encoder.type             : transformer
2021-12-23 19:15:35,927 cfg.model.encoder.type             : transformer
INFO:slt.signjoey.helpers:cfg.model.encoder.num_layers       : 3
2021-12-23 19:15:35,927 cfg.model.encoder.num_layers       : 3
INFO:slt.signjoey.helpers:cfg.model.encoder.num_heads        : 8
2021-12-23 19:15:35,927 cfg.model.encoder.num_heads        : 8
INFO:slt.signjoey.helpers:cfg.model.encoder.embeddings.embedding_dim : 512
2021-12-23 19:15:35,928 cfg.model.encoder.embeddings.embedding_dim : 512
INFO:slt.signjoey.helpers:cfg.model.encoder.embeddings.scale : False
2021-12-23 19:15:35,928 cfg.model.encoder.embeddings.scale : False
INFO:slt.signjoey.helpers:cfg.model.encoder.embeddings.dropout : 0.1
2021-12-23 19:15:35,928 cfg.model.encoder.embeddings.dropout : 0.1
INFO:slt.signjoey.helpers:cfg.model.encoder.embeddings.norm_type : batch
2021-12-23 19:15:35,928 cfg.model.encoder.embeddings.norm_type : batch
INFO:slt.signjoey.helpers:cfg.model.encoder.embeddings.activation_type : softsign
2021-12-23 19:15:35,928 cfg.model.encoder.embeddings.activation_type : softsign
INFO:slt.signjoey.helpers:cfg.model.encoder.hidden_size      : 512
2021-12-23 19:15:35,928 cfg.model.encoder.hidden_size      : 512
INFO:slt.signjoey.helpers:cfg.model.encoder.ff_size          : 2048
2021-12-23 19:15:35,929 cfg.model.encoder.ff_size          : 2048
INFO:slt.signjoey.helpers:cfg.model.encoder.dropout          : 0.1
2021-12-23 19:15:35,929 cfg.model.encoder.dropout          : 0.1
INFO:slt.signjoey.helpers:cfg.model.decoder.type             : transformer
2021-12-23 19:15:35,929 cfg.model.decoder.type             : transformer
INFO:slt.signjoey.helpers:cfg.model.decoder.num_layers       : 3
2021-12-23 19:15:35,929 cfg.model.decoder.num_layers       : 3
INFO:slt.signjoey.helpers:cfg.model.decoder.num_heads        : 8
2021-12-23 19:15:35,929 cfg.model.decoder.num_heads        : 8
INFO:slt.signjoey.helpers:cfg.model.decoder.embeddings.embedding_dim : 512
2021-12-23 19:15:35,930 cfg.model.decoder.embeddings.embedding_dim : 512
INFO:slt.signjoey.helpers:cfg.model.decoder.embeddings.scale : False
2021-12-23 19:15:35,930 cfg.model.decoder.embeddings.scale : False
INFO:slt.signjoey.helpers:cfg.model.decoder.embeddings.dropout : 0.1
2021-12-23 19:15:35,930 cfg.model.decoder.embeddings.dropout : 0.1
INFO:slt.signjoey.helpers:cfg.model.decoder.embeddings.norm_type : batch
2021-12-23 19:15:35,930 cfg.model.decoder.embeddings.norm_type : batch
INFO:slt.signjoey.helpers:cfg.model.decoder.embeddings.activation_type : softsign
2021-12-23 19:15:35,930 cfg.model.decoder.embeddings.activation_type : softsign
INFO:slt.signjoey.helpers:cfg.model.decoder.hidden_size      : 512
2021-12-23 19:15:35,930 cfg.model.decoder.hidden_size      : 512
INFO:slt.signjoey.helpers:cfg.model.decoder.ff_size          : 2048
2021-12-23 19:15:35,931 cfg.model.decoder.ff_size          : 2048
INFO:slt.signjoey.helpers:cfg.model.decoder.dropout          : 0.1
2021-12-23 19:15:35,931 cfg.model.decoder.dropout          : 0.1
INFO:slt.signjoey.helpers:SignModel(
	encoder=TransformerEncoder(num_layers=3, num_heads=8),
	decoder=TransformerDecoder(num_layers=3, num_heads=8),
	sgn_embed=SpatialEmbeddings(embedding_dim=512, input_size=1000),
	txt_embed=Embeddings(embedding_dim=512, vocab_size=2733))
2021-12-23 19:15:35,931 SignModel(
	encoder=TransformerEncoder(num_layers=3, num_heads=8),
	decoder=TransformerDecoder(num_layers=3, num_heads=8),
	sgn_embed=SpatialEmbeddings(embedding_dim=512, input_size=1000),
	txt_embed=Embeddings(embedding_dim=512, vocab_size=2733))
SLT_total_params: 27927304
SLT_total_trained_params: 27927304
INFO:slt.signjoey.helpers:EPOCH 1
2021-12-23 19:15:36,444 EPOCH 1
index: 1
sequence: deafvideo_1-thedeafmoth_1032
sgn_lengths: 43
signer: 0026
gls: [2, 587, 1]

index: 2
sequence: awti-austin_andrews_0796
sgn_lengths: 19
signer: 0017
gls: [2, 15, 1]

index: 3
sequence: youtube_3-evelina_gaina_4707
sgn_lengths: 14
signer: 0054
gls: [2, 81, 1]

index: 4
sequence: deafvideo_2-frekky_1396
sgn_lengths: 11
signer: 0021
gls: [2, 7, 1]

index: 5
sequence: youtube_4-alex_abenchuchan_5503
sgn_lengths: 29
signer: 0050
gls: [2, 169, 1]

index: 6
sequence: deafvideo_4-taylerade_5628
sgn_lengths: 8
signer: 0025
gls: [2, 23, 1]

index: 7
sequence: youtube_5-michael_kaufer_6288
sgn_lengths: 34
signer: 0072
gls: [2, 2406, 1]

index: 8
sequence: youtube_2-alex_abenchuchan_3307
sgn_lengths: 15
signer: 0050
gls: [2, 5, 1]

index: 9
sequence: youtube_2-tia_albert_3813
sgn_lengths: 15
signer: 0060
gls: [2, 165, 1]

index: 10
sequence: deafvideo_4-mattref2005_5157
sgn_lengths: 26
signer: 0037
gls: [2, 1801, 1]

index: 11
sequence: deafvideo_1-wesley_arey_0914
sgn_lengths: 19
signer: 0027
gls: [2, 120, 1]

index: 12
sequence: deafvideo_2-frekky_1385
sgn_lengths: 24
signer: 0021
gls: [2, 99, 1]

index: 13
sequence: youtube_5-tawny_holmes_6200
sgn_lengths: 22
signer: 0068
gls: [2, 1695, 1]

index: 14
sequence: misc_2-marlon_kuntze_2516
sgn_lengths: 42
signer: 0046
gls: [2, 430, 1]

index: 15
sequence: youtube_6-marlee_matlin_6769
sgn_lengths: 62
signer: 0078
gls: [2, 2524, 1]

index: 16
sequence: misc_2-aidan_mack_3183
sgn_lengths: 6
signer: 0048
gls: [2, 26, 1]

index: 17
sequence: deafvideo_1-deafaynrand_1181
sgn_lengths: 64
signer: 0020
gls: [2, 2295, 1]

index: 18
sequence: deafvideo_2-archie_2967
sgn_lengths: 35
signer: 0029
gls: [2, 236, 1]

index: 19
sequence: aslized-elsie_stecker_0233
sgn_lengths: 20
signer: 0000
gls: [2, 4, 1]

index: 20
sequence: awti-austin_andrews_0632
sgn_lengths: 53
signer: 0017
gls: [2, 1354, 1]

index: 21
sequence: gallaudet-mj_bienvenu_4500
sgn_lengths: 38
signer: 0003
gls: [2, 1108, 1]

index: 22
sequence: youtube_3-alex_abenchuchan_4232
sgn_lengths: 22
signer: 0050
gls: [2, 50, 1]

index: 23
sequence: misc_2-marlon_kuntze_2597
sgn_lengths: 70
signer: 0046
gls: [2, 219, 1]

index: 24
sequence: youtube_6-lchaim2007_6505
sgn_lengths: 26
signer: 0086
gls: [2, 19, 1]

index: 25
sequence: aslized-elsie_stecker_0231
sgn_lengths: 28
signer: 0000
gls: [2, 13, 1]

index: 26
sequence: youtube_6-tom_humphries_6646
sgn_lengths: 45
signer: 0080
gls: [2, 2444, 1]

index: 27
sequence: misc_1-carol_padden_2046
sgn_lengths: 38
signer: 0045
gls: [2, 31, 1]

index: 28
sequence: youtube_2-alex_abenchuchan_3377
sgn_lengths: 40
signer: 0050
gls: [2, 402, 1]

index: 29
sequence: youtube_2-alex_abenchuchan_3300
sgn_lengths: 22
signer: 0050
gls: [2, 17, 1]

index: 30
sequence: youtube_2-tia_albert_3814
sgn_lengths: 14
signer: 0060
gls: [2, 71, 1]

index: 31
sequence: youtube_4-raymond_merritt_4823
sgn_lengths: 12
signer: 0062
gls: [2, 18, 1]

index: 32
sequence: deafvideo_3-deafmermaid_3708
sgn_lengths: 72
signer: 0031
gls: [2, 1139, 1]

INFO:slt.signjoey.helpers:[Epoch: 001 Step: 00000001] Batch Translation Loss:   8.018621 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 19:15:51,862 [Epoch: 001 Step: 00000001] Batch Translation Loss:   8.018621 => Txt Tokens per Sec:        2 || Lr: 0.001000
index: 1
sequence: youtube_6-lchaim2007_6497
sgn_lengths: 37
signer: 0086
gls: [2, 83, 1]

index: 2
sequence: deafvideo_1-wesley_arey_0906
sgn_lengths: 20
signer: 0027
gls: [2, 18, 1]

index: 3
sequence: youtube_2-alex_abenchuchan_3351
sgn_lengths: 20
signer: 0050
gls: [2, 285, 1]

index: 4
sequence: deafvideo_3-deafaynrand_4489
sgn_lengths: 8
signer: 0020
gls: [2, 284, 1]

index: 5
sequence: youtube_1-jackie_roth_2981
sgn_lengths: 19
signer: 0055
gls: [2, 215, 1]

index: 6
sequence: youtube_4-alex_abenchuchan_5378
sgn_lengths: 14
signer: 0050
gls: [2, 13, 1]

index: 7
sequence: deafvideo_1-wesley_arey_0950
sgn_lengths: 43
signer: 0027
gls: [2, 1128, 1]

index: 8
sequence: misc_1-marlon_kuntze_2447
sgn_lengths: 32
signer: 0046
gls: [2, 297, 1]

index: 9
sequence: awti-austin_andrews_0695
sgn_lengths: 198
signer: 0017
gls: [2, 2495, 1]

Traceback (most recent call last):
  File "/home/nlp/dorink/project/slt/signjoey/__main__.py", line 41, in <module>
    main()
  File "/home/nlp/dorink/project/slt/signjoey/__main__.py", line 32, in main
    train(cfg_file=args.config_path)
  File "/home/nlp/dorink/project/slt/signjoey/training.py", line 2088, in train
    trainer.train_and_validate_chicago(train_data=train_data, valid_data=dev_data)
  File "/home/nlp/dorink/project/slt/signjoey/training.py", line 1308, in train_and_validate_chicago
    out = self.model.image_encoder(sample.cuda(DEVICE))
  File "/home/nlp/dorink/anaconda3/envs/slt_env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/nlp/dorink/anaconda3/envs/slt_env/lib/python3.8/site-packages/torchvision/models/mobilenetv3.py", line 184, in forward
    return self._forward_impl(x)
  File "/home/nlp/dorink/anaconda3/envs/slt_env/lib/python3.8/site-packages/torchvision/models/mobilenetv3.py", line 174, in _forward_impl
    x = self.features(x)
  File "/home/nlp/dorink/anaconda3/envs/slt_env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/nlp/dorink/anaconda3/envs/slt_env/lib/python3.8/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/nlp/dorink/anaconda3/envs/slt_env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/nlp/dorink/anaconda3/envs/slt_env/lib/python3.8/site-packages/torchvision/models/mobilenetv3.py", line 95, in forward
    result = self.block(input)
  File "/home/nlp/dorink/anaconda3/envs/slt_env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/nlp/dorink/anaconda3/envs/slt_env/lib/python3.8/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/nlp/dorink/anaconda3/envs/slt_env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/nlp/dorink/anaconda3/envs/slt_env/lib/python3.8/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/nlp/dorink/anaconda3/envs/slt_env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/nlp/dorink/anaconda3/envs/slt_env/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py", line 135, in forward
    return F.batch_norm(
  File "/home/nlp/dorink/anaconda3/envs/slt_env/lib/python3.8/site-packages/torch/nn/functional.py", line 2149, in batch_norm
    return torch.batch_norm(
RuntimeError: CUDA out of memory. Tried to allocate 168.00 MiB (GPU 0; 10.76 GiB total capacity; 9.36 GiB already allocated; 69.44 MiB free; 9.45 GiB reserved in total by PyTorch)

Process finished with exit code 1
