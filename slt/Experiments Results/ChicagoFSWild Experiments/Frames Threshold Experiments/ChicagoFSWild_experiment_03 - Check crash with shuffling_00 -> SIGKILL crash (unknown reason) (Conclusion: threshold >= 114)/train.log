2021-12-23 22:25:10,050 Hello! This is Joey-NMT.
2021-12-23 22:25:10,090 Total params: 27927304
2021-12-23 22:25:10,092 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.output_layer.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'image_encoder.classifier.0.bias', 'image_encoder.classifier.0.weight', 'image_encoder.classifier.3.bias', 'image_encoder.classifier.3.weight', 'image_encoder.features.0.0.weight', 'image_encoder.features.0.1.bias', 'image_encoder.features.0.1.weight', 'image_encoder.features.1.block.0.0.weight', 'image_encoder.features.1.block.0.1.bias', 'image_encoder.features.1.block.0.1.weight', 'image_encoder.features.1.block.1.fc1.bias', 'image_encoder.features.1.block.1.fc1.weight', 'image_encoder.features.1.block.1.fc2.bias', 'image_encoder.features.1.block.1.fc2.weight', 'image_encoder.features.1.block.2.0.weight', 'image_encoder.features.1.block.2.1.bias', 'image_encoder.features.1.block.2.1.weight', 'image_encoder.features.10.block.0.0.weight', 'image_encoder.features.10.block.0.1.bias', 'image_encoder.features.10.block.0.1.weight', 'image_encoder.features.10.block.1.0.weight', 'image_encoder.features.10.block.1.1.bias', 'image_encoder.features.10.block.1.1.weight', 'image_encoder.features.10.block.2.fc1.bias', 'image_encoder.features.10.block.2.fc1.weight', 'image_encoder.features.10.block.2.fc2.bias', 'image_encoder.features.10.block.2.fc2.weight', 'image_encoder.features.10.block.3.0.weight', 'image_encoder.features.10.block.3.1.bias', 'image_encoder.features.10.block.3.1.weight', 'image_encoder.features.11.block.0.0.weight', 'image_encoder.features.11.block.0.1.bias', 'image_encoder.features.11.block.0.1.weight', 'image_encoder.features.11.block.1.0.weight', 'image_encoder.features.11.block.1.1.bias', 'image_encoder.features.11.block.1.1.weight', 'image_encoder.features.11.block.2.fc1.bias', 'image_encoder.features.11.block.2.fc1.weight', 'image_encoder.features.11.block.2.fc2.bias', 'image_encoder.features.11.block.2.fc2.weight', 'image_encoder.features.11.block.3.0.weight', 'image_encoder.features.11.block.3.1.bias', 'image_encoder.features.11.block.3.1.weight', 'image_encoder.features.12.0.weight', 'image_encoder.features.12.1.bias', 'image_encoder.features.12.1.weight', 'image_encoder.features.2.block.0.0.weight', 'image_encoder.features.2.block.0.1.bias', 'image_encoder.features.2.block.0.1.weight', 'image_encoder.features.2.block.1.0.weight', 'image_encoder.features.2.block.1.1.bias', 'image_encoder.features.2.block.1.1.weight', 'image_encoder.features.2.block.2.0.weight', 'image_encoder.features.2.block.2.1.bias', 'image_encoder.features.2.block.2.1.weight', 'image_encoder.features.3.block.0.0.weight', 'image_encoder.features.3.block.0.1.bias', 'image_encoder.features.3.block.0.1.weight', 'image_encoder.features.3.block.1.0.weight', 'image_encoder.features.3.block.1.1.bias', 'image_encoder.features.3.block.1.1.weight', 'image_encoder.features.3.block.2.0.weight', 'image_encoder.features.3.block.2.1.bias', 'image_encoder.features.3.block.2.1.weight', 'image_encoder.features.4.block.0.0.weight', 'image_encoder.features.4.block.0.1.bias', 'image_encoder.features.4.block.0.1.weight', 'image_encoder.features.4.block.1.0.weight', 'image_encoder.features.4.block.1.1.bias', 'image_encoder.features.4.block.1.1.weight', 'image_encoder.features.4.block.2.fc1.bias', 'image_encoder.features.4.block.2.fc1.weight', 'image_encoder.features.4.block.2.fc2.bias', 'image_encoder.features.4.block.2.fc2.weight', 'image_encoder.features.4.block.3.0.weight', 'image_encoder.features.4.block.3.1.bias', 'image_encoder.features.4.block.3.1.weight', 'image_encoder.features.5.block.0.0.weight', 'image_encoder.features.5.block.0.1.bias', 'image_encoder.features.5.block.0.1.weight', 'image_encoder.features.5.block.1.0.weight', 'image_encoder.features.5.block.1.1.bias', 'image_encoder.features.5.block.1.1.weight', 'image_encoder.features.5.block.2.fc1.bias', 'image_encoder.features.5.block.2.fc1.weight', 'image_encoder.features.5.block.2.fc2.bias', 'image_encoder.features.5.block.2.fc2.weight', 'image_encoder.features.5.block.3.0.weight', 'image_encoder.features.5.block.3.1.bias', 'image_encoder.features.5.block.3.1.weight', 'image_encoder.features.6.block.0.0.weight', 'image_encoder.features.6.block.0.1.bias', 'image_encoder.features.6.block.0.1.weight', 'image_encoder.features.6.block.1.0.weight', 'image_encoder.features.6.block.1.1.bias', 'image_encoder.features.6.block.1.1.weight', 'image_encoder.features.6.block.2.fc1.bias', 'image_encoder.features.6.block.2.fc1.weight', 'image_encoder.features.6.block.2.fc2.bias', 'image_encoder.features.6.block.2.fc2.weight', 'image_encoder.features.6.block.3.0.weight', 'image_encoder.features.6.block.3.1.bias', 'image_encoder.features.6.block.3.1.weight', 'image_encoder.features.7.block.0.0.weight', 'image_encoder.features.7.block.0.1.bias', 'image_encoder.features.7.block.0.1.weight', 'image_encoder.features.7.block.1.0.weight', 'image_encoder.features.7.block.1.1.bias', 'image_encoder.features.7.block.1.1.weight', 'image_encoder.features.7.block.2.fc1.bias', 'image_encoder.features.7.block.2.fc1.weight', 'image_encoder.features.7.block.2.fc2.bias', 'image_encoder.features.7.block.2.fc2.weight', 'image_encoder.features.7.block.3.0.weight', 'image_encoder.features.7.block.3.1.bias', 'image_encoder.features.7.block.3.1.weight', 'image_encoder.features.8.block.0.0.weight', 'image_encoder.features.8.block.0.1.bias', 'image_encoder.features.8.block.0.1.weight', 'image_encoder.features.8.block.1.0.weight', 'image_encoder.features.8.block.1.1.bias', 'image_encoder.features.8.block.1.1.weight', 'image_encoder.features.8.block.2.fc1.bias', 'image_encoder.features.8.block.2.fc1.weight', 'image_encoder.features.8.block.2.fc2.bias', 'image_encoder.features.8.block.2.fc2.weight', 'image_encoder.features.8.block.3.0.weight', 'image_encoder.features.8.block.3.1.bias', 'image_encoder.features.8.block.3.1.weight', 'image_encoder.features.9.block.0.0.weight', 'image_encoder.features.9.block.0.1.bias', 'image_encoder.features.9.block.0.1.weight', 'image_encoder.features.9.block.1.0.weight', 'image_encoder.features.9.block.1.1.bias', 'image_encoder.features.9.block.1.1.weight', 'image_encoder.features.9.block.2.fc1.bias', 'image_encoder.features.9.block.2.fc1.weight', 'image_encoder.features.9.block.2.fc2.bias', 'image_encoder.features.9.block.2.fc2.weight', 'image_encoder.features.9.block.3.0.weight', 'image_encoder.features.9.block.3.1.bias', 'image_encoder.features.9.block.3.1.weight', 'sgn_embed.ln.bias', 'sgn_embed.ln.weight', 'sgn_embed.norm.norm.bias', 'sgn_embed.norm.norm.weight', 'txt_embed.lut.weight', 'txt_embed.norm.norm.bias', 'txt_embed.norm.norm.weight']
2021-12-23 22:25:13,630 cfg.name                           : ChicagoFSWild Experiment
2021-12-23 22:25:13,630 cfg.data.data_path                 : ./data/
2021-12-23 22:25:13,630 cfg.data.version                   : ChicagoFSWild
2021-12-23 22:25:13,630 cfg.data.sgn                       : sign
2021-12-23 22:25:13,630 cfg.data.gls                       : gloss
2021-12-23 22:25:13,630 cfg.data.feature_size              : 1000
2021-12-23 22:25:13,630 cfg.data.level                     : word
2021-12-23 22:25:13,630 cfg.data.max_sent_length           : 400
2021-12-23 22:25:13,630 cfg.data.random_train_subset       : -1
2021-12-23 22:25:13,630 cfg.data.random_dev_subset         : -1
2021-12-23 22:25:13,630 cfg.testing.recognition_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2021-12-23 22:25:13,630 cfg.testing.translation_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2021-12-23 22:25:13,630 cfg.testing.translation_beam_alphas : [-1, 0, 1, 2, 3, 4, 5]
2021-12-23 22:25:13,631 cfg.training.reset_best_ckpt       : False
2021-12-23 22:25:13,631 cfg.training.reset_scheduler       : False
2021-12-23 22:25:13,631 cfg.training.reset_optimizer       : False
2021-12-23 22:25:13,631 cfg.training.random_seed           : 42
2021-12-23 22:25:13,631 cfg.training.model_dir             : ./ChicagoFSWild Experiments/ChicagoFSWild_experiment_03
2021-12-23 22:25:13,631 cfg.training.recognition_loss_weight : 0.0
2021-12-23 22:25:13,631 cfg.training.translation_loss_weight : 1.0
2021-12-23 22:25:13,631 cfg.training.eval_metric           : bleu
2021-12-23 22:25:13,631 cfg.training.optimizer             : adam
2021-12-23 22:25:13,631 cfg.training.learning_rate         : 0.001
2021-12-23 22:25:13,631 cfg.training.batch_size            : 32
2021-12-23 22:25:13,631 cfg.training.num_valid_log         : 5
2021-12-23 22:25:13,631 cfg.training.epochs                : 5000000
2021-12-23 22:25:13,631 cfg.training.early_stopping_metric : eval_metric
2021-12-23 22:25:13,631 cfg.training.batch_type            : token
2021-12-23 22:25:13,631 cfg.training.translation_normalization : batch
2021-12-23 22:25:13,631 cfg.training.eval_recognition_beam_size : 9
2021-12-23 22:25:13,631 cfg.training.eval_translation_beam_size : 9
2021-12-23 22:25:13,631 cfg.training.eval_translation_beam_alpha : 1
2021-12-23 22:25:13,631 cfg.training.overwrite             : True
2021-12-23 22:25:13,631 cfg.training.shuffle               : True
2021-12-23 22:25:13,631 cfg.training.use_cuda              : True
2021-12-23 22:25:13,632 cfg.training.translation_max_output_length : 5
2021-12-23 22:25:13,632 cfg.training.keep_last_ckpts       : 1
2021-12-23 22:25:13,632 cfg.training.batch_multiplier      : 1
2021-12-23 22:25:13,632 cfg.training.logging_freq          : 1
2021-12-23 22:25:13,632 cfg.training.validation_freq       : 200
2021-12-23 22:25:13,632 cfg.training.betas                 : [0.9, 0.998]
2021-12-23 22:25:13,632 cfg.training.scheduling            : plateau
2021-12-23 22:25:13,632 cfg.training.learning_rate_min     : 1e-06
2021-12-23 22:25:13,632 cfg.training.weight_decay          : 0.001
2021-12-23 22:25:13,632 cfg.training.patience              : 8
2021-12-23 22:25:13,632 cfg.training.decrease_factor       : 0.7
2021-12-23 22:25:13,632 cfg.training.label_smoothing       : 0.0
2021-12-23 22:25:13,632 cfg.model.initializer              : xavier
2021-12-23 22:25:13,632 cfg.model.bias_initializer         : zeros
2021-12-23 22:25:13,632 cfg.model.init_gain                : 1.0
2021-12-23 22:25:13,632 cfg.model.embed_initializer        : xavier
2021-12-23 22:25:13,632 cfg.model.embed_init_gain          : 1.0
2021-12-23 22:25:13,632 cfg.model.tied_softmax             : False
2021-12-23 22:25:13,632 cfg.model.encoder.type             : transformer
2021-12-23 22:25:13,632 cfg.model.encoder.num_layers       : 3
2021-12-23 22:25:13,632 cfg.model.encoder.num_heads        : 8
2021-12-23 22:25:13,632 cfg.model.encoder.embeddings.embedding_dim : 512
2021-12-23 22:25:13,633 cfg.model.encoder.embeddings.scale : False
2021-12-23 22:25:13,633 cfg.model.encoder.embeddings.dropout : 0.1
2021-12-23 22:25:13,633 cfg.model.encoder.embeddings.norm_type : batch
2021-12-23 22:25:13,633 cfg.model.encoder.embeddings.activation_type : softsign
2021-12-23 22:25:13,633 cfg.model.encoder.hidden_size      : 512
2021-12-23 22:25:13,633 cfg.model.encoder.ff_size          : 2048
2021-12-23 22:25:13,633 cfg.model.encoder.dropout          : 0.1
2021-12-23 22:25:13,633 cfg.model.decoder.type             : transformer
2021-12-23 22:25:13,633 cfg.model.decoder.num_layers       : 3
2021-12-23 22:25:13,633 cfg.model.decoder.num_heads        : 8
2021-12-23 22:25:13,633 cfg.model.decoder.embeddings.embedding_dim : 512
2021-12-23 22:25:13,633 cfg.model.decoder.embeddings.scale : False
2021-12-23 22:25:13,633 cfg.model.decoder.embeddings.dropout : 0.1
2021-12-23 22:25:13,633 cfg.model.decoder.embeddings.norm_type : batch
2021-12-23 22:25:13,633 cfg.model.decoder.embeddings.activation_type : softsign
2021-12-23 22:25:13,633 cfg.model.decoder.hidden_size      : 512
2021-12-23 22:25:13,633 cfg.model.decoder.ff_size          : 2048
2021-12-23 22:25:13,633 cfg.model.decoder.dropout          : 0.1
2021-12-23 22:25:13,633 SignModel(
	encoder=TransformerEncoder(num_layers=3, num_heads=8),
	decoder=TransformerDecoder(num_layers=3, num_heads=8),
	sgn_embed=SpatialEmbeddings(embedding_dim=512, input_size=1000),
	txt_embed=Embeddings(embedding_dim=512, vocab_size=2733))
2021-12-23 22:25:13,638 EPOCH 1
2021-12-23 22:25:20,179 [Epoch: 001 Step: 00000001] Batch Translation Loss:   8.042301 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-23 22:25:26,388 [Epoch: 001 Step: 00000002] Batch Translation Loss:   7.850011 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-23 22:25:33,564 [Epoch: 001 Step: 00000003] Batch Translation Loss:   7.873614 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-23 22:25:41,770 [Epoch: 001 Step: 00000004] Batch Translation Loss:   7.909392 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-23 22:25:51,352 [Epoch: 001 Step: 00000005] Batch Translation Loss:   8.038666 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-23 22:26:02,777 [Epoch: 001 Step: 00000006] Batch Translation Loss:   8.032281 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-23 22:26:11,726 [Epoch: 001 Step: 00000007] Batch Translation Loss:   8.008533 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-23 22:26:20,746 [Epoch: 001 Step: 00000008] Batch Translation Loss:   8.168160 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-23 22:26:30,888 [Epoch: 001 Step: 00000009] Batch Translation Loss:   8.084901 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-23 22:26:43,598 [Epoch: 001 Step: 00000010] Batch Translation Loss:   8.161083 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-23 22:26:51,007 [Epoch: 001 Step: 00000011] Batch Translation Loss:   7.742465 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-23 22:27:02,145 [Epoch: 001 Step: 00000012] Batch Translation Loss:   8.043606 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-23 22:27:10,589 [Epoch: 001 Step: 00000013] Batch Translation Loss:   7.746788 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-23 22:27:24,457 [Epoch: 001 Step: 00000014] Batch Translation Loss:   8.110128 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:27:33,568 [Epoch: 001 Step: 00000015] Batch Translation Loss:   8.071898 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-23 22:27:47,848 [Epoch: 001 Step: 00000016] Batch Translation Loss:   7.747305 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:27:55,744 [Epoch: 001 Step: 00000017] Batch Translation Loss:   8.059848 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-23 22:28:10,819 [Epoch: 001 Step: 00000018] Batch Translation Loss:   7.976480 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:28:23,902 [Epoch: 001 Step: 00000019] Batch Translation Loss:   7.870667 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:28:36,953 [Epoch: 001 Step: 00000020] Batch Translation Loss:   7.625799 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:28:47,500 [Epoch: 001 Step: 00000021] Batch Translation Loss:   8.081510 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-23 22:29:03,908 [Epoch: 001 Step: 00000022] Batch Translation Loss:   7.833189 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:29:13,971 [Epoch: 001 Step: 00000023] Batch Translation Loss:   7.819671 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-23 22:29:30,824 [Epoch: 001 Step: 00000024] Batch Translation Loss:   8.190354 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:29:46,567 [Epoch: 001 Step: 00000025] Batch Translation Loss:   8.344238 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:30:03,632 [Epoch: 001 Step: 00000026] Batch Translation Loss:   7.757293 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:30:13,899 [Epoch: 001 Step: 00000027] Batch Translation Loss:   7.971161 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-23 22:30:24,513 [Epoch: 001 Step: 00000028] Batch Translation Loss:   7.828395 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-23 22:30:36,305 [Epoch: 001 Step: 00000029] Batch Translation Loss:   7.432514 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-23 22:30:47,366 [Epoch: 001 Step: 00000030] Batch Translation Loss:   7.899216 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-23 22:31:10,085 [Epoch: 001 Step: 00000031] Batch Translation Loss:   8.050872 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:31:20,972 [Epoch: 001 Step: 00000032] Batch Translation Loss:   7.998512 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-23 22:31:40,773 [Epoch: 001 Step: 00000033] Batch Translation Loss:   7.773261 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:31:56,508 [Epoch: 001 Step: 00000034] Batch Translation Loss:   7.937456 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:32:09,167 [Epoch: 001 Step: 00000035] Batch Translation Loss:   8.058514 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-23 22:32:28,733 [Epoch: 001 Step: 00000036] Batch Translation Loss:   7.968204 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:32:41,029 [Epoch: 001 Step: 00000037] Batch Translation Loss:   7.666490 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-23 22:33:01,203 [Epoch: 001 Step: 00000038] Batch Translation Loss:   7.855486 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:33:22,440 [Epoch: 001 Step: 00000039] Batch Translation Loss:   7.839100 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:33:46,132 [Epoch: 001 Step: 00000040] Batch Translation Loss:   8.302029 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:33:57,320 [Epoch: 001 Step: 00000041] Batch Translation Loss:   8.013371 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-23 22:34:20,246 [Epoch: 001 Step: 00000042] Batch Translation Loss:   8.102956 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:34:33,579 [Epoch: 001 Step: 00000043] Batch Translation Loss:   8.273698 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:34:45,888 [Epoch: 001 Step: 00000044] Batch Translation Loss:   8.234689 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-23 22:35:08,085 [Epoch: 001 Step: 00000045] Batch Translation Loss:   8.166987 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:35:29,971 [Epoch: 001 Step: 00000046] Batch Translation Loss:   7.974813 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:35:42,526 [Epoch: 001 Step: 00000047] Batch Translation Loss:   7.955104 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-23 22:35:55,727 [Epoch: 001 Step: 00000048] Batch Translation Loss:   8.276704 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:36:17,558 [Epoch: 001 Step: 00000049] Batch Translation Loss:   8.300990 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:36:32,602 [Epoch: 001 Step: 00000050] Batch Translation Loss:   7.974736 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:37:03,293 [Epoch: 001 Step: 00000051] Batch Translation Loss:   8.088906 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:37:17,729 [Epoch: 001 Step: 00000052] Batch Translation Loss:   7.226823 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:37:31,598 [Epoch: 001 Step: 00000053] Batch Translation Loss:   7.448931 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:37:45,603 [Epoch: 001 Step: 00000054] Batch Translation Loss:   7.796028 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:38:00,166 [Epoch: 001 Step: 00000055] Batch Translation Loss:   7.286117 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:38:25,574 [Epoch: 001 Step: 00000056] Batch Translation Loss:   7.843369 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:38:40,851 [Epoch: 001 Step: 00000057] Batch Translation Loss:   7.210242 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:39:04,496 [Epoch: 001 Step: 00000058] Batch Translation Loss:   7.844073 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:39:31,941 [Epoch: 001 Step: 00000059] Batch Translation Loss:   7.272470 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:39:49,895 [Epoch: 001 Step: 00000060] Batch Translation Loss:   6.636223 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:40:14,932 [Epoch: 001 Step: 00000061] Batch Translation Loss:   7.938608 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:40:34,157 [Epoch: 001 Step: 00000062] Batch Translation Loss:   7.893092 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:40:54,308 [Epoch: 001 Step: 00000063] Batch Translation Loss:   7.644940 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:41:32,791 [Epoch: 001 Step: 00000064] Batch Translation Loss:   8.128613 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:42:04,262 [Epoch: 001 Step: 00000065] Batch Translation Loss:   7.237689 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:42:24,960 [Epoch: 001 Step: 00000066] Batch Translation Loss:   8.043090 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:42:46,005 [Epoch: 001 Step: 00000067] Batch Translation Loss:   7.964725 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:43:05,732 [Epoch: 001 Step: 00000068] Batch Translation Loss:   7.831680 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:43:27,638 [Epoch: 001 Step: 00000069] Batch Translation Loss:   7.484726 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:43:47,233 [Epoch: 001 Step: 00000070] Batch Translation Loss:   7.647991 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:44:10,784 [Epoch: 001 Step: 00000071] Batch Translation Loss:   7.810587 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:44:34,962 [Epoch: 001 Step: 00000072] Batch Translation Loss:   7.392464 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:45:05,846 [Epoch: 001 Step: 00000073] Batch Translation Loss:   7.685438 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:45:27,930 [Epoch: 001 Step: 00000074] Batch Translation Loss:   7.481482 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:45:52,343 [Epoch: 001 Step: 00000075] Batch Translation Loss:   7.441670 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:46:12,475 [Epoch: 001 Step: 00000076] Batch Translation Loss:   7.218076 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-23 22:47:01,035 [Epoch: 001 Step: 00000077] Batch Translation Loss:   7.170365 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:47:24,441 [Epoch: 001 Step: 00000078] Batch Translation Loss:   8.203931 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:47:46,733 [Epoch: 001 Step: 00000079] Batch Translation Loss:   8.039948 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:48:32,774 [Epoch: 001 Step: 00000080] Batch Translation Loss:   7.799319 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:48:58,645 [Epoch: 001 Step: 00000081] Batch Translation Loss:   7.880043 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:49:25,267 [Epoch: 001 Step: 00000082] Batch Translation Loss:   7.581308 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:49:50,119 [Epoch: 001 Step: 00000083] Batch Translation Loss:   7.757260 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:50:13,733 [Epoch: 001 Step: 00000084] Batch Translation Loss:   7.921518 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:51:03,653 [Epoch: 001 Step: 00000085] Batch Translation Loss:   7.979424 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:51:54,768 [Epoch: 001 Step: 00000086] Batch Translation Loss:   7.977806 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:52:18,580 [Epoch: 001 Step: 00000087] Batch Translation Loss:   8.423563 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:52:46,021 [Epoch: 001 Step: 00000088] Batch Translation Loss:   7.630449 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:53:16,055 [Epoch: 001 Step: 00000089] Batch Translation Loss:   7.974399 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:54:11,028 [Epoch: 001 Step: 00000090] Batch Translation Loss:   7.517149 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:54:36,247 [Epoch: 001 Step: 00000091] Batch Translation Loss:   8.107388 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:55:03,519 [Epoch: 001 Step: 00000092] Batch Translation Loss:   7.547591 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:55:34,558 [Epoch: 001 Step: 00000093] Batch Translation Loss:   8.394634 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:56:05,166 [Epoch: 001 Step: 00000094] Batch Translation Loss:   7.939724 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:56:35,518 [Epoch: 001 Step: 00000095] Batch Translation Loss:   7.662423 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:57:08,478 [Epoch: 001 Step: 00000096] Batch Translation Loss:   7.583454 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:57:39,326 [Epoch: 001 Step: 00000097] Batch Translation Loss:   7.614979 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:58:13,780 [Epoch: 001 Step: 00000098] Batch Translation Loss:   7.428575 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:58:39,274 [Epoch: 001 Step: 00000099] Batch Translation Loss:   7.219347 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:59:09,433 [Epoch: 001 Step: 00000100] Batch Translation Loss:   7.760495 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 22:59:44,362 [Epoch: 001 Step: 00000101] Batch Translation Loss:   7.643775 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:00:13,016 [Epoch: 001 Step: 00000102] Batch Translation Loss:   7.690170 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:00:47,040 [Epoch: 001 Step: 00000103] Batch Translation Loss:   7.403406 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:01:19,643 [Epoch: 001 Step: 00000104] Batch Translation Loss:   7.654394 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:01:52,645 [Epoch: 001 Step: 00000105] Batch Translation Loss:   7.381232 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:02:22,397 [Epoch: 001 Step: 00000106] Batch Translation Loss:   7.333329 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:03:28,164 [Epoch: 001 Step: 00000107] Batch Translation Loss:   8.364779 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 23:04:01,511 [Epoch: 001 Step: 00000108] Batch Translation Loss:   7.549344 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:04:35,705 [Epoch: 001 Step: 00000109] Batch Translation Loss:   7.741693 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:05:13,401 [Epoch: 001 Step: 00000110] Batch Translation Loss:   7.858119 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:05:48,633 [Epoch: 001 Step: 00000111] Batch Translation Loss:   7.978914 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:06:27,984 [Epoch: 001 Step: 00000112] Batch Translation Loss:   7.334390 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:07:01,609 [Epoch: 001 Step: 00000113] Batch Translation Loss:   7.503184 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:08:16,635 [Epoch: 001 Step: 00000114] Batch Translation Loss:   7.648189 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 23:08:53,690 [Epoch: 001 Step: 00000115] Batch Translation Loss:   7.172606 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:09:31,174 [Epoch: 001 Step: 00000116] Batch Translation Loss:   7.181959 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:10:06,660 [Epoch: 001 Step: 00000117] Batch Translation Loss:   8.075994 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:10:50,786 [Epoch: 001 Step: 00000118] Batch Translation Loss:   6.839582 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:11:52,830 [Epoch: 001 Step: 00000119] Batch Translation Loss:   6.954058 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:12:34,399 [Epoch: 001 Step: 00000120] Batch Translation Loss:   7.666064 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:14:49,468 [Epoch: 001 Step: 00000121] Batch Translation Loss:   7.367929 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 23:16:18,955 [Epoch: 001 Step: 00000122] Batch Translation Loss:   7.367437 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 23:17:10,240 [Epoch: 001 Step: 00000123] Batch Translation Loss:   7.561922 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:18:10,271 [Epoch: 001 Step: 00000124] Batch Translation Loss:   7.924736 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:18:54,102 [Epoch: 001 Step: 00000125] Batch Translation Loss:   7.637231 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:19:44,894 [Epoch: 001 Step: 00000126] Batch Translation Loss:   7.640594 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:20:35,023 [Epoch: 001 Step: 00000127] Batch Translation Loss:   7.999626 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:21:13,758 [Epoch: 001 Step: 00000128] Batch Translation Loss:   7.127351 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:22:58,480 [Epoch: 001 Step: 00000129] Batch Translation Loss:   7.356634 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 23:25:16,322 [Epoch: 001 Step: 00000130] Batch Translation Loss:   7.649993 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 23:26:55,319 [Epoch: 001 Step: 00000131] Batch Translation Loss:   7.854384 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 23:27:56,289 [Epoch: 001 Step: 00000132] Batch Translation Loss:   6.636954 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:28:56,822 [Epoch: 001 Step: 00000133] Batch Translation Loss:   7.487305 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:30:27,128 [Epoch: 001 Step: 00000134] Batch Translation Loss:   7.859707 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 23:31:21,524 [Epoch: 001 Step: 00000135] Batch Translation Loss:   7.503953 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:33:20,064 [Epoch: 001 Step: 00000136] Batch Translation Loss:   7.625858 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 23:37:56,888 [Epoch: 001 Step: 00000137] Batch Translation Loss:   7.651783 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 23:40:19,869 [Epoch: 001 Step: 00000138] Batch Translation Loss:   7.454421 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 23:41:25,687 [Epoch: 001 Step: 00000139] Batch Translation Loss:   7.771408 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 23:41:56,784 [Epoch: 001 Step: 00000140] Batch Translation Loss:   7.236411 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:42:27,840 [Epoch: 001 Step: 00000141] Batch Translation Loss:   7.465931 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:43:22,874 [Epoch: 001 Step: 00000142] Batch Translation Loss:   7.429775 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:43:54,764 [Epoch: 001 Step: 00000143] Batch Translation Loss:   6.814089 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:44:53,025 [Epoch: 001 Step: 00000144] Batch Translation Loss:   7.450606 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:45:24,274 [Epoch: 001 Step: 00000145] Batch Translation Loss:   6.929852 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:46:25,223 [Epoch: 001 Step: 00000146] Batch Translation Loss:   7.071303 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:46:56,044 [Epoch: 001 Step: 00000147] Batch Translation Loss:   6.917231 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:47:53,438 [Epoch: 001 Step: 00000148] Batch Translation Loss:   6.811392 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:48:24,128 [Epoch: 001 Step: 00000149] Batch Translation Loss:   8.245900 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:49:56,666 [Epoch: 001 Step: 00000150] Batch Translation Loss:   7.767064 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 23:50:45,002 [Epoch: 001 Step: 00000151] Batch Translation Loss:   7.904227 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:51:47,136 [Epoch: 001 Step: 00000152] Batch Translation Loss:   7.660031 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:52:35,622 [Epoch: 001 Step: 00000153] Batch Translation Loss:   7.201284 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:53:46,329 [Epoch: 001 Step: 00000154] Batch Translation Loss:   7.401199 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 23:54:50,173 [Epoch: 001 Step: 00000155] Batch Translation Loss:   7.641478 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:55:51,543 [Epoch: 001 Step: 00000156] Batch Translation Loss:   6.520957 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:56:41,740 [Epoch: 001 Step: 00000157] Batch Translation Loss:   6.595751 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:57:49,705 [Epoch: 001 Step: 00000158] Batch Translation Loss:   7.130034 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 23:58:44,780 [Epoch: 001 Step: 00000159] Batch Translation Loss:   6.870893 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 23:59:44,081 [Epoch: 001 Step: 00000160] Batch Translation Loss:   8.026559 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 00:01:01,642 [Epoch: 001 Step: 00000161] Batch Translation Loss:   7.399475 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 00:03:04,471 [Epoch: 001 Step: 00000162] Batch Translation Loss:   7.783754 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 00:04:10,622 [Epoch: 001 Step: 00000163] Batch Translation Loss:   7.676744 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 00:05:25,691 [Epoch: 001 Step: 00000164] Batch Translation Loss:   6.708746 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 00:06:19,963 [Epoch: 001 Step: 00000165] Batch Translation Loss:   8.135108 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 00:07:26,402 [Epoch: 001 Step: 00000166] Batch Translation Loss:   7.736307 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 00:08:20,144 [Epoch: 001 Step: 00000167] Batch Translation Loss:   7.913138 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 00:09:30,340 [Epoch: 001 Step: 00000168] Batch Translation Loss:   7.047637 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 00:10:20,583 [Epoch: 001 Step: 00000169] Batch Translation Loss:   7.346624 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 00:10:20,748 Epoch   1: Total Training Recognition Loss -1.00  Total Training Translation Loss 1298.95 
2021-12-24 00:10:20,748 EPOCH 2
2021-12-24 00:10:37,153 [Epoch: 002 Step: 00000170] Batch Translation Loss:   7.646654 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-24 00:10:55,300 [Epoch: 002 Step: 00000171] Batch Translation Loss:   7.804564 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-24 00:11:07,190 [Epoch: 002 Step: 00000172] Batch Translation Loss:   8.304580 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-24 00:11:32,435 [Epoch: 002 Step: 00000173] Batch Translation Loss:   8.540448 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 00:11:57,924 [Epoch: 002 Step: 00000174] Batch Translation Loss:   7.862162 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 00:12:17,502 [Epoch: 002 Step: 00000175] Batch Translation Loss:   7.860945 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-24 00:13:01,686 [Epoch: 002 Step: 00000176] Batch Translation Loss:   7.488630 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 00:13:15,064 [Epoch: 002 Step: 00000177] Batch Translation Loss:   7.084888 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-24 00:13:41,377 [Epoch: 002 Step: 00000178] Batch Translation Loss:   8.229086 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 00:13:57,950 [Epoch: 002 Step: 00000179] Batch Translation Loss:   7.990831 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-24 00:14:18,797 [Epoch: 002 Step: 00000180] Batch Translation Loss:   8.480031 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-24 00:14:56,781 [Epoch: 002 Step: 00000181] Batch Translation Loss:   8.669560 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 00:15:21,534 [Epoch: 002 Step: 00000182] Batch Translation Loss:   7.948798 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 00:15:34,105 [Epoch: 002 Step: 00000183] Batch Translation Loss:   7.810423 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-24 00:16:06,724 [Epoch: 002 Step: 00000184] Batch Translation Loss:   8.529151 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 00:16:40,554 [Epoch: 002 Step: 00000185] Batch Translation Loss:   8.156486 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 00:17:10,720 [Epoch: 002 Step: 00000186] Batch Translation Loss:   8.102633 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 00:17:36,439 [Epoch: 002 Step: 00000187] Batch Translation Loss:   8.014552 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 00:18:05,240 [Epoch: 002 Step: 00000188] Batch Translation Loss:   8.004383 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 00:18:40,635 [Epoch: 002 Step: 00000189] Batch Translation Loss:   7.802479 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 00:19:11,852 [Epoch: 002 Step: 00000190] Batch Translation Loss:   7.657907 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 00:19:32,381 [Epoch: 002 Step: 00000191] Batch Translation Loss:   7.769247 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-24 00:20:00,519 [Epoch: 002 Step: 00000192] Batch Translation Loss:   8.043836 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 00:20:21,303 [Epoch: 002 Step: 00000193] Batch Translation Loss:   8.226012 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-24 00:21:01,695 [Epoch: 002 Step: 00000194] Batch Translation Loss:   8.153779 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 00:21:21,535 [Epoch: 002 Step: 00000195] Batch Translation Loss:   7.786099 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-24 00:21:59,299 [Epoch: 002 Step: 00000196] Batch Translation Loss:   7.294350 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 00:22:19,091 [Epoch: 002 Step: 00000197] Batch Translation Loss:   8.323873 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-24 00:22:43,646 [Epoch: 002 Step: 00000198] Batch Translation Loss:   7.896380 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 00:23:20,809 [Epoch: 002 Step: 00000199] Batch Translation Loss:   8.255846 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 00:23:57,000 [Epoch: 002 Step: 00000200] Batch Translation Loss:   7.767653 => Txt Tokens per Sec:        1 || Lr: 0.001000
