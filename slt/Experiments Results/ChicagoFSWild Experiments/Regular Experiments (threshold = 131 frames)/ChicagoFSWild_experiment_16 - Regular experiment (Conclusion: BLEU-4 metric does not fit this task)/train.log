2021-12-27 23:26:03,292 Hello! This is Joey-NMT.
2021-12-27 23:26:03,724 Total params: 27927304
2021-12-27 23:26:03,729 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.output_layer.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'image_encoder.classifier.0.bias', 'image_encoder.classifier.0.weight', 'image_encoder.classifier.3.bias', 'image_encoder.classifier.3.weight', 'image_encoder.features.0.0.weight', 'image_encoder.features.0.1.bias', 'image_encoder.features.0.1.weight', 'image_encoder.features.1.block.0.0.weight', 'image_encoder.features.1.block.0.1.bias', 'image_encoder.features.1.block.0.1.weight', 'image_encoder.features.1.block.1.fc1.bias', 'image_encoder.features.1.block.1.fc1.weight', 'image_encoder.features.1.block.1.fc2.bias', 'image_encoder.features.1.block.1.fc2.weight', 'image_encoder.features.1.block.2.0.weight', 'image_encoder.features.1.block.2.1.bias', 'image_encoder.features.1.block.2.1.weight', 'image_encoder.features.10.block.0.0.weight', 'image_encoder.features.10.block.0.1.bias', 'image_encoder.features.10.block.0.1.weight', 'image_encoder.features.10.block.1.0.weight', 'image_encoder.features.10.block.1.1.bias', 'image_encoder.features.10.block.1.1.weight', 'image_encoder.features.10.block.2.fc1.bias', 'image_encoder.features.10.block.2.fc1.weight', 'image_encoder.features.10.block.2.fc2.bias', 'image_encoder.features.10.block.2.fc2.weight', 'image_encoder.features.10.block.3.0.weight', 'image_encoder.features.10.block.3.1.bias', 'image_encoder.features.10.block.3.1.weight', 'image_encoder.features.11.block.0.0.weight', 'image_encoder.features.11.block.0.1.bias', 'image_encoder.features.11.block.0.1.weight', 'image_encoder.features.11.block.1.0.weight', 'image_encoder.features.11.block.1.1.bias', 'image_encoder.features.11.block.1.1.weight', 'image_encoder.features.11.block.2.fc1.bias', 'image_encoder.features.11.block.2.fc1.weight', 'image_encoder.features.11.block.2.fc2.bias', 'image_encoder.features.11.block.2.fc2.weight', 'image_encoder.features.11.block.3.0.weight', 'image_encoder.features.11.block.3.1.bias', 'image_encoder.features.11.block.3.1.weight', 'image_encoder.features.12.0.weight', 'image_encoder.features.12.1.bias', 'image_encoder.features.12.1.weight', 'image_encoder.features.2.block.0.0.weight', 'image_encoder.features.2.block.0.1.bias', 'image_encoder.features.2.block.0.1.weight', 'image_encoder.features.2.block.1.0.weight', 'image_encoder.features.2.block.1.1.bias', 'image_encoder.features.2.block.1.1.weight', 'image_encoder.features.2.block.2.0.weight', 'image_encoder.features.2.block.2.1.bias', 'image_encoder.features.2.block.2.1.weight', 'image_encoder.features.3.block.0.0.weight', 'image_encoder.features.3.block.0.1.bias', 'image_encoder.features.3.block.0.1.weight', 'image_encoder.features.3.block.1.0.weight', 'image_encoder.features.3.block.1.1.bias', 'image_encoder.features.3.block.1.1.weight', 'image_encoder.features.3.block.2.0.weight', 'image_encoder.features.3.block.2.1.bias', 'image_encoder.features.3.block.2.1.weight', 'image_encoder.features.4.block.0.0.weight', 'image_encoder.features.4.block.0.1.bias', 'image_encoder.features.4.block.0.1.weight', 'image_encoder.features.4.block.1.0.weight', 'image_encoder.features.4.block.1.1.bias', 'image_encoder.features.4.block.1.1.weight', 'image_encoder.features.4.block.2.fc1.bias', 'image_encoder.features.4.block.2.fc1.weight', 'image_encoder.features.4.block.2.fc2.bias', 'image_encoder.features.4.block.2.fc2.weight', 'image_encoder.features.4.block.3.0.weight', 'image_encoder.features.4.block.3.1.bias', 'image_encoder.features.4.block.3.1.weight', 'image_encoder.features.5.block.0.0.weight', 'image_encoder.features.5.block.0.1.bias', 'image_encoder.features.5.block.0.1.weight', 'image_encoder.features.5.block.1.0.weight', 'image_encoder.features.5.block.1.1.bias', 'image_encoder.features.5.block.1.1.weight', 'image_encoder.features.5.block.2.fc1.bias', 'image_encoder.features.5.block.2.fc1.weight', 'image_encoder.features.5.block.2.fc2.bias', 'image_encoder.features.5.block.2.fc2.weight', 'image_encoder.features.5.block.3.0.weight', 'image_encoder.features.5.block.3.1.bias', 'image_encoder.features.5.block.3.1.weight', 'image_encoder.features.6.block.0.0.weight', 'image_encoder.features.6.block.0.1.bias', 'image_encoder.features.6.block.0.1.weight', 'image_encoder.features.6.block.1.0.weight', 'image_encoder.features.6.block.1.1.bias', 'image_encoder.features.6.block.1.1.weight', 'image_encoder.features.6.block.2.fc1.bias', 'image_encoder.features.6.block.2.fc1.weight', 'image_encoder.features.6.block.2.fc2.bias', 'image_encoder.features.6.block.2.fc2.weight', 'image_encoder.features.6.block.3.0.weight', 'image_encoder.features.6.block.3.1.bias', 'image_encoder.features.6.block.3.1.weight', 'image_encoder.features.7.block.0.0.weight', 'image_encoder.features.7.block.0.1.bias', 'image_encoder.features.7.block.0.1.weight', 'image_encoder.features.7.block.1.0.weight', 'image_encoder.features.7.block.1.1.bias', 'image_encoder.features.7.block.1.1.weight', 'image_encoder.features.7.block.2.fc1.bias', 'image_encoder.features.7.block.2.fc1.weight', 'image_encoder.features.7.block.2.fc2.bias', 'image_encoder.features.7.block.2.fc2.weight', 'image_encoder.features.7.block.3.0.weight', 'image_encoder.features.7.block.3.1.bias', 'image_encoder.features.7.block.3.1.weight', 'image_encoder.features.8.block.0.0.weight', 'image_encoder.features.8.block.0.1.bias', 'image_encoder.features.8.block.0.1.weight', 'image_encoder.features.8.block.1.0.weight', 'image_encoder.features.8.block.1.1.bias', 'image_encoder.features.8.block.1.1.weight', 'image_encoder.features.8.block.2.fc1.bias', 'image_encoder.features.8.block.2.fc1.weight', 'image_encoder.features.8.block.2.fc2.bias', 'image_encoder.features.8.block.2.fc2.weight', 'image_encoder.features.8.block.3.0.weight', 'image_encoder.features.8.block.3.1.bias', 'image_encoder.features.8.block.3.1.weight', 'image_encoder.features.9.block.0.0.weight', 'image_encoder.features.9.block.0.1.bias', 'image_encoder.features.9.block.0.1.weight', 'image_encoder.features.9.block.1.0.weight', 'image_encoder.features.9.block.1.1.bias', 'image_encoder.features.9.block.1.1.weight', 'image_encoder.features.9.block.2.fc1.bias', 'image_encoder.features.9.block.2.fc1.weight', 'image_encoder.features.9.block.2.fc2.bias', 'image_encoder.features.9.block.2.fc2.weight', 'image_encoder.features.9.block.3.0.weight', 'image_encoder.features.9.block.3.1.bias', 'image_encoder.features.9.block.3.1.weight', 'sgn_embed.ln.bias', 'sgn_embed.ln.weight', 'sgn_embed.norm.norm.bias', 'sgn_embed.norm.norm.weight', 'txt_embed.lut.weight', 'txt_embed.norm.norm.bias', 'txt_embed.norm.norm.weight']
2021-12-27 23:26:31,372 cfg.name                           : ChicagoFSWild Experiment
2021-12-27 23:26:31,422 cfg.data.data_path                 : ./data/
2021-12-27 23:26:31,422 cfg.data.version                   : ChicagoFSWild
2021-12-27 23:26:31,422 cfg.data.sgn                       : sign
2021-12-27 23:26:31,422 cfg.data.gls                       : gloss
2021-12-27 23:26:31,422 cfg.data.feature_size              : 1000
2021-12-27 23:26:31,423 cfg.data.level                     : word
2021-12-27 23:26:31,423 cfg.data.max_sent_length           : 400
2021-12-27 23:26:31,423 cfg.data.random_train_subset       : -1
2021-12-27 23:26:31,423 cfg.data.random_dev_subset         : -1
2021-12-27 23:26:31,423 cfg.testing.recognition_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2021-12-27 23:26:31,423 cfg.testing.translation_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2021-12-27 23:26:31,423 cfg.testing.translation_beam_alphas : [-1, 0, 1, 2, 3, 4, 5]
2021-12-27 23:26:31,423 cfg.training.reset_best_ckpt       : False
2021-12-27 23:26:31,423 cfg.training.reset_scheduler       : False
2021-12-27 23:26:31,423 cfg.training.reset_optimizer       : False
2021-12-27 23:26:31,423 cfg.training.random_seed           : 42
2021-12-27 23:26:31,423 cfg.training.model_dir             : ./ChicagoFSWild Experiments/ChicagoFSWild_experiment_16
2021-12-27 23:26:31,424 cfg.training.recognition_loss_weight : 0.0
2021-12-27 23:26:31,424 cfg.training.translation_loss_weight : 1.0
2021-12-27 23:26:31,424 cfg.training.eval_metric           : bleu
2021-12-27 23:26:31,424 cfg.training.optimizer             : adam
2021-12-27 23:26:31,424 cfg.training.learning_rate         : 0.001
2021-12-27 23:26:31,424 cfg.training.batch_size            : 32
2021-12-27 23:26:31,424 cfg.training.num_valid_log         : 5
2021-12-27 23:26:31,424 cfg.training.epochs                : 5000000
2021-12-27 23:26:31,424 cfg.training.early_stopping_metric : eval_metric
2021-12-27 23:26:31,424 cfg.training.batch_type            : token
2021-12-27 23:26:31,424 cfg.training.translation_normalization : batch
2021-12-27 23:26:31,424 cfg.training.eval_recognition_beam_size : 9
2021-12-27 23:26:31,424 cfg.training.eval_translation_beam_size : 9
2021-12-27 23:26:31,425 cfg.training.eval_translation_beam_alpha : 1
2021-12-27 23:26:31,425 cfg.training.overwrite             : True
2021-12-27 23:26:31,425 cfg.training.shuffle               : True
2021-12-27 23:26:31,425 cfg.training.use_cuda              : True
2021-12-27 23:26:31,425 cfg.training.translation_max_output_length : 1
2021-12-27 23:26:31,425 cfg.training.keep_last_ckpts       : 1
2021-12-27 23:26:31,425 cfg.training.batch_multiplier      : 1
2021-12-27 23:26:31,425 cfg.training.logging_freq          : 1
2021-12-27 23:26:31,425 cfg.training.validation_freq       : 100
2021-12-27 23:26:31,425 cfg.training.betas                 : [0.9, 0.998]
2021-12-27 23:26:31,425 cfg.training.scheduling            : plateau
2021-12-27 23:26:31,425 cfg.training.learning_rate_min     : 1e-06
2021-12-27 23:26:31,425 cfg.training.weight_decay          : 0.001
2021-12-27 23:26:31,426 cfg.training.patience              : 8
2021-12-27 23:26:31,426 cfg.training.decrease_factor       : 0.7
2021-12-27 23:26:31,426 cfg.training.label_smoothing       : 0.0
2021-12-27 23:26:31,426 cfg.model.initializer              : xavier
2021-12-27 23:26:31,426 cfg.model.bias_initializer         : zeros
2021-12-27 23:26:31,426 cfg.model.init_gain                : 1.0
2021-12-27 23:26:31,426 cfg.model.embed_initializer        : xavier
2021-12-27 23:26:31,426 cfg.model.embed_init_gain          : 1.0
2021-12-27 23:26:31,426 cfg.model.tied_softmax             : False
2021-12-27 23:26:31,426 cfg.model.encoder.type             : transformer
2021-12-27 23:26:31,426 cfg.model.encoder.num_layers       : 3
2021-12-27 23:26:31,426 cfg.model.encoder.num_heads        : 8
2021-12-27 23:26:31,426 cfg.model.encoder.embeddings.embedding_dim : 512
2021-12-27 23:26:31,427 cfg.model.encoder.embeddings.scale : False
2021-12-27 23:26:31,427 cfg.model.encoder.embeddings.dropout : 0.1
2021-12-27 23:26:31,427 cfg.model.encoder.embeddings.norm_type : batch
2021-12-27 23:26:31,427 cfg.model.encoder.embeddings.activation_type : softsign
2021-12-27 23:26:31,427 cfg.model.encoder.hidden_size      : 512
2021-12-27 23:26:31,427 cfg.model.encoder.ff_size          : 2048
2021-12-27 23:26:31,427 cfg.model.encoder.dropout          : 0.1
2021-12-27 23:26:31,427 cfg.model.decoder.type             : transformer
2021-12-27 23:26:31,427 cfg.model.decoder.num_layers       : 3
2021-12-27 23:26:31,427 cfg.model.decoder.num_heads        : 8
2021-12-27 23:26:31,427 cfg.model.decoder.embeddings.embedding_dim : 512
2021-12-27 23:26:31,427 cfg.model.decoder.embeddings.scale : False
2021-12-27 23:26:31,427 cfg.model.decoder.embeddings.dropout : 0.1
2021-12-27 23:26:31,428 cfg.model.decoder.embeddings.norm_type : batch
2021-12-27 23:26:31,428 cfg.model.decoder.embeddings.activation_type : softsign
2021-12-27 23:26:31,428 cfg.model.decoder.hidden_size      : 512
2021-12-27 23:26:31,428 cfg.model.decoder.ff_size          : 2048
2021-12-27 23:26:31,428 cfg.model.decoder.dropout          : 0.1
2021-12-27 23:26:31,428 SignModel(
	encoder=TransformerEncoder(num_layers=3, num_heads=8),
	decoder=TransformerDecoder(num_layers=3, num_heads=8),
	sgn_embed=SpatialEmbeddings(embedding_dim=512, input_size=1000),
	txt_embed=Embeddings(embedding_dim=512, vocab_size=2733))
2021-12-27 23:26:31,733 EPOCH 1
2021-12-27 23:26:44,925 [Epoch: 001 Step: 00000001] Batch Translation Loss:   8.105168 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:26:56,846 [Epoch: 001 Step: 00000002] Batch Translation Loss:   7.949241 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-27 23:27:14,285 [Epoch: 001 Step: 00000003] Batch Translation Loss:   8.012571 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:27:33,201 [Epoch: 001 Step: 00000004] Batch Translation Loss:   7.876113 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:27:49,406 [Epoch: 001 Step: 00000005] Batch Translation Loss:   8.038077 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:28:13,463 [Epoch: 001 Step: 00000006] Batch Translation Loss:   8.036859 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:28:27,931 [Epoch: 001 Step: 00000007] Batch Translation Loss:   7.802645 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:28:44,357 [Epoch: 001 Step: 00000008] Batch Translation Loss:   7.833926 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:29:06,218 [Epoch: 001 Step: 00000009] Batch Translation Loss:   8.059882 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:29:28,690 [Epoch: 001 Step: 00000010] Batch Translation Loss:   7.960886 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:29:41,361 [Epoch: 001 Step: 00000011] Batch Translation Loss:   8.476361 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-27 23:30:04,688 [Epoch: 001 Step: 00000012] Batch Translation Loss:   8.136175 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:30:26,642 [Epoch: 001 Step: 00000013] Batch Translation Loss:   8.000137 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:30:47,579 [Epoch: 001 Step: 00000014] Batch Translation Loss:   8.174116 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:31:02,489 [Epoch: 001 Step: 00000015] Batch Translation Loss:   7.716516 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:31:20,481 [Epoch: 001 Step: 00000016] Batch Translation Loss:   7.712904 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:31:29,752 [Epoch: 001 Step: 00000017] Batch Translation Loss:   7.781170 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-27 23:31:51,338 [Epoch: 001 Step: 00000018] Batch Translation Loss:   7.814215 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:32:11,556 [Epoch: 001 Step: 00000019] Batch Translation Loss:   8.334524 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:32:25,318 [Epoch: 001 Step: 00000020] Batch Translation Loss:   7.954397 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:32:47,673 [Epoch: 001 Step: 00000021] Batch Translation Loss:   7.909365 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:33:01,669 [Epoch: 001 Step: 00000022] Batch Translation Loss:   7.660521 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:33:21,841 [Epoch: 001 Step: 00000023] Batch Translation Loss:   8.128629 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:33:37,420 [Epoch: 001 Step: 00000024] Batch Translation Loss:   7.860592 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:33:52,768 [Epoch: 001 Step: 00000025] Batch Translation Loss:   7.942429 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:34:15,680 [Epoch: 001 Step: 00000026] Batch Translation Loss:   8.260770 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:34:30,444 [Epoch: 001 Step: 00000027] Batch Translation Loss:   7.948383 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:34:46,141 [Epoch: 001 Step: 00000028] Batch Translation Loss:   8.212402 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:35:02,095 [Epoch: 001 Step: 00000029] Batch Translation Loss:   8.024207 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:35:26,716 [Epoch: 001 Step: 00000030] Batch Translation Loss:   8.559057 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:35:40,792 [Epoch: 001 Step: 00000031] Batch Translation Loss:   7.988100 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:35:55,807 [Epoch: 001 Step: 00000032] Batch Translation Loss:   7.925379 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:36:10,084 [Epoch: 001 Step: 00000033] Batch Translation Loss:   7.856887 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:36:23,565 [Epoch: 001 Step: 00000034] Batch Translation Loss:   7.011589 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:36:36,005 [Epoch: 001 Step: 00000035] Batch Translation Loss:   7.404651 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-27 23:36:48,635 [Epoch: 001 Step: 00000036] Batch Translation Loss:   8.656555 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-27 23:37:00,869 [Epoch: 001 Step: 00000037] Batch Translation Loss:   7.769037 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-27 23:37:16,552 [Epoch: 001 Step: 00000038] Batch Translation Loss:   7.346003 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:37:41,658 [Epoch: 001 Step: 00000039] Batch Translation Loss:   7.662480 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:37:58,229 [Epoch: 001 Step: 00000040] Batch Translation Loss:   8.351085 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:38:16,369 [Epoch: 001 Step: 00000041] Batch Translation Loss:   7.565915 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:38:42,327 [Epoch: 001 Step: 00000042] Batch Translation Loss:   8.293908 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:39:00,125 [Epoch: 001 Step: 00000043] Batch Translation Loss:   8.053329 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:39:16,062 [Epoch: 001 Step: 00000044] Batch Translation Loss:   8.132107 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:39:33,217 [Epoch: 001 Step: 00000045] Batch Translation Loss:   7.883951 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:39:53,229 [Epoch: 001 Step: 00000046] Batch Translation Loss:   8.044857 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:40:10,630 [Epoch: 001 Step: 00000047] Batch Translation Loss:   7.817309 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:40:27,865 [Epoch: 001 Step: 00000048] Batch Translation Loss:   7.816783 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:40:47,306 [Epoch: 001 Step: 00000049] Batch Translation Loss:   8.014818 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:41:03,641 [Epoch: 001 Step: 00000050] Batch Translation Loss:   7.331602 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:41:22,875 [Epoch: 001 Step: 00000051] Batch Translation Loss:   7.743936 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:41:41,837 [Epoch: 001 Step: 00000052] Batch Translation Loss:   8.172898 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:41:59,576 [Epoch: 001 Step: 00000053] Batch Translation Loss:   7.918644 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:42:32,381 [Epoch: 001 Step: 00000054] Batch Translation Loss:   7.161741 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:42:47,728 [Epoch: 001 Step: 00000055] Batch Translation Loss:   7.551943 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:43:04,058 [Epoch: 001 Step: 00000056] Batch Translation Loss:   7.919696 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:43:18,760 [Epoch: 001 Step: 00000057] Batch Translation Loss:   7.270260 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:43:37,496 [Epoch: 001 Step: 00000058] Batch Translation Loss:   7.115361 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:43:56,088 [Epoch: 001 Step: 00000059] Batch Translation Loss:   7.602909 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:44:18,070 [Epoch: 001 Step: 00000060] Batch Translation Loss:   7.346979 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:44:40,190 [Epoch: 001 Step: 00000061] Batch Translation Loss:   7.961249 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:45:01,652 [Epoch: 001 Step: 00000062] Batch Translation Loss:   7.714373 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:45:24,018 [Epoch: 001 Step: 00000063] Batch Translation Loss:   7.105148 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:45:46,215 [Epoch: 001 Step: 00000064] Batch Translation Loss:   7.093482 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:46:08,743 [Epoch: 001 Step: 00000065] Batch Translation Loss:   7.743857 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:46:29,463 [Epoch: 001 Step: 00000066] Batch Translation Loss:   8.154037 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:46:52,927 [Epoch: 001 Step: 00000067] Batch Translation Loss:   7.554917 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:47:17,178 [Epoch: 001 Step: 00000068] Batch Translation Loss:   7.985062 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:47:41,848 [Epoch: 001 Step: 00000069] Batch Translation Loss:   7.675502 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:48:08,058 [Epoch: 001 Step: 00000070] Batch Translation Loss:   7.495794 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:48:29,898 [Epoch: 001 Step: 00000071] Batch Translation Loss:   7.599721 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:48:47,661 [Epoch: 001 Step: 00000072] Batch Translation Loss:   7.589194 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:49:10,220 [Epoch: 001 Step: 00000073] Batch Translation Loss:   7.263382 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:49:28,394 [Epoch: 001 Step: 00000074] Batch Translation Loss:   6.333164 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:49:48,424 [Epoch: 001 Step: 00000075] Batch Translation Loss:   7.397615 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:50:12,670 [Epoch: 001 Step: 00000076] Batch Translation Loss:   7.275260 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:50:42,146 [Epoch: 001 Step: 00000077] Batch Translation Loss:   7.848496 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:51:06,960 [Epoch: 001 Step: 00000078] Batch Translation Loss:   7.283242 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:51:32,940 [Epoch: 001 Step: 00000079] Batch Translation Loss:   7.282239 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:51:58,096 [Epoch: 001 Step: 00000080] Batch Translation Loss:   7.545808 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:52:24,390 [Epoch: 001 Step: 00000081] Batch Translation Loss:   6.916444 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:52:53,491 [Epoch: 001 Step: 00000082] Batch Translation Loss:   6.817010 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:53:19,653 [Epoch: 001 Step: 00000083] Batch Translation Loss:   7.165716 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:53:47,449 [Epoch: 001 Step: 00000084] Batch Translation Loss:   7.861767 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:54:12,643 [Epoch: 001 Step: 00000085] Batch Translation Loss:   7.665883 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:54:37,991 [Epoch: 001 Step: 00000086] Batch Translation Loss:   7.523485 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:55:23,037 [Epoch: 001 Step: 00000087] Batch Translation Loss:   7.670468 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:56:02,116 [Epoch: 001 Step: 00000088] Batch Translation Loss:   7.786712 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:56:20,959 [Epoch: 001 Step: 00000089] Batch Translation Loss:   7.720931 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-27 23:56:42,462 [Epoch: 001 Step: 00000090] Batch Translation Loss:   7.888651 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:57:04,654 [Epoch: 001 Step: 00000091] Batch Translation Loss:   7.698287 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:57:31,743 [Epoch: 001 Step: 00000092] Batch Translation Loss:   7.561873 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:58:01,523 [Epoch: 001 Step: 00000093] Batch Translation Loss:   7.434905 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:58:29,559 [Epoch: 001 Step: 00000094] Batch Translation Loss:   7.795928 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:58:56,369 [Epoch: 001 Step: 00000095] Batch Translation Loss:   7.876248 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:59:21,264 [Epoch: 001 Step: 00000096] Batch Translation Loss:   7.617848 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 23:59:51,607 [Epoch: 001 Step: 00000097] Batch Translation Loss:   7.452130 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:00:17,967 [Epoch: 001 Step: 00000098] Batch Translation Loss:   7.282960 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:00:45,746 [Epoch: 001 Step: 00000099] Batch Translation Loss:   7.447072 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:01:14,967 [Epoch: 001 Step: 00000100] Batch Translation Loss:   7.907438 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:08:47,622 Hooray! New best validation result [eval_metric]!
2021-12-28 00:08:47,622 Saving new checkpoint.
2021-12-28 00:08:49,473 Validation result at epoch   1, step      100: duration: 454.4884s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 7913.19580	PPL: 3641.68945
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 0.69,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.76	ROUGE 0.52
2021-12-28 00:08:56,166 Logging Recognition and Translation Outputs
2021-12-28 00:08:56,239 ========================================================================================================================
2021-12-28 00:08:56,240 Logging Sequence: aslized-suzanne_stecker_0274
2021-12-28 00:08:56,240 	Text Reference  :	so      
2021-12-28 00:08:56,240 	Text Hypothesis :	handling
2021-12-28 00:08:56,240 	Text Alignment  :	S       
2021-12-28 00:08:56,240 ========================================================================================================================
2021-12-28 00:08:56,240 Logging Sequence: youtube_5-sean_berdy_6089
2021-12-28 00:08:56,240 	Text Reference  :	unin
2021-12-28 00:08:56,241 	Text Hypothesis :	if  
2021-12-28 00:08:56,241 	Text Alignment  :	S   
2021-12-28 00:08:56,241 ========================================================================================================================
2021-12-28 00:08:56,241 Logging Sequence: deafvideo_5-silentoneye_7318
2021-12-28 00:08:56,241 	Text Reference  :	sc         
2021-12-28 00:08:56,241 	Text Hypothesis :	initializon
2021-12-28 00:08:56,241 	Text Alignment  :	S          
2021-12-28 00:08:56,241 ========================================================================================================================
2021-12-28 00:08:56,241 Logging Sequence: deafvideo_5-morningstar_6266
2021-12-28 00:08:56,241 	Text Reference  :	aslized
2021-12-28 00:08:56,242 	Text Hypothesis :	als    
2021-12-28 00:08:56,242 	Text Alignment  :	S      
2021-12-28 00:08:56,242 ========================================================================================================================
2021-12-28 00:08:56,242 Logging Sequence: youtube_5-melissa_draganac-hawk_5834
2021-12-28 00:08:56,242 	Text Reference  :	to  
2021-12-28 00:08:56,242 	Text Hypothesis :	free
2021-12-28 00:08:56,242 	Text Alignment  :	S   
2021-12-28 00:08:56,242 ========================================================================================================================
2021-12-28 00:10:54,231 [Epoch: 001 Step: 00000101] Batch Translation Loss:   8.142149 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 00:11:58,730 [Epoch: 001 Step: 00000102] Batch Translation Loss:   7.404231 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 00:12:48,892 [Epoch: 001 Step: 00000103] Batch Translation Loss:   7.393350 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:13:15,662 [Epoch: 001 Step: 00000104] Batch Translation Loss:   8.268441 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:13:42,495 [Epoch: 001 Step: 00000105] Batch Translation Loss:   7.078402 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:14:11,640 [Epoch: 001 Step: 00000106] Batch Translation Loss:   7.861187 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:14:38,776 [Epoch: 001 Step: 00000107] Batch Translation Loss:   7.286698 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:15:09,681 [Epoch: 001 Step: 00000108] Batch Translation Loss:   8.043845 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:15:40,800 [Epoch: 001 Step: 00000109] Batch Translation Loss:   7.470673 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:16:10,253 [Epoch: 001 Step: 00000110] Batch Translation Loss:   7.785896 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:16:33,399 [Epoch: 001 Step: 00000111] Batch Translation Loss:   6.879364 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:16:58,370 [Epoch: 001 Step: 00000112] Batch Translation Loss:   7.893926 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:17:48,941 [Epoch: 001 Step: 00000113] Batch Translation Loss:   6.903308 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:18:32,629 [Epoch: 001 Step: 00000114] Batch Translation Loss:   7.470472 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:19:04,106 [Epoch: 001 Step: 00000115] Batch Translation Loss:   7.693612 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:19:34,484 [Epoch: 001 Step: 00000116] Batch Translation Loss:   7.241543 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:20:07,946 [Epoch: 001 Step: 00000117] Batch Translation Loss:   7.507324 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:20:36,165 [Epoch: 001 Step: 00000118] Batch Translation Loss:   7.700017 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:21:12,600 [Epoch: 001 Step: 00000119] Batch Translation Loss:   7.092518 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:21:43,980 [Epoch: 001 Step: 00000120] Batch Translation Loss:   7.552767 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:22:16,706 [Epoch: 001 Step: 00000121] Batch Translation Loss:   7.097044 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:22:48,007 [Epoch: 001 Step: 00000122] Batch Translation Loss:   6.709359 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:23:18,332 [Epoch: 001 Step: 00000123] Batch Translation Loss:   6.495419 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:23:51,764 [Epoch: 001 Step: 00000124] Batch Translation Loss:   8.149936 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:24:26,374 [Epoch: 001 Step: 00000125] Batch Translation Loss:   7.250142 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:25:01,343 [Epoch: 001 Step: 00000126] Batch Translation Loss:   7.302348 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:25:59,513 [Epoch: 001 Step: 00000127] Batch Translation Loss:   7.347850 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:26:30,860 [Epoch: 001 Step: 00000128] Batch Translation Loss:   7.397824 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:27:03,199 [Epoch: 001 Step: 00000129] Batch Translation Loss:   7.310090 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:27:33,478 [Epoch: 001 Step: 00000130] Batch Translation Loss:   7.689796 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:28:08,970 [Epoch: 001 Step: 00000131] Batch Translation Loss:   6.573847 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:28:41,164 [Epoch: 001 Step: 00000132] Batch Translation Loss:   7.212277 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:29:20,593 [Epoch: 001 Step: 00000133] Batch Translation Loss:   6.762211 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:30:34,800 [Epoch: 001 Step: 00000134] Batch Translation Loss:   7.216319 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 00:31:04,175 [Epoch: 001 Step: 00000135] Batch Translation Loss:   7.257005 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:31:37,985 [Epoch: 001 Step: 00000136] Batch Translation Loss:   6.705837 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:32:09,765 [Epoch: 001 Step: 00000137] Batch Translation Loss:   6.344943 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:32:55,967 [Epoch: 001 Step: 00000138] Batch Translation Loss:   7.049278 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:33:26,957 [Epoch: 001 Step: 00000139] Batch Translation Loss:   7.818102 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:34:05,157 [Epoch: 001 Step: 00000140] Batch Translation Loss:   7.730363 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:35:09,691 [Epoch: 001 Step: 00000141] Batch Translation Loss:   6.969768 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 00:35:46,337 [Epoch: 001 Step: 00000142] Batch Translation Loss:   7.365905 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:36:24,795 [Epoch: 001 Step: 00000143] Batch Translation Loss:   7.637159 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:36:55,671 [Epoch: 001 Step: 00000144] Batch Translation Loss:   7.293848 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:37:28,833 [Epoch: 001 Step: 00000145] Batch Translation Loss:   7.241859 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:37:59,861 [Epoch: 001 Step: 00000146] Batch Translation Loss:   6.904452 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:38:51,996 [Epoch: 001 Step: 00000147] Batch Translation Loss:   6.590137 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:39:30,506 [Epoch: 001 Step: 00000148] Batch Translation Loss:   7.030142 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:40:12,696 [Epoch: 001 Step: 00000149] Batch Translation Loss:   7.339142 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:41:07,531 [Epoch: 001 Step: 00000150] Batch Translation Loss:   7.004172 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:41:44,318 [Epoch: 001 Step: 00000151] Batch Translation Loss:   7.049230 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:42:30,963 [Epoch: 001 Step: 00000152] Batch Translation Loss:   7.265408 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:43:06,526 [Epoch: 001 Step: 00000153] Batch Translation Loss:   7.430701 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:43:39,075 [Epoch: 001 Step: 00000154] Batch Translation Loss:   7.618976 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:44:10,610 [Epoch: 001 Step: 00000155] Batch Translation Loss:   8.324814 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:44:43,110 [Epoch: 001 Step: 00000156] Batch Translation Loss:   7.828455 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:45:28,827 [Epoch: 001 Step: 00000157] Batch Translation Loss:   7.236383 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:46:06,470 [Epoch: 001 Step: 00000158] Batch Translation Loss:   8.058000 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:46:46,522 [Epoch: 001 Step: 00000159] Batch Translation Loss:   7.426463 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:47:26,328 [Epoch: 001 Step: 00000160] Batch Translation Loss:   7.141149 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:48:05,265 [Epoch: 001 Step: 00000161] Batch Translation Loss:   8.065683 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:48:43,486 [Epoch: 001 Step: 00000162] Batch Translation Loss:   7.524088 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:49:34,210 [Epoch: 001 Step: 00000163] Batch Translation Loss:   6.972612 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:50:11,556 [Epoch: 001 Step: 00000164] Batch Translation Loss:   7.330931 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:50:42,376 [Epoch: 001 Step: 00000165] Batch Translation Loss:   7.457777 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:51:13,313 [Epoch: 001 Step: 00000166] Batch Translation Loss:   6.941618 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:51:47,440 [Epoch: 001 Step: 00000167] Batch Translation Loss:   7.473299 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:52:33,049 [Epoch: 001 Step: 00000168] Batch Translation Loss:   7.915421 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:53:13,704 [Epoch: 001 Step: 00000169] Batch Translation Loss:   8.535044 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:53:50,752 [Epoch: 001 Step: 00000170] Batch Translation Loss:   7.950727 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:53:50,874 Epoch   1: Total Training Recognition Loss -1.00  Total Training Translation Loss 1291.02 
2021-12-28 00:53:50,874 EPOCH 2
2021-12-28 00:53:59,014 [Epoch: 002 Step: 00000171] Batch Translation Loss:   7.536062 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-28 00:54:06,629 [Epoch: 002 Step: 00000172] Batch Translation Loss:   8.028873 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-28 00:54:16,337 [Epoch: 002 Step: 00000173] Batch Translation Loss:   7.546268 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 00:54:26,245 [Epoch: 002 Step: 00000174] Batch Translation Loss:   7.285614 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 00:54:37,927 [Epoch: 002 Step: 00000175] Batch Translation Loss:   7.765587 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 00:54:50,235 [Epoch: 002 Step: 00000176] Batch Translation Loss:   7.607341 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 00:55:03,021 [Epoch: 002 Step: 00000177] Batch Translation Loss:   7.547294 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 00:55:13,907 [Epoch: 002 Step: 00000178] Batch Translation Loss:   7.277301 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 00:55:32,617 [Epoch: 002 Step: 00000179] Batch Translation Loss:   7.868212 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 00:55:48,574 [Epoch: 002 Step: 00000180] Batch Translation Loss:   7.991046 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 00:56:03,795 [Epoch: 002 Step: 00000181] Batch Translation Loss:   7.721786 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 00:56:20,295 [Epoch: 002 Step: 00000182] Batch Translation Loss:   7.385457 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 00:56:34,530 [Epoch: 002 Step: 00000183] Batch Translation Loss:   7.219837 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 00:56:49,167 [Epoch: 002 Step: 00000184] Batch Translation Loss:   7.444172 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 00:57:04,729 [Epoch: 002 Step: 00000185] Batch Translation Loss:   7.035198 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 00:57:16,178 [Epoch: 002 Step: 00000186] Batch Translation Loss:   7.428453 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 00:57:33,711 [Epoch: 002 Step: 00000187] Batch Translation Loss:   7.575676 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 00:57:44,024 [Epoch: 002 Step: 00000188] Batch Translation Loss:   8.050945 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 00:57:56,550 [Epoch: 002 Step: 00000189] Batch Translation Loss:   7.982858 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 00:58:18,318 [Epoch: 002 Step: 00000190] Batch Translation Loss:   7.529349 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:58:30,590 [Epoch: 002 Step: 00000191] Batch Translation Loss:   7.358646 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 00:58:42,543 [Epoch: 002 Step: 00000192] Batch Translation Loss:   7.737897 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 00:59:03,971 [Epoch: 002 Step: 00000193] Batch Translation Loss:   7.265617 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 00:59:16,587 [Epoch: 002 Step: 00000194] Batch Translation Loss:   8.077065 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 00:59:29,546 [Epoch: 002 Step: 00000195] Batch Translation Loss:   7.058952 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 00:59:42,715 [Epoch: 002 Step: 00000196] Batch Translation Loss:   7.100730 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 00:59:57,249 [Epoch: 002 Step: 00000197] Batch Translation Loss:   7.390884 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:00:11,086 [Epoch: 002 Step: 00000198] Batch Translation Loss:   7.503265 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:00:22,296 [Epoch: 002 Step: 00000199] Batch Translation Loss:   7.420691 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 01:00:35,148 [Epoch: 002 Step: 00000200] Batch Translation Loss:   7.168916 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:07:48,876 Validation result at epoch   2, step      200: duration: 433.7035s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 8170.02246	PPL: 4794.03271
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 1.55,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 4.43	ROUGE 2.30
2021-12-28 01:07:57,417 Logging Recognition and Translation Outputs
2021-12-28 01:07:57,430 ========================================================================================================================
2021-12-28 01:07:57,430 Logging Sequence: deafvideo_3-yellowbirdie84_4664
2021-12-28 01:07:57,431 	Text Reference  :	or 
2021-12-28 01:07:57,431 	Text Hypothesis :	asl
2021-12-28 01:07:57,431 	Text Alignment  :	S  
2021-12-28 01:07:57,431 ========================================================================================================================
2021-12-28 01:07:57,431 Logging Sequence: aslized-suzanne_stecker_0245
2021-12-28 01:07:57,431 	Text Reference  :	ok
2021-12-28 01:07:57,431 	Text Hypothesis :	cl
2021-12-28 01:07:57,431 	Text Alignment  :	S 
2021-12-28 01:07:57,432 ========================================================================================================================
2021-12-28 01:07:57,432 Logging Sequence: youtube_1-don_grushkin_2776
2021-12-28 01:07:57,432 	Text Reference  :	***** brain 
2021-12-28 01:07:57,432 	Text Hypothesis :	croft haiman
2021-12-28 01:07:57,432 	Text Alignment  :	I     S     
2021-12-28 01:07:57,432 ========================================================================================================================
2021-12-28 01:07:57,432 Logging Sequence: youtube_1-shoshannah_stern_2380
2021-12-28 01:07:57,432 	Text Reference  :	dept   
2021-12-28 01:07:57,432 	Text Hypothesis :	wobsits
2021-12-28 01:07:57,432 	Text Alignment  :	S      
2021-12-28 01:07:57,432 ========================================================================================================================
2021-12-28 01:07:57,433 Logging Sequence: deafvideo_2-sddsimple_1575
2021-12-28 01:07:57,433 	Text Reference  :	asl
2021-12-28 01:07:57,433 	Text Hypothesis :	asl
2021-12-28 01:07:57,433 	Text Alignment  :	   
2021-12-28 01:07:57,433 ========================================================================================================================
2021-12-28 01:08:51,932 [Epoch: 002 Step: 00000201] Batch Translation Loss:   7.262878 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:09:26,925 [Epoch: 002 Step: 00000202] Batch Translation Loss:   7.621418 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:09:58,244 [Epoch: 002 Step: 00000203] Batch Translation Loss:   7.245696 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:10:19,443 [Epoch: 002 Step: 00000204] Batch Translation Loss:   6.494908 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:10:36,736 [Epoch: 002 Step: 00000205] Batch Translation Loss:   7.287333 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:11:03,690 [Epoch: 002 Step: 00000206] Batch Translation Loss:   7.688948 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:11:14,296 [Epoch: 002 Step: 00000207] Batch Translation Loss:   6.982458 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 01:11:32,249 [Epoch: 002 Step: 00000208] Batch Translation Loss:   7.033183 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:11:45,380 [Epoch: 002 Step: 00000209] Batch Translation Loss:   6.952507 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:11:57,843 [Epoch: 002 Step: 00000210] Batch Translation Loss:   7.676093 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 01:12:15,275 [Epoch: 002 Step: 00000211] Batch Translation Loss:   7.060061 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:12:42,540 [Epoch: 002 Step: 00000212] Batch Translation Loss:   7.193885 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:12:57,363 [Epoch: 002 Step: 00000213] Batch Translation Loss:   7.142261 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:13:13,457 [Epoch: 002 Step: 00000214] Batch Translation Loss:   7.302580 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:13:29,018 [Epoch: 002 Step: 00000215] Batch Translation Loss:   7.652053 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:13:44,436 [Epoch: 002 Step: 00000216] Batch Translation Loss:   6.539777 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:14:14,733 [Epoch: 002 Step: 00000217] Batch Translation Loss:   7.844486 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:14:32,920 [Epoch: 002 Step: 00000218] Batch Translation Loss:   6.856391 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:14:49,622 [Epoch: 002 Step: 00000219] Batch Translation Loss:   6.976194 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:15:06,906 [Epoch: 002 Step: 00000220] Batch Translation Loss:   6.740234 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:15:24,901 [Epoch: 002 Step: 00000221] Batch Translation Loss:   7.348564 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:15:41,822 [Epoch: 002 Step: 00000222] Batch Translation Loss:   7.694404 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:16:13,622 [Epoch: 002 Step: 00000223] Batch Translation Loss:   7.724003 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:16:31,235 [Epoch: 002 Step: 00000224] Batch Translation Loss:   7.064800 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:16:48,594 [Epoch: 002 Step: 00000225] Batch Translation Loss:   7.427431 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:17:19,942 [Epoch: 002 Step: 00000226] Batch Translation Loss:   7.128126 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:17:37,841 [Epoch: 002 Step: 00000227] Batch Translation Loss:   7.542583 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:17:53,740 [Epoch: 002 Step: 00000228] Batch Translation Loss:   6.682834 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:18:08,947 [Epoch: 002 Step: 00000229] Batch Translation Loss:   6.883152 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:18:26,271 [Epoch: 002 Step: 00000230] Batch Translation Loss:   7.063574 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:18:43,745 [Epoch: 002 Step: 00000231] Batch Translation Loss:   7.086243 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:19:02,884 [Epoch: 002 Step: 00000232] Batch Translation Loss:   6.863891 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:19:30,287 [Epoch: 002 Step: 00000233] Batch Translation Loss:   6.766826 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:19:49,722 [Epoch: 002 Step: 00000234] Batch Translation Loss:   6.447142 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:20:10,334 [Epoch: 002 Step: 00000235] Batch Translation Loss:   6.954801 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:20:33,237 [Epoch: 002 Step: 00000236] Batch Translation Loss:   7.327181 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:20:53,604 [Epoch: 002 Step: 00000237] Batch Translation Loss:   6.675744 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:21:15,340 [Epoch: 002 Step: 00000238] Batch Translation Loss:   7.092598 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:21:38,776 [Epoch: 002 Step: 00000239] Batch Translation Loss:   7.109004 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:22:13,002 [Epoch: 002 Step: 00000240] Batch Translation Loss:   7.570709 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:23:12,997 [Epoch: 002 Step: 00000241] Batch Translation Loss:   7.597304 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:23:37,361 [Epoch: 002 Step: 00000242] Batch Translation Loss:   7.217474 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:23:59,493 [Epoch: 002 Step: 00000243] Batch Translation Loss:   7.447646 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:24:21,482 [Epoch: 002 Step: 00000244] Batch Translation Loss:   7.292038 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:24:44,948 [Epoch: 002 Step: 00000245] Batch Translation Loss:   7.024747 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:25:04,477 [Epoch: 002 Step: 00000246] Batch Translation Loss:   7.270219 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:25:22,663 [Epoch: 002 Step: 00000247] Batch Translation Loss:   7.213326 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:25:42,431 [Epoch: 002 Step: 00000248] Batch Translation Loss:   7.517154 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:26:03,268 [Epoch: 002 Step: 00000249] Batch Translation Loss:   6.960738 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:26:31,439 [Epoch: 002 Step: 00000250] Batch Translation Loss:   6.510279 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:26:56,074 [Epoch: 002 Step: 00000251] Batch Translation Loss:   6.591290 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:27:21,478 [Epoch: 002 Step: 00000252] Batch Translation Loss:   7.631025 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:27:43,929 [Epoch: 002 Step: 00000253] Batch Translation Loss:   7.230997 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:28:06,265 [Epoch: 002 Step: 00000254] Batch Translation Loss:   6.983052 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:28:30,820 [Epoch: 002 Step: 00000255] Batch Translation Loss:   6.660362 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:28:55,392 [Epoch: 002 Step: 00000256] Batch Translation Loss:   7.212502 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:29:23,580 [Epoch: 002 Step: 00000257] Batch Translation Loss:   6.881294 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:29:46,796 [Epoch: 002 Step: 00000258] Batch Translation Loss:   6.678936 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:30:11,544 [Epoch: 002 Step: 00000259] Batch Translation Loss:   6.645420 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:30:36,731 [Epoch: 002 Step: 00000260] Batch Translation Loss:   7.214195 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:31:03,290 [Epoch: 002 Step: 00000261] Batch Translation Loss:   7.461753 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:31:26,708 [Epoch: 002 Step: 00000262] Batch Translation Loss:   6.763947 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:31:46,939 [Epoch: 002 Step: 00000263] Batch Translation Loss:   6.758098 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:32:08,268 [Epoch: 002 Step: 00000264] Batch Translation Loss:   6.858351 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 01:32:31,940 [Epoch: 002 Step: 00000265] Batch Translation Loss:   7.180290 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:33:04,703 [Epoch: 002 Step: 00000266] Batch Translation Loss:   7.384376 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:33:30,239 [Epoch: 002 Step: 00000267] Batch Translation Loss:   7.360757 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:33:57,576 [Epoch: 002 Step: 00000268] Batch Translation Loss:   6.851600 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:34:25,246 [Epoch: 002 Step: 00000269] Batch Translation Loss:   7.442562 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:34:54,920 [Epoch: 002 Step: 00000270] Batch Translation Loss:   7.792571 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:35:21,361 [Epoch: 002 Step: 00000271] Batch Translation Loss:   6.968462 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:35:49,403 [Epoch: 002 Step: 00000272] Batch Translation Loss:   7.309805 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:36:18,768 [Epoch: 002 Step: 00000273] Batch Translation Loss:   6.720001 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:36:46,285 [Epoch: 002 Step: 00000274] Batch Translation Loss:   7.397982 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:37:16,947 [Epoch: 002 Step: 00000275] Batch Translation Loss:   6.835246 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:37:43,394 [Epoch: 002 Step: 00000276] Batch Translation Loss:   7.462358 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:38:14,687 [Epoch: 002 Step: 00000277] Batch Translation Loss:   7.100546 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:38:37,247 [Epoch: 002 Step: 00000278] Batch Translation Loss:   7.393382 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:38:59,780 [Epoch: 002 Step: 00000279] Batch Translation Loss:   7.449020 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:39:22,445 [Epoch: 002 Step: 00000280] Batch Translation Loss:   7.309054 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:40:08,958 [Epoch: 002 Step: 00000281] Batch Translation Loss:   7.408329 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:40:50,270 [Epoch: 002 Step: 00000282] Batch Translation Loss:   7.372090 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:41:19,210 [Epoch: 002 Step: 00000283] Batch Translation Loss:   7.080974 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:41:49,894 [Epoch: 002 Step: 00000284] Batch Translation Loss:   6.788646 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:42:19,385 [Epoch: 002 Step: 00000285] Batch Translation Loss:   7.530886 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:42:52,897 [Epoch: 002 Step: 00000286] Batch Translation Loss:   6.875051 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:43:39,372 [Epoch: 002 Step: 00000287] Batch Translation Loss:   6.816947 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:44:26,102 [Epoch: 002 Step: 00000288] Batch Translation Loss:   7.082490 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:44:54,202 [Epoch: 002 Step: 00000289] Batch Translation Loss:   6.908573 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:45:47,500 [Epoch: 002 Step: 00000290] Batch Translation Loss:   7.006155 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:46:13,683 [Epoch: 002 Step: 00000291] Batch Translation Loss:   6.993392 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:46:57,970 [Epoch: 002 Step: 00000292] Batch Translation Loss:   7.074343 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:47:49,545 [Epoch: 002 Step: 00000293] Batch Translation Loss:   6.617623 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:48:26,855 [Epoch: 002 Step: 00000294] Batch Translation Loss:   7.101594 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:49:00,745 [Epoch: 002 Step: 00000295] Batch Translation Loss:   7.313783 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:50:15,135 [Epoch: 002 Step: 00000296] Batch Translation Loss:   6.431708 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 01:50:44,798 [Epoch: 002 Step: 00000297] Batch Translation Loss:   7.469532 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:51:15,359 [Epoch: 002 Step: 00000298] Batch Translation Loss:   7.298914 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:51:46,762 [Epoch: 002 Step: 00000299] Batch Translation Loss:   6.307417 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:52:24,189 [Epoch: 002 Step: 00000300] Batch Translation Loss:   6.962742 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 01:59:24,915 Validation result at epoch   2, step      300: duration: 420.6847s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 8121.76660	PPL: 4481.11035
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 3.73,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 4.80	ROUGE 3.34
2021-12-28 01:59:34,118 Logging Recognition and Translation Outputs
2021-12-28 01:59:34,147 ========================================================================================================================
2021-12-28 01:59:34,147 Logging Sequence: deafvideo_3-titans_4703
2021-12-28 01:59:34,148 	Text Reference  :	senses
2021-12-28 01:59:34,149 	Text Hypothesis :	asl   
2021-12-28 01:59:34,149 	Text Alignment  :	S     
2021-12-28 01:59:34,149 ========================================================================================================================
2021-12-28 01:59:34,149 Logging Sequence: deafvideo_2-sddsimple_1581
2021-12-28 01:59:34,150 	Text Reference  :	aha
2021-12-28 01:59:34,150 	Text Hypothesis :	or 
2021-12-28 01:59:34,150 	Text Alignment  :	S  
2021-12-28 01:59:34,150 ========================================================================================================================
2021-12-28 01:59:34,150 Logging Sequence: youtube_1-catherine_mackinnon_2777
2021-12-28 01:59:34,151 	Text Reference  :	syran
2021-12-28 01:59:34,151 	Text Hypothesis :	asl  
2021-12-28 01:59:34,151 	Text Alignment  :	S    
2021-12-28 01:59:34,151 ========================================================================================================================
2021-12-28 01:59:34,152 Logging Sequence: youtube_1-don_grushkin_2332
2021-12-28 01:59:34,152 	Text Reference  :	paleo herew
2021-12-28 01:59:34,152 	Text Hypothesis :	***** asl  
2021-12-28 01:59:34,153 	Text Alignment  :	D     S    
2021-12-28 01:59:34,153 ========================================================================================================================
2021-12-28 01:59:34,153 Logging Sequence: youtube_1-catherine_mackinnon_2824
2021-12-28 01:59:34,153 	Text Reference  :	jd
2021-12-28 01:59:34,154 	Text Hypothesis :	or
2021-12-28 01:59:34,154 	Text Alignment  :	S 
2021-12-28 01:59:34,154 ========================================================================================================================
2021-12-28 02:01:36,443 [Epoch: 002 Step: 00000301] Batch Translation Loss:   7.312227 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 02:02:14,155 [Epoch: 002 Step: 00000302] Batch Translation Loss:   6.650726 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:02:57,756 [Epoch: 002 Step: 00000303] Batch Translation Loss:   7.130226 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:04:04,639 [Epoch: 002 Step: 00000304] Batch Translation Loss:   6.936780 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 02:04:50,938 [Epoch: 002 Step: 00000305] Batch Translation Loss:   6.915247 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:05:28,630 [Epoch: 002 Step: 00000306] Batch Translation Loss:   7.086992 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:06:39,309 [Epoch: 002 Step: 00000307] Batch Translation Loss:   6.644939 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 02:07:16,916 [Epoch: 002 Step: 00000308] Batch Translation Loss:   7.587771 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:07:47,294 [Epoch: 002 Step: 00000309] Batch Translation Loss:   6.674366 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:08:15,484 [Epoch: 002 Step: 00000310] Batch Translation Loss:   6.629307 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:08:46,892 [Epoch: 002 Step: 00000311] Batch Translation Loss:   7.138530 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:09:30,857 [Epoch: 002 Step: 00000312] Batch Translation Loss:   7.552738 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:10:05,255 [Epoch: 002 Step: 00000313] Batch Translation Loss:   6.935665 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:10:42,681 [Epoch: 002 Step: 00000314] Batch Translation Loss:   6.637626 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:11:15,917 [Epoch: 002 Step: 00000315] Batch Translation Loss:   7.086472 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:11:51,095 [Epoch: 002 Step: 00000316] Batch Translation Loss:   6.564507 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:12:28,407 [Epoch: 002 Step: 00000317] Batch Translation Loss:   7.535826 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:13:04,871 [Epoch: 002 Step: 00000318] Batch Translation Loss:   7.108065 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:13:51,540 [Epoch: 002 Step: 00000319] Batch Translation Loss:   6.661150 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:14:27,783 [Epoch: 002 Step: 00000320] Batch Translation Loss:   6.614422 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:15:04,182 [Epoch: 002 Step: 00000321] Batch Translation Loss:   6.779882 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:15:34,125 [Epoch: 002 Step: 00000322] Batch Translation Loss:   6.220430 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:16:31,850 [Epoch: 002 Step: 00000323] Batch Translation Loss:   6.553360 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:17:14,568 [Epoch: 002 Step: 00000324] Batch Translation Loss:   6.615879 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:17:49,169 [Epoch: 002 Step: 00000325] Batch Translation Loss:   6.956104 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:18:27,273 [Epoch: 002 Step: 00000326] Batch Translation Loss:   6.849261 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:19:06,970 [Epoch: 002 Step: 00000327] Batch Translation Loss:   6.597330 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:19:46,224 [Epoch: 002 Step: 00000328] Batch Translation Loss:   7.206943 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:20:26,180 [Epoch: 002 Step: 00000329] Batch Translation Loss:   7.288685 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:21:08,177 [Epoch: 002 Step: 00000330] Batch Translation Loss:   7.024809 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:22:01,340 [Epoch: 002 Step: 00000331] Batch Translation Loss:   6.915386 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:22:32,060 [Epoch: 002 Step: 00000332] Batch Translation Loss:   6.086307 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:23:03,727 [Epoch: 002 Step: 00000333] Batch Translation Loss:   6.127329 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:23:45,094 [Epoch: 002 Step: 00000334] Batch Translation Loss:   6.604340 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:24:24,126 [Epoch: 002 Step: 00000335] Batch Translation Loss:   6.953562 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:25:04,919 [Epoch: 002 Step: 00000336] Batch Translation Loss:   6.616414 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:25:41,873 [Epoch: 002 Step: 00000337] Batch Translation Loss:   6.370969 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:26:52,388 [Epoch: 002 Step: 00000338] Batch Translation Loss:   7.218478 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 02:27:32,608 [Epoch: 002 Step: 00000339] Batch Translation Loss:   7.128441 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:28:09,015 [Epoch: 002 Step: 00000340] Batch Translation Loss:   7.179694 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 02:28:09,156 Epoch   2: Total Training Recognition Loss -1.00  Total Training Translation Loss 1212.64 
2021-12-28 02:28:09,157 EPOCH 3
2021-12-28 02:28:16,039 [Epoch: 003 Step: 00000341] Batch Translation Loss:   6.288059 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-28 02:28:21,922 [Epoch: 003 Step: 00000342] Batch Translation Loss:   7.116201 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-28 02:28:29,712 [Epoch: 003 Step: 00000343] Batch Translation Loss:   7.358672 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-28 02:28:38,909 [Epoch: 003 Step: 00000344] Batch Translation Loss:   7.369006 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 02:28:52,135 [Epoch: 003 Step: 00000345] Batch Translation Loss:   7.504689 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:29:02,368 [Epoch: 003 Step: 00000346] Batch Translation Loss:   7.423452 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 02:29:14,334 [Epoch: 003 Step: 00000347] Batch Translation Loss:   7.071872 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 02:29:23,007 [Epoch: 003 Step: 00000348] Batch Translation Loss:   7.066443 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-28 02:29:33,756 [Epoch: 003 Step: 00000349] Batch Translation Loss:   6.867884 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 02:29:48,452 [Epoch: 003 Step: 00000350] Batch Translation Loss:   7.218286 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:30:00,617 [Epoch: 003 Step: 00000351] Batch Translation Loss:   7.098079 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 02:30:15,054 [Epoch: 003 Step: 00000352] Batch Translation Loss:   7.035700 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:30:24,383 [Epoch: 003 Step: 00000353] Batch Translation Loss:   7.274913 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 02:30:37,320 [Epoch: 003 Step: 00000354] Batch Translation Loss:   6.883978 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:30:46,660 [Epoch: 003 Step: 00000355] Batch Translation Loss:   7.106458 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 02:30:55,635 [Epoch: 003 Step: 00000356] Batch Translation Loss:   6.787710 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-28 02:31:09,859 [Epoch: 003 Step: 00000357] Batch Translation Loss:   7.109674 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:31:27,109 [Epoch: 003 Step: 00000358] Batch Translation Loss:   6.863663 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:31:38,176 [Epoch: 003 Step: 00000359] Batch Translation Loss:   7.082656 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 02:31:47,681 [Epoch: 003 Step: 00000360] Batch Translation Loss:   7.154551 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 02:32:04,167 [Epoch: 003 Step: 00000361] Batch Translation Loss:   7.218925 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:32:19,516 [Epoch: 003 Step: 00000362] Batch Translation Loss:   7.031898 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:32:37,824 [Epoch: 003 Step: 00000363] Batch Translation Loss:   6.962603 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:32:54,791 [Epoch: 003 Step: 00000364] Batch Translation Loss:   6.715350 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:33:09,615 [Epoch: 003 Step: 00000365] Batch Translation Loss:   5.869401 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:33:25,638 [Epoch: 003 Step: 00000366] Batch Translation Loss:   6.578751 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:33:38,122 [Epoch: 003 Step: 00000367] Batch Translation Loss:   7.055691 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 02:33:49,337 [Epoch: 003 Step: 00000368] Batch Translation Loss:   6.572364 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 02:34:09,655 [Epoch: 003 Step: 00000369] Batch Translation Loss:   6.652287 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:34:25,396 [Epoch: 003 Step: 00000370] Batch Translation Loss:   6.068761 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:34:41,501 [Epoch: 003 Step: 00000371] Batch Translation Loss:   6.963364 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:34:56,382 [Epoch: 003 Step: 00000372] Batch Translation Loss:   6.360080 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:35:09,655 [Epoch: 003 Step: 00000373] Batch Translation Loss:   7.401031 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:35:26,198 [Epoch: 003 Step: 00000374] Batch Translation Loss:   7.167396 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:35:43,170 [Epoch: 003 Step: 00000375] Batch Translation Loss:   6.836808 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:35:57,071 [Epoch: 003 Step: 00000376] Batch Translation Loss:   6.583633 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:36:10,958 [Epoch: 003 Step: 00000377] Batch Translation Loss:   6.551592 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:36:26,293 [Epoch: 003 Step: 00000378] Batch Translation Loss:   7.294677 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:36:43,969 [Epoch: 003 Step: 00000379] Batch Translation Loss:   6.670837 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:36:56,537 [Epoch: 003 Step: 00000380] Batch Translation Loss:   7.319760 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 02:37:08,770 [Epoch: 003 Step: 00000381] Batch Translation Loss:   6.660328 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 02:37:21,788 [Epoch: 003 Step: 00000382] Batch Translation Loss:   6.764915 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:37:34,666 [Epoch: 003 Step: 00000383] Batch Translation Loss:   6.583099 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:37:49,630 [Epoch: 003 Step: 00000384] Batch Translation Loss:   6.861738 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:38:16,827 [Epoch: 003 Step: 00000385] Batch Translation Loss:   6.524907 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:38:50,429 [Epoch: 003 Step: 00000386] Batch Translation Loss:   7.098458 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:39:08,047 [Epoch: 003 Step: 00000387] Batch Translation Loss:   8.076982 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:39:25,612 [Epoch: 003 Step: 00000388] Batch Translation Loss:   7.308774 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:39:42,912 [Epoch: 003 Step: 00000389] Batch Translation Loss:   6.577624 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:40:02,509 [Epoch: 003 Step: 00000390] Batch Translation Loss:   7.041150 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:40:19,174 [Epoch: 003 Step: 00000391] Batch Translation Loss:   6.580895 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:40:38,730 [Epoch: 003 Step: 00000392] Batch Translation Loss:   7.038419 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:40:58,424 [Epoch: 003 Step: 00000393] Batch Translation Loss:   6.929611 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:41:15,644 [Epoch: 003 Step: 00000394] Batch Translation Loss:   6.782051 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:41:35,638 [Epoch: 003 Step: 00000395] Batch Translation Loss:   6.550140 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:41:53,634 [Epoch: 003 Step: 00000396] Batch Translation Loss:   6.976902 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:42:13,336 [Epoch: 003 Step: 00000397] Batch Translation Loss:   6.600120 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:42:30,359 [Epoch: 003 Step: 00000398] Batch Translation Loss:   6.806720 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:42:50,502 [Epoch: 003 Step: 00000399] Batch Translation Loss:   6.355767 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:43:10,104 [Epoch: 003 Step: 00000400] Batch Translation Loss:   7.011934 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:50:25,414 Validation result at epoch   3, step      400: duration: 435.2907s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 7931.59033	PPL: 3711.77319
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 1.86,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 5.68	ROUGE 2.99
2021-12-28 02:50:34,167 Logging Recognition and Translation Outputs
2021-12-28 02:50:34,219 ========================================================================================================================
2021-12-28 02:50:34,219 Logging Sequence: youtube_1-don_grushkin_2311
2021-12-28 02:50:34,220 	Text Reference  :	mic
2021-12-28 02:50:34,220 	Text Hypothesis :	or 
2021-12-28 02:50:34,221 	Text Alignment  :	S  
2021-12-28 02:50:34,221 ========================================================================================================================
2021-12-28 02:50:34,221 Logging Sequence: youtube_4-sean_berdy_5753
2021-12-28 02:50:34,221 	Text Reference  :	if 
2021-12-28 02:50:34,221 	Text Hypothesis :	asl
2021-12-28 02:50:34,221 	Text Alignment  :	S  
2021-12-28 02:50:34,222 ========================================================================================================================
2021-12-28 02:50:34,222 Logging Sequence: deafvideo_2-fairytales9_2280
2021-12-28 02:50:34,222 	Text Reference  :	ovn
2021-12-28 02:50:34,222 	Text Hypothesis :	asl
2021-12-28 02:50:34,222 	Text Alignment  :	S  
2021-12-28 02:50:34,222 ========================================================================================================================
2021-12-28 02:50:34,222 Logging Sequence: youtube_5-caroline_jackson_5851
2021-12-28 02:50:34,223 	Text Reference  :	bobbi cordano
2021-12-28 02:50:34,223 	Text Hypothesis :	***** asl    
2021-12-28 02:50:34,223 	Text Alignment  :	D     S      
2021-12-28 02:50:34,223 ========================================================================================================================
2021-12-28 02:50:34,223 Logging Sequence: youtube_4-howard_rosenblum_5561
2021-12-28 02:50:34,223 	Text Reference  :	ntid
2021-12-28 02:50:34,224 	Text Hypothesis :	asl 
2021-12-28 02:50:34,224 	Text Alignment  :	S   
2021-12-28 02:50:34,224 ========================================================================================================================
2021-12-28 02:51:45,760 [Epoch: 003 Step: 00000401] Batch Translation Loss:   7.285117 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 02:52:24,327 [Epoch: 003 Step: 00000402] Batch Translation Loss:   6.375441 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:52:44,438 [Epoch: 003 Step: 00000403] Batch Translation Loss:   7.563695 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:53:02,927 [Epoch: 003 Step: 00000404] Batch Translation Loss:   6.475672 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:53:20,657 [Epoch: 003 Step: 00000405] Batch Translation Loss:   6.621366 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:53:42,488 [Epoch: 003 Step: 00000406] Batch Translation Loss:   7.373571 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:54:01,763 [Epoch: 003 Step: 00000407] Batch Translation Loss:   6.584918 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:54:21,439 [Epoch: 003 Step: 00000408] Batch Translation Loss:   7.136460 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:54:48,735 [Epoch: 003 Step: 00000409] Batch Translation Loss:   6.883410 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:55:07,964 [Epoch: 003 Step: 00000410] Batch Translation Loss:   7.002047 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:55:29,849 [Epoch: 003 Step: 00000411] Batch Translation Loss:   7.358865 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:55:53,106 [Epoch: 003 Step: 00000412] Batch Translation Loss:   7.080215 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:56:15,912 [Epoch: 003 Step: 00000413] Batch Translation Loss:   6.868264 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:56:42,801 [Epoch: 003 Step: 00000414] Batch Translation Loss:   6.834975 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:57:07,334 [Epoch: 003 Step: 00000415] Batch Translation Loss:   6.180401 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:57:29,406 [Epoch: 003 Step: 00000416] Batch Translation Loss:   6.477168 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:57:50,526 [Epoch: 003 Step: 00000417] Batch Translation Loss:   6.983659 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 02:58:17,565 [Epoch: 003 Step: 00000418] Batch Translation Loss:   6.278241 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:58:40,684 [Epoch: 003 Step: 00000419] Batch Translation Loss:   6.578742 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:59:22,257 [Epoch: 003 Step: 00000420] Batch Translation Loss:   6.847462 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 02:59:43,230 [Epoch: 003 Step: 00000421] Batch Translation Loss:   6.811574 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 03:00:04,806 [Epoch: 003 Step: 00000422] Batch Translation Loss:   7.194964 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:00:22,532 [Epoch: 003 Step: 00000423] Batch Translation Loss:   6.749172 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 03:00:44,339 [Epoch: 003 Step: 00000424] Batch Translation Loss:   7.128166 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:01:09,872 [Epoch: 003 Step: 00000425] Batch Translation Loss:   6.875868 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:01:37,789 [Epoch: 003 Step: 00000426] Batch Translation Loss:   6.812609 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:02:02,954 [Epoch: 003 Step: 00000427] Batch Translation Loss:   6.836215 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:02:27,519 [Epoch: 003 Step: 00000428] Batch Translation Loss:   6.947385 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:02:51,021 [Epoch: 003 Step: 00000429] Batch Translation Loss:   6.435952 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:03:16,997 [Epoch: 003 Step: 00000430] Batch Translation Loss:   6.481294 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:03:42,411 [Epoch: 003 Step: 00000431] Batch Translation Loss:   6.352387 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:04:09,644 [Epoch: 003 Step: 00000432] Batch Translation Loss:   6.295754 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:04:35,331 [Epoch: 003 Step: 00000433] Batch Translation Loss:   6.158582 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:05:20,424 [Epoch: 003 Step: 00000434] Batch Translation Loss:   6.816487 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:05:46,255 [Epoch: 003 Step: 00000435] Batch Translation Loss:   7.289887 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:06:13,565 [Epoch: 003 Step: 00000436] Batch Translation Loss:   7.242870 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:06:40,062 [Epoch: 003 Step: 00000437] Batch Translation Loss:   6.731431 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:07:03,568 [Epoch: 003 Step: 00000438] Batch Translation Loss:   6.827996 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:07:25,502 [Epoch: 003 Step: 00000439] Batch Translation Loss:   6.230915 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:07:45,754 [Epoch: 003 Step: 00000440] Batch Translation Loss:   7.093872 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 03:08:11,415 [Epoch: 003 Step: 00000441] Batch Translation Loss:   7.074867 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:08:35,669 [Epoch: 003 Step: 00000442] Batch Translation Loss:   6.818556 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:09:11,870 [Epoch: 003 Step: 00000443] Batch Translation Loss:   7.073842 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:09:38,726 [Epoch: 003 Step: 00000444] Batch Translation Loss:   6.800374 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:10:08,945 [Epoch: 003 Step: 00000445] Batch Translation Loss:   6.634775 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:10:37,502 [Epoch: 003 Step: 00000446] Batch Translation Loss:   6.574095 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:11:07,838 [Epoch: 003 Step: 00000447] Batch Translation Loss:   7.373207 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:11:34,976 [Epoch: 003 Step: 00000448] Batch Translation Loss:   6.564829 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:12:05,125 [Epoch: 003 Step: 00000449] Batch Translation Loss:   7.016296 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:12:34,474 [Epoch: 003 Step: 00000450] Batch Translation Loss:   6.426230 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:13:04,862 [Epoch: 003 Step: 00000451] Batch Translation Loss:   6.227781 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:13:34,982 [Epoch: 003 Step: 00000452] Batch Translation Loss:   6.369741 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:14:03,778 [Epoch: 003 Step: 00000453] Batch Translation Loss:   6.067778 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:14:34,155 [Epoch: 003 Step: 00000454] Batch Translation Loss:   6.573776 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:15:20,506 [Epoch: 003 Step: 00000455] Batch Translation Loss:   6.914490 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:16:03,420 [Epoch: 003 Step: 00000456] Batch Translation Loss:   6.692877 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:16:29,567 [Epoch: 003 Step: 00000457] Batch Translation Loss:   6.748670 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:16:59,762 [Epoch: 003 Step: 00000458] Batch Translation Loss:   6.782417 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:17:32,204 [Epoch: 003 Step: 00000459] Batch Translation Loss:   6.287931 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:18:09,914 [Epoch: 003 Step: 00000460] Batch Translation Loss:   7.028908 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:18:39,362 [Epoch: 003 Step: 00000461] Batch Translation Loss:   6.893524 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:19:11,170 [Epoch: 003 Step: 00000462] Batch Translation Loss:   6.740114 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:19:41,987 [Epoch: 003 Step: 00000463] Batch Translation Loss:   6.441035 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:20:13,311 [Epoch: 003 Step: 00000464] Batch Translation Loss:   6.193941 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:20:42,527 [Epoch: 003 Step: 00000465] Batch Translation Loss:   6.691336 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:21:17,083 [Epoch: 003 Step: 00000466] Batch Translation Loss:   6.657494 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:21:49,906 [Epoch: 003 Step: 00000467] Batch Translation Loss:   6.787748 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:22:24,419 [Epoch: 003 Step: 00000468] Batch Translation Loss:   6.783750 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:22:54,186 [Epoch: 003 Step: 00000469] Batch Translation Loss:   6.447422 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:23:19,238 [Epoch: 003 Step: 00000470] Batch Translation Loss:   6.748827 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:23:44,586 [Epoch: 003 Step: 00000471] Batch Translation Loss:   7.219247 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:24:15,491 [Epoch: 003 Step: 00000472] Batch Translation Loss:   6.641117 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:24:54,723 [Epoch: 003 Step: 00000473] Batch Translation Loss:   6.843283 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:25:24,827 [Epoch: 003 Step: 00000474] Batch Translation Loss:   6.197982 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:26:02,443 [Epoch: 003 Step: 00000475] Batch Translation Loss:   7.022317 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:26:41,731 [Epoch: 003 Step: 00000476] Batch Translation Loss:   6.878970 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:27:14,602 [Epoch: 003 Step: 00000477] Batch Translation Loss:   6.350730 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:28:01,480 [Epoch: 003 Step: 00000478] Batch Translation Loss:   7.008193 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:28:37,433 [Epoch: 003 Step: 00000479] Batch Translation Loss:   6.971639 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:29:11,020 [Epoch: 003 Step: 00000480] Batch Translation Loss:   7.087363 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:29:52,969 [Epoch: 003 Step: 00000481] Batch Translation Loss:   6.778558 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:30:26,552 [Epoch: 003 Step: 00000482] Batch Translation Loss:   6.162798 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:30:57,219 [Epoch: 003 Step: 00000483] Batch Translation Loss:   6.661282 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:31:26,511 [Epoch: 003 Step: 00000484] Batch Translation Loss:   6.863699 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:32:25,293 [Epoch: 003 Step: 00000485] Batch Translation Loss:   7.461923 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:33:10,493 [Epoch: 003 Step: 00000486] Batch Translation Loss:   6.634790 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:34:18,502 [Epoch: 003 Step: 00000487] Batch Translation Loss:   6.573458 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 03:34:54,216 [Epoch: 003 Step: 00000488] Batch Translation Loss:   6.924417 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:35:32,358 [Epoch: 003 Step: 00000489] Batch Translation Loss:   6.718070 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:36:06,299 [Epoch: 003 Step: 00000490] Batch Translation Loss:   6.919920 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:36:44,101 [Epoch: 003 Step: 00000491] Batch Translation Loss:   7.232716 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:37:18,614 [Epoch: 003 Step: 00000492] Batch Translation Loss:   7.027479 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:38:00,484 [Epoch: 003 Step: 00000493] Batch Translation Loss:   6.427349 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:38:38,281 [Epoch: 003 Step: 00000494] Batch Translation Loss:   6.971107 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:39:12,605 [Epoch: 003 Step: 00000495] Batch Translation Loss:   6.781225 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:39:41,753 [Epoch: 003 Step: 00000496] Batch Translation Loss:   7.201452 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:40:42,954 [Epoch: 003 Step: 00000497] Batch Translation Loss:   6.791399 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:41:54,552 [Epoch: 003 Step: 00000498] Batch Translation Loss:   6.513371 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 03:42:34,625 [Epoch: 003 Step: 00000499] Batch Translation Loss:   6.706180 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:43:12,127 [Epoch: 003 Step: 00000500] Batch Translation Loss:   5.684270 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:50:24,903 Validation result at epoch   3, step      500: duration: 432.7292s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 7793.87109	PPL: 3624.41431
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 1.58,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 4.99	ROUGE 2.22
2021-12-28 03:50:31,541 Logging Recognition and Translation Outputs
2021-12-28 03:50:31,603 ========================================================================================================================
2021-12-28 03:50:31,604 Logging Sequence: youtube_1-don_grushkin_2774
2021-12-28 03:50:31,604 	Text Reference  :	of it 
2021-12-28 03:50:31,605 	Text Hypothesis :	** asl
2021-12-28 03:50:31,605 	Text Alignment  :	D  S  
2021-12-28 03:50:31,605 ========================================================================================================================
2021-12-28 03:50:31,605 Logging Sequence: youtube_1-don_grushkin_2303
2021-12-28 03:50:31,606 	Text Reference  :	* *** ovn
2021-12-28 03:50:31,606 	Text Hypothesis :	l asl lit
2021-12-28 03:50:31,606 	Text Alignment  :	I I   S  
2021-12-28 03:50:31,606 ========================================================================================================================
2021-12-28 03:50:31,606 Logging Sequence: youtube_5-sean_berdy_6100
2021-12-28 03:50:31,607 	Text Reference  :	* *** outeach
2021-12-28 03:50:31,607 	Text Hypothesis :	l asl lit    
2021-12-28 03:50:31,607 	Text Alignment  :	I I   S      
2021-12-28 03:50:31,607 ========================================================================================================================
2021-12-28 03:50:31,607 Logging Sequence: aslized-suzanne_stecker_0198
2021-12-28 03:50:31,608 	Text Reference  :	all senses
2021-12-28 03:50:31,608 	Text Hypothesis :	*** so    
2021-12-28 03:50:31,608 	Text Alignment  :	D   S     
2021-12-28 03:50:31,608 ========================================================================================================================
2021-12-28 03:50:31,608 Logging Sequence: deafvideo_2-deafpoweronethumbtwo_1794
2021-12-28 03:50:31,609 	Text Reference  :	dona carell
2021-12-28 03:50:31,609 	Text Hypothesis :	**** asl   
2021-12-28 03:50:31,609 	Text Alignment  :	D    S     
2021-12-28 03:50:31,609 ========================================================================================================================
2021-12-28 03:52:53,952 [Epoch: 003 Step: 00000501] Batch Translation Loss:   6.646581 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 03:53:47,920 [Epoch: 003 Step: 00000502] Batch Translation Loss:   6.802956 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:54:23,331 [Epoch: 003 Step: 00000503] Batch Translation Loss:   6.717607 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:54:59,034 [Epoch: 003 Step: 00000504] Batch Translation Loss:   6.918950 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:55:38,835 [Epoch: 003 Step: 00000505] Batch Translation Loss:   6.882966 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:56:17,232 [Epoch: 003 Step: 00000506] Batch Translation Loss:   6.785317 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:56:48,830 [Epoch: 003 Step: 00000507] Batch Translation Loss:   6.870232 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:57:50,960 [Epoch: 003 Step: 00000508] Batch Translation Loss:   6.456476 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:58:36,160 [Epoch: 003 Step: 00000509] Batch Translation Loss:   7.082224 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 03:59:46,049 [Epoch: 003 Step: 00000510] Batch Translation Loss:   6.774376 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 03:59:46,526 Epoch   3: Total Training Recognition Loss -1.00  Total Training Translation Loss 1158.42 
2021-12-28 03:59:46,526 EPOCH 4
2021-12-28 03:59:54,533 [Epoch: 004 Step: 00000511] Batch Translation Loss:   7.372747 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-28 04:00:02,727 [Epoch: 004 Step: 00000512] Batch Translation Loss:   7.118492 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-28 04:00:12,182 [Epoch: 004 Step: 00000513] Batch Translation Loss:   7.183419 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 04:00:20,802 [Epoch: 004 Step: 00000514] Batch Translation Loss:   6.921757 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-28 04:00:31,599 [Epoch: 004 Step: 00000515] Batch Translation Loss:   7.140625 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 04:00:41,681 [Epoch: 004 Step: 00000516] Batch Translation Loss:   7.247424 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 04:00:55,509 [Epoch: 004 Step: 00000517] Batch Translation Loss:   6.886489 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:01:04,449 [Epoch: 004 Step: 00000518] Batch Translation Loss:   7.569253 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-28 04:01:14,025 [Epoch: 004 Step: 00000519] Batch Translation Loss:   6.738701 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 04:01:24,862 [Epoch: 004 Step: 00000520] Batch Translation Loss:   6.589921 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 04:01:35,157 [Epoch: 004 Step: 00000521] Batch Translation Loss:   6.866388 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 04:01:48,255 [Epoch: 004 Step: 00000522] Batch Translation Loss:   7.857427 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:01:58,835 [Epoch: 004 Step: 00000523] Batch Translation Loss:   7.080948 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 04:02:11,360 [Epoch: 004 Step: 00000524] Batch Translation Loss:   7.021791 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 04:02:21,571 [Epoch: 004 Step: 00000525] Batch Translation Loss:   6.875644 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 04:02:34,914 [Epoch: 004 Step: 00000526] Batch Translation Loss:   6.488392 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:02:47,050 [Epoch: 004 Step: 00000527] Batch Translation Loss:   6.862135 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 04:03:07,030 [Epoch: 004 Step: 00000528] Batch Translation Loss:   6.558640 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:03:18,847 [Epoch: 004 Step: 00000529] Batch Translation Loss:   6.477100 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 04:03:31,395 [Epoch: 004 Step: 00000530] Batch Translation Loss:   6.686888 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 04:03:41,736 [Epoch: 004 Step: 00000531] Batch Translation Loss:   6.905873 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 04:04:01,304 [Epoch: 004 Step: 00000532] Batch Translation Loss:   6.595815 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:04:16,029 [Epoch: 004 Step: 00000533] Batch Translation Loss:   7.051661 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:04:26,664 [Epoch: 004 Step: 00000534] Batch Translation Loss:   6.949975 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 04:04:41,574 [Epoch: 004 Step: 00000535] Batch Translation Loss:   6.710941 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:04:52,270 [Epoch: 004 Step: 00000536] Batch Translation Loss:   6.634590 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 04:05:01,879 [Epoch: 004 Step: 00000537] Batch Translation Loss:   6.945066 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 04:05:14,583 [Epoch: 004 Step: 00000538] Batch Translation Loss:   6.670834 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 04:05:26,168 [Epoch: 004 Step: 00000539] Batch Translation Loss:   6.766420 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 04:05:38,414 [Epoch: 004 Step: 00000540] Batch Translation Loss:   6.485684 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 04:06:04,087 [Epoch: 004 Step: 00000541] Batch Translation Loss:   6.704373 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:06:18,515 [Epoch: 004 Step: 00000542] Batch Translation Loss:   6.611909 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:06:32,118 [Epoch: 004 Step: 00000543] Batch Translation Loss:   6.260561 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:06:46,643 [Epoch: 004 Step: 00000544] Batch Translation Loss:   6.503569 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:07:03,162 [Epoch: 004 Step: 00000545] Batch Translation Loss:   6.924989 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:07:19,913 [Epoch: 004 Step: 00000546] Batch Translation Loss:   5.510259 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:07:34,480 [Epoch: 004 Step: 00000547] Batch Translation Loss:   6.870021 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:07:59,629 [Epoch: 004 Step: 00000548] Batch Translation Loss:   6.838423 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:08:16,811 [Epoch: 004 Step: 00000549] Batch Translation Loss:   6.696153 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:08:32,627 [Epoch: 004 Step: 00000550] Batch Translation Loss:   6.765785 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:08:47,790 [Epoch: 004 Step: 00000551] Batch Translation Loss:   6.714011 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:09:02,424 [Epoch: 004 Step: 00000552] Batch Translation Loss:   6.794026 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:09:18,468 [Epoch: 004 Step: 00000553] Batch Translation Loss:   6.621569 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:09:36,146 [Epoch: 004 Step: 00000554] Batch Translation Loss:   6.593670 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:09:50,678 [Epoch: 004 Step: 00000555] Batch Translation Loss:   6.496528 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:10:06,399 [Epoch: 004 Step: 00000556] Batch Translation Loss:   6.795309 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:10:23,209 [Epoch: 004 Step: 00000557] Batch Translation Loss:   6.815566 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:10:40,851 [Epoch: 004 Step: 00000558] Batch Translation Loss:   6.783463 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:10:56,314 [Epoch: 004 Step: 00000559] Batch Translation Loss:   6.633839 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:11:13,462 [Epoch: 004 Step: 00000560] Batch Translation Loss:   6.227190 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:11:31,240 [Epoch: 004 Step: 00000561] Batch Translation Loss:   6.262115 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:11:49,701 [Epoch: 004 Step: 00000562] Batch Translation Loss:   6.620140 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:12:06,818 [Epoch: 004 Step: 00000563] Batch Translation Loss:   6.828721 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:12:24,940 [Epoch: 004 Step: 00000564] Batch Translation Loss:   6.725307 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:12:53,497 [Epoch: 004 Step: 00000565] Batch Translation Loss:   6.849222 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:13:08,532 [Epoch: 004 Step: 00000566] Batch Translation Loss:   6.755920 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:13:24,508 [Epoch: 004 Step: 00000567] Batch Translation Loss:   6.984140 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:13:42,020 [Epoch: 004 Step: 00000568] Batch Translation Loss:   7.043942 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:13:58,361 [Epoch: 004 Step: 00000569] Batch Translation Loss:   6.902666 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:14:30,176 [Epoch: 004 Step: 00000570] Batch Translation Loss:   6.496424 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:14:53,631 [Epoch: 004 Step: 00000571] Batch Translation Loss:   5.926928 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:15:29,484 [Epoch: 004 Step: 00000572] Batch Translation Loss:   6.860436 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:15:54,467 [Epoch: 004 Step: 00000573] Batch Translation Loss:   6.405282 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:16:12,980 [Epoch: 004 Step: 00000574] Batch Translation Loss:   5.839265 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:16:32,018 [Epoch: 004 Step: 00000575] Batch Translation Loss:   7.056276 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:16:56,463 [Epoch: 004 Step: 00000576] Batch Translation Loss:   7.319414 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:17:15,956 [Epoch: 004 Step: 00000577] Batch Translation Loss:   6.843294 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:17:33,579 [Epoch: 004 Step: 00000578] Batch Translation Loss:   6.335614 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:17:55,843 [Epoch: 004 Step: 00000579] Batch Translation Loss:   6.587936 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:18:19,024 [Epoch: 004 Step: 00000580] Batch Translation Loss:   6.935396 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:19:00,993 [Epoch: 004 Step: 00000581] Batch Translation Loss:   6.113300 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:19:25,084 [Epoch: 004 Step: 00000582] Batch Translation Loss:   7.057507 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:19:48,716 [Epoch: 004 Step: 00000583] Batch Translation Loss:   6.357897 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:20:09,878 [Epoch: 004 Step: 00000584] Batch Translation Loss:   6.375337 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:20:47,919 [Epoch: 004 Step: 00000585] Batch Translation Loss:   7.023966 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:21:07,570 [Epoch: 004 Step: 00000586] Batch Translation Loss:   5.987975 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:21:25,370 [Epoch: 004 Step: 00000587] Batch Translation Loss:   5.968828 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:21:42,250 [Epoch: 004 Step: 00000588] Batch Translation Loss:   6.187282 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:22:01,278 [Epoch: 004 Step: 00000589] Batch Translation Loss:   6.577073 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:22:36,476 [Epoch: 004 Step: 00000590] Batch Translation Loss:   6.743291 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:23:04,658 [Epoch: 004 Step: 00000591] Batch Translation Loss:   7.320677 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:23:26,974 [Epoch: 004 Step: 00000592] Batch Translation Loss:   6.993453 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:23:46,910 [Epoch: 004 Step: 00000593] Batch Translation Loss:   6.689545 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:24:15,715 [Epoch: 004 Step: 00000594] Batch Translation Loss:   6.455763 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:24:38,267 [Epoch: 004 Step: 00000595] Batch Translation Loss:   7.190191 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:25:20,011 [Epoch: 004 Step: 00000596] Batch Translation Loss:   6.631037 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:25:46,068 [Epoch: 004 Step: 00000597] Batch Translation Loss:   6.889816 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:26:08,229 [Epoch: 004 Step: 00000598] Batch Translation Loss:   6.813560 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:26:35,268 [Epoch: 004 Step: 00000599] Batch Translation Loss:   6.520987 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:26:58,526 [Epoch: 004 Step: 00000600] Batch Translation Loss:   6.979974 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:34:08,520 Validation result at epoch   4, step      600: duration: 429.9546s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 7999.19873	PPL: 4380.43750
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 2.53,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 5.31	ROUGE 2.19
2021-12-28 04:34:15,863 Logging Recognition and Translation Outputs
2021-12-28 04:34:15,919 ========================================================================================================================
2021-12-28 04:34:15,919 Logging Sequence: youtube_5-sean_berdy_6107
2021-12-28 04:34:15,919 	Text Reference  :	mssd
2021-12-28 04:34:15,919 	Text Hypothesis :	asl 
2021-12-28 04:34:15,919 	Text Alignment  :	S   
2021-12-28 04:34:15,920 ========================================================================================================================
2021-12-28 04:34:15,920 Logging Sequence: youtube_1-don_grushkin_2304
2021-12-28 04:34:15,920 	Text Reference  :	******** map   
2021-12-28 04:34:15,920 	Text Hypothesis :	reilable source
2021-12-28 04:34:15,920 	Text Alignment  :	I        S     
2021-12-28 04:34:15,920 ========================================================================================================================
2021-12-28 04:34:15,920 Logging Sequence: deafvideo_2-fairytales9_2283
2021-12-28 04:34:15,920 	Text Reference  :	n zone nfl
2021-12-28 04:34:15,920 	Text Hypothesis :	* **** ok 
2021-12-28 04:34:15,921 	Text Alignment  :	D D    S  
2021-12-28 04:34:15,921 ========================================================================================================================
2021-12-28 04:34:15,921 Logging Sequence: deafvideo_3-yellowbirdie84_4668
2021-12-28 04:34:15,921 	Text Reference  :	nyke prince
2021-12-28 04:34:15,921 	Text Hypothesis :	riot gar   
2021-12-28 04:34:15,921 	Text Alignment  :	S    S     
2021-12-28 04:34:15,921 ========================================================================================================================
2021-12-28 04:34:15,921 Logging Sequence: youtube_5-debra_patkin_5790
2021-12-28 04:34:15,921 	Text Reference  :	******** it    
2021-12-28 04:34:15,921 	Text Hypothesis :	reilable source
2021-12-28 04:34:15,921 	Text Alignment  :	I        S     
2021-12-28 04:34:15,922 ========================================================================================================================
2021-12-28 04:36:55,184 [Epoch: 004 Step: 00000601] Batch Translation Loss:   6.933557 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 04:37:26,263 [Epoch: 004 Step: 00000602] Batch Translation Loss:   6.978802 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:37:50,248 [Epoch: 004 Step: 00000603] Batch Translation Loss:   6.049883 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:38:16,683 [Epoch: 004 Step: 00000604] Batch Translation Loss:   6.867925 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:38:37,277 [Epoch: 004 Step: 00000605] Batch Translation Loss:   6.504107 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:38:57,621 [Epoch: 004 Step: 00000606] Batch Translation Loss:   6.670611 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 04:39:19,665 [Epoch: 004 Step: 00000607] Batch Translation Loss:   6.441826 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:39:41,725 [Epoch: 004 Step: 00000608] Batch Translation Loss:   7.012348 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:40:05,062 [Epoch: 004 Step: 00000609] Batch Translation Loss:   6.961111 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:40:38,383 [Epoch: 004 Step: 00000610] Batch Translation Loss:   6.127704 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:41:09,274 [Epoch: 004 Step: 00000611] Batch Translation Loss:   6.215821 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:41:36,716 [Epoch: 004 Step: 00000612] Batch Translation Loss:   6.412620 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:42:02,579 [Epoch: 004 Step: 00000613] Batch Translation Loss:   6.741425 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:42:32,144 [Epoch: 004 Step: 00000614] Batch Translation Loss:   6.992338 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:42:59,517 [Epoch: 004 Step: 00000615] Batch Translation Loss:   6.804915 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:43:28,031 [Epoch: 004 Step: 00000616] Batch Translation Loss:   6.733677 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:44:18,378 [Epoch: 004 Step: 00000617] Batch Translation Loss:   6.590735 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:44:46,991 [Epoch: 004 Step: 00000618] Batch Translation Loss:   7.382879 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:45:34,475 [Epoch: 004 Step: 00000619] Batch Translation Loss:   6.648973 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:46:06,867 [Epoch: 004 Step: 00000620] Batch Translation Loss:   6.749673 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:46:36,324 [Epoch: 004 Step: 00000621] Batch Translation Loss:   6.813576 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:46:59,355 [Epoch: 004 Step: 00000622] Batch Translation Loss:   6.090412 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:47:22,146 [Epoch: 004 Step: 00000623] Batch Translation Loss:   6.929478 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:47:49,132 [Epoch: 004 Step: 00000624] Batch Translation Loss:   6.595811 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:48:20,267 [Epoch: 004 Step: 00000625] Batch Translation Loss:   6.620581 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:48:55,943 [Epoch: 004 Step: 00000626] Batch Translation Loss:   7.219013 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:49:28,913 [Epoch: 004 Step: 00000627] Batch Translation Loss:   6.347477 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:50:03,291 [Epoch: 004 Step: 00000628] Batch Translation Loss:   6.190784 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:50:34,730 [Epoch: 004 Step: 00000629] Batch Translation Loss:   6.907882 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:51:18,014 [Epoch: 004 Step: 00000630] Batch Translation Loss:   6.755745 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:51:48,497 [Epoch: 004 Step: 00000631] Batch Translation Loss:   6.924447 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:52:24,506 [Epoch: 004 Step: 00000632] Batch Translation Loss:   6.827685 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:52:55,704 [Epoch: 004 Step: 00000633] Batch Translation Loss:   6.838218 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:53:23,100 [Epoch: 004 Step: 00000634] Batch Translation Loss:   6.839520 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:53:54,443 [Epoch: 004 Step: 00000635] Batch Translation Loss:   6.764765 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:54:26,369 [Epoch: 004 Step: 00000636] Batch Translation Loss:   6.175261 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:54:53,369 [Epoch: 004 Step: 00000637] Batch Translation Loss:   6.752716 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:55:21,405 [Epoch: 004 Step: 00000638] Batch Translation Loss:   7.737660 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:55:49,908 [Epoch: 004 Step: 00000639] Batch Translation Loss:   6.296075 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:56:22,227 [Epoch: 004 Step: 00000640] Batch Translation Loss:   6.813844 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:56:56,721 [Epoch: 004 Step: 00000641] Batch Translation Loss:   6.685929 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:57:33,160 [Epoch: 004 Step: 00000642] Batch Translation Loss:   6.211599 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:58:03,988 [Epoch: 004 Step: 00000643] Batch Translation Loss:   6.755947 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:58:38,642 [Epoch: 004 Step: 00000644] Batch Translation Loss:   6.333668 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:59:11,048 [Epoch: 004 Step: 00000645] Batch Translation Loss:   6.423436 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 04:59:47,099 [Epoch: 004 Step: 00000646] Batch Translation Loss:   6.571577 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:00:22,081 [Epoch: 004 Step: 00000647] Batch Translation Loss:   6.834931 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:00:56,875 [Epoch: 004 Step: 00000648] Batch Translation Loss:   7.063514 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:01:34,856 [Epoch: 004 Step: 00000649] Batch Translation Loss:   5.931613 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:02:07,392 [Epoch: 004 Step: 00000650] Batch Translation Loss:   7.330844 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:02:54,992 [Epoch: 004 Step: 00000651] Batch Translation Loss:   6.703471 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:03:45,086 [Epoch: 004 Step: 00000652] Batch Translation Loss:   5.989594 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:04:19,764 [Epoch: 004 Step: 00000653] Batch Translation Loss:   6.602748 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:04:59,754 [Epoch: 004 Step: 00000654] Batch Translation Loss:   7.096252 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:05:34,019 [Epoch: 004 Step: 00000655] Batch Translation Loss:   6.444006 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:06:37,259 [Epoch: 004 Step: 00000656] Batch Translation Loss:   6.480400 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:07:15,573 [Epoch: 004 Step: 00000657] Batch Translation Loss:   6.436898 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:07:50,878 [Epoch: 004 Step: 00000658] Batch Translation Loss:   6.866873 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:08:29,434 [Epoch: 004 Step: 00000659] Batch Translation Loss:   6.588506 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:09:07,786 [Epoch: 004 Step: 00000660] Batch Translation Loss:   6.541838 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:09:43,959 [Epoch: 004 Step: 00000661] Batch Translation Loss:   5.972848 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:10:51,887 [Epoch: 004 Step: 00000662] Batch Translation Loss:   6.450464 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 05:11:22,034 [Epoch: 004 Step: 00000663] Batch Translation Loss:   6.789852 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:11:53,903 [Epoch: 004 Step: 00000664] Batch Translation Loss:   6.274096 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:12:34,713 [Epoch: 004 Step: 00000665] Batch Translation Loss:   6.515020 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:13:09,251 [Epoch: 004 Step: 00000666] Batch Translation Loss:   6.375777 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:13:45,861 [Epoch: 004 Step: 00000667] Batch Translation Loss:   6.244062 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:14:22,698 [Epoch: 004 Step: 00000668] Batch Translation Loss:   6.535083 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:15:01,100 [Epoch: 004 Step: 00000669] Batch Translation Loss:   6.559152 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:15:37,339 [Epoch: 004 Step: 00000670] Batch Translation Loss:   6.816901 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:16:15,825 [Epoch: 004 Step: 00000671] Batch Translation Loss:   6.596015 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:16:51,468 [Epoch: 004 Step: 00000672] Batch Translation Loss:   6.145033 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:17:30,388 [Epoch: 004 Step: 00000673] Batch Translation Loss:   7.116012 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:18:11,178 [Epoch: 004 Step: 00000674] Batch Translation Loss:   6.288179 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:18:47,640 [Epoch: 004 Step: 00000675] Batch Translation Loss:   5.810763 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:19:21,543 [Epoch: 004 Step: 00000676] Batch Translation Loss:   5.985089 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:19:52,653 [Epoch: 004 Step: 00000677] Batch Translation Loss:   6.319781 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:20:26,945 [Epoch: 004 Step: 00000678] Batch Translation Loss:   6.661623 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:21:05,340 [Epoch: 004 Step: 00000679] Batch Translation Loss:   6.314897 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:22:13,697 [Epoch: 004 Step: 00000680] Batch Translation Loss:   6.599006 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 05:22:14,075 Epoch   4: Total Training Recognition Loss -1.00  Total Training Translation Loss 1134.40 
2021-12-28 05:22:14,075 EPOCH 5
2021-12-28 05:22:21,480 [Epoch: 005 Step: 00000681] Batch Translation Loss:   6.937449 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-28 05:22:29,830 [Epoch: 005 Step: 00000682] Batch Translation Loss:   6.360251 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-28 05:22:37,549 [Epoch: 005 Step: 00000683] Batch Translation Loss:   6.616475 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-28 05:22:45,385 [Epoch: 005 Step: 00000684] Batch Translation Loss:   6.678441 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-28 05:22:55,329 [Epoch: 005 Step: 00000685] Batch Translation Loss:   6.456907 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 05:23:06,126 [Epoch: 005 Step: 00000686] Batch Translation Loss:   7.326344 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 05:23:15,991 [Epoch: 005 Step: 00000687] Batch Translation Loss:   6.645961 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 05:23:30,494 [Epoch: 005 Step: 00000688] Batch Translation Loss:   6.388050 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:23:43,827 [Epoch: 005 Step: 00000689] Batch Translation Loss:   7.389794 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:23:52,586 [Epoch: 005 Step: 00000690] Batch Translation Loss:   6.250953 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-28 05:24:03,105 [Epoch: 005 Step: 00000691] Batch Translation Loss:   6.302869 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 05:24:18,085 [Epoch: 005 Step: 00000692] Batch Translation Loss:   7.013850 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:24:36,901 [Epoch: 005 Step: 00000693] Batch Translation Loss:   6.808771 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:24:48,529 [Epoch: 005 Step: 00000694] Batch Translation Loss:   6.609547 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 05:25:01,125 [Epoch: 005 Step: 00000695] Batch Translation Loss:   6.941008 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 05:25:19,734 [Epoch: 005 Step: 00000696] Batch Translation Loss:   6.935019 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:25:32,626 [Epoch: 005 Step: 00000697] Batch Translation Loss:   6.474663 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:25:50,510 [Epoch: 005 Step: 00000698] Batch Translation Loss:   7.594527 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:26:09,370 [Epoch: 005 Step: 00000699] Batch Translation Loss:   6.901158 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:26:21,115 [Epoch: 005 Step: 00000700] Batch Translation Loss:   6.330514 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 05:33:39,082 Validation result at epoch   5, step      700: duration: 437.9465s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 8043.52295	PPL: 4097.02734
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 2.49,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 4.60	ROUGE 2.50
2021-12-28 05:33:45,613 Logging Recognition and Translation Outputs
2021-12-28 05:33:45,673 ========================================================================================================================
2021-12-28 05:33:45,674 Logging Sequence: youtube_6-myles_de_bastion_6519
2021-12-28 05:33:45,675 	Text Reference  :	ed    
2021-12-28 05:33:45,675 	Text Hypothesis :	beaver
2021-12-28 05:33:45,676 	Text Alignment  :	S     
2021-12-28 05:33:45,676 ========================================================================================================================
2021-12-28 05:33:45,676 Logging Sequence: youtube_1-don_grushkin_2318
2021-12-28 05:33:45,676 	Text Reference  :	onts
2021-12-28 05:33:45,677 	Text Hypothesis :	asl 
2021-12-28 05:33:45,677 	Text Alignment  :	S   
2021-12-28 05:33:45,677 ========================================================================================================================
2021-12-28 05:33:45,677 Logging Sequence: youtube_5-sean_berdy_6101
2021-12-28 05:33:45,678 	Text Reference  :	tool
2021-12-28 05:33:45,678 	Text Hypothesis :	or  
2021-12-28 05:33:45,678 	Text Alignment  :	S   
2021-12-28 05:33:45,678 ========================================================================================================================
2021-12-28 05:33:45,679 Logging Sequence: deafvideo_3-deafgoldenhair_3067
2021-12-28 05:33:45,679 	Text Reference  :	rollover
2021-12-28 05:33:45,679 	Text Hypothesis :	beaver  
2021-12-28 05:33:45,680 	Text Alignment  :	S       
2021-12-28 05:33:45,680 ========================================================================================================================
2021-12-28 05:33:45,680 Logging Sequence: deafvideo_3-titans_4691
2021-12-28 05:33:45,680 	Text Reference  :	asl
2021-12-28 05:33:45,681 	Text Hypothesis :	asl
2021-12-28 05:33:45,681 	Text Alignment  :	   
2021-12-28 05:33:45,681 ========================================================================================================================
2021-12-28 05:34:34,521 [Epoch: 005 Step: 00000701] Batch Translation Loss:   6.559562 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:35:03,648 [Epoch: 005 Step: 00000702] Batch Translation Loss:   7.029887 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:35:29,635 [Epoch: 005 Step: 00000703] Batch Translation Loss:   6.468140 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:36:12,678 [Epoch: 005 Step: 00000704] Batch Translation Loss:   6.611921 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:36:31,465 [Epoch: 005 Step: 00000705] Batch Translation Loss:   6.693398 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:37:02,114 [Epoch: 005 Step: 00000706] Batch Translation Loss:   6.845482 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:37:11,078 [Epoch: 005 Step: 00000707] Batch Translation Loss:   6.113136 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-28 05:37:22,384 [Epoch: 005 Step: 00000708] Batch Translation Loss:   6.687304 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 05:37:37,157 [Epoch: 005 Step: 00000709] Batch Translation Loss:   6.934948 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:37:49,461 [Epoch: 005 Step: 00000710] Batch Translation Loss:   6.511560 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 05:38:04,093 [Epoch: 005 Step: 00000711] Batch Translation Loss:   5.798802 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:38:39,209 [Epoch: 005 Step: 00000712] Batch Translation Loss:   6.285244 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:38:52,359 [Epoch: 005 Step: 00000713] Batch Translation Loss:   6.451510 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:39:04,335 [Epoch: 005 Step: 00000714] Batch Translation Loss:   6.696271 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 05:39:17,363 [Epoch: 005 Step: 00000715] Batch Translation Loss:   6.308003 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:39:36,384 [Epoch: 005 Step: 00000716] Batch Translation Loss:   6.734525 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:39:50,097 [Epoch: 005 Step: 00000717] Batch Translation Loss:   6.862205 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:40:05,833 [Epoch: 005 Step: 00000718] Batch Translation Loss:   6.192917 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:40:23,741 [Epoch: 005 Step: 00000719] Batch Translation Loss:   6.246243 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:40:42,524 [Epoch: 005 Step: 00000720] Batch Translation Loss:   7.539089 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:40:57,391 [Epoch: 005 Step: 00000721] Batch Translation Loss:   6.401085 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:41:12,929 [Epoch: 005 Step: 00000722] Batch Translation Loss:   6.802359 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:41:28,103 [Epoch: 005 Step: 00000723] Batch Translation Loss:   6.456742 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:41:45,887 [Epoch: 005 Step: 00000724] Batch Translation Loss:   6.384376 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:42:04,081 [Epoch: 005 Step: 00000725] Batch Translation Loss:   7.363623 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:42:19,387 [Epoch: 005 Step: 00000726] Batch Translation Loss:   6.758018 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:42:34,499 [Epoch: 005 Step: 00000727] Batch Translation Loss:   6.869465 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:42:52,887 [Epoch: 005 Step: 00000728] Batch Translation Loss:   6.539854 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:43:19,086 [Epoch: 005 Step: 00000729] Batch Translation Loss:   6.944463 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:43:37,859 [Epoch: 005 Step: 00000730] Batch Translation Loss:   6.100618 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:43:58,790 [Epoch: 005 Step: 00000731] Batch Translation Loss:   6.440613 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:44:17,259 [Epoch: 005 Step: 00000732] Batch Translation Loss:   6.677570 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:44:35,020 [Epoch: 005 Step: 00000733] Batch Translation Loss:   6.539599 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:45:01,502 [Epoch: 005 Step: 00000734] Batch Translation Loss:   6.566883 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:45:16,325 [Epoch: 005 Step: 00000735] Batch Translation Loss:   6.891317 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:45:29,993 [Epoch: 005 Step: 00000736] Batch Translation Loss:   6.792196 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:45:57,860 [Epoch: 005 Step: 00000737] Batch Translation Loss:   6.080207 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:46:15,485 [Epoch: 005 Step: 00000738] Batch Translation Loss:   6.571545 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:46:40,869 [Epoch: 005 Step: 00000739] Batch Translation Loss:   6.474752 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:47:01,537 [Epoch: 005 Step: 00000740] Batch Translation Loss:   7.176048 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:47:20,614 [Epoch: 005 Step: 00000741] Batch Translation Loss:   7.465606 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:47:39,522 [Epoch: 005 Step: 00000742] Batch Translation Loss:   5.813855 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:48:00,646 [Epoch: 005 Step: 00000743] Batch Translation Loss:   6.343685 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:48:20,361 [Epoch: 005 Step: 00000744] Batch Translation Loss:   6.197774 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:48:54,656 [Epoch: 005 Step: 00000745] Batch Translation Loss:   6.532916 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:49:16,550 [Epoch: 005 Step: 00000746] Batch Translation Loss:   6.756173 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:49:42,617 [Epoch: 005 Step: 00000747] Batch Translation Loss:   6.781628 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:50:03,077 [Epoch: 005 Step: 00000748] Batch Translation Loss:   6.904525 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:50:24,879 [Epoch: 005 Step: 00000749] Batch Translation Loss:   6.069386 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:50:44,755 [Epoch: 005 Step: 00000750] Batch Translation Loss:   6.780355 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:51:06,798 [Epoch: 005 Step: 00000751] Batch Translation Loss:   7.010544 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:51:47,770 [Epoch: 005 Step: 00000752] Batch Translation Loss:   7.080230 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:52:28,912 [Epoch: 005 Step: 00000753] Batch Translation Loss:   6.142521 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:52:52,246 [Epoch: 005 Step: 00000754] Batch Translation Loss:   6.462981 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:53:23,604 [Epoch: 005 Step: 00000755] Batch Translation Loss:   6.597212 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:53:41,988 [Epoch: 005 Step: 00000756] Batch Translation Loss:   6.813247 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:54:01,367 [Epoch: 005 Step: 00000757] Batch Translation Loss:   6.849679 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:54:22,529 [Epoch: 005 Step: 00000758] Batch Translation Loss:   6.521314 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:54:45,539 [Epoch: 005 Step: 00000759] Batch Translation Loss:   6.732269 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:55:13,961 [Epoch: 005 Step: 00000760] Batch Translation Loss:   6.424479 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:55:35,346 [Epoch: 005 Step: 00000761] Batch Translation Loss:   6.612337 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 05:55:59,357 [Epoch: 005 Step: 00000762] Batch Translation Loss:   6.712494 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:56:25,974 [Epoch: 005 Step: 00000763] Batch Translation Loss:   6.356932 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:56:49,860 [Epoch: 005 Step: 00000764] Batch Translation Loss:   6.134939 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:57:14,775 [Epoch: 005 Step: 00000765] Batch Translation Loss:   6.549862 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:57:39,506 [Epoch: 005 Step: 00000766] Batch Translation Loss:   6.417480 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:58:02,927 [Epoch: 005 Step: 00000767] Batch Translation Loss:   7.132611 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:58:47,715 [Epoch: 005 Step: 00000768] Batch Translation Loss:   6.998470 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:59:13,045 [Epoch: 005 Step: 00000769] Batch Translation Loss:   7.158780 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 05:59:41,917 [Epoch: 005 Step: 00000770] Batch Translation Loss:   7.027259 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:00:06,387 [Epoch: 005 Step: 00000771] Batch Translation Loss:   7.345699 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:00:34,058 [Epoch: 005 Step: 00000772] Batch Translation Loss:   6.154853 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:01:03,875 [Epoch: 005 Step: 00000773] Batch Translation Loss:   6.726039 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:01:29,309 [Epoch: 005 Step: 00000774] Batch Translation Loss:   6.427326 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:01:53,378 [Epoch: 005 Step: 00000775] Batch Translation Loss:   6.850831 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:02:31,497 [Epoch: 005 Step: 00000776] Batch Translation Loss:   6.536878 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:03:10,903 [Epoch: 005 Step: 00000777] Batch Translation Loss:   6.213720 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:03:43,559 [Epoch: 005 Step: 00000778] Batch Translation Loss:   5.961908 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:04:11,340 [Epoch: 005 Step: 00000779] Batch Translation Loss:   6.651597 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:04:38,243 [Epoch: 005 Step: 00000780] Batch Translation Loss:   7.246419 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:05:07,686 [Epoch: 005 Step: 00000781] Batch Translation Loss:   6.361372 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:05:33,447 [Epoch: 005 Step: 00000782] Batch Translation Loss:   6.247181 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:06:03,526 [Epoch: 005 Step: 00000783] Batch Translation Loss:   6.834293 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:06:31,047 [Epoch: 005 Step: 00000784] Batch Translation Loss:   6.647262 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:07:01,156 [Epoch: 005 Step: 00000785] Batch Translation Loss:   6.514515 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:07:27,567 [Epoch: 005 Step: 00000786] Batch Translation Loss:   6.710137 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:07:57,766 [Epoch: 005 Step: 00000787] Batch Translation Loss:   7.052742 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:08:25,677 [Epoch: 005 Step: 00000788] Batch Translation Loss:   5.711400 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:08:53,337 [Epoch: 005 Step: 00000789] Batch Translation Loss:   6.099323 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:09:52,515 [Epoch: 005 Step: 00000790] Batch Translation Loss:   6.554969 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:10:23,776 [Epoch: 005 Step: 00000791] Batch Translation Loss:   6.598183 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:10:46,424 [Epoch: 005 Step: 00000792] Batch Translation Loss:   6.364025 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:11:12,056 [Epoch: 005 Step: 00000793] Batch Translation Loss:   6.266503 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:11:46,541 [Epoch: 005 Step: 00000794] Batch Translation Loss:   6.452536 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:12:13,710 [Epoch: 005 Step: 00000795] Batch Translation Loss:   6.642708 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:12:47,545 [Epoch: 005 Step: 00000796] Batch Translation Loss:   6.945071 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:13:14,819 [Epoch: 005 Step: 00000797] Batch Translation Loss:   6.596618 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:14:12,151 [Epoch: 005 Step: 00000798] Batch Translation Loss:   7.037090 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:14:41,043 [Epoch: 005 Step: 00000799] Batch Translation Loss:   6.756621 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:15:51,325 [Epoch: 005 Step: 00000800] Batch Translation Loss:   7.008447 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 06:23:23,943 Validation result at epoch   5, step      800: duration: 452.5685s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 8037.46094	PPL: 4519.64697
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 1.84,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 4.91	ROUGE 2.02
2021-12-28 06:23:32,002 Logging Recognition and Translation Outputs
2021-12-28 06:23:32,034 ========================================================================================================================
2021-12-28 06:23:32,034 Logging Sequence: youtube_1-catherine_mackinnon_2777
2021-12-28 06:23:32,039 	Text Reference  :	adm
2021-12-28 06:23:32,039 	Text Hypothesis :	asl
2021-12-28 06:23:32,039 	Text Alignment  :	S  
2021-12-28 06:23:32,039 ========================================================================================================================
2021-12-28 06:23:32,039 Logging Sequence: deafvideo_3-yesyes_4480
2021-12-28 06:23:32,040 	Text Reference  :	***** ****** ****** ad  
2021-12-28 06:23:32,040 	Text Hypothesis :	ralph lauren pololo polo
2021-12-28 06:23:32,040 	Text Alignment  :	I     I      I      S   
2021-12-28 06:23:32,040 ========================================================================================================================
2021-12-28 06:23:32,040 Logging Sequence: youtube_5-roberta_cordano_6152
2021-12-28 06:23:32,040 	Text Reference  :	hartfrd conn
2021-12-28 06:23:32,040 	Text Hypothesis :	******* asl 
2021-12-28 06:23:32,040 	Text Alignment  :	D       S   
2021-12-28 06:23:32,040 ========================================================================================================================
2021-12-28 06:23:32,040 Logging Sequence: youtube_1-catherine_mackinnon_2840
2021-12-28 06:23:32,041 	Text Reference  :	oscar
2021-12-28 06:23:32,041 	Text Hypothesis :	coda 
2021-12-28 06:23:32,041 	Text Alignment  :	S    
2021-12-28 06:23:32,041 ========================================================================================================================
2021-12-28 06:23:32,041 Logging Sequence: deafvideo_5-silentoneye_7330
2021-12-28 06:23:32,041 	Text Reference  :	gulag
2021-12-28 06:23:32,041 	Text Hypothesis :	asl  
2021-12-28 06:23:32,041 	Text Alignment  :	S    
2021-12-28 06:23:32,041 ========================================================================================================================
2021-12-28 06:25:39,810 [Epoch: 005 Step: 00000801] Batch Translation Loss:   7.164753 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 06:26:58,361 [Epoch: 005 Step: 00000802] Batch Translation Loss:   6.396020 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 06:27:30,154 [Epoch: 005 Step: 00000803] Batch Translation Loss:   6.885732 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:27:55,722 [Epoch: 005 Step: 00000804] Batch Translation Loss:   6.360051 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:28:20,443 [Epoch: 005 Step: 00000805] Batch Translation Loss:   6.416333 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:29:08,186 [Epoch: 005 Step: 00000806] Batch Translation Loss:   6.339760 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:29:43,803 [Epoch: 005 Step: 00000807] Batch Translation Loss:   6.324671 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:30:17,715 [Epoch: 005 Step: 00000808] Batch Translation Loss:   6.240602 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:31:25,017 [Epoch: 005 Step: 00000809] Batch Translation Loss:   6.849506 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 06:32:00,733 [Epoch: 005 Step: 00000810] Batch Translation Loss:   6.716980 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:32:34,225 [Epoch: 005 Step: 00000811] Batch Translation Loss:   6.939260 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:33:10,957 [Epoch: 005 Step: 00000812] Batch Translation Loss:   6.516961 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:33:46,605 [Epoch: 005 Step: 00000813] Batch Translation Loss:   6.627258 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:34:20,612 [Epoch: 005 Step: 00000814] Batch Translation Loss:   6.056939 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:34:49,174 [Epoch: 005 Step: 00000815] Batch Translation Loss:   6.917008 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:35:40,813 [Epoch: 005 Step: 00000816] Batch Translation Loss:   6.494158 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:36:45,041 [Epoch: 005 Step: 00000817] Batch Translation Loss:   6.486995 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 06:37:18,480 [Epoch: 005 Step: 00000818] Batch Translation Loss:   7.077010 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:37:59,362 [Epoch: 005 Step: 00000819] Batch Translation Loss:   6.827257 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:38:35,206 [Epoch: 005 Step: 00000820] Batch Translation Loss:   6.624134 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:39:08,027 [Epoch: 005 Step: 00000821] Batch Translation Loss:   6.828207 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:39:43,957 [Epoch: 005 Step: 00000822] Batch Translation Loss:   6.746088 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:40:20,586 [Epoch: 005 Step: 00000823] Batch Translation Loss:   6.595186 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:40:57,413 [Epoch: 005 Step: 00000824] Batch Translation Loss:   7.040767 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:42:02,653 [Epoch: 005 Step: 00000825] Batch Translation Loss:   6.693893 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 06:42:40,804 [Epoch: 005 Step: 00000826] Batch Translation Loss:   6.414501 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:43:13,647 [Epoch: 005 Step: 00000827] Batch Translation Loss:   6.345275 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:43:43,233 [Epoch: 005 Step: 00000828] Batch Translation Loss:   6.816545 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:44:11,154 [Epoch: 005 Step: 00000829] Batch Translation Loss:   7.093727 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:44:47,891 [Epoch: 005 Step: 00000830] Batch Translation Loss:   6.626284 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:45:28,017 [Epoch: 005 Step: 00000831] Batch Translation Loss:   6.424404 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:46:08,174 [Epoch: 005 Step: 00000832] Batch Translation Loss:   6.315624 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:46:45,528 [Epoch: 005 Step: 00000833] Batch Translation Loss:   6.712942 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:47:25,926 [Epoch: 005 Step: 00000834] Batch Translation Loss:   6.034718 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:48:04,652 [Epoch: 005 Step: 00000835] Batch Translation Loss:   6.550841 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:48:50,600 [Epoch: 005 Step: 00000836] Batch Translation Loss:   6.695098 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:49:30,263 [Epoch: 005 Step: 00000837] Batch Translation Loss:   6.438842 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:50:10,642 [Epoch: 005 Step: 00000838] Batch Translation Loss:   6.412131 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:50:48,096 [Epoch: 005 Step: 00000839] Batch Translation Loss:   6.454731 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:51:16,382 [Epoch: 005 Step: 00000840] Batch Translation Loss:   6.856145 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:51:44,561 [Epoch: 005 Step: 00000841] Batch Translation Loss:   6.626730 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:52:22,055 [Epoch: 005 Step: 00000842] Batch Translation Loss:   6.217661 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:52:59,579 [Epoch: 005 Step: 00000843] Batch Translation Loss:   6.820707 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:54:13,353 [Epoch: 005 Step: 00000844] Batch Translation Loss:   6.659245 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 06:54:51,728 [Epoch: 005 Step: 00000845] Batch Translation Loss:   6.636888 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:55:31,579 [Epoch: 005 Step: 00000846] Batch Translation Loss:   7.205073 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:56:10,093 [Epoch: 005 Step: 00000847] Batch Translation Loss:   7.025209 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:56:48,979 [Epoch: 005 Step: 00000848] Batch Translation Loss:   6.881164 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:57:24,601 [Epoch: 005 Step: 00000849] Batch Translation Loss:   6.693144 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 06:58:36,992 [Epoch: 005 Step: 00000850] Batch Translation Loss:   7.156637 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 06:58:37,208 Epoch   5: Total Training Recognition Loss -1.00  Total Training Translation Loss 1128.54 
2021-12-28 06:58:37,208 EPOCH 6
2021-12-28 06:58:44,759 [Epoch: 006 Step: 00000851] Batch Translation Loss:   6.167697 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-28 06:58:52,847 [Epoch: 006 Step: 00000852] Batch Translation Loss:   6.893338 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-28 06:59:01,952 [Epoch: 006 Step: 00000853] Batch Translation Loss:   7.183383 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-28 06:59:10,896 [Epoch: 006 Step: 00000854] Batch Translation Loss:   6.721055 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-28 06:59:19,254 [Epoch: 006 Step: 00000855] Batch Translation Loss:   7.105999 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-28 06:59:30,328 [Epoch: 006 Step: 00000856] Batch Translation Loss:   6.993488 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 06:59:50,643 [Epoch: 006 Step: 00000857] Batch Translation Loss:   6.542680 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:00:01,963 [Epoch: 006 Step: 00000858] Batch Translation Loss:   7.123013 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 07:00:16,785 [Epoch: 006 Step: 00000859] Batch Translation Loss:   7.079556 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:00:28,915 [Epoch: 006 Step: 00000860] Batch Translation Loss:   6.131699 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 07:00:42,587 [Epoch: 006 Step: 00000861] Batch Translation Loss:   6.314905 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:00:53,870 [Epoch: 006 Step: 00000862] Batch Translation Loss:   6.469689 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 07:01:07,421 [Epoch: 006 Step: 00000863] Batch Translation Loss:   7.336572 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:01:22,954 [Epoch: 006 Step: 00000864] Batch Translation Loss:   6.624426 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:01:33,348 [Epoch: 006 Step: 00000865] Batch Translation Loss:   6.355975 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 07:01:43,404 [Epoch: 006 Step: 00000866] Batch Translation Loss:   5.843704 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 07:01:53,360 [Epoch: 006 Step: 00000867] Batch Translation Loss:   6.987994 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 07:02:04,381 [Epoch: 006 Step: 00000868] Batch Translation Loss:   6.781226 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 07:02:22,506 [Epoch: 006 Step: 00000869] Batch Translation Loss:   6.443794 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:02:41,605 [Epoch: 006 Step: 00000870] Batch Translation Loss:   5.891095 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:02:53,510 [Epoch: 006 Step: 00000871] Batch Translation Loss:   6.787515 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 07:03:05,037 [Epoch: 006 Step: 00000872] Batch Translation Loss:   6.517491 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 07:03:20,106 [Epoch: 006 Step: 00000873] Batch Translation Loss:   6.953910 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:03:33,229 [Epoch: 006 Step: 00000874] Batch Translation Loss:   5.902447 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:03:46,242 [Epoch: 006 Step: 00000875] Batch Translation Loss:   6.647238 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:04:00,227 [Epoch: 006 Step: 00000876] Batch Translation Loss:   6.989862 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:04:12,161 [Epoch: 006 Step: 00000877] Batch Translation Loss:   6.137574 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 07:04:28,422 [Epoch: 006 Step: 00000878] Batch Translation Loss:   6.495332 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:04:52,399 [Epoch: 006 Step: 00000879] Batch Translation Loss:   6.293177 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:05:05,395 [Epoch: 006 Step: 00000880] Batch Translation Loss:   6.595095 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:05:25,427 [Epoch: 006 Step: 00000881] Batch Translation Loss:   6.511156 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:05:48,265 [Epoch: 006 Step: 00000882] Batch Translation Loss:   6.759263 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:06:01,985 [Epoch: 006 Step: 00000883] Batch Translation Loss:   6.024093 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:06:16,211 [Epoch: 006 Step: 00000884] Batch Translation Loss:   6.133911 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:06:30,874 [Epoch: 006 Step: 00000885] Batch Translation Loss:   6.752317 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:06:46,069 [Epoch: 006 Step: 00000886] Batch Translation Loss:   6.625822 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:07:01,416 [Epoch: 006 Step: 00000887] Batch Translation Loss:   6.296109 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:07:17,538 [Epoch: 006 Step: 00000888] Batch Translation Loss:   7.271423 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:07:30,357 [Epoch: 006 Step: 00000889] Batch Translation Loss:   6.676520 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:07:42,402 [Epoch: 006 Step: 00000890] Batch Translation Loss:   6.099395 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 07:08:04,778 [Epoch: 006 Step: 00000891] Batch Translation Loss:   7.224469 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:08:16,420 [Epoch: 006 Step: 00000892] Batch Translation Loss:   6.058980 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 07:08:28,650 [Epoch: 006 Step: 00000893] Batch Translation Loss:   6.761868 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-28 07:08:42,273 [Epoch: 006 Step: 00000894] Batch Translation Loss:   6.487756 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:08:55,667 [Epoch: 006 Step: 00000895] Batch Translation Loss:   6.158875 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:09:11,048 [Epoch: 006 Step: 00000896] Batch Translation Loss:   5.811502 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:09:42,584 [Epoch: 006 Step: 00000897] Batch Translation Loss:   6.121808 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:09:58,627 [Epoch: 006 Step: 00000898] Batch Translation Loss:   6.324524 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:10:17,730 [Epoch: 006 Step: 00000899] Batch Translation Loss:   6.819775 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:10:49,515 [Epoch: 006 Step: 00000900] Batch Translation Loss:   6.707833 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:18:29,828 Validation result at epoch   6, step      900: duration: 460.2773s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 8193.16406	PPL: 5087.52051
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 3.56,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 6.03	ROUGE 1.76
2021-12-28 07:18:38,521 Logging Recognition and Translation Outputs
2021-12-28 07:18:38,548 ========================================================================================================================
2021-12-28 07:18:38,549 Logging Sequence: youtube_5-tanea_brown_6028
2021-12-28 07:18:38,549 	Text Reference  :	so     
2021-12-28 07:18:38,550 	Text Hypothesis :	aslized
2021-12-28 07:18:38,550 	Text Alignment  :	S      
2021-12-28 07:18:38,550 ========================================================================================================================
2021-12-28 07:18:38,550 Logging Sequence: deafvideo_3-yellowbirdie84_4681
2021-12-28 07:18:38,550 	Text Reference  :	aked
2021-12-28 07:18:38,551 	Text Hypothesis :	or  
2021-12-28 07:18:38,551 	Text Alignment  :	S   
2021-12-28 07:18:38,551 ========================================================================================================================
2021-12-28 07:18:38,551 Logging Sequence: youtube_1-melvin_patterson_2358
2021-12-28 07:18:38,551 	Text Reference  :	sb 
2021-12-28 07:18:38,552 	Text Hypothesis :	asl
2021-12-28 07:18:38,552 	Text Alignment  :	S  
2021-12-28 07:18:38,552 ========================================================================================================================
2021-12-28 07:18:38,552 Logging Sequence: deafvideo_5-morningstar_6244
2021-12-28 07:18:38,552 	Text Reference  :	do it     
2021-12-28 07:18:38,552 	Text Hypothesis :	** aslized
2021-12-28 07:18:38,553 	Text Alignment  :	D  S      
2021-12-28 07:18:38,553 ========================================================================================================================
2021-12-28 07:18:38,553 Logging Sequence: deafvideo_5-silentoneye_7325
2021-12-28 07:18:38,553 	Text Reference  :	******* disown  
2021-12-28 07:18:38,553 	Text Hypothesis :	frosted lemonade
2021-12-28 07:18:38,553 	Text Alignment  :	I       S       
2021-12-28 07:18:38,554 ========================================================================================================================
2021-12-28 07:20:07,038 [Epoch: 006 Step: 00000901] Batch Translation Loss:   7.013812 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 07:20:48,470 [Epoch: 006 Step: 00000902] Batch Translation Loss:   7.059660 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:21:26,460 [Epoch: 006 Step: 00000903] Batch Translation Loss:   6.505073 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:21:51,422 [Epoch: 006 Step: 00000904] Batch Translation Loss:   6.376660 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:22:09,467 [Epoch: 006 Step: 00000905] Batch Translation Loss:   6.336704 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:22:27,477 [Epoch: 006 Step: 00000906] Batch Translation Loss:   6.530206 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:23:03,732 [Epoch: 006 Step: 00000907] Batch Translation Loss:   6.624101 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:23:23,970 [Epoch: 006 Step: 00000908] Batch Translation Loss:   6.267949 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:24:02,850 [Epoch: 006 Step: 00000909] Batch Translation Loss:   6.422676 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:24:19,478 [Epoch: 006 Step: 00000910] Batch Translation Loss:   6.285125 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:24:35,233 [Epoch: 006 Step: 00000911] Batch Translation Loss:   6.808279 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:24:53,062 [Epoch: 006 Step: 00000912] Batch Translation Loss:   6.853500 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:25:10,058 [Epoch: 006 Step: 00000913] Batch Translation Loss:   6.029092 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:25:29,349 [Epoch: 006 Step: 00000914] Batch Translation Loss:   6.263863 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:25:50,339 [Epoch: 006 Step: 00000915] Batch Translation Loss:   5.940187 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:26:09,550 [Epoch: 006 Step: 00000916] Batch Translation Loss:   6.284153 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:26:30,834 [Epoch: 006 Step: 00000917] Batch Translation Loss:   6.479092 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:26:51,473 [Epoch: 006 Step: 00000918] Batch Translation Loss:   6.504280 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:27:12,581 [Epoch: 006 Step: 00000919] Batch Translation Loss:   6.468065 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:27:32,732 [Epoch: 006 Step: 00000920] Batch Translation Loss:   6.232653 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:27:57,240 [Epoch: 006 Step: 00000921] Batch Translation Loss:   6.146357 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:28:19,916 [Epoch: 006 Step: 00000922] Batch Translation Loss:   6.701725 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:28:41,877 [Epoch: 006 Step: 00000923] Batch Translation Loss:   6.177237 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:29:02,097 [Epoch: 006 Step: 00000924] Batch Translation Loss:   5.923668 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:29:31,365 [Epoch: 006 Step: 00000925] Batch Translation Loss:   6.704714 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:29:52,992 [Epoch: 006 Step: 00000926] Batch Translation Loss:   6.379277 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:30:15,054 [Epoch: 006 Step: 00000927] Batch Translation Loss:   6.798085 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:30:40,804 [Epoch: 006 Step: 00000928] Batch Translation Loss:   6.422752 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:31:04,549 [Epoch: 006 Step: 00000929] Batch Translation Loss:   5.942513 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:31:28,993 [Epoch: 006 Step: 00000930] Batch Translation Loss:   6.326762 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:31:52,595 [Epoch: 006 Step: 00000931] Batch Translation Loss:   6.917840 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:32:17,714 [Epoch: 006 Step: 00000932] Batch Translation Loss:   7.015921 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:32:37,340 [Epoch: 006 Step: 00000933] Batch Translation Loss:   6.923790 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:32:57,229 [Epoch: 006 Step: 00000934] Batch Translation Loss:   7.209547 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:33:16,571 [Epoch: 006 Step: 00000935] Batch Translation Loss:   6.250132 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-28 07:33:38,905 [Epoch: 006 Step: 00000936] Batch Translation Loss:   6.281503 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:34:02,355 [Epoch: 006 Step: 00000937] Batch Translation Loss:   6.860027 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:34:31,886 [Epoch: 006 Step: 00000938] Batch Translation Loss:   6.442786 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:35:15,289 [Epoch: 006 Step: 00000939] Batch Translation Loss:   6.618832 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:35:41,373 [Epoch: 006 Step: 00000940] Batch Translation Loss:   6.581902 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:36:10,089 [Epoch: 006 Step: 00000941] Batch Translation Loss:   6.677001 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:36:34,415 [Epoch: 006 Step: 00000942] Batch Translation Loss:   6.549407 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:37:20,056 [Epoch: 006 Step: 00000943] Batch Translation Loss:   5.969243 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:38:09,797 [Epoch: 006 Step: 00000944] Batch Translation Loss:   6.577396 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:38:56,590 [Epoch: 006 Step: 00000945] Batch Translation Loss:   6.293747 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:39:23,377 [Epoch: 006 Step: 00000946] Batch Translation Loss:   6.909297 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:39:48,416 [Epoch: 006 Step: 00000947] Batch Translation Loss:   6.998386 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:40:16,392 [Epoch: 006 Step: 00000948] Batch Translation Loss:   6.768633 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:40:45,323 [Epoch: 006 Step: 00000949] Batch Translation Loss:   7.162887 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:41:09,903 [Epoch: 006 Step: 00000950] Batch Translation Loss:   6.238580 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:41:31,434 [Epoch: 006 Step: 00000951] Batch Translation Loss:   6.479544 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:41:55,463 [Epoch: 006 Step: 00000952] Batch Translation Loss:   6.333766 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:42:19,765 [Epoch: 006 Step: 00000953] Batch Translation Loss:   6.233173 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:42:42,680 [Epoch: 006 Step: 00000954] Batch Translation Loss:   6.737213 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:43:18,424 [Epoch: 006 Step: 00000955] Batch Translation Loss:   6.580553 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:43:47,240 [Epoch: 006 Step: 00000956] Batch Translation Loss:   6.813875 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:44:13,581 [Epoch: 006 Step: 00000957] Batch Translation Loss:   6.156034 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:44:41,439 [Epoch: 006 Step: 00000958] Batch Translation Loss:   6.421092 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:45:10,044 [Epoch: 006 Step: 00000959] Batch Translation Loss:   6.065164 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:46:02,052 [Epoch: 006 Step: 00000960] Batch Translation Loss:   6.903815 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:46:48,562 [Epoch: 006 Step: 00000961] Batch Translation Loss:   6.762002 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:47:16,632 [Epoch: 006 Step: 00000962] Batch Translation Loss:   6.188346 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:48:02,919 [Epoch: 006 Step: 00000963] Batch Translation Loss:   6.796243 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:48:53,957 [Epoch: 006 Step: 00000964] Batch Translation Loss:   6.962416 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:49:23,416 [Epoch: 006 Step: 00000965] Batch Translation Loss:   6.654278 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:49:51,196 [Epoch: 006 Step: 00000966] Batch Translation Loss:   6.527665 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:50:19,110 [Epoch: 006 Step: 00000967] Batch Translation Loss:   6.741029 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:50:42,679 [Epoch: 006 Step: 00000968] Batch Translation Loss:   6.587376 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:51:09,764 [Epoch: 006 Step: 00000969] Batch Translation Loss:   7.217035 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:51:45,876 [Epoch: 006 Step: 00000970] Batch Translation Loss:   6.610524 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:52:14,571 [Epoch: 006 Step: 00000971] Batch Translation Loss:   7.005630 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:52:50,269 [Epoch: 006 Step: 00000972] Batch Translation Loss:   6.545127 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:53:50,275 [Epoch: 006 Step: 00000973] Batch Translation Loss:   6.196687 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:54:18,957 [Epoch: 006 Step: 00000974] Batch Translation Loss:   6.091901 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:54:51,357 [Epoch: 006 Step: 00000975] Batch Translation Loss:   6.716671 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:55:22,649 [Epoch: 006 Step: 00000976] Batch Translation Loss:   6.268984 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:55:55,202 [Epoch: 006 Step: 00000977] Batch Translation Loss:   6.324161 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:56:26,428 [Epoch: 006 Step: 00000978] Batch Translation Loss:   6.683326 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:57:01,349 [Epoch: 006 Step: 00000979] Batch Translation Loss:   5.878792 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:57:39,511 [Epoch: 006 Step: 00000980] Batch Translation Loss:   6.328351 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:58:14,306 [Epoch: 006 Step: 00000981] Batch Translation Loss:   6.272692 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:58:45,650 [Epoch: 006 Step: 00000982] Batch Translation Loss:   6.367689 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:59:13,429 [Epoch: 006 Step: 00000983] Batch Translation Loss:   6.416701 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 07:59:40,166 [Epoch: 006 Step: 00000984] Batch Translation Loss:   6.320492 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 08:00:09,552 [Epoch: 006 Step: 00000985] Batch Translation Loss:   6.355700 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 08:00:50,284 [Epoch: 006 Step: 00000986] Batch Translation Loss:   6.996484 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 08:01:24,044 [Epoch: 006 Step: 00000987] Batch Translation Loss:   6.456131 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 08:02:00,586 [Epoch: 006 Step: 00000988] Batch Translation Loss:   6.388722 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 08:02:43,388 [Epoch: 006 Step: 00000989] Batch Translation Loss:   6.477139 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 08:03:17,121 [Epoch: 006 Step: 00000990] Batch Translation Loss:   6.762262 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 08:04:32,320 [Epoch: 006 Step: 00000991] Batch Translation Loss:   6.464953 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 08:05:08,861 [Epoch: 006 Step: 00000992] Batch Translation Loss:   6.844869 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 08:05:48,305 [Epoch: 006 Step: 00000993] Batch Translation Loss:   6.254510 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 08:06:24,536 [Epoch: 006 Step: 00000994] Batch Translation Loss:   6.506137 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 08:06:59,210 [Epoch: 006 Step: 00000995] Batch Translation Loss:   6.515826 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 08:07:28,330 [Epoch: 006 Step: 00000996] Batch Translation Loss:   6.374535 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 08:08:22,692 [Epoch: 006 Step: 00000997] Batch Translation Loss:   6.760597 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 08:09:05,786 [Epoch: 006 Step: 00000998] Batch Translation Loss:   6.997664 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 08:09:41,468 [Epoch: 006 Step: 00000999] Batch Translation Loss:   7.119492 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 08:10:19,823 [Epoch: 006 Step: 00001000] Batch Translation Loss:   6.345807 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-28 08:18:23,147 Validation result at epoch   6, step     1000: duration: 483.2632s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 8131.23975	PPL: 4769.71680
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 1.96,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 4.97	ROUGE 2.38
2021-12-28 08:18:29,651 Logging Recognition and Translation Outputs
2021-12-28 08:18:29,702 ========================================================================================================================
2021-12-28 08:18:29,702 Logging Sequence: youtube_1-shoshannah_stern_2379
2021-12-28 08:18:29,703 	Text Reference  :	** extra
2021-12-28 08:18:29,703 	Text Hypothesis :	he did  
2021-12-28 08:18:29,703 	Text Alignment  :	I  S    
2021-12-28 08:18:29,704 ========================================================================================================================
2021-12-28 08:18:29,704 Logging Sequence: youtube_1-catherine_mackinnon_2835
2021-12-28 08:18:29,704 	Text Reference  :	ok      
2021-12-28 08:18:29,705 	Text Hypothesis :	aslizers
2021-12-28 08:18:29,705 	Text Alignment  :	S       
2021-12-28 08:18:29,705 ========================================================================================================================
2021-12-28 08:18:29,705 Logging Sequence: youtube_1-shoshannah_stern_2376
2021-12-28 08:18:29,706 	Text Reference  :	us
2021-12-28 08:18:29,706 	Text Hypothesis :	so
2021-12-28 08:18:29,706 	Text Alignment  :	S 
2021-12-28 08:18:29,706 ========================================================================================================================
2021-12-28 08:18:29,706 Logging Sequence: youtube_5-sean_berdy_6109
2021-12-28 08:18:29,707 	Text Reference  :	** season
2021-12-28 08:18:29,707 	Text Hypothesis :	he did   
2021-12-28 08:18:29,707 	Text Alignment  :	I  S     
2021-12-28 08:18:29,707 ========================================================================================================================
2021-12-28 08:18:29,708 Logging Sequence: deafvideo_2-sddsimple_1551
2021-12-28 08:18:29,708 	Text Reference  :	tim
2021-12-28 08:18:29,708 	Text Hypothesis :	asl
2021-12-28 08:18:29,708 	Text Alignment  :	S  
2021-12-28 08:18:29,709 ========================================================================================================================
2021-12-28 08:20:41,286 [Epoch: 006 Step: 00001001] Batch Translation Loss:   6.386949 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 08:21:21,988 [Epoch: 006 Step: 00001002] Batch Translation Loss:   6.745962 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:22:03,489 [Epoch: 006 Step: 00001003] Batch Translation Loss:   7.091087 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:22:43,102 [Epoch: 006 Step: 00001004] Batch Translation Loss:   6.737097 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:23:20,306 [Epoch: 006 Step: 00001005] Batch Translation Loss:   6.817942 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:24:02,197 [Epoch: 006 Step: 00001006] Batch Translation Loss:   6.430640 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:24:42,070 [Epoch: 006 Step: 00001007] Batch Translation Loss:   6.490758 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:25:13,647 [Epoch: 006 Step: 00001008] Batch Translation Loss:   6.704830 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:25:43,340 [Epoch: 006 Step: 00001009] Batch Translation Loss:   6.504383 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:26:18,635 [Epoch: 006 Step: 00001010] Batch Translation Loss:   6.425678 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:27:01,158 [Epoch: 006 Step: 00001011] Batch Translation Loss:   6.492751 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:27:39,157 [Epoch: 006 Step: 00001012] Batch Translation Loss:   6.201118 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:28:17,558 [Epoch: 006 Step: 00001013] Batch Translation Loss:   6.226526 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:28:57,901 [Epoch: 006 Step: 00001014] Batch Translation Loss:   6.352222 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:29:36,577 [Epoch: 006 Step: 00001015] Batch Translation Loss:   6.519558 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:30:21,644 [Epoch: 006 Step: 00001016] Batch Translation Loss:   7.264723 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:31:00,683 [Epoch: 006 Step: 00001017] Batch Translation Loss:   6.637400 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:31:39,249 [Epoch: 006 Step: 00001018] Batch Translation Loss:   6.154243 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:33:01,194 [Epoch: 006 Step: 00001019] Batch Translation Loss:   6.955699 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 08:33:36,801 [Epoch: 006 Step: 00001020] Batch Translation Loss:   6.944186 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 08:33:36,914 Epoch   6: Total Training Recognition Loss -1.00  Total Training Translation Loss 1112.89 
2021-12-28 08:33:36,914 EPOCH 7
2021-12-28 08:33:45,199 [Epoch: 007 Step: 00001021] Batch Translation Loss:   6.439116 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-28 08:33:54,003 [Epoch: 007 Step: 00001022] Batch Translation Loss:   6.677775 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-28 08:34:03,728 [Epoch: 007 Step: 00001023] Batch Translation Loss:   6.608713 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 08:34:13,344 [Epoch: 007 Step: 00001024] Batch Translation Loss:   6.541397 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 08:34:26,799 [Epoch: 007 Step: 00001025] Batch Translation Loss:   6.790929 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:34:35,523 [Epoch: 007 Step: 00001026] Batch Translation Loss:   6.662870 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-28 08:34:43,850 [Epoch: 007 Step: 00001027] Batch Translation Loss:   7.381949 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-28 08:35:01,134 [Epoch: 007 Step: 00001028] Batch Translation Loss:   7.170480 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:35:13,159 [Epoch: 007 Step: 00001029] Batch Translation Loss:   6.450624 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 08:35:27,911 [Epoch: 007 Step: 00001030] Batch Translation Loss:   6.728689 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:35:44,056 [Epoch: 007 Step: 00001031] Batch Translation Loss:   6.558275 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:36:01,623 [Epoch: 007 Step: 00001032] Batch Translation Loss:   6.759389 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:36:13,840 [Epoch: 007 Step: 00001033] Batch Translation Loss:   7.070243 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 08:36:24,008 [Epoch: 007 Step: 00001034] Batch Translation Loss:   6.643468 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 08:36:42,305 [Epoch: 007 Step: 00001035] Batch Translation Loss:   6.940144 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:36:53,940 [Epoch: 007 Step: 00001036] Batch Translation Loss:   6.764391 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 08:37:09,854 [Epoch: 007 Step: 00001037] Batch Translation Loss:   6.535010 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:37:22,116 [Epoch: 007 Step: 00001038] Batch Translation Loss:   7.160300 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 08:37:32,304 [Epoch: 007 Step: 00001039] Batch Translation Loss:   6.600055 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 08:37:52,457 [Epoch: 007 Step: 00001040] Batch Translation Loss:   6.260070 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:38:09,227 [Epoch: 007 Step: 00001041] Batch Translation Loss:   6.668235 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:38:22,462 [Epoch: 007 Step: 00001042] Batch Translation Loss:   6.572765 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:38:34,351 [Epoch: 007 Step: 00001043] Batch Translation Loss:   6.644840 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 08:38:47,040 [Epoch: 007 Step: 00001044] Batch Translation Loss:   6.758139 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 08:38:59,224 [Epoch: 007 Step: 00001045] Batch Translation Loss:   6.302894 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 08:39:12,240 [Epoch: 007 Step: 00001046] Batch Translation Loss:   6.656825 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:39:33,910 [Epoch: 007 Step: 00001047] Batch Translation Loss:   6.408679 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:39:47,920 [Epoch: 007 Step: 00001048] Batch Translation Loss:   6.565352 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:40:11,800 [Epoch: 007 Step: 00001049] Batch Translation Loss:   6.529692 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:40:34,180 [Epoch: 007 Step: 00001050] Batch Translation Loss:   6.787979 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:40:47,494 [Epoch: 007 Step: 00001051] Batch Translation Loss:   6.500509 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:41:02,948 [Epoch: 007 Step: 00001052] Batch Translation Loss:   6.665421 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:41:18,873 [Epoch: 007 Step: 00001053] Batch Translation Loss:   6.645609 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:41:33,547 [Epoch: 007 Step: 00001054] Batch Translation Loss:   6.695069 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:41:52,050 [Epoch: 007 Step: 00001055] Batch Translation Loss:   6.455389 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:42:07,101 [Epoch: 007 Step: 00001056] Batch Translation Loss:   6.700546 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:42:19,744 [Epoch: 007 Step: 00001057] Batch Translation Loss:   6.575263 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 08:42:31,609 [Epoch: 007 Step: 00001058] Batch Translation Loss:   6.706698 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 08:42:55,962 [Epoch: 007 Step: 00001059] Batch Translation Loss:   6.435014 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:43:10,965 [Epoch: 007 Step: 00001060] Batch Translation Loss:   6.748895 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:43:25,229 [Epoch: 007 Step: 00001061] Batch Translation Loss:   7.075065 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:43:39,357 [Epoch: 007 Step: 00001062] Batch Translation Loss:   6.571676 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:44:11,717 [Epoch: 007 Step: 00001063] Batch Translation Loss:   6.773380 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:44:27,061 [Epoch: 007 Step: 00001064] Batch Translation Loss:   5.858792 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:44:55,807 [Epoch: 007 Step: 00001065] Batch Translation Loss:   6.559302 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:45:11,455 [Epoch: 007 Step: 00001066] Batch Translation Loss:   6.947927 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:45:28,668 [Epoch: 007 Step: 00001067] Batch Translation Loss:   6.627998 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:45:47,658 [Epoch: 007 Step: 00001068] Batch Translation Loss:   6.620953 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:46:03,939 [Epoch: 007 Step: 00001069] Batch Translation Loss:   6.680717 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:46:22,674 [Epoch: 007 Step: 00001070] Batch Translation Loss:   6.612860 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:46:54,980 [Epoch: 007 Step: 00001071] Batch Translation Loss:   6.978583 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:47:13,554 [Epoch: 007 Step: 00001072] Batch Translation Loss:   6.799139 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:47:31,485 [Epoch: 007 Step: 00001073] Batch Translation Loss:   5.916745 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:47:51,108 [Epoch: 007 Step: 00001074] Batch Translation Loss:   5.965927 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:48:08,928 [Epoch: 007 Step: 00001075] Batch Translation Loss:   6.432937 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:48:26,710 [Epoch: 007 Step: 00001076] Batch Translation Loss:   6.563421 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:48:45,068 [Epoch: 007 Step: 00001077] Batch Translation Loss:   6.471672 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:49:03,730 [Epoch: 007 Step: 00001078] Batch Translation Loss:   6.282619 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:49:38,459 [Epoch: 007 Step: 00001079] Batch Translation Loss:   6.200663 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:49:59,431 [Epoch: 007 Step: 00001080] Batch Translation Loss:   6.357360 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:50:18,803 [Epoch: 007 Step: 00001081] Batch Translation Loss:   6.373959 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:50:38,124 [Epoch: 007 Step: 00001082] Batch Translation Loss:   6.879442 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:50:58,497 [Epoch: 007 Step: 00001083] Batch Translation Loss:   6.368787 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:51:19,332 [Epoch: 007 Step: 00001084] Batch Translation Loss:   6.000302 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:51:36,246 [Epoch: 007 Step: 00001085] Batch Translation Loss:   6.692872 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:51:55,424 [Epoch: 007 Step: 00001086] Batch Translation Loss:   6.565823 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:52:12,435 [Epoch: 007 Step: 00001087] Batch Translation Loss:   6.744138 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:52:45,232 [Epoch: 007 Step: 00001088] Batch Translation Loss:   5.996378 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:53:05,358 [Epoch: 007 Step: 00001089] Batch Translation Loss:   6.526990 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:53:33,622 [Epoch: 007 Step: 00001090] Batch Translation Loss:   7.173779 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:53:52,459 [Epoch: 007 Step: 00001091] Batch Translation Loss:   6.384245 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:54:14,338 [Epoch: 007 Step: 00001092] Batch Translation Loss:   7.165240 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:54:40,519 [Epoch: 007 Step: 00001093] Batch Translation Loss:   6.498696 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:55:00,860 [Epoch: 007 Step: 00001094] Batch Translation Loss:   5.713838 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 08:55:24,740 [Epoch: 007 Step: 00001095] Batch Translation Loss:   6.079772 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:55:48,435 [Epoch: 007 Step: 00001096] Batch Translation Loss:   6.169312 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:56:16,587 [Epoch: 007 Step: 00001097] Batch Translation Loss:   5.967982 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:57:02,124 [Epoch: 007 Step: 00001098] Batch Translation Loss:   6.344470 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:57:28,761 [Epoch: 007 Step: 00001099] Batch Translation Loss:   6.297671 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 08:57:54,679 [Epoch: 007 Step: 00001100] Batch Translation Loss:   6.608407 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:05:05,825 Validation result at epoch   7, step     1100: duration: 431.1268s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 8187.64600	PPL: 4673.12354
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 1.74,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 4.98	ROUGE 1.02
2021-12-28 09:05:13,052 Logging Recognition and Translation Outputs
2021-12-28 09:05:13,122 ========================================================================================================================
2021-12-28 09:05:13,122 Logging Sequence: youtube_3-ben_bahan_4529
2021-12-28 09:05:13,123 	Text Reference  :	nad
2021-12-28 09:05:13,123 	Text Hypothesis :	asl
2021-12-28 09:05:13,123 	Text Alignment  :	S  
2021-12-28 09:05:13,123 ========================================================================================================================
2021-12-28 09:05:13,124 Logging Sequence: youtube_1-shoshannah_stern_2393
2021-12-28 09:05:13,124 	Text Reference  :	moritz
2021-12-28 09:05:13,124 	Text Hypothesis :	asl   
2021-12-28 09:05:13,125 	Text Alignment  :	S     
2021-12-28 09:05:13,125 ========================================================================================================================
2021-12-28 09:05:13,125 Logging Sequence: youtube_1-shoshannah_stern_2377
2021-12-28 09:05:13,125 	Text Reference  :	siri
2021-12-28 09:05:13,126 	Text Hypothesis :	so  
2021-12-28 09:05:13,126 	Text Alignment  :	S   
2021-12-28 09:05:13,126 ========================================================================================================================
2021-12-28 09:05:13,126 Logging Sequence: deafvideo_3-geoalpha_4551
2021-12-28 09:05:13,127 	Text Reference  :	he cope
2021-12-28 09:05:13,127 	Text Hypothesis :	** asl 
2021-12-28 09:05:13,127 	Text Alignment  :	D  S   
2021-12-28 09:05:13,127 ========================================================================================================================
2021-12-28 09:05:13,128 Logging Sequence: youtube_1-melvin_patterson_2358
2021-12-28 09:05:13,128 	Text Reference  :	sn      
2021-12-28 09:05:13,128 	Text Hypothesis :	holocast
2021-12-28 09:05:13,128 	Text Alignment  :	S       
2021-12-28 09:05:13,129 ========================================================================================================================
2021-12-28 09:07:16,696 [Epoch: 007 Step: 00001101] Batch Translation Loss:   6.322010 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 09:07:46,310 [Epoch: 007 Step: 00001102] Batch Translation Loss:   6.027966 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:08:08,502 [Epoch: 007 Step: 00001103] Batch Translation Loss:   6.817190 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:08:32,972 [Epoch: 007 Step: 00001104] Batch Translation Loss:   6.224233 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:08:59,884 [Epoch: 007 Step: 00001105] Batch Translation Loss:   6.866835 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:09:25,128 [Epoch: 007 Step: 00001106] Batch Translation Loss:   6.496512 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:09:53,514 [Epoch: 007 Step: 00001107] Batch Translation Loss:   6.848582 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:10:14,665 [Epoch: 007 Step: 00001108] Batch Translation Loss:   6.561753 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 09:10:34,348 [Epoch: 007 Step: 00001109] Batch Translation Loss:   6.147314 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 09:10:55,024 [Epoch: 007 Step: 00001110] Batch Translation Loss:   6.107991 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 09:11:16,617 [Epoch: 007 Step: 00001111] Batch Translation Loss:   6.021568 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:11:40,712 [Epoch: 007 Step: 00001112] Batch Translation Loss:   6.772963 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:12:39,589 [Epoch: 007 Step: 00001113] Batch Translation Loss:   6.633867 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:13:10,508 [Epoch: 007 Step: 00001114] Batch Translation Loss:   5.953578 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:13:57,280 [Epoch: 007 Step: 00001115] Batch Translation Loss:   6.758681 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:14:23,623 [Epoch: 007 Step: 00001116] Batch Translation Loss:   6.653337 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:15:11,646 [Epoch: 007 Step: 00001117] Batch Translation Loss:   6.091900 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:15:39,263 [Epoch: 007 Step: 00001118] Batch Translation Loss:   6.635176 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:16:07,273 [Epoch: 007 Step: 00001119] Batch Translation Loss:   6.864455 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:16:35,255 [Epoch: 007 Step: 00001120] Batch Translation Loss:   5.796020 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:17:03,048 [Epoch: 007 Step: 00001121] Batch Translation Loss:   6.330735 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:17:31,637 [Epoch: 007 Step: 00001122] Batch Translation Loss:   5.948758 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:18:18,981 [Epoch: 007 Step: 00001123] Batch Translation Loss:   6.632280 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:18:44,692 [Epoch: 007 Step: 00001124] Batch Translation Loss:   6.227216 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:19:08,577 [Epoch: 007 Step: 00001125] Batch Translation Loss:   6.705139 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:19:31,369 [Epoch: 007 Step: 00001126] Batch Translation Loss:   6.483379 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:19:57,170 [Epoch: 007 Step: 00001127] Batch Translation Loss:   6.485550 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:20:29,773 [Epoch: 007 Step: 00001128] Batch Translation Loss:   6.453922 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:20:57,542 [Epoch: 007 Step: 00001129] Batch Translation Loss:   6.303535 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:21:33,753 [Epoch: 007 Step: 00001130] Batch Translation Loss:   6.988372 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:22:03,853 [Epoch: 007 Step: 00001131] Batch Translation Loss:   6.562560 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:22:55,219 [Epoch: 007 Step: 00001132] Batch Translation Loss:   5.592466 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:23:24,889 [Epoch: 007 Step: 00001133] Batch Translation Loss:   6.435750 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:23:56,281 [Epoch: 007 Step: 00001134] Batch Translation Loss:   6.188840 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:24:27,525 [Epoch: 007 Step: 00001135] Batch Translation Loss:   6.437278 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:24:59,634 [Epoch: 007 Step: 00001136] Batch Translation Loss:   6.873293 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:25:31,930 [Epoch: 007 Step: 00001137] Batch Translation Loss:   5.687163 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:26:02,191 [Epoch: 007 Step: 00001138] Batch Translation Loss:   6.089378 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:26:36,056 [Epoch: 007 Step: 00001139] Batch Translation Loss:   6.651257 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:27:07,900 [Epoch: 007 Step: 00001140] Batch Translation Loss:   6.471469 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:27:43,459 [Epoch: 007 Step: 00001141] Batch Translation Loss:   6.749900 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:28:12,475 [Epoch: 007 Step: 00001142] Batch Translation Loss:   7.363141 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:28:39,182 [Epoch: 007 Step: 00001143] Batch Translation Loss:   6.785538 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:29:10,038 [Epoch: 007 Step: 00001144] Batch Translation Loss:   5.851108 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:29:47,079 [Epoch: 007 Step: 00001145] Batch Translation Loss:   6.226510 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:30:19,920 [Epoch: 007 Step: 00001146] Batch Translation Loss:   6.856895 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:30:53,761 [Epoch: 007 Step: 00001147] Batch Translation Loss:   6.520626 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:31:28,099 [Epoch: 007 Step: 00001148] Batch Translation Loss:   6.873419 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:32:01,633 [Epoch: 007 Step: 00001149] Batch Translation Loss:   6.256313 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:33:04,152 [Epoch: 007 Step: 00001150] Batch Translation Loss:   6.170162 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:33:38,282 [Epoch: 007 Step: 00001151] Batch Translation Loss:   6.546331 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:34:15,372 [Epoch: 007 Step: 00001152] Batch Translation Loss:   6.028810 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:34:52,915 [Epoch: 007 Step: 00001153] Batch Translation Loss:   6.253492 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:35:28,942 [Epoch: 007 Step: 00001154] Batch Translation Loss:   6.680186 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:36:05,888 [Epoch: 007 Step: 00001155] Batch Translation Loss:   6.278732 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:36:33,791 [Epoch: 007 Step: 00001156] Batch Translation Loss:   6.228065 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:37:00,633 [Epoch: 007 Step: 00001157] Batch Translation Loss:   6.541194 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:37:31,133 [Epoch: 007 Step: 00001158] Batch Translation Loss:   6.200442 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:38:18,574 [Epoch: 007 Step: 00001159] Batch Translation Loss:   6.532841 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:39:24,913 [Epoch: 007 Step: 00001160] Batch Translation Loss:   7.087865 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 09:40:05,758 [Epoch: 007 Step: 00001161] Batch Translation Loss:   6.705439 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:40:43,446 [Epoch: 007 Step: 00001162] Batch Translation Loss:   6.609794 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:41:19,564 [Epoch: 007 Step: 00001163] Batch Translation Loss:   6.529109 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:41:58,042 [Epoch: 007 Step: 00001164] Batch Translation Loss:   6.388607 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:42:34,678 [Epoch: 007 Step: 00001165] Batch Translation Loss:   6.425590 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:43:13,234 [Epoch: 007 Step: 00001166] Batch Translation Loss:   6.009529 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:43:50,731 [Epoch: 007 Step: 00001167] Batch Translation Loss:   6.631075 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:44:33,274 [Epoch: 007 Step: 00001168] Batch Translation Loss:   6.421623 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:45:11,329 [Epoch: 007 Step: 00001169] Batch Translation Loss:   6.290316 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:45:46,501 [Epoch: 007 Step: 00001170] Batch Translation Loss:   6.395446 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:46:16,636 [Epoch: 007 Step: 00001171] Batch Translation Loss:   6.745663 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:46:48,619 [Epoch: 007 Step: 00001172] Batch Translation Loss:   6.282580 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:47:22,014 [Epoch: 007 Step: 00001173] Batch Translation Loss:   6.170515 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:48:36,843 [Epoch: 007 Step: 00001174] Batch Translation Loss:   6.602582 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 09:49:18,614 [Epoch: 007 Step: 00001175] Batch Translation Loss:   6.635213 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:50:44,964 [Epoch: 007 Step: 00001176] Batch Translation Loss:   6.646676 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 09:51:59,334 [Epoch: 007 Step: 00001177] Batch Translation Loss:   5.751901 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 09:52:38,270 [Epoch: 007 Step: 00001178] Batch Translation Loss:   6.743664 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:53:20,493 [Epoch: 007 Step: 00001179] Batch Translation Loss:   6.985950 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:54:02,984 [Epoch: 007 Step: 00001180] Batch Translation Loss:   6.217908 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:54:36,380 [Epoch: 007 Step: 00001181] Batch Translation Loss:   6.616560 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:55:07,620 [Epoch: 007 Step: 00001182] Batch Translation Loss:   6.528399 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:55:41,772 [Epoch: 007 Step: 00001183] Batch Translation Loss:   6.615952 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:56:27,886 [Epoch: 007 Step: 00001184] Batch Translation Loss:   6.353170 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:57:06,938 [Epoch: 007 Step: 00001185] Batch Translation Loss:   6.045822 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:57:43,384 [Epoch: 007 Step: 00001186] Batch Translation Loss:   6.473957 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:58:23,808 [Epoch: 007 Step: 00001187] Batch Translation Loss:   6.777951 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:59:02,827 [Epoch: 007 Step: 00001188] Batch Translation Loss:   6.792041 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 09:59:40,496 [Epoch: 007 Step: 00001189] Batch Translation Loss:   6.968963 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:00:17,783 [Epoch: 007 Step: 00001190] Batch Translation Loss:   6.626180 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 10:00:17,987 Epoch   7: Total Training Recognition Loss -1.00  Total Training Translation Loss 1106.79 
2021-12-28 10:00:17,987 EPOCH 8
2021-12-28 10:00:27,481 [Epoch: 008 Step: 00001191] Batch Translation Loss:   6.678389 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 10:00:37,207 [Epoch: 008 Step: 00001192] Batch Translation Loss:   6.940148 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 10:00:46,324 [Epoch: 008 Step: 00001193] Batch Translation Loss:   6.729261 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-28 10:00:56,560 [Epoch: 008 Step: 00001194] Batch Translation Loss:   6.924545 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 10:01:07,976 [Epoch: 008 Step: 00001195] Batch Translation Loss:   6.750729 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 10:01:21,431 [Epoch: 008 Step: 00001196] Batch Translation Loss:   6.212148 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:01:33,097 [Epoch: 008 Step: 00001197] Batch Translation Loss:   6.838952 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 10:01:42,758 [Epoch: 008 Step: 00001198] Batch Translation Loss:   6.451428 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 10:01:53,622 [Epoch: 008 Step: 00001199] Batch Translation Loss:   6.114298 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 10:02:13,585 [Epoch: 008 Step: 00001200] Batch Translation Loss:   6.763290 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:10:34,124 Validation result at epoch   8, step     1200: duration: 500.4955s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 8348.14551	PPL: 6257.35742
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 1.89,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 4.45	ROUGE 1.25
2021-12-28 10:10:41,811 Logging Recognition and Translation Outputs
2021-12-28 10:10:41,863 ========================================================================================================================
2021-12-28 10:10:41,864 Logging Sequence: youtube_1-catherine_mackinnon_2808
2021-12-28 10:10:41,864 	Text Reference  :	tylor
2021-12-28 10:10:41,864 	Text Hypothesis :	so   
2021-12-28 10:10:41,864 	Text Alignment  :	S    
2021-12-28 10:10:41,864 ========================================================================================================================
2021-12-28 10:10:41,864 Logging Sequence: deafvideo_3-deafgoldenhair_3062
2021-12-28 10:10:41,864 	Text Reference  :	** ** dhf     
2021-12-28 10:10:41,864 	Text Hypothesis :	dr mj bienvenu
2021-12-28 10:10:41,865 	Text Alignment  :	I  I  S       
2021-12-28 10:10:41,865 ========================================================================================================================
2021-12-28 10:10:41,865 Logging Sequence: youtube_1-don_grushkin_2328
2021-12-28 10:10:41,865 	Text Reference  :	** ** ada     
2021-12-28 10:10:41,865 	Text Hypothesis :	dr mj bienvenu
2021-12-28 10:10:41,865 	Text Alignment  :	I  I  S       
2021-12-28 10:10:41,865 ========================================================================================================================
2021-12-28 10:10:41,865 Logging Sequence: youtube_1-don_grushkin_2774
2021-12-28 10:10:41,865 	Text Reference  :	all 
2021-12-28 10:10:41,865 	Text Hypothesis :	coda
2021-12-28 10:10:41,865 	Text Alignment  :	S   
2021-12-28 10:10:41,865 ========================================================================================================================
2021-12-28 10:10:41,865 Logging Sequence: youtube_6-myles_de_bastion_6529
2021-12-28 10:10:41,866 	Text Reference  :	** ** gaddafi 
2021-12-28 10:10:41,866 	Text Hypothesis :	dr mj bienvenu
2021-12-28 10:10:41,866 	Text Alignment  :	I  I  S       
2021-12-28 10:10:41,866 ========================================================================================================================
2021-12-28 10:11:39,997 [Epoch: 008 Step: 00001201] Batch Translation Loss:   6.682246 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 10:12:03,270 [Epoch: 008 Step: 00001202] Batch Translation Loss:   6.152607 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:12:30,508 [Epoch: 008 Step: 00001203] Batch Translation Loss:   6.757053 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:12:49,168 [Epoch: 008 Step: 00001204] Batch Translation Loss:   6.668698 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:13:04,556 [Epoch: 008 Step: 00001205] Batch Translation Loss:   6.488731 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:13:16,957 [Epoch: 008 Step: 00001206] Batch Translation Loss:   6.713836 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 10:13:36,864 [Epoch: 008 Step: 00001207] Batch Translation Loss:   6.284589 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:13:52,781 [Epoch: 008 Step: 00001208] Batch Translation Loss:   6.536372 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:14:04,910 [Epoch: 008 Step: 00001209] Batch Translation Loss:   6.678329 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 10:14:18,891 [Epoch: 008 Step: 00001210] Batch Translation Loss:   6.724695 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:14:36,843 [Epoch: 008 Step: 00001211] Batch Translation Loss:   6.436188 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:14:52,225 [Epoch: 008 Step: 00001212] Batch Translation Loss:   6.629873 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:15:04,732 [Epoch: 008 Step: 00001213] Batch Translation Loss:   6.450208 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 10:15:24,179 [Epoch: 008 Step: 00001214] Batch Translation Loss:   6.117631 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:15:37,119 [Epoch: 008 Step: 00001215] Batch Translation Loss:   6.708746 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:15:51,289 [Epoch: 008 Step: 00001216] Batch Translation Loss:   6.558316 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:16:13,275 [Epoch: 008 Step: 00001217] Batch Translation Loss:   6.972396 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:16:26,164 [Epoch: 008 Step: 00001218] Batch Translation Loss:   6.257007 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:16:39,338 [Epoch: 008 Step: 00001219] Batch Translation Loss:   5.827876 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:16:52,607 [Epoch: 008 Step: 00001220] Batch Translation Loss:   6.178093 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:17:17,573 [Epoch: 008 Step: 00001221] Batch Translation Loss:   6.038518 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:17:44,988 [Epoch: 008 Step: 00001222] Batch Translation Loss:   5.959519 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:17:59,420 [Epoch: 008 Step: 00001223] Batch Translation Loss:   6.810806 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:18:25,926 [Epoch: 008 Step: 00001224] Batch Translation Loss:   6.268366 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:18:40,997 [Epoch: 008 Step: 00001225] Batch Translation Loss:   6.526020 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:18:55,666 [Epoch: 008 Step: 00001226] Batch Translation Loss:   6.288261 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:19:13,028 [Epoch: 008 Step: 00001227] Batch Translation Loss:   6.085970 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:19:30,778 [Epoch: 008 Step: 00001228] Batch Translation Loss:   5.912541 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:19:48,048 [Epoch: 008 Step: 00001229] Batch Translation Loss:   6.619207 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:20:05,484 [Epoch: 008 Step: 00001230] Batch Translation Loss:   6.127723 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:20:22,406 [Epoch: 008 Step: 00001231] Batch Translation Loss:   7.146595 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:20:37,708 [Epoch: 008 Step: 00001232] Batch Translation Loss:   6.675550 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:21:05,673 [Epoch: 008 Step: 00001233] Batch Translation Loss:   6.421844 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:21:23,730 [Epoch: 008 Step: 00001234] Batch Translation Loss:   6.620172 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:21:37,844 [Epoch: 008 Step: 00001235] Batch Translation Loss:   6.359160 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:21:54,992 [Epoch: 008 Step: 00001236] Batch Translation Loss:   6.306950 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:22:15,370 [Epoch: 008 Step: 00001237] Batch Translation Loss:   6.722109 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:22:31,377 [Epoch: 008 Step: 00001238] Batch Translation Loss:   6.246604 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:22:46,686 [Epoch: 008 Step: 00001239] Batch Translation Loss:   6.011089 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:23:02,432 [Epoch: 008 Step: 00001240] Batch Translation Loss:   6.993984 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:23:28,312 [Epoch: 008 Step: 00001241] Batch Translation Loss:   6.116578 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:23:48,384 [Epoch: 008 Step: 00001242] Batch Translation Loss:   6.355459 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:24:10,004 [Epoch: 008 Step: 00001243] Batch Translation Loss:   6.706264 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:24:28,603 [Epoch: 008 Step: 00001244] Batch Translation Loss:   6.707198 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:24:48,886 [Epoch: 008 Step: 00001245] Batch Translation Loss:   6.770091 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:25:07,238 [Epoch: 008 Step: 00001246] Batch Translation Loss:   6.328546 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:25:29,210 [Epoch: 008 Step: 00001247] Batch Translation Loss:   6.321619 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:25:48,137 [Epoch: 008 Step: 00001248] Batch Translation Loss:   6.354034 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:26:06,988 [Epoch: 008 Step: 00001249] Batch Translation Loss:   6.824302 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:26:27,271 [Epoch: 008 Step: 00001250] Batch Translation Loss:   6.417611 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:26:47,804 [Epoch: 008 Step: 00001251] Batch Translation Loss:   6.535663 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:27:08,692 [Epoch: 008 Step: 00001252] Batch Translation Loss:   6.523377 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:27:46,196 [Epoch: 008 Step: 00001253] Batch Translation Loss:   6.157880 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:28:06,893 [Epoch: 008 Step: 00001254] Batch Translation Loss:   6.782209 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:28:26,869 [Epoch: 008 Step: 00001255] Batch Translation Loss:   5.985672 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:28:50,726 [Epoch: 008 Step: 00001256] Batch Translation Loss:   6.591529 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:29:27,730 [Epoch: 008 Step: 00001257] Batch Translation Loss:   6.184978 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:29:50,656 [Epoch: 008 Step: 00001258] Batch Translation Loss:   6.052408 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:30:23,593 [Epoch: 008 Step: 00001259] Batch Translation Loss:   6.448228 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:30:41,799 [Epoch: 008 Step: 00001260] Batch Translation Loss:   6.327471 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:30:59,198 [Epoch: 008 Step: 00001261] Batch Translation Loss:   5.942575 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:31:18,347 [Epoch: 008 Step: 00001262] Batch Translation Loss:   6.903210 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:31:37,642 [Epoch: 008 Step: 00001263] Batch Translation Loss:   6.592685 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:32:02,199 [Epoch: 008 Step: 00001264] Batch Translation Loss:   6.339838 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:32:24,126 [Epoch: 008 Step: 00001265] Batch Translation Loss:   6.114408 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:32:48,239 [Epoch: 008 Step: 00001266] Batch Translation Loss:   6.196569 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:33:29,280 [Epoch: 008 Step: 00001267] Batch Translation Loss:   6.693603 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:33:51,362 [Epoch: 008 Step: 00001268] Batch Translation Loss:   6.824108 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:34:14,216 [Epoch: 008 Step: 00001269] Batch Translation Loss:   6.486451 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:34:39,538 [Epoch: 008 Step: 00001270] Batch Translation Loss:   6.291373 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:35:04,477 [Epoch: 008 Step: 00001271] Batch Translation Loss:   6.745944 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:35:27,921 [Epoch: 008 Step: 00001272] Batch Translation Loss:   6.605117 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:36:10,908 [Epoch: 008 Step: 00001273] Batch Translation Loss:   6.435655 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:36:33,982 [Epoch: 008 Step: 00001274] Batch Translation Loss:   6.590035 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:37:18,779 [Epoch: 008 Step: 00001275] Batch Translation Loss:   6.651577 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:37:44,367 [Epoch: 008 Step: 00001276] Batch Translation Loss:   5.804350 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:38:28,841 [Epoch: 008 Step: 00001277] Batch Translation Loss:   5.488341 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:38:52,512 [Epoch: 008 Step: 00001278] Batch Translation Loss:   6.478463 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:39:39,780 [Epoch: 008 Step: 00001279] Batch Translation Loss:   6.389350 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:40:03,227 [Epoch: 008 Step: 00001280] Batch Translation Loss:   6.721420 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:40:23,920 [Epoch: 008 Step: 00001281] Batch Translation Loss:   5.854283 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:40:44,679 [Epoch: 008 Step: 00001282] Batch Translation Loss:   5.942601 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 10:41:10,709 [Epoch: 008 Step: 00001283] Batch Translation Loss:   5.921033 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:41:35,940 [Epoch: 008 Step: 00001284] Batch Translation Loss:   6.006312 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:42:09,927 [Epoch: 008 Step: 00001285] Batch Translation Loss:   5.992001 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:42:37,082 [Epoch: 008 Step: 00001286] Batch Translation Loss:   6.130089 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:43:04,862 [Epoch: 008 Step: 00001287] Batch Translation Loss:   6.651467 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:43:36,488 [Epoch: 008 Step: 00001288] Batch Translation Loss:   6.329020 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:44:04,114 [Epoch: 008 Step: 00001289] Batch Translation Loss:   6.078568 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:44:31,984 [Epoch: 008 Step: 00001290] Batch Translation Loss:   6.573900 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:44:58,342 [Epoch: 008 Step: 00001291] Batch Translation Loss:   6.271272 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:45:28,592 [Epoch: 008 Step: 00001292] Batch Translation Loss:   6.696425 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:45:58,494 [Epoch: 008 Step: 00001293] Batch Translation Loss:   6.372660 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:46:26,534 [Epoch: 008 Step: 00001294] Batch Translation Loss:   6.641169 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:46:55,166 [Epoch: 008 Step: 00001295] Batch Translation Loss:   6.811878 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:47:26,052 [Epoch: 008 Step: 00001296] Batch Translation Loss:   6.488884 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:47:57,749 [Epoch: 008 Step: 00001297] Batch Translation Loss:   5.932119 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:48:26,900 [Epoch: 008 Step: 00001298] Batch Translation Loss:   6.524951 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:48:54,057 [Epoch: 008 Step: 00001299] Batch Translation Loss:   6.592752 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:49:23,974 [Epoch: 008 Step: 00001300] Batch Translation Loss:   6.769061 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:56:29,645 Validation result at epoch   8, step     1300: duration: 425.6702s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 8209.67969	PPL: 5511.34521
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 1.34,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 4.53	ROUGE 1.21
2021-12-28 10:56:38,609 Logging Recognition and Translation Outputs
2021-12-28 10:56:38,645 ========================================================================================================================
2021-12-28 10:56:38,645 Logging Sequence: deafvideo_2-fairytales9_2292
2021-12-28 10:56:38,646 	Text Reference  :	tool
2021-12-28 10:56:38,647 	Text Hypothesis :	asl 
2021-12-28 10:56:38,647 	Text Alignment  :	S   
2021-12-28 10:56:38,647 ========================================================================================================================
2021-12-28 10:56:38,648 Logging Sequence: youtube_4-lizzie_sorkin_5250
2021-12-28 10:56:38,648 	Text Reference  :	files
2021-12-28 10:56:38,648 	Text Hypothesis :	asl  
2021-12-28 10:56:38,649 	Text Alignment  :	S    
2021-12-28 10:56:38,649 ========================================================================================================================
2021-12-28 10:56:38,649 Logging Sequence: deafvideo_3-geoalpha_4572
2021-12-28 10:56:38,649 	Text Reference  :	do      
2021-12-28 10:56:38,650 	Text Hypothesis :	handling
2021-12-28 10:56:38,650 	Text Alignment  :	S       
2021-12-28 10:56:38,650 ========================================================================================================================
2021-12-28 10:56:38,650 Logging Sequence: deafvideo_3-yesyes_3103
2021-12-28 10:56:38,651 	Text Reference  :	*** scan
2021-12-28 10:56:38,651 	Text Hypothesis :	cdi cdi 
2021-12-28 10:56:38,651 	Text Alignment  :	I   S   
2021-12-28 10:56:38,652 ========================================================================================================================
2021-12-28 10:56:38,652 Logging Sequence: youtube_1-shoshannah_stern_2388
2021-12-28 10:56:38,658 	Text Reference  :	use
2021-12-28 10:56:38,659 	Text Hypothesis :	asl
2021-12-28 10:56:38,659 	Text Alignment  :	S  
2021-12-28 10:56:38,659 ========================================================================================================================
2021-12-28 10:58:32,699 [Epoch: 008 Step: 00001301] Batch Translation Loss:   7.035126 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 10:59:11,043 [Epoch: 008 Step: 00001302] Batch Translation Loss:   6.078526 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 10:59:35,053 [Epoch: 008 Step: 00001303] Batch Translation Loss:   6.070076 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:00:49,153 [Epoch: 008 Step: 00001304] Batch Translation Loss:   6.540949 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 11:01:18,935 [Epoch: 008 Step: 00001305] Batch Translation Loss:   6.623463 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:02:16,285 [Epoch: 008 Step: 00001306] Batch Translation Loss:   6.247909 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:02:49,590 [Epoch: 008 Step: 00001307] Batch Translation Loss:   7.032616 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:03:20,799 [Epoch: 008 Step: 00001308] Batch Translation Loss:   6.260005 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:03:54,242 [Epoch: 008 Step: 00001309] Batch Translation Loss:   6.791850 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:04:27,481 [Epoch: 008 Step: 00001310] Batch Translation Loss:   6.914779 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:04:59,975 [Epoch: 008 Step: 00001311] Batch Translation Loss:   6.196352 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:05:34,159 [Epoch: 008 Step: 00001312] Batch Translation Loss:   6.449421 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:06:06,717 [Epoch: 008 Step: 00001313] Batch Translation Loss:   6.353262 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:07:06,883 [Epoch: 008 Step: 00001314] Batch Translation Loss:   6.496198 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:07:36,932 [Epoch: 008 Step: 00001315] Batch Translation Loss:   6.477373 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:08:27,841 [Epoch: 008 Step: 00001316] Batch Translation Loss:   6.671392 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:08:57,398 [Epoch: 008 Step: 00001317] Batch Translation Loss:   7.165413 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:09:34,604 [Epoch: 008 Step: 00001318] Batch Translation Loss:   6.169756 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:10:07,331 [Epoch: 008 Step: 00001319] Batch Translation Loss:   6.975012 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:10:46,653 [Epoch: 008 Step: 00001320] Batch Translation Loss:   6.325103 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:11:34,319 [Epoch: 008 Step: 00001321] Batch Translation Loss:   5.723852 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:12:08,604 [Epoch: 008 Step: 00001322] Batch Translation Loss:   6.925965 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:12:48,985 [Epoch: 008 Step: 00001323] Batch Translation Loss:   6.385001 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:13:23,163 [Epoch: 008 Step: 00001324] Batch Translation Loss:   6.749957 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:14:02,315 [Epoch: 008 Step: 00001325] Batch Translation Loss:   5.624365 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:14:39,686 [Epoch: 008 Step: 00001326] Batch Translation Loss:   6.694149 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:15:16,570 [Epoch: 008 Step: 00001327] Batch Translation Loss:   6.286827 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:15:55,051 [Epoch: 008 Step: 00001328] Batch Translation Loss:   6.568006 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:16:29,819 [Epoch: 008 Step: 00001329] Batch Translation Loss:   6.830941 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:17:07,515 [Epoch: 008 Step: 00001330] Batch Translation Loss:   6.602009 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:17:37,125 [Epoch: 008 Step: 00001331] Batch Translation Loss:   6.445185 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:18:18,871 [Epoch: 008 Step: 00001332] Batch Translation Loss:   6.471286 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:18:55,059 [Epoch: 008 Step: 00001333] Batch Translation Loss:   6.312189 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:19:30,425 [Epoch: 008 Step: 00001334] Batch Translation Loss:   6.134367 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:20:08,553 [Epoch: 008 Step: 00001335] Batch Translation Loss:   6.529848 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:20:45,710 [Epoch: 008 Step: 00001336] Batch Translation Loss:   6.229441 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:21:24,681 [Epoch: 008 Step: 00001337] Batch Translation Loss:   6.364376 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:22:05,211 [Epoch: 008 Step: 00001338] Batch Translation Loss:   6.907032 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:22:41,376 [Epoch: 008 Step: 00001339] Batch Translation Loss:   6.768708 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:23:20,877 [Epoch: 008 Step: 00001340] Batch Translation Loss:   7.006665 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:23:58,618 [Epoch: 008 Step: 00001341] Batch Translation Loss:   6.754559 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:24:37,196 [Epoch: 008 Step: 00001342] Batch Translation Loss:   6.285262 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:25:50,585 [Epoch: 008 Step: 00001343] Batch Translation Loss:   6.611650 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 11:26:24,507 [Epoch: 008 Step: 00001344] Batch Translation Loss:   6.258174 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:26:56,015 [Epoch: 008 Step: 00001345] Batch Translation Loss:   6.486346 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:27:26,152 [Epoch: 008 Step: 00001346] Batch Translation Loss:   6.206464 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:27:59,762 [Epoch: 008 Step: 00001347] Batch Translation Loss:   6.989194 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:29:14,312 [Epoch: 008 Step: 00001348] Batch Translation Loss:   6.473794 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 11:29:52,728 [Epoch: 008 Step: 00001349] Batch Translation Loss:   6.141937 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:30:29,347 [Epoch: 008 Step: 00001350] Batch Translation Loss:   5.991925 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:31:07,348 [Epoch: 008 Step: 00001351] Batch Translation Loss:   6.406981 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:31:49,832 [Epoch: 008 Step: 00001352] Batch Translation Loss:   6.658350 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:32:32,066 [Epoch: 008 Step: 00001353] Batch Translation Loss:   6.431972 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:33:11,080 [Epoch: 008 Step: 00001354] Batch Translation Loss:   6.511242 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:33:52,166 [Epoch: 008 Step: 00001355] Batch Translation Loss:   5.962967 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:34:32,353 [Epoch: 008 Step: 00001356] Batch Translation Loss:   6.000467 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:35:45,997 [Epoch: 008 Step: 00001357] Batch Translation Loss:   6.741992 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 11:36:51,880 [Epoch: 008 Step: 00001358] Batch Translation Loss:   6.610802 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 11:38:00,400 [Epoch: 008 Step: 00001359] Batch Translation Loss:   6.407358 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 11:39:12,513 [Epoch: 008 Step: 00001360] Batch Translation Loss:   6.063990 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 11:39:12,668 Epoch   8: Total Training Recognition Loss -1.00  Total Training Translation Loss 1096.16 
2021-12-28 11:39:12,668 EPOCH 9
2021-12-28 11:39:20,903 [Epoch: 009 Step: 00001361] Batch Translation Loss:   6.784985 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-28 11:39:30,133 [Epoch: 009 Step: 00001362] Batch Translation Loss:   6.997268 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 11:39:40,343 [Epoch: 009 Step: 00001363] Batch Translation Loss:   6.864037 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 11:39:50,517 [Epoch: 009 Step: 00001364] Batch Translation Loss:   6.389573 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 11:40:04,410 [Epoch: 009 Step: 00001365] Batch Translation Loss:   7.095975 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 11:40:14,428 [Epoch: 009 Step: 00001366] Batch Translation Loss:   6.770427 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 11:40:24,077 [Epoch: 009 Step: 00001367] Batch Translation Loss:   6.493535 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 11:40:36,537 [Epoch: 009 Step: 00001368] Batch Translation Loss:   6.921048 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 11:40:50,806 [Epoch: 009 Step: 00001369] Batch Translation Loss:   6.051661 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 11:41:05,881 [Epoch: 009 Step: 00001370] Batch Translation Loss:   6.751110 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 11:41:16,130 [Epoch: 009 Step: 00001371] Batch Translation Loss:   6.446158 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 11:41:31,223 [Epoch: 009 Step: 00001372] Batch Translation Loss:   7.070994 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 11:41:45,852 [Epoch: 009 Step: 00001373] Batch Translation Loss:   6.492609 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 11:42:02,868 [Epoch: 009 Step: 00001374] Batch Translation Loss:   6.395303 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 11:42:14,373 [Epoch: 009 Step: 00001375] Batch Translation Loss:   6.532914 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 11:42:30,028 [Epoch: 009 Step: 00001376] Batch Translation Loss:   6.391521 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 11:42:48,065 [Epoch: 009 Step: 00001377] Batch Translation Loss:   6.700770 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 11:42:57,977 [Epoch: 009 Step: 00001378] Batch Translation Loss:   5.917416 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 11:43:15,584 [Epoch: 009 Step: 00001379] Batch Translation Loss:   6.823311 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 11:43:27,582 [Epoch: 009 Step: 00001380] Batch Translation Loss:   6.388948 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 11:43:43,309 [Epoch: 009 Step: 00001381] Batch Translation Loss:   5.896023 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 11:43:55,436 [Epoch: 009 Step: 00001382] Batch Translation Loss:   5.994535 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 11:44:15,695 [Epoch: 009 Step: 00001383] Batch Translation Loss:   6.978459 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 11:44:28,440 [Epoch: 009 Step: 00001384] Batch Translation Loss:   6.440039 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 11:44:41,564 [Epoch: 009 Step: 00001385] Batch Translation Loss:   6.531141 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 11:44:54,202 [Epoch: 009 Step: 00001386] Batch Translation Loss:   5.860255 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 11:45:09,929 [Epoch: 009 Step: 00001387] Batch Translation Loss:   6.709406 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 11:45:24,363 [Epoch: 009 Step: 00001388] Batch Translation Loss:   6.481090 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 11:45:46,030 [Epoch: 009 Step: 00001389] Batch Translation Loss:   6.206179 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:46:01,042 [Epoch: 009 Step: 00001390] Batch Translation Loss:   7.030102 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 11:46:21,217 [Epoch: 009 Step: 00001391] Batch Translation Loss:   6.334364 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 11:46:33,161 [Epoch: 009 Step: 00001392] Batch Translation Loss:   6.308183 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 11:46:45,420 [Epoch: 009 Step: 00001393] Batch Translation Loss:   6.440666 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 11:47:08,376 [Epoch: 009 Step: 00001394] Batch Translation Loss:   6.484559 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:47:33,402 [Epoch: 009 Step: 00001395] Batch Translation Loss:   6.569868 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:47:49,573 [Epoch: 009 Step: 00001396] Batch Translation Loss:   6.800676 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 11:48:10,965 [Epoch: 009 Step: 00001397] Batch Translation Loss:   6.706542 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:48:25,664 [Epoch: 009 Step: 00001398] Batch Translation Loss:   6.247094 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 11:48:42,995 [Epoch: 009 Step: 00001399] Batch Translation Loss:   6.922688 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 11:48:59,255 [Epoch: 009 Step: 00001400] Batch Translation Loss:   6.600140 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 11:56:30,149 Validation result at epoch   9, step     1400: duration: 450.8483s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 8318.85742	PPL: 6353.06055
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 1.27,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 4.68	ROUGE 1.61
2021-12-28 11:56:37,341 Logging Recognition and Translation Outputs
2021-12-28 11:56:37,364 ========================================================================================================================
2021-12-28 11:56:37,364 Logging Sequence: deafvideo_2-sddsimple_1597
2021-12-28 11:56:37,365 	Text Reference  :	** **** ** away
2021-12-28 11:56:37,366 	Text Hypothesis :	ag bell ag bad 
2021-12-28 11:56:37,366 	Text Alignment  :	I  I    I  S   
2021-12-28 11:56:37,366 ========================================================================================================================
2021-12-28 11:56:37,366 Logging Sequence: deafvideo_3-deafgoldenhair_3064
2021-12-28 11:56:37,367 	Text Reference  :	lt
2021-12-28 11:56:37,367 	Text Hypothesis :	or
2021-12-28 11:56:37,367 	Text Alignment  :	S 
2021-12-28 11:56:37,368 ========================================================================================================================
2021-12-28 11:56:37,368 Logging Sequence: youtube_5-melissa_draganac-hawk_5836
2021-12-28 11:56:37,368 	Text Reference  :	f 
2021-12-28 11:56:37,368 	Text Hypothesis :	or
2021-12-28 11:56:37,369 	Text Alignment  :	S 
2021-12-28 11:56:37,369 ========================================================================================================================
2021-12-28 11:56:37,369 Logging Sequence: youtube_5-roberta_cordano_6149
2021-12-28 11:56:37,369 	Text Reference  :	nad        
2021-12-28 11:56:37,370 	Text Hypothesis :	concentrian
2021-12-28 11:56:37,370 	Text Alignment  :	S          
2021-12-28 11:56:37,370 ========================================================================================================================
2021-12-28 11:56:37,370 Logging Sequence: youtube_5-melissa_draganac-hawk_5835
2021-12-28 11:56:37,371 	Text Reference  :	ok asl
2021-12-28 11:56:37,371 	Text Hypothesis :	** asl
2021-12-28 11:56:37,371 	Text Alignment  :	D     
2021-12-28 11:56:37,371 ========================================================================================================================
2021-12-28 11:57:31,748 [Epoch: 009 Step: 00001401] Batch Translation Loss:   6.387412 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:58:33,690 [Epoch: 009 Step: 00001402] Batch Translation Loss:   6.410611 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 11:58:50,584 [Epoch: 009 Step: 00001403] Batch Translation Loss:   7.157468 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 11:59:07,602 [Epoch: 009 Step: 00001404] Batch Translation Loss:   6.739820 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 11:59:23,725 [Epoch: 009 Step: 00001405] Batch Translation Loss:   6.492934 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 11:59:42,298 [Epoch: 009 Step: 00001406] Batch Translation Loss:   6.044312 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 11:59:59,000 [Epoch: 009 Step: 00001407] Batch Translation Loss:   6.247525 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 12:00:19,619 [Epoch: 009 Step: 00001408] Batch Translation Loss:   6.589645 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 12:00:36,182 [Epoch: 009 Step: 00001409] Batch Translation Loss:   7.031595 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 12:00:53,665 [Epoch: 009 Step: 00001410] Batch Translation Loss:   6.312364 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 12:01:11,358 [Epoch: 009 Step: 00001411] Batch Translation Loss:   6.410319 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 12:01:29,853 [Epoch: 009 Step: 00001412] Batch Translation Loss:   6.424859 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 12:01:49,239 [Epoch: 009 Step: 00001413] Batch Translation Loss:   6.059835 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 12:02:07,693 [Epoch: 009 Step: 00001414] Batch Translation Loss:   6.192050 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 12:02:27,362 [Epoch: 009 Step: 00001415] Batch Translation Loss:   6.720376 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 12:02:45,308 [Epoch: 009 Step: 00001416] Batch Translation Loss:   6.408039 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 12:03:04,655 [Epoch: 009 Step: 00001417] Batch Translation Loss:   6.178729 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 12:03:23,912 [Epoch: 009 Step: 00001418] Batch Translation Loss:   6.571161 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 12:03:42,142 [Epoch: 009 Step: 00001419] Batch Translation Loss:   6.185414 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 12:04:08,755 [Epoch: 009 Step: 00001420] Batch Translation Loss:   6.978751 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:04:29,708 [Epoch: 009 Step: 00001421] Batch Translation Loss:   6.353998 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 12:04:49,826 [Epoch: 009 Step: 00001422] Batch Translation Loss:   6.087388 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 12:05:08,616 [Epoch: 009 Step: 00001423] Batch Translation Loss:   6.634872 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 12:05:41,153 [Epoch: 009 Step: 00001424] Batch Translation Loss:   6.278924 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:05:58,506 [Epoch: 009 Step: 00001425] Batch Translation Loss:   6.914783 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 12:06:15,413 [Epoch: 009 Step: 00001426] Batch Translation Loss:   6.445019 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 12:06:35,224 [Epoch: 009 Step: 00001427] Batch Translation Loss:   6.734910 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 12:06:58,969 [Epoch: 009 Step: 00001428] Batch Translation Loss:   6.435635 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:07:20,183 [Epoch: 009 Step: 00001429] Batch Translation Loss:   6.665996 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 12:07:43,130 [Epoch: 009 Step: 00001430] Batch Translation Loss:   6.577826 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:08:05,449 [Epoch: 009 Step: 00001431] Batch Translation Loss:   6.834079 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:08:50,046 [Epoch: 009 Step: 00001432] Batch Translation Loss:   6.068789 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:09:13,415 [Epoch: 009 Step: 00001433] Batch Translation Loss:   6.149602 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:09:37,554 [Epoch: 009 Step: 00001434] Batch Translation Loss:   6.220467 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:09:59,074 [Epoch: 009 Step: 00001435] Batch Translation Loss:   6.290654 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:10:38,725 [Epoch: 009 Step: 00001436] Batch Translation Loss:   6.437829 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:11:04,431 [Epoch: 009 Step: 00001437] Batch Translation Loss:   6.288329 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:11:27,031 [Epoch: 009 Step: 00001438] Batch Translation Loss:   6.356693 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:11:51,134 [Epoch: 009 Step: 00001439] Batch Translation Loss:   6.296232 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:12:15,845 [Epoch: 009 Step: 00001440] Batch Translation Loss:   6.195669 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:12:45,134 [Epoch: 009 Step: 00001441] Batch Translation Loss:   6.484888 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:13:10,922 [Epoch: 009 Step: 00001442] Batch Translation Loss:   6.803755 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:13:35,386 [Epoch: 009 Step: 00001443] Batch Translation Loss:   5.961838 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:14:00,231 [Epoch: 009 Step: 00001444] Batch Translation Loss:   6.135317 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:14:38,770 [Epoch: 009 Step: 00001445] Batch Translation Loss:   6.748020 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:14:58,569 [Epoch: 009 Step: 00001446] Batch Translation Loss:   6.637420 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 12:15:20,241 [Epoch: 009 Step: 00001447] Batch Translation Loss:   6.535302 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:15:45,610 [Epoch: 009 Step: 00001448] Batch Translation Loss:   6.217221 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:16:10,183 [Epoch: 009 Step: 00001449] Batch Translation Loss:   6.651988 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:16:38,202 [Epoch: 009 Step: 00001450] Batch Translation Loss:   6.575201 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:17:03,948 [Epoch: 009 Step: 00001451] Batch Translation Loss:   6.683841 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:17:31,123 [Epoch: 009 Step: 00001452] Batch Translation Loss:   6.592649 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:17:58,324 [Epoch: 009 Step: 00001453] Batch Translation Loss:   6.444123 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:18:25,238 [Epoch: 009 Step: 00001454] Batch Translation Loss:   6.378745 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:19:13,953 [Epoch: 009 Step: 00001455] Batch Translation Loss:   6.585160 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:19:40,432 [Epoch: 009 Step: 00001456] Batch Translation Loss:   6.143629 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:20:28,841 [Epoch: 009 Step: 00001457] Batch Translation Loss:   6.363228 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:21:01,851 [Epoch: 009 Step: 00001458] Batch Translation Loss:   6.881558 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:21:30,173 [Epoch: 009 Step: 00001459] Batch Translation Loss:   6.752978 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:21:57,302 [Epoch: 009 Step: 00001460] Batch Translation Loss:   5.803000 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:22:27,730 [Epoch: 009 Step: 00001461] Batch Translation Loss:   5.763048 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:22:56,952 [Epoch: 009 Step: 00001462] Batch Translation Loss:   6.444666 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:23:24,867 [Epoch: 009 Step: 00001463] Batch Translation Loss:   6.222410 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:23:53,352 [Epoch: 009 Step: 00001464] Batch Translation Loss:   6.111772 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:24:16,695 [Epoch: 009 Step: 00001465] Batch Translation Loss:   6.469333 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:24:40,005 [Epoch: 009 Step: 00001466] Batch Translation Loss:   6.586970 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:25:07,410 [Epoch: 009 Step: 00001467] Batch Translation Loss:   6.401679 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:25:54,330 [Epoch: 009 Step: 00001468] Batch Translation Loss:   6.017420 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:26:32,831 [Epoch: 009 Step: 00001469] Batch Translation Loss:   6.602255 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:27:01,975 [Epoch: 009 Step: 00001470] Batch Translation Loss:   6.473325 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:27:32,071 [Epoch: 009 Step: 00001471] Batch Translation Loss:   6.570435 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:28:19,790 [Epoch: 009 Step: 00001472] Batch Translation Loss:   6.572417 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:28:51,984 [Epoch: 009 Step: 00001473] Batch Translation Loss:   6.804139 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:29:20,487 [Epoch: 009 Step: 00001474] Batch Translation Loss:   6.363922 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:29:50,864 [Epoch: 009 Step: 00001475] Batch Translation Loss:   6.662089 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:30:22,437 [Epoch: 009 Step: 00001476] Batch Translation Loss:   6.984971 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:30:53,174 [Epoch: 009 Step: 00001477] Batch Translation Loss:   6.012314 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:31:53,269 [Epoch: 009 Step: 00001478] Batch Translation Loss:   6.486804 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:33:03,449 [Epoch: 009 Step: 00001479] Batch Translation Loss:   6.615855 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 12:33:31,192 [Epoch: 009 Step: 00001480] Batch Translation Loss:   5.842734 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:33:57,697 [Epoch: 009 Step: 00001481] Batch Translation Loss:   6.348695 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:34:25,604 [Epoch: 009 Step: 00001482] Batch Translation Loss:   6.256755 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:35:04,608 [Epoch: 009 Step: 00001483] Batch Translation Loss:   5.764181 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:35:34,816 [Epoch: 009 Step: 00001484] Batch Translation Loss:   6.495766 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:36:11,708 [Epoch: 009 Step: 00001485] Batch Translation Loss:   6.392879 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:36:45,224 [Epoch: 009 Step: 00001486] Batch Translation Loss:   6.048003 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:37:18,867 [Epoch: 009 Step: 00001487] Batch Translation Loss:   6.850304 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:37:50,957 [Epoch: 009 Step: 00001488] Batch Translation Loss:   6.337578 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:38:23,009 [Epoch: 009 Step: 00001489] Batch Translation Loss:   6.005165 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:38:56,065 [Epoch: 009 Step: 00001490] Batch Translation Loss:   6.756778 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:39:38,483 [Epoch: 009 Step: 00001491] Batch Translation Loss:   6.663532 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:40:08,896 [Epoch: 009 Step: 00001492] Batch Translation Loss:   6.133298 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:40:41,085 [Epoch: 009 Step: 00001493] Batch Translation Loss:   6.753747 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:41:14,219 [Epoch: 009 Step: 00001494] Batch Translation Loss:   6.390609 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:41:45,755 [Epoch: 009 Step: 00001495] Batch Translation Loss:   6.186064 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:42:48,266 [Epoch: 009 Step: 00001496] Batch Translation Loss:   6.292542 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:43:16,504 [Epoch: 009 Step: 00001497] Batch Translation Loss:   6.311085 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:43:42,544 [Epoch: 009 Step: 00001498] Batch Translation Loss:   6.150319 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:44:13,084 [Epoch: 009 Step: 00001499] Batch Translation Loss:   6.246444 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:44:59,652 [Epoch: 009 Step: 00001500] Batch Translation Loss:   5.995455 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:52:01,674 Validation result at epoch   9, step     1500: duration: 421.9894s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 8222.99414	PPL: 4804.52734
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 2.50,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 4.73	ROUGE 1.58
2021-12-28 12:52:07,265 Logging Recognition and Translation Outputs
2021-12-28 12:52:07,265 ========================================================================================================================
2021-12-28 12:52:07,265 Logging Sequence: youtube_4-howard_rosenblum_5575
2021-12-28 12:52:07,266 	Text Reference  :	respect
2021-12-28 12:52:07,266 	Text Hypothesis :	morkie 
2021-12-28 12:52:07,266 	Text Alignment  :	S      
2021-12-28 12:52:07,266 ========================================================================================================================
2021-12-28 12:52:07,266 Logging Sequence: youtube_4-howard_rosenblum_5563
2021-12-28 12:52:07,267 	Text Reference  :	kafi lemons
2021-12-28 12:52:07,267 	Text Hypothesis :	**** so    
2021-12-28 12:52:07,267 	Text Alignment  :	D    S     
2021-12-28 12:52:07,267 ========================================================================================================================
2021-12-28 12:52:07,267 Logging Sequence: deafvideo_3-yellowbirdie84_4684
2021-12-28 12:52:07,267 	Text Reference  :	do it 
2021-12-28 12:52:07,267 	Text Hypothesis :	** asl
2021-12-28 12:52:07,267 	Text Alignment  :	D  S  
2021-12-28 12:52:07,267 ========================================================================================================================
2021-12-28 12:52:07,268 Logging Sequence: deafvideo_2-fairytales9_2284
2021-12-28 12:52:07,268 	Text Reference  :	ntid
2021-12-28 12:52:07,268 	Text Hypothesis :	asl 
2021-12-28 12:52:07,268 	Text Alignment  :	S   
2021-12-28 12:52:07,268 ========================================================================================================================
2021-12-28 12:52:07,268 Logging Sequence: youtube_5-daniel_durant_5893
2021-12-28 12:52:07,268 	Text Reference  :	*** faq
2021-12-28 12:52:07,268 	Text Hypothesis :	asl lit
2021-12-28 12:52:07,268 	Text Alignment  :	I   S  
2021-12-28 12:52:07,269 ========================================================================================================================
2021-12-28 12:53:40,221 [Epoch: 009 Step: 00001501] Batch Translation Loss:   6.569560 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 12:54:32,755 [Epoch: 009 Step: 00001502] Batch Translation Loss:   6.939867 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:55:03,902 [Epoch: 009 Step: 00001503] Batch Translation Loss:   6.330874 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:55:48,936 [Epoch: 009 Step: 00001504] Batch Translation Loss:   6.345797 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:56:22,139 [Epoch: 009 Step: 00001505] Batch Translation Loss:   6.159995 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:57:00,155 [Epoch: 009 Step: 00001506] Batch Translation Loss:   5.895976 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 12:58:06,251 [Epoch: 009 Step: 00001507] Batch Translation Loss:   6.147763 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 12:59:11,774 [Epoch: 009 Step: 00001508] Batch Translation Loss:   6.752720 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 12:59:48,757 [Epoch: 009 Step: 00001509] Batch Translation Loss:   6.154428 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:00:26,584 [Epoch: 009 Step: 00001510] Batch Translation Loss:   6.174541 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:01:12,952 [Epoch: 009 Step: 00001511] Batch Translation Loss:   6.616420 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:01:49,935 [Epoch: 009 Step: 00001512] Batch Translation Loss:   6.298829 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:02:35,130 [Epoch: 009 Step: 00001513] Batch Translation Loss:   6.930499 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:03:06,381 [Epoch: 009 Step: 00001514] Batch Translation Loss:   5.787273 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:04:20,130 [Epoch: 009 Step: 00001515] Batch Translation Loss:   5.974955 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 13:04:57,124 [Epoch: 009 Step: 00001516] Batch Translation Loss:   6.457833 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:05:36,704 [Epoch: 009 Step: 00001517] Batch Translation Loss:   6.597620 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:06:15,330 [Epoch: 009 Step: 00001518] Batch Translation Loss:   6.545868 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:06:53,905 [Epoch: 009 Step: 00001519] Batch Translation Loss:   6.994329 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:07:28,708 [Epoch: 009 Step: 00001520] Batch Translation Loss:   6.576095 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:08:07,133 [Epoch: 009 Step: 00001521] Batch Translation Loss:   6.346033 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:08:44,771 [Epoch: 009 Step: 00001522] Batch Translation Loss:   6.933450 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:09:21,812 [Epoch: 009 Step: 00001523] Batch Translation Loss:   6.892091 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:09:59,217 [Epoch: 009 Step: 00001524] Batch Translation Loss:   6.637251 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:10:34,667 [Epoch: 009 Step: 00001525] Batch Translation Loss:   6.360563 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:11:13,470 [Epoch: 009 Step: 00001526] Batch Translation Loss:   6.202991 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:12:14,347 [Epoch: 009 Step: 00001527] Batch Translation Loss:   6.612265 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:12:44,605 [Epoch: 009 Step: 00001528] Batch Translation Loss:   6.273234 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:13:18,800 [Epoch: 009 Step: 00001529] Batch Translation Loss:   6.642873 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:14:33,512 [Epoch: 009 Step: 00001530] Batch Translation Loss:   6.409805 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 13:14:33,714 Epoch   9: Total Training Recognition Loss -1.00  Total Training Translation Loss 1096.96 
2021-12-28 13:14:33,714 EPOCH 10
2021-12-28 13:14:41,248 [Epoch: 010 Step: 00001531] Batch Translation Loss:   6.456181 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-28 13:14:47,360 [Epoch: 010 Step: 00001532] Batch Translation Loss:   6.535954 => Txt Tokens per Sec:        5 || Lr: 0.000700
2021-12-28 13:14:55,241 [Epoch: 010 Step: 00001533] Batch Translation Loss:   6.982416 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-28 13:15:05,641 [Epoch: 010 Step: 00001534] Batch Translation Loss:   7.063238 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 13:15:15,531 [Epoch: 010 Step: 00001535] Batch Translation Loss:   7.163635 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 13:15:24,571 [Epoch: 010 Step: 00001536] Batch Translation Loss:   6.635930 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-28 13:15:39,537 [Epoch: 010 Step: 00001537] Batch Translation Loss:   6.965015 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:15:50,243 [Epoch: 010 Step: 00001538] Batch Translation Loss:   6.390188 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 13:15:59,746 [Epoch: 010 Step: 00001539] Batch Translation Loss:   6.825395 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 13:16:15,726 [Epoch: 010 Step: 00001540] Batch Translation Loss:   6.777159 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:16:25,759 [Epoch: 010 Step: 00001541] Batch Translation Loss:   6.835013 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 13:16:37,171 [Epoch: 010 Step: 00001542] Batch Translation Loss:   5.938711 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 13:16:47,354 [Epoch: 010 Step: 00001543] Batch Translation Loss:   6.859581 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 13:16:56,938 [Epoch: 010 Step: 00001544] Batch Translation Loss:   6.441547 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 13:17:07,803 [Epoch: 010 Step: 00001545] Batch Translation Loss:   6.359255 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 13:17:20,100 [Epoch: 010 Step: 00001546] Batch Translation Loss:   5.861113 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 13:17:31,535 [Epoch: 010 Step: 00001547] Batch Translation Loss:   6.372166 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 13:17:48,348 [Epoch: 010 Step: 00001548] Batch Translation Loss:   6.105647 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:18:00,957 [Epoch: 010 Step: 00001549] Batch Translation Loss:   7.087826 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 13:18:12,779 [Epoch: 010 Step: 00001550] Batch Translation Loss:   6.683784 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 13:18:23,158 [Epoch: 010 Step: 00001551] Batch Translation Loss:   5.964596 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 13:18:42,101 [Epoch: 010 Step: 00001552] Batch Translation Loss:   6.695409 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:18:57,755 [Epoch: 010 Step: 00001553] Batch Translation Loss:   6.816083 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:19:12,598 [Epoch: 010 Step: 00001554] Batch Translation Loss:   6.537754 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:19:23,842 [Epoch: 010 Step: 00001555] Batch Translation Loss:   6.333782 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 13:19:36,467 [Epoch: 010 Step: 00001556] Batch Translation Loss:   6.175730 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 13:19:49,307 [Epoch: 010 Step: 00001557] Batch Translation Loss:   6.998441 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 13:20:12,084 [Epoch: 010 Step: 00001558] Batch Translation Loss:   6.434501 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:20:26,658 [Epoch: 010 Step: 00001559] Batch Translation Loss:   6.279239 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:20:43,715 [Epoch: 010 Step: 00001560] Batch Translation Loss:   6.235805 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:20:57,607 [Epoch: 010 Step: 00001561] Batch Translation Loss:   6.644185 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:21:10,967 [Epoch: 010 Step: 00001562] Batch Translation Loss:   6.431628 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:21:36,452 [Epoch: 010 Step: 00001563] Batch Translation Loss:   6.311211 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:21:47,322 [Epoch: 010 Step: 00001564] Batch Translation Loss:   5.970435 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 13:22:00,321 [Epoch: 010 Step: 00001565] Batch Translation Loss:   5.943643 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:22:19,480 [Epoch: 010 Step: 00001566] Batch Translation Loss:   6.131764 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:22:30,998 [Epoch: 010 Step: 00001567] Batch Translation Loss:   6.633255 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 13:22:43,903 [Epoch: 010 Step: 00001568] Batch Translation Loss:   6.699364 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:22:57,978 [Epoch: 010 Step: 00001569] Batch Translation Loss:   6.183115 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:23:16,949 [Epoch: 010 Step: 00001570] Batch Translation Loss:   6.696909 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:23:31,953 [Epoch: 010 Step: 00001571] Batch Translation Loss:   6.700848 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:23:54,616 [Epoch: 010 Step: 00001572] Batch Translation Loss:   6.445269 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:24:25,451 [Epoch: 010 Step: 00001573] Batch Translation Loss:   6.053377 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:24:55,431 [Epoch: 010 Step: 00001574] Batch Translation Loss:   6.109466 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:25:34,300 [Epoch: 010 Step: 00001575] Batch Translation Loss:   6.103424 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:25:52,472 [Epoch: 010 Step: 00001576] Batch Translation Loss:   5.928491 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:26:08,904 [Epoch: 010 Step: 00001577] Batch Translation Loss:   6.441298 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:26:25,556 [Epoch: 010 Step: 00001578] Batch Translation Loss:   6.323003 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:26:55,957 [Epoch: 010 Step: 00001579] Batch Translation Loss:   6.784811 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:27:11,983 [Epoch: 010 Step: 00001580] Batch Translation Loss:   6.874520 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:27:30,843 [Epoch: 010 Step: 00001581] Batch Translation Loss:   6.080612 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:27:48,861 [Epoch: 010 Step: 00001582] Batch Translation Loss:   6.087923 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:28:05,147 [Epoch: 010 Step: 00001583] Batch Translation Loss:   6.151837 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:28:31,376 [Epoch: 010 Step: 00001584] Batch Translation Loss:   6.799253 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:28:49,925 [Epoch: 010 Step: 00001585] Batch Translation Loss:   5.822269 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:29:07,438 [Epoch: 010 Step: 00001586] Batch Translation Loss:   6.842432 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:29:24,622 [Epoch: 010 Step: 00001587] Batch Translation Loss:   6.522021 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:29:44,668 [Epoch: 010 Step: 00001588] Batch Translation Loss:   5.508302 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:30:26,902 [Epoch: 010 Step: 00001589] Batch Translation Loss:   7.200371 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:30:45,138 [Epoch: 010 Step: 00001590] Batch Translation Loss:   6.121056 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:31:04,772 [Epoch: 010 Step: 00001591] Batch Translation Loss:   6.365478 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:31:23,778 [Epoch: 010 Step: 00001592] Batch Translation Loss:   6.276409 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:31:41,720 [Epoch: 010 Step: 00001593] Batch Translation Loss:   6.707048 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:32:12,778 [Epoch: 010 Step: 00001594] Batch Translation Loss:   6.091455 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:32:29,887 [Epoch: 010 Step: 00001595] Batch Translation Loss:   6.891712 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:32:47,011 [Epoch: 010 Step: 00001596] Batch Translation Loss:   6.508182 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:33:05,068 [Epoch: 010 Step: 00001597] Batch Translation Loss:   6.671645 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:33:23,214 [Epoch: 010 Step: 00001598] Batch Translation Loss:   6.194236 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:33:49,929 [Epoch: 010 Step: 00001599] Batch Translation Loss:   6.231842 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:34:09,017 [Epoch: 010 Step: 00001600] Batch Translation Loss:   6.176380 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:41:16,403 Validation result at epoch  10, step     1600: duration: 427.3247s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 8302.04102	PPL: 5547.03809
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 1.71,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 4.97	ROUGE 1.56
2021-12-28 13:41:24,220 Logging Recognition and Translation Outputs
2021-12-28 13:41:24,281 ========================================================================================================================
2021-12-28 13:41:24,282 Logging Sequence: youtube_4-howard_rosenblum_5578
2021-12-28 13:41:24,282 	Text Reference  :	asl
2021-12-28 13:41:24,283 	Text Hypothesis :	asl
2021-12-28 13:41:24,283 	Text Alignment  :	   
2021-12-28 13:41:24,283 ========================================================================================================================
2021-12-28 13:41:24,284 Logging Sequence: youtube_5-daniel_durant_5878
2021-12-28 13:41:24,284 	Text Reference  :	*** zack
2021-12-28 13:41:24,285 	Text Hypothesis :	cdi cdi 
2021-12-28 13:41:24,285 	Text Alignment  :	I   S   
2021-12-28 13:41:24,285 ========================================================================================================================
2021-12-28 13:41:24,285 Logging Sequence: youtube_1-melvin_patterson_2369
2021-12-28 13:41:24,286 	Text Reference  :	only
2021-12-28 13:41:24,286 	Text Hypothesis :	so  
2021-12-28 13:41:24,286 	Text Alignment  :	S   
2021-12-28 13:41:24,286 ========================================================================================================================
2021-12-28 13:41:24,286 Logging Sequence: deafvideo_3-otismhill82_4617
2021-12-28 13:41:24,286 	Text Reference  :	ok
2021-12-28 13:41:24,287 	Text Hypothesis :	so
2021-12-28 13:41:24,287 	Text Alignment  :	S 
2021-12-28 13:41:24,287 ========================================================================================================================
2021-12-28 13:41:24,287 Logging Sequence: youtube_5-caroline_jackson_5854
2021-12-28 13:41:24,287 	Text Reference  :	electronics
2021-12-28 13:41:24,287 	Text Hypothesis :	asl        
2021-12-28 13:41:24,288 	Text Alignment  :	S          
2021-12-28 13:41:24,288 ========================================================================================================================
2021-12-28 13:42:24,908 [Epoch: 010 Step: 00001601] Batch Translation Loss:   5.266538 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 13:43:01,375 [Epoch: 010 Step: 00001602] Batch Translation Loss:   6.669871 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:43:38,268 [Epoch: 010 Step: 00001603] Batch Translation Loss:   6.137465 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:44:00,083 [Epoch: 010 Step: 00001604] Batch Translation Loss:   6.845663 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:44:23,304 [Epoch: 010 Step: 00001605] Batch Translation Loss:   5.762027 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:44:45,567 [Epoch: 010 Step: 00001606] Batch Translation Loss:   6.926819 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:45:09,617 [Epoch: 010 Step: 00001607] Batch Translation Loss:   6.528653 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:45:33,868 [Epoch: 010 Step: 00001608] Batch Translation Loss:   6.531895 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:45:54,126 [Epoch: 010 Step: 00001609] Batch Translation Loss:   6.676873 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:46:19,795 [Epoch: 010 Step: 00001610] Batch Translation Loss:   6.576259 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:46:44,431 [Epoch: 010 Step: 00001611] Batch Translation Loss:   6.133768 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:47:06,333 [Epoch: 010 Step: 00001612] Batch Translation Loss:   6.547546 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:47:36,365 [Epoch: 010 Step: 00001613] Batch Translation Loss:   5.887032 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:48:00,574 [Epoch: 010 Step: 00001614] Batch Translation Loss:   6.251613 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:48:23,088 [Epoch: 010 Step: 00001615] Batch Translation Loss:   6.352008 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:48:50,300 [Epoch: 010 Step: 00001616] Batch Translation Loss:   6.091002 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:49:14,678 [Epoch: 010 Step: 00001617] Batch Translation Loss:   5.906543 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:49:38,730 [Epoch: 010 Step: 00001618] Batch Translation Loss:   6.080147 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:50:02,653 [Epoch: 010 Step: 00001619] Batch Translation Loss:   6.665047 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:50:28,341 [Epoch: 010 Step: 00001620] Batch Translation Loss:   6.328618 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:50:52,860 [Epoch: 010 Step: 00001621] Batch Translation Loss:   6.991412 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:51:20,434 [Epoch: 010 Step: 00001622] Batch Translation Loss:   6.171841 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:51:44,644 [Epoch: 010 Step: 00001623] Batch Translation Loss:   6.502535 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:52:11,890 [Epoch: 010 Step: 00001624] Batch Translation Loss:   6.254058 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:52:32,701 [Epoch: 010 Step: 00001625] Batch Translation Loss:   6.331861 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:52:53,655 [Epoch: 010 Step: 00001626] Batch Translation Loss:   6.691181 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 13:53:34,437 [Epoch: 010 Step: 00001627] Batch Translation Loss:   6.253700 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:54:04,372 [Epoch: 010 Step: 00001628] Batch Translation Loss:   7.075505 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:54:34,595 [Epoch: 010 Step: 00001629] Batch Translation Loss:   6.251612 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:55:01,932 [Epoch: 010 Step: 00001630] Batch Translation Loss:   6.165373 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:55:34,683 [Epoch: 010 Step: 00001631] Batch Translation Loss:   6.473347 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:55:59,219 [Epoch: 010 Step: 00001632] Batch Translation Loss:   6.070237 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:56:26,476 [Epoch: 010 Step: 00001633] Batch Translation Loss:   6.590644 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:56:54,216 [Epoch: 010 Step: 00001634] Batch Translation Loss:   6.390505 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:57:20,200 [Epoch: 010 Step: 00001635] Batch Translation Loss:   6.274526 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:57:47,565 [Epoch: 010 Step: 00001636] Batch Translation Loss:   6.110414 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:58:16,471 [Epoch: 010 Step: 00001637] Batch Translation Loss:   6.065060 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:58:44,867 [Epoch: 010 Step: 00001638] Batch Translation Loss:   6.358693 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 13:59:40,790 [Epoch: 010 Step: 00001639] Batch Translation Loss:   6.365222 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:00:28,631 [Epoch: 010 Step: 00001640] Batch Translation Loss:   6.233228 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:00:59,674 [Epoch: 010 Step: 00001641] Batch Translation Loss:   6.371084 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:01:31,129 [Epoch: 010 Step: 00001642] Batch Translation Loss:   6.641151 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:02:18,732 [Epoch: 010 Step: 00001643] Batch Translation Loss:   6.305190 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:02:40,855 [Epoch: 010 Step: 00001644] Batch Translation Loss:   5.935999 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:03:06,164 [Epoch: 010 Step: 00001645] Batch Translation Loss:   5.990798 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:03:38,406 [Epoch: 010 Step: 00001646] Batch Translation Loss:   6.041800 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:04:07,384 [Epoch: 010 Step: 00001647] Batch Translation Loss:   6.751644 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:04:39,573 [Epoch: 010 Step: 00001648] Batch Translation Loss:   6.108868 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:05:08,753 [Epoch: 010 Step: 00001649] Batch Translation Loss:   5.898819 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:05:38,948 [Epoch: 010 Step: 00001650] Batch Translation Loss:   6.279786 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:06:08,750 [Epoch: 010 Step: 00001651] Batch Translation Loss:   6.045357 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:06:42,760 [Epoch: 010 Step: 00001652] Batch Translation Loss:   6.773637 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:07:16,626 [Epoch: 010 Step: 00001653] Batch Translation Loss:   6.643738 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:07:46,988 [Epoch: 010 Step: 00001654] Batch Translation Loss:   6.224122 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:08:18,853 [Epoch: 010 Step: 00001655] Batch Translation Loss:   5.874073 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:08:48,396 [Epoch: 010 Step: 00001656] Batch Translation Loss:   6.150697 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:09:34,844 [Epoch: 010 Step: 00001657] Batch Translation Loss:   6.125530 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:10:07,789 [Epoch: 010 Step: 00001658] Batch Translation Loss:   6.455469 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:10:38,753 [Epoch: 010 Step: 00001659] Batch Translation Loss:   6.836852 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:11:10,699 [Epoch: 010 Step: 00001660] Batch Translation Loss:   6.828582 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:11:44,145 [Epoch: 010 Step: 00001661] Batch Translation Loss:   5.975122 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:12:19,592 [Epoch: 010 Step: 00001662] Batch Translation Loss:   6.388766 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:12:48,885 [Epoch: 010 Step: 00001663] Batch Translation Loss:   6.321506 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:13:20,366 [Epoch: 010 Step: 00001664] Batch Translation Loss:   6.596611 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:13:48,220 [Epoch: 010 Step: 00001665] Batch Translation Loss:   6.543623 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:14:17,122 [Epoch: 010 Step: 00001666] Batch Translation Loss:   6.143682 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:14:57,204 [Epoch: 010 Step: 00001667] Batch Translation Loss:   6.211974 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:15:27,678 [Epoch: 010 Step: 00001668] Batch Translation Loss:   5.921640 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:16:06,791 [Epoch: 010 Step: 00001669] Batch Translation Loss:   6.358737 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:16:38,963 [Epoch: 010 Step: 00001670] Batch Translation Loss:   6.422302 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:17:43,217 [Epoch: 010 Step: 00001671] Batch Translation Loss:   6.560517 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 14:18:18,018 [Epoch: 010 Step: 00001672] Batch Translation Loss:   6.184543 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:18:52,333 [Epoch: 010 Step: 00001673] Batch Translation Loss:   6.570770 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:19:29,995 [Epoch: 010 Step: 00001674] Batch Translation Loss:   5.995568 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:20:07,475 [Epoch: 010 Step: 00001675] Batch Translation Loss:   6.247807 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:20:45,837 [Epoch: 010 Step: 00001676] Batch Translation Loss:   6.216712 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:21:27,637 [Epoch: 010 Step: 00001677] Batch Translation Loss:   6.622833 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:22:14,771 [Epoch: 010 Step: 00001678] Batch Translation Loss:   6.455463 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:22:47,642 [Epoch: 010 Step: 00001679] Batch Translation Loss:   6.314531 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:23:16,849 [Epoch: 010 Step: 00001680] Batch Translation Loss:   6.148901 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:23:45,534 [Epoch: 010 Step: 00001681] Batch Translation Loss:   6.738968 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:24:27,217 [Epoch: 010 Step: 00001682] Batch Translation Loss:   5.929706 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:25:02,643 [Epoch: 010 Step: 00001683] Batch Translation Loss:   6.668743 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:25:38,557 [Epoch: 010 Step: 00001684] Batch Translation Loss:   5.915789 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:27:06,441 [Epoch: 010 Step: 00001685] Batch Translation Loss:   6.971550 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 14:28:14,938 [Epoch: 010 Step: 00001686] Batch Translation Loss:   6.457349 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 14:28:51,952 [Epoch: 010 Step: 00001687] Batch Translation Loss:   6.672681 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:29:28,267 [Epoch: 010 Step: 00001688] Batch Translation Loss:   6.045911 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:30:06,874 [Epoch: 010 Step: 00001689] Batch Translation Loss:   6.728216 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:30:41,489 [Epoch: 010 Step: 00001690] Batch Translation Loss:   6.974877 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:31:19,767 [Epoch: 010 Step: 00001691] Batch Translation Loss:   6.452588 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:31:57,346 [Epoch: 010 Step: 00001692] Batch Translation Loss:   6.049489 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:32:44,501 [Epoch: 010 Step: 00001693] Batch Translation Loss:   6.541338 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:33:15,741 [Epoch: 010 Step: 00001694] Batch Translation Loss:   6.396071 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:33:45,957 [Epoch: 010 Step: 00001695] Batch Translation Loss:   6.582716 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:34:18,330 [Epoch: 010 Step: 00001696] Batch Translation Loss:   6.078063 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:35:02,727 [Epoch: 010 Step: 00001697] Batch Translation Loss:   5.585219 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:35:39,687 [Epoch: 010 Step: 00001698] Batch Translation Loss:   6.032976 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:36:25,835 [Epoch: 010 Step: 00001699] Batch Translation Loss:   6.396450 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:37:00,958 [Epoch: 010 Step: 00001700] Batch Translation Loss:   6.702901 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:45:00,127 Validation result at epoch  10, step     1700: duration: 479.1436s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 8127.65527	PPL: 5586.36523
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 1.81,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 5.85	ROUGE 1.94
2021-12-28 14:45:08,062 Logging Recognition and Translation Outputs
2021-12-28 14:45:08,127 ========================================================================================================================
2021-12-28 14:45:08,127 Logging Sequence: youtube_5-roberta_cordano_6131
2021-12-28 14:45:08,128 	Text Reference  :	*** it 
2021-12-28 14:45:08,129 	Text Hypothesis :	asl lit
2021-12-28 14:45:08,129 	Text Alignment  :	I   S  
2021-12-28 14:45:08,129 ========================================================================================================================
2021-12-28 14:45:08,129 Logging Sequence: youtube_5-roberta_cordano_6138
2021-12-28 14:45:08,130 	Text Reference  :	tool   
2021-12-28 14:45:08,130 	Text Hypothesis :	aslized
2021-12-28 14:45:08,130 	Text Alignment  :	S      
2021-12-28 14:45:08,131 ========================================================================================================================
2021-12-28 14:45:08,131 Logging Sequence: youtube_5-roberta_cordano_6128
2021-12-28 14:45:08,131 	Text Reference  :	love   
2021-12-28 14:45:08,131 	Text Hypothesis :	aslized
2021-12-28 14:45:08,132 	Text Alignment  :	S      
2021-12-28 14:45:08,132 ========================================================================================================================
2021-12-28 14:45:08,132 Logging Sequence: deafvideo_2-sddsimple_1547
2021-12-28 14:45:08,132 	Text Reference  :	agents      
2021-12-28 14:45:08,133 	Text Hypothesis :	propaedeutic
2021-12-28 14:45:08,133 	Text Alignment  :	S           
2021-12-28 14:45:08,133 ========================================================================================================================
2021-12-28 14:45:08,133 Logging Sequence: deafvideo_2-fairytales9_2291
2021-12-28 14:45:08,134 	Text Reference  :	by     
2021-12-28 14:45:08,134 	Text Hypothesis :	aslized
2021-12-28 14:45:08,134 	Text Alignment  :	S      
2021-12-28 14:45:08,134 ========================================================================================================================
2021-12-28 14:45:08,726 Epoch  10: Total Training Recognition Loss -1.00  Total Training Translation Loss 1085.66 
2021-12-28 14:45:08,726 EPOCH 11
2021-12-28 14:45:37,472 [Epoch: 011 Step: 00001701] Batch Translation Loss:   6.266582 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:46:08,923 [Epoch: 011 Step: 00001702] Batch Translation Loss:   6.764880 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:46:51,166 [Epoch: 011 Step: 00001703] Batch Translation Loss:   6.510746 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:47:13,628 [Epoch: 011 Step: 00001704] Batch Translation Loss:   6.602678 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:47:28,603 [Epoch: 011 Step: 00001705] Batch Translation Loss:   6.443204 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:47:48,214 [Epoch: 011 Step: 00001706] Batch Translation Loss:   6.604244 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:48:02,807 [Epoch: 011 Step: 00001707] Batch Translation Loss:   6.632323 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:48:18,830 [Epoch: 011 Step: 00001708] Batch Translation Loss:   6.572596 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:48:34,446 [Epoch: 011 Step: 00001709] Batch Translation Loss:   6.438552 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:48:47,000 [Epoch: 011 Step: 00001710] Batch Translation Loss:   6.137121 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 14:49:12,386 [Epoch: 011 Step: 00001711] Batch Translation Loss:   6.660118 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:49:31,139 [Epoch: 011 Step: 00001712] Batch Translation Loss:   6.449026 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:49:48,650 [Epoch: 011 Step: 00001713] Batch Translation Loss:   6.731495 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:49:58,339 [Epoch: 011 Step: 00001714] Batch Translation Loss:   6.416834 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 14:50:08,448 [Epoch: 011 Step: 00001715] Batch Translation Loss:   6.539870 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 14:50:21,122 [Epoch: 011 Step: 00001716] Batch Translation Loss:   6.908627 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 14:50:35,004 [Epoch: 011 Step: 00001717] Batch Translation Loss:   6.409430 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:50:48,358 [Epoch: 011 Step: 00001718] Batch Translation Loss:   6.336976 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:50:59,811 [Epoch: 011 Step: 00001719] Batch Translation Loss:   6.779732 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 14:51:14,536 [Epoch: 011 Step: 00001720] Batch Translation Loss:   6.840405 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:51:26,164 [Epoch: 011 Step: 00001721] Batch Translation Loss:   6.551593 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 14:51:37,719 [Epoch: 011 Step: 00001722] Batch Translation Loss:   6.551750 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 14:51:49,366 [Epoch: 011 Step: 00001723] Batch Translation Loss:   6.233026 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 14:52:02,196 [Epoch: 011 Step: 00001724] Batch Translation Loss:   5.631002 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 14:52:14,322 [Epoch: 011 Step: 00001725] Batch Translation Loss:   6.559486 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 14:52:26,552 [Epoch: 011 Step: 00001726] Batch Translation Loss:   6.018003 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 14:52:48,168 [Epoch: 011 Step: 00001727] Batch Translation Loss:   6.398374 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 14:53:02,822 [Epoch: 011 Step: 00001728] Batch Translation Loss:   6.270284 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:53:18,199 [Epoch: 011 Step: 00001729] Batch Translation Loss:   6.409487 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:53:31,296 [Epoch: 011 Step: 00001730] Batch Translation Loss:   6.502990 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:53:48,554 [Epoch: 011 Step: 00001731] Batch Translation Loss:   5.917111 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:54:00,370 [Epoch: 011 Step: 00001732] Batch Translation Loss:   5.817131 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 14:54:13,768 [Epoch: 011 Step: 00001733] Batch Translation Loss:   6.207840 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:54:26,431 [Epoch: 011 Step: 00001734] Batch Translation Loss:   6.694424 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 14:54:37,043 [Epoch: 011 Step: 00001735] Batch Translation Loss:   5.774526 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 14:54:52,618 [Epoch: 011 Step: 00001736] Batch Translation Loss:   6.551615 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:55:09,737 [Epoch: 011 Step: 00001737] Batch Translation Loss:   7.031628 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:55:25,598 [Epoch: 011 Step: 00001738] Batch Translation Loss:   5.824039 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:55:41,328 [Epoch: 011 Step: 00001739] Batch Translation Loss:   6.379217 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:56:00,503 [Epoch: 011 Step: 00001740] Batch Translation Loss:   6.174054 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:56:17,452 [Epoch: 011 Step: 00001741] Batch Translation Loss:   5.923852 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:56:33,809 [Epoch: 011 Step: 00001742] Batch Translation Loss:   6.539374 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:56:50,864 [Epoch: 011 Step: 00001743] Batch Translation Loss:   6.390297 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:57:09,323 [Epoch: 011 Step: 00001744] Batch Translation Loss:   6.199934 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:57:25,919 [Epoch: 011 Step: 00001745] Batch Translation Loss:   6.222854 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:57:47,036 [Epoch: 011 Step: 00001746] Batch Translation Loss:   6.645181 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:58:03,910 [Epoch: 011 Step: 00001747] Batch Translation Loss:   6.584552 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:58:21,228 [Epoch: 011 Step: 00001748] Batch Translation Loss:   6.056062 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:58:37,936 [Epoch: 011 Step: 00001749] Batch Translation Loss:   6.590421 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:58:56,144 [Epoch: 011 Step: 00001750] Batch Translation Loss:   6.604465 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:59:13,773 [Epoch: 011 Step: 00001751] Batch Translation Loss:   6.189089 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:59:32,223 [Epoch: 011 Step: 00001752] Batch Translation Loss:   6.345784 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 14:59:51,824 [Epoch: 011 Step: 00001753] Batch Translation Loss:   6.411719 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 15:00:10,862 [Epoch: 011 Step: 00001754] Batch Translation Loss:   6.623119 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 15:00:29,032 [Epoch: 011 Step: 00001755] Batch Translation Loss:   6.424459 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 15:01:02,642 [Epoch: 011 Step: 00001756] Batch Translation Loss:   6.397553 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:01:24,625 [Epoch: 011 Step: 00001757] Batch Translation Loss:   6.487516 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:01:46,738 [Epoch: 011 Step: 00001758] Batch Translation Loss:   6.044084 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:02:08,183 [Epoch: 011 Step: 00001759] Batch Translation Loss:   6.271636 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:02:24,347 [Epoch: 011 Step: 00001760] Batch Translation Loss:   6.524463 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 15:02:40,241 [Epoch: 011 Step: 00001761] Batch Translation Loss:   6.593860 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 15:02:57,929 [Epoch: 011 Step: 00001762] Batch Translation Loss:   6.198172 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 15:03:13,807 [Epoch: 011 Step: 00001763] Batch Translation Loss:   6.385025 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 15:03:33,958 [Epoch: 011 Step: 00001764] Batch Translation Loss:   6.426291 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 15:03:56,470 [Epoch: 011 Step: 00001765] Batch Translation Loss:   6.886518 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:04:35,274 [Epoch: 011 Step: 00001766] Batch Translation Loss:   6.355754 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:04:56,121 [Epoch: 011 Step: 00001767] Batch Translation Loss:   6.480635 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 15:05:16,530 [Epoch: 011 Step: 00001768] Batch Translation Loss:   6.174558 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 15:05:37,661 [Epoch: 011 Step: 00001769] Batch Translation Loss:   7.051764 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 15:06:15,270 [Epoch: 011 Step: 00001770] Batch Translation Loss:   6.197225 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:06:36,837 [Epoch: 011 Step: 00001771] Batch Translation Loss:   6.062101 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:06:58,937 [Epoch: 011 Step: 00001772] Batch Translation Loss:   5.799048 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:07:20,326 [Epoch: 011 Step: 00001773] Batch Translation Loss:   6.278880 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:07:45,406 [Epoch: 011 Step: 00001774] Batch Translation Loss:   6.606175 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:08:08,910 [Epoch: 011 Step: 00001775] Batch Translation Loss:   6.458941 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:08:35,926 [Epoch: 011 Step: 00001776] Batch Translation Loss:   6.210087 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:09:01,232 [Epoch: 011 Step: 00001777] Batch Translation Loss:   6.785087 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:09:43,629 [Epoch: 011 Step: 00001778] Batch Translation Loss:   6.551583 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:10:07,261 [Epoch: 011 Step: 00001779] Batch Translation Loss:   5.967941 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:10:31,085 [Epoch: 011 Step: 00001780] Batch Translation Loss:   6.911074 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:10:53,137 [Epoch: 011 Step: 00001781] Batch Translation Loss:   6.695609 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:11:12,389 [Epoch: 011 Step: 00001782] Batch Translation Loss:   6.900103 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 15:11:31,205 [Epoch: 011 Step: 00001783] Batch Translation Loss:   5.738137 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 15:11:53,410 [Epoch: 011 Step: 00001784] Batch Translation Loss:   6.385600 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:12:19,672 [Epoch: 011 Step: 00001785] Batch Translation Loss:   6.185495 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:13:08,629 [Epoch: 011 Step: 00001786] Batch Translation Loss:   6.262149 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:13:34,518 [Epoch: 011 Step: 00001787] Batch Translation Loss:   5.993386 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:14:19,595 [Epoch: 011 Step: 00001788] Batch Translation Loss:   6.167889 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:15:07,216 [Epoch: 011 Step: 00001789] Batch Translation Loss:   6.223724 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:15:54,607 [Epoch: 011 Step: 00001790] Batch Translation Loss:   6.322986 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:16:42,429 [Epoch: 011 Step: 00001791] Batch Translation Loss:   6.098876 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:17:08,857 [Epoch: 011 Step: 00001792] Batch Translation Loss:   6.265369 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:17:34,413 [Epoch: 011 Step: 00001793] Batch Translation Loss:   6.246023 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:18:01,146 [Epoch: 011 Step: 00001794] Batch Translation Loss:   6.473617 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:18:49,088 [Epoch: 011 Step: 00001795] Batch Translation Loss:   6.487389 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:19:16,150 [Epoch: 011 Step: 00001796] Batch Translation Loss:   6.294806 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:19:39,781 [Epoch: 011 Step: 00001797] Batch Translation Loss:   6.218745 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:20:03,467 [Epoch: 011 Step: 00001798] Batch Translation Loss:   6.495435 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:20:25,073 [Epoch: 011 Step: 00001799] Batch Translation Loss:   6.071201 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:20:56,614 [Epoch: 011 Step: 00001800] Batch Translation Loss:   6.240312 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:28:34,675 Validation result at epoch  11, step     1800: duration: 458.0176s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 8330.95703	PPL: 5716.12158
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 2.51,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 4.72	ROUGE 1.86
2021-12-28 15:28:42,912 Logging Recognition and Translation Outputs
2021-12-28 15:28:42,913 ========================================================================================================================
2021-12-28 15:28:42,913 Logging Sequence: youtube_5-sean_berdy_6091
2021-12-28 15:28:42,913 	Text Reference  :	rainbow sity    
2021-12-28 15:28:42,914 	Text Hypothesis :	ss      medicaid
2021-12-28 15:28:42,914 	Text Alignment  :	S       S       
2021-12-28 15:28:42,914 ========================================================================================================================
2021-12-28 15:28:42,914 Logging Sequence: deafvideo_2-goatman_1525
2021-12-28 15:28:42,914 	Text Reference  :	dvtv
2021-12-28 15:28:42,914 	Text Hypothesis :	asl 
2021-12-28 15:28:42,914 	Text Alignment  :	S   
2021-12-28 15:28:42,914 ========================================================================================================================
2021-12-28 15:28:42,914 Logging Sequence: deafvideo_3-yesyes_3106
2021-12-28 15:28:42,915 	Text Reference  :	*** or 
2021-12-28 15:28:42,915 	Text Hypothesis :	asl lit
2021-12-28 15:28:42,915 	Text Alignment  :	I   S  
2021-12-28 15:28:42,915 ========================================================================================================================
2021-12-28 15:28:42,915 Logging Sequence: deafvideo_4-tax_tips_by_irs_4960
2021-12-28 15:28:42,915 	Text Reference  :	** md      
2021-12-28 15:28:42,915 	Text Hypothesis :	ss medicaid
2021-12-28 15:28:42,915 	Text Alignment  :	I  S       
2021-12-28 15:28:42,915 ========================================================================================================================
2021-12-28 15:28:42,916 Logging Sequence: deafvideo_3-otismhill82_4603
2021-12-28 15:28:42,916 	Text Reference  :	link
2021-12-28 15:28:42,916 	Text Hypothesis :	or  
2021-12-28 15:28:42,916 	Text Alignment  :	S   
2021-12-28 15:28:42,916 ========================================================================================================================
2021-12-28 15:29:40,969 [Epoch: 011 Step: 00001801] Batch Translation Loss:   6.594580 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 15:30:07,785 [Epoch: 011 Step: 00001802] Batch Translation Loss:   6.827598 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:30:33,462 [Epoch: 011 Step: 00001803] Batch Translation Loss:   6.667936 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:31:01,163 [Epoch: 011 Step: 00001804] Batch Translation Loss:   6.344848 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:31:28,121 [Epoch: 011 Step: 00001805] Batch Translation Loss:   6.097746 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:32:15,142 [Epoch: 011 Step: 00001806] Batch Translation Loss:   6.586885 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:32:45,484 [Epoch: 011 Step: 00001807] Batch Translation Loss:   7.127353 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:33:13,986 [Epoch: 011 Step: 00001808] Batch Translation Loss:   6.587401 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:33:40,558 [Epoch: 011 Step: 00001809] Batch Translation Loss:   6.163797 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:34:10,506 [Epoch: 011 Step: 00001810] Batch Translation Loss:   6.656916 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:35:21,113 [Epoch: 011 Step: 00001811] Batch Translation Loss:   6.466216 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 15:36:09,393 [Epoch: 011 Step: 00001812] Batch Translation Loss:   6.747168 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:36:39,956 [Epoch: 011 Step: 00001813] Batch Translation Loss:   6.488269 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:37:10,370 [Epoch: 011 Step: 00001814] Batch Translation Loss:   6.706705 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:37:57,141 [Epoch: 011 Step: 00001815] Batch Translation Loss:   6.842512 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:38:25,132 [Epoch: 011 Step: 00001816] Batch Translation Loss:   6.489951 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:38:49,146 [Epoch: 011 Step: 00001817] Batch Translation Loss:   6.685330 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:39:13,890 [Epoch: 011 Step: 00001818] Batch Translation Loss:   6.334789 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:39:41,798 [Epoch: 011 Step: 00001819] Batch Translation Loss:   6.296729 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:40:16,915 [Epoch: 011 Step: 00001820] Batch Translation Loss:   6.341364 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:40:46,724 [Epoch: 011 Step: 00001821] Batch Translation Loss:   6.446049 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:41:16,779 [Epoch: 011 Step: 00001822] Batch Translation Loss:   6.291370 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:41:49,135 [Epoch: 011 Step: 00001823] Batch Translation Loss:   6.336450 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:42:21,248 [Epoch: 011 Step: 00001824] Batch Translation Loss:   6.658432 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:42:53,040 [Epoch: 011 Step: 00001825] Batch Translation Loss:   6.290265 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:43:24,455 [Epoch: 011 Step: 00001826] Batch Translation Loss:   6.593959 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:43:56,275 [Epoch: 011 Step: 00001827] Batch Translation Loss:   6.649625 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:44:28,370 [Epoch: 011 Step: 00001828] Batch Translation Loss:   6.363003 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:44:59,231 [Epoch: 011 Step: 00001829] Batch Translation Loss:   6.487929 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:45:32,246 [Epoch: 011 Step: 00001830] Batch Translation Loss:   6.306139 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:46:11,489 [Epoch: 011 Step: 00001831] Batch Translation Loss:   6.794066 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:46:45,095 [Epoch: 011 Step: 00001832] Batch Translation Loss:   6.590251 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:47:19,774 [Epoch: 011 Step: 00001833] Batch Translation Loss:   6.836103 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:47:57,259 [Epoch: 011 Step: 00001834] Batch Translation Loss:   6.617301 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:48:26,705 [Epoch: 011 Step: 00001835] Batch Translation Loss:   6.156551 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:48:53,211 [Epoch: 011 Step: 00001836] Batch Translation Loss:   6.420028 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:49:22,400 [Epoch: 011 Step: 00001837] Batch Translation Loss:   6.560968 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:49:57,585 [Epoch: 011 Step: 00001838] Batch Translation Loss:   6.512665 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:50:31,396 [Epoch: 011 Step: 00001839] Batch Translation Loss:   5.810615 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:51:06,288 [Epoch: 011 Step: 00001840] Batch Translation Loss:   6.367392 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:51:38,854 [Epoch: 011 Step: 00001841] Batch Translation Loss:   6.477779 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:52:13,953 [Epoch: 011 Step: 00001842] Batch Translation Loss:   6.616104 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:52:53,222 [Epoch: 011 Step: 00001843] Batch Translation Loss:   6.420821 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:53:29,485 [Epoch: 011 Step: 00001844] Batch Translation Loss:   6.507459 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:54:05,226 [Epoch: 011 Step: 00001845] Batch Translation Loss:   6.443805 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:54:41,381 [Epoch: 011 Step: 00001846] Batch Translation Loss:   6.192532 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:55:20,759 [Epoch: 011 Step: 00001847] Batch Translation Loss:   6.073079 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:56:02,893 [Epoch: 011 Step: 00001848] Batch Translation Loss:   6.818797 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:56:39,631 [Epoch: 011 Step: 00001849] Batch Translation Loss:   6.402134 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:57:14,323 [Epoch: 011 Step: 00001850] Batch Translation Loss:   6.218056 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:57:45,596 [Epoch: 011 Step: 00001851] Batch Translation Loss:   6.439401 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:58:13,168 [Epoch: 011 Step: 00001852] Batch Translation Loss:   6.325129 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:59:01,151 [Epoch: 011 Step: 00001853] Batch Translation Loss:   5.937654 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 15:59:37,979 [Epoch: 011 Step: 00001854] Batch Translation Loss:   5.913631 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 16:00:24,849 [Epoch: 011 Step: 00001855] Batch Translation Loss:   6.675992 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 16:01:00,336 [Epoch: 011 Step: 00001856] Batch Translation Loss:   6.682097 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 16:02:07,546 [Epoch: 011 Step: 00001857] Batch Translation Loss:   6.304994 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 16:02:42,997 [Epoch: 011 Step: 00001858] Batch Translation Loss:   6.307938 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 16:03:21,477 [Epoch: 011 Step: 00001859] Batch Translation Loss:   6.662386 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 16:03:58,521 [Epoch: 011 Step: 00001860] Batch Translation Loss:   6.209731 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 16:04:37,700 [Epoch: 011 Step: 00001861] Batch Translation Loss:   6.124590 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 16:05:14,275 [Epoch: 011 Step: 00001862] Batch Translation Loss:   6.692660 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 16:05:51,968 [Epoch: 011 Step: 00001863] Batch Translation Loss:   6.463989 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 16:06:29,843 [Epoch: 011 Step: 00001864] Batch Translation Loss:   6.190138 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 16:07:06,533 [Epoch: 011 Step: 00001865] Batch Translation Loss:   6.772832 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 16:07:41,749 [Epoch: 011 Step: 00001866] Batch Translation Loss:   6.253807 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 16:08:13,056 [Epoch: 011 Step: 00001867] Batch Translation Loss:   6.694199 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 16:08:46,299 [Epoch: 011 Step: 00001868] Batch Translation Loss:   6.498021 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 16:09:26,724 [Epoch: 011 Step: 00001869] Batch Translation Loss:   6.896828 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 16:10:45,018 [Epoch: 011 Step: 00001870] Batch Translation Loss:   6.821177 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-28 16:10:45,133 Epoch  11: Total Training Recognition Loss -1.00  Total Training Translation Loss 1091.35 
2021-12-28 16:10:45,133 EPOCH 12
2021-12-28 16:10:52,205 [Epoch: 012 Step: 00001871] Batch Translation Loss:   6.052722 => Txt Tokens per Sec:        5 || Lr: 0.000700
2021-12-28 16:11:00,673 [Epoch: 012 Step: 00001872] Batch Translation Loss:   6.355222 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-28 16:11:08,904 [Epoch: 012 Step: 00001873] Batch Translation Loss:   6.009637 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-28 16:11:18,294 [Epoch: 012 Step: 00001874] Batch Translation Loss:   6.979772 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 16:11:29,403 [Epoch: 012 Step: 00001875] Batch Translation Loss:   5.898034 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 16:11:39,559 [Epoch: 012 Step: 00001876] Batch Translation Loss:   6.380706 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 16:11:49,296 [Epoch: 012 Step: 00001877] Batch Translation Loss:   6.591663 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 16:12:00,520 [Epoch: 012 Step: 00001878] Batch Translation Loss:   7.190054 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 16:12:08,271 [Epoch: 012 Step: 00001879] Batch Translation Loss:   6.603142 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-28 16:12:22,399 [Epoch: 012 Step: 00001880] Batch Translation Loss:   5.992767 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 16:12:32,893 [Epoch: 012 Step: 00001881] Batch Translation Loss:   6.301121 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 16:12:43,395 [Epoch: 012 Step: 00001882] Batch Translation Loss:   6.739079 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 16:12:52,502 [Epoch: 012 Step: 00001883] Batch Translation Loss:   6.343435 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-28 16:13:04,355 [Epoch: 012 Step: 00001884] Batch Translation Loss:   6.379807 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 16:13:19,813 [Epoch: 012 Step: 00001885] Batch Translation Loss:   6.730647 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 16:13:30,550 [Epoch: 012 Step: 00001886] Batch Translation Loss:   6.112145 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 16:13:47,175 [Epoch: 012 Step: 00001887] Batch Translation Loss:   6.507534 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 16:13:59,324 [Epoch: 012 Step: 00001888] Batch Translation Loss:   6.428278 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 16:14:17,097 [Epoch: 012 Step: 00001889] Batch Translation Loss:   5.961615 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 16:14:32,179 [Epoch: 012 Step: 00001890] Batch Translation Loss:   6.342268 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 16:14:43,092 [Epoch: 012 Step: 00001891] Batch Translation Loss:   5.693024 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 16:14:55,925 [Epoch: 012 Step: 00001892] Batch Translation Loss:   6.615839 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 16:15:07,191 [Epoch: 012 Step: 00001893] Batch Translation Loss:   5.745980 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 16:15:22,890 [Epoch: 012 Step: 00001894] Batch Translation Loss:   6.630254 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 16:15:35,799 [Epoch: 012 Step: 00001895] Batch Translation Loss:   5.857565 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 16:15:50,177 [Epoch: 012 Step: 00001896] Batch Translation Loss:   6.453181 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 16:16:02,862 [Epoch: 012 Step: 00001897] Batch Translation Loss:   6.285959 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-28 16:16:23,325 [Epoch: 012 Step: 00001898] Batch Translation Loss:   6.633187 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 16:16:46,294 [Epoch: 012 Step: 00001899] Batch Translation Loss:   6.067206 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-28 16:17:01,594 [Epoch: 012 Step: 00001900] Batch Translation Loss:   6.483111 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-28 16:24:40,885 Validation result at epoch  12, step     1900: duration: 459.2399s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 8504.18262	PPL: 7034.09521
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 1.39,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 5.15	ROUGE 2.42
2021-12-28 16:24:48,531 Logging Recognition and Translation Outputs
2021-12-28 16:24:48,565 ========================================================================================================================
2021-12-28 16:24:48,566 Logging Sequence: youtube_5-roberta_cordano_6151
2021-12-28 16:24:48,567 	Text Reference  :	****** ** weite
2021-12-28 16:24:48,567 	Text Hypothesis :	memory of gust 
2021-12-28 16:24:48,567 	Text Alignment  :	I      I  S    
2021-12-28 16:24:48,568 ========================================================================================================================
2021-12-28 16:24:48,568 Logging Sequence: deafvideo_2-fairytales9_2299
2021-12-28 16:24:48,568 	Text Reference  :	****** ** set 
2021-12-28 16:24:48,569 	Text Hypothesis :	memory of gust
2021-12-28 16:24:48,569 	Text Alignment  :	I      I  S   
2021-12-28 16:24:48,569 ========================================================================================================================
2021-12-28 16:24:48,569 Logging Sequence: deafvideo_3-geoalpha_4573
2021-12-28 16:24:48,570 	Text Reference  :	****** ** nad 
2021-12-28 16:24:48,570 	Text Hypothesis :	memory of gust
2021-12-28 16:24:48,570 	Text Alignment  :	I      I  S   
2021-12-28 16:24:48,570 ========================================================================================================================
2021-12-28 16:24:48,571 Logging Sequence: youtube_5-caroline_jackson_5848
2021-12-28 16:24:48,571 	Text Reference  :	or 
2021-12-28 16:24:48,571 	Text Hypothesis :	asl
2021-12-28 16:24:48,571 	Text Alignment  :	S  
2021-12-28 16:24:48,572 ========================================================================================================================
2021-12-28 16:24:48,572 Logging Sequence: youtube_1-melvin_patterson_2342
2021-12-28 16:24:48,572 	Text Reference  :	saw
2021-12-28 16:24:48,572 	Text Hypothesis :	so 
2021-12-28 16:24:48,573 	Text Alignment  :	S  
2021-12-28 16:24:48,573 ========================================================================================================================
2021-12-28 16:24:49,179 Training ended since there were no improvements inthe last learning rate step: 0.000700
2021-12-28 16:24:49,180 Best validation result at step      100:   0.00 eval_metric.
