2021-12-31 13:29:39,501 Hello! This is Joey-NMT.
2021-12-31 13:29:39,536 Total params: 27946760
2021-12-31 13:29:39,537 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.output_layer.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'image_encoder.classifier.0.bias', 'image_encoder.classifier.0.weight', 'image_encoder.classifier.3.bias', 'image_encoder.classifier.3.weight', 'image_encoder.features.0.0.weight', 'image_encoder.features.0.1.bias', 'image_encoder.features.0.1.weight', 'image_encoder.features.1.block.0.0.weight', 'image_encoder.features.1.block.0.1.bias', 'image_encoder.features.1.block.0.1.weight', 'image_encoder.features.1.block.1.fc1.bias', 'image_encoder.features.1.block.1.fc1.weight', 'image_encoder.features.1.block.1.fc2.bias', 'image_encoder.features.1.block.1.fc2.weight', 'image_encoder.features.1.block.2.0.weight', 'image_encoder.features.1.block.2.1.bias', 'image_encoder.features.1.block.2.1.weight', 'image_encoder.features.10.block.0.0.weight', 'image_encoder.features.10.block.0.1.bias', 'image_encoder.features.10.block.0.1.weight', 'image_encoder.features.10.block.1.0.weight', 'image_encoder.features.10.block.1.1.bias', 'image_encoder.features.10.block.1.1.weight', 'image_encoder.features.10.block.2.fc1.bias', 'image_encoder.features.10.block.2.fc1.weight', 'image_encoder.features.10.block.2.fc2.bias', 'image_encoder.features.10.block.2.fc2.weight', 'image_encoder.features.10.block.3.0.weight', 'image_encoder.features.10.block.3.1.bias', 'image_encoder.features.10.block.3.1.weight', 'image_encoder.features.11.block.0.0.weight', 'image_encoder.features.11.block.0.1.bias', 'image_encoder.features.11.block.0.1.weight', 'image_encoder.features.11.block.1.0.weight', 'image_encoder.features.11.block.1.1.bias', 'image_encoder.features.11.block.1.1.weight', 'image_encoder.features.11.block.2.fc1.bias', 'image_encoder.features.11.block.2.fc1.weight', 'image_encoder.features.11.block.2.fc2.bias', 'image_encoder.features.11.block.2.fc2.weight', 'image_encoder.features.11.block.3.0.weight', 'image_encoder.features.11.block.3.1.bias', 'image_encoder.features.11.block.3.1.weight', 'image_encoder.features.12.0.weight', 'image_encoder.features.12.1.bias', 'image_encoder.features.12.1.weight', 'image_encoder.features.2.block.0.0.weight', 'image_encoder.features.2.block.0.1.bias', 'image_encoder.features.2.block.0.1.weight', 'image_encoder.features.2.block.1.0.weight', 'image_encoder.features.2.block.1.1.bias', 'image_encoder.features.2.block.1.1.weight', 'image_encoder.features.2.block.2.0.weight', 'image_encoder.features.2.block.2.1.bias', 'image_encoder.features.2.block.2.1.weight', 'image_encoder.features.3.block.0.0.weight', 'image_encoder.features.3.block.0.1.bias', 'image_encoder.features.3.block.0.1.weight', 'image_encoder.features.3.block.1.0.weight', 'image_encoder.features.3.block.1.1.bias', 'image_encoder.features.3.block.1.1.weight', 'image_encoder.features.3.block.2.0.weight', 'image_encoder.features.3.block.2.1.bias', 'image_encoder.features.3.block.2.1.weight', 'image_encoder.features.4.block.0.0.weight', 'image_encoder.features.4.block.0.1.bias', 'image_encoder.features.4.block.0.1.weight', 'image_encoder.features.4.block.1.0.weight', 'image_encoder.features.4.block.1.1.bias', 'image_encoder.features.4.block.1.1.weight', 'image_encoder.features.4.block.2.fc1.bias', 'image_encoder.features.4.block.2.fc1.weight', 'image_encoder.features.4.block.2.fc2.bias', 'image_encoder.features.4.block.2.fc2.weight', 'image_encoder.features.4.block.3.0.weight', 'image_encoder.features.4.block.3.1.bias', 'image_encoder.features.4.block.3.1.weight', 'image_encoder.features.5.block.0.0.weight', 'image_encoder.features.5.block.0.1.bias', 'image_encoder.features.5.block.0.1.weight', 'image_encoder.features.5.block.1.0.weight', 'image_encoder.features.5.block.1.1.bias', 'image_encoder.features.5.block.1.1.weight', 'image_encoder.features.5.block.2.fc1.bias', 'image_encoder.features.5.block.2.fc1.weight', 'image_encoder.features.5.block.2.fc2.bias', 'image_encoder.features.5.block.2.fc2.weight', 'image_encoder.features.5.block.3.0.weight', 'image_encoder.features.5.block.3.1.bias', 'image_encoder.features.5.block.3.1.weight', 'image_encoder.features.6.block.0.0.weight', 'image_encoder.features.6.block.0.1.bias', 'image_encoder.features.6.block.0.1.weight', 'image_encoder.features.6.block.1.0.weight', 'image_encoder.features.6.block.1.1.bias', 'image_encoder.features.6.block.1.1.weight', 'image_encoder.features.6.block.2.fc1.bias', 'image_encoder.features.6.block.2.fc1.weight', 'image_encoder.features.6.block.2.fc2.bias', 'image_encoder.features.6.block.2.fc2.weight', 'image_encoder.features.6.block.3.0.weight', 'image_encoder.features.6.block.3.1.bias', 'image_encoder.features.6.block.3.1.weight', 'image_encoder.features.7.block.0.0.weight', 'image_encoder.features.7.block.0.1.bias', 'image_encoder.features.7.block.0.1.weight', 'image_encoder.features.7.block.1.0.weight', 'image_encoder.features.7.block.1.1.bias', 'image_encoder.features.7.block.1.1.weight', 'image_encoder.features.7.block.2.fc1.bias', 'image_encoder.features.7.block.2.fc1.weight', 'image_encoder.features.7.block.2.fc2.bias', 'image_encoder.features.7.block.2.fc2.weight', 'image_encoder.features.7.block.3.0.weight', 'image_encoder.features.7.block.3.1.bias', 'image_encoder.features.7.block.3.1.weight', 'image_encoder.features.8.block.0.0.weight', 'image_encoder.features.8.block.0.1.bias', 'image_encoder.features.8.block.0.1.weight', 'image_encoder.features.8.block.1.0.weight', 'image_encoder.features.8.block.1.1.bias', 'image_encoder.features.8.block.1.1.weight', 'image_encoder.features.8.block.2.fc1.bias', 'image_encoder.features.8.block.2.fc1.weight', 'image_encoder.features.8.block.2.fc2.bias', 'image_encoder.features.8.block.2.fc2.weight', 'image_encoder.features.8.block.3.0.weight', 'image_encoder.features.8.block.3.1.bias', 'image_encoder.features.8.block.3.1.weight', 'image_encoder.features.9.block.0.0.weight', 'image_encoder.features.9.block.0.1.bias', 'image_encoder.features.9.block.0.1.weight', 'image_encoder.features.9.block.1.0.weight', 'image_encoder.features.9.block.1.1.bias', 'image_encoder.features.9.block.1.1.weight', 'image_encoder.features.9.block.2.fc1.bias', 'image_encoder.features.9.block.2.fc1.weight', 'image_encoder.features.9.block.2.fc2.bias', 'image_encoder.features.9.block.2.fc2.weight', 'image_encoder.features.9.block.3.0.weight', 'image_encoder.features.9.block.3.1.bias', 'image_encoder.features.9.block.3.1.weight', 'sgn_embed.ln.bias', 'sgn_embed.ln.weight', 'sgn_embed.norm.norm.bias', 'sgn_embed.norm.norm.weight', 'txt_embed.lut.weight', 'txt_embed.norm.norm.bias', 'txt_embed.norm.norm.weight']
2021-12-31 13:29:43,169 cfg.name                           : ChicagoFSWild Experiment
2021-12-31 13:29:43,169 cfg.data.data_path                 : ./data/
2021-12-31 13:29:43,169 cfg.data.version                   : ChicagoFSWild
2021-12-31 13:29:43,169 cfg.data.sgn                       : sign
2021-12-31 13:29:43,169 cfg.data.gls                       : gloss
2021-12-31 13:29:43,169 cfg.data.feature_size              : 1000
2021-12-31 13:29:43,169 cfg.data.level                     : word
2021-12-31 13:29:43,169 cfg.data.max_sent_length           : 400
2021-12-31 13:29:43,169 cfg.data.random_train_subset       : -1
2021-12-31 13:29:43,169 cfg.data.random_dev_subset         : -1
2021-12-31 13:29:43,169 cfg.testing.recognition_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2021-12-31 13:29:43,170 cfg.testing.translation_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2021-12-31 13:29:43,170 cfg.testing.translation_beam_alphas : [-1, 0, 1, 2, 3, 4, 5]
2021-12-31 13:29:43,170 cfg.training.reset_best_ckpt       : False
2021-12-31 13:29:43,170 cfg.training.reset_scheduler       : False
2021-12-31 13:29:43,170 cfg.training.reset_optimizer       : False
2021-12-31 13:29:43,170 cfg.training.random_seed           : 42
2021-12-31 13:29:43,170 cfg.training.model_dir             : ./ChicagoFSWild Experiments/ChicagoFSWild_experiment_18
2021-12-31 13:29:43,170 cfg.training.recognition_loss_weight : 0.0
2021-12-31 13:29:43,170 cfg.training.translation_loss_weight : 1.0
2021-12-31 13:29:43,170 cfg.training.eval_metric           : wacc
2021-12-31 13:29:43,170 cfg.training.optimizer             : adam
2021-12-31 13:29:43,170 cfg.training.learning_rate         : 0.001
2021-12-31 13:29:43,170 cfg.training.batch_size            : 32
2021-12-31 13:29:43,170 cfg.training.num_valid_log         : 5
2021-12-31 13:29:43,170 cfg.training.epochs                : 5000000
2021-12-31 13:29:43,170 cfg.training.early_stopping_metric : eval_metric
2021-12-31 13:29:43,170 cfg.training.batch_type            : token
2021-12-31 13:29:43,171 cfg.training.translation_normalization : batch
2021-12-31 13:29:43,171 cfg.training.eval_recognition_beam_size : 9
2021-12-31 13:29:43,171 cfg.training.eval_translation_beam_size : 9
2021-12-31 13:29:43,171 cfg.training.eval_translation_beam_alpha : 1
2021-12-31 13:29:43,171 cfg.training.overwrite             : True
2021-12-31 13:29:43,171 cfg.training.shuffle               : True
2021-12-31 13:29:43,171 cfg.training.use_cuda              : True
2021-12-31 13:29:43,171 cfg.training.translation_max_output_length : 1
2021-12-31 13:29:43,171 cfg.training.keep_last_ckpts       : 1
2021-12-31 13:29:43,171 cfg.training.batch_multiplier      : 1
2021-12-31 13:29:43,171 cfg.training.logging_freq          : 1
2021-12-31 13:29:43,171 cfg.training.validation_freq       : 100
2021-12-31 13:29:43,171 cfg.training.betas                 : [0.9, 0.998]
2021-12-31 13:29:43,171 cfg.training.scheduling            : plateau
2021-12-31 13:29:43,171 cfg.training.learning_rate_min     : 1e-06
2021-12-31 13:29:43,171 cfg.training.weight_decay          : 0.001
2021-12-31 13:29:43,171 cfg.training.patience              : 8
2021-12-31 13:29:43,171 cfg.training.decrease_factor       : 0.7
2021-12-31 13:29:43,171 cfg.training.label_smoothing       : 0.0
2021-12-31 13:29:43,171 cfg.model.initializer              : xavier
2021-12-31 13:29:43,172 cfg.model.bias_initializer         : zeros
2021-12-31 13:29:43,172 cfg.model.init_gain                : 1.0
2021-12-31 13:29:43,172 cfg.model.embed_initializer        : xavier
2021-12-31 13:29:43,172 cfg.model.embed_init_gain          : 1.0
2021-12-31 13:29:43,172 cfg.model.tied_softmax             : False
2021-12-31 13:29:43,172 cfg.model.encoder.type             : transformer
2021-12-31 13:29:43,172 cfg.model.encoder.num_layers       : 3
2021-12-31 13:29:43,172 cfg.model.encoder.num_heads        : 8
2021-12-31 13:29:43,172 cfg.model.encoder.embeddings.embedding_dim : 512
2021-12-31 13:29:43,172 cfg.model.encoder.embeddings.scale : False
2021-12-31 13:29:43,172 cfg.model.encoder.embeddings.dropout : 0.1
2021-12-31 13:29:43,172 cfg.model.encoder.embeddings.norm_type : batch
2021-12-31 13:29:43,172 cfg.model.encoder.embeddings.activation_type : softsign
2021-12-31 13:29:43,172 cfg.model.encoder.hidden_size      : 512
2021-12-31 13:29:43,172 cfg.model.encoder.ff_size          : 2048
2021-12-31 13:29:43,172 cfg.model.encoder.dropout          : 0.1
2021-12-31 13:29:43,172 cfg.model.decoder.type             : transformer
2021-12-31 13:29:43,172 cfg.model.decoder.num_layers       : 3
2021-12-31 13:29:43,172 cfg.model.decoder.num_heads        : 8
2021-12-31 13:29:43,172 cfg.model.decoder.embeddings.embedding_dim : 512
2021-12-31 13:29:43,172 cfg.model.decoder.embeddings.scale : False
2021-12-31 13:29:43,173 cfg.model.decoder.embeddings.dropout : 0.1
2021-12-31 13:29:43,173 cfg.model.decoder.embeddings.norm_type : batch
2021-12-31 13:29:43,173 cfg.model.decoder.embeddings.activation_type : softsign
2021-12-31 13:29:43,173 cfg.model.decoder.hidden_size      : 512
2021-12-31 13:29:43,173 cfg.model.decoder.ff_size          : 2048
2021-12-31 13:29:43,173 cfg.model.decoder.dropout          : 0.1
2021-12-31 13:29:43,173 SignModel(
	encoder=TransformerEncoder(num_layers=3, num_heads=8),
	decoder=TransformerDecoder(num_layers=3, num_heads=8),
	sgn_embed=SpatialEmbeddings(embedding_dim=512, input_size=1000),
	txt_embed=Embeddings(embedding_dim=512, vocab_size=2752))
2021-12-31 13:29:43,178 EPOCH 1
2021-12-31 13:29:49,589 [Epoch: 001 Step: 00000001] Batch Translation Loss:   9.069869 => Txt Tokens per Sec:        6 || Lr: 0.001000
2021-12-31 13:29:56,085 [Epoch: 001 Step: 00000002] Batch Translation Loss:   9.570372 => Txt Tokens per Sec:        6 || Lr: 0.001000
2021-12-31 13:30:03,935 [Epoch: 001 Step: 00000003] Batch Translation Loss:  11.049969 => Txt Tokens per Sec:        6 || Lr: 0.001000
2021-12-31 13:30:11,950 [Epoch: 001 Step: 00000004] Batch Translation Loss:  10.948699 => Txt Tokens per Sec:        6 || Lr: 0.001000
2021-12-31 13:30:19,458 [Epoch: 001 Step: 00000005] Batch Translation Loss:   9.268578 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-31 13:30:27,003 [Epoch: 001 Step: 00000006] Batch Translation Loss:  11.118138 => Txt Tokens per Sec:        6 || Lr: 0.001000
2021-12-31 13:30:36,382 [Epoch: 001 Step: 00000007] Batch Translation Loss:  11.539468 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-31 13:30:46,111 [Epoch: 001 Step: 00000008] Batch Translation Loss:  13.714135 => Txt Tokens per Sec:        6 || Lr: 0.001000
2021-12-31 13:30:59,901 [Epoch: 001 Step: 00000009] Batch Translation Loss:  13.323400 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-31 13:31:15,523 [Epoch: 001 Step: 00000010] Batch Translation Loss:  13.322667 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-31 13:31:28,803 [Epoch: 001 Step: 00000011] Batch Translation Loss:  11.158494 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-31 13:31:38,273 [Epoch: 001 Step: 00000012] Batch Translation Loss:  10.987104 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-31 13:31:52,112 [Epoch: 001 Step: 00000013] Batch Translation Loss:  11.322289 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-31 13:32:04,746 [Epoch: 001 Step: 00000014] Batch Translation Loss:  13.427464 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-31 13:32:17,716 [Epoch: 001 Step: 00000015] Batch Translation Loss:  10.446235 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-31 13:32:27,560 [Epoch: 001 Step: 00000016] Batch Translation Loss:   9.581732 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-31 13:32:43,724 [Epoch: 001 Step: 00000017] Batch Translation Loss:  10.464860 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-31 13:32:54,981 [Epoch: 001 Step: 00000018] Batch Translation Loss:   9.334112 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-31 13:33:14,203 [Epoch: 001 Step: 00000019] Batch Translation Loss:   9.410008 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:33:32,298 [Epoch: 001 Step: 00000020] Batch Translation Loss:   9.437302 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:33:48,338 [Epoch: 001 Step: 00000021] Batch Translation Loss:   9.957215 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-31 13:34:03,438 [Epoch: 001 Step: 00000022] Batch Translation Loss:   8.362719 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:34:19,411 [Epoch: 001 Step: 00000023] Batch Translation Loss:   8.648631 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:34:35,524 [Epoch: 001 Step: 00000024] Batch Translation Loss:  11.202630 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-31 13:34:52,218 [Epoch: 001 Step: 00000025] Batch Translation Loss:  10.245302 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-31 13:35:08,337 [Epoch: 001 Step: 00000026] Batch Translation Loss:  10.862718 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-31 13:35:24,755 [Epoch: 001 Step: 00000027] Batch Translation Loss:   9.058734 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:35:50,086 [Epoch: 001 Step: 00000028] Batch Translation Loss:  12.650872 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:36:06,208 [Epoch: 001 Step: 00000029] Batch Translation Loss:  10.376858 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-31 13:36:35,059 [Epoch: 001 Step: 00000030] Batch Translation Loss:  13.098743 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:37:02,545 [Epoch: 001 Step: 00000031] Batch Translation Loss:   9.951826 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 13:37:28,507 [Epoch: 001 Step: 00000032] Batch Translation Loss:  10.698958 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:37:46,301 [Epoch: 001 Step: 00000033] Batch Translation Loss:  10.170271 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:38:16,010 [Epoch: 001 Step: 00000034] Batch Translation Loss:  10.108435 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 13:38:45,506 [Epoch: 001 Step: 00000035] Batch Translation Loss:  10.765524 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 13:39:03,029 [Epoch: 001 Step: 00000036] Batch Translation Loss:   8.094526 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:39:19,805 [Epoch: 001 Step: 00000037] Batch Translation Loss:   8.460662 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:40:00,053 [Epoch: 001 Step: 00000038] Batch Translation Loss:  13.037156 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 13:40:18,717 [Epoch: 001 Step: 00000039] Batch Translation Loss:   8.984898 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:40:38,917 [Epoch: 001 Step: 00000040] Batch Translation Loss:  11.120707 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:40:58,677 [Epoch: 001 Step: 00000041] Batch Translation Loss:   8.976155 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:41:31,801 [Epoch: 001 Step: 00000042] Batch Translation Loss:  11.259125 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 13:41:48,698 [Epoch: 001 Step: 00000043] Batch Translation Loss:   7.690360 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:42:07,708 [Epoch: 001 Step: 00000044] Batch Translation Loss:   7.922623 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:42:24,894 [Epoch: 001 Step: 00000045] Batch Translation Loss:   8.045415 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:42:43,640 [Epoch: 001 Step: 00000046] Batch Translation Loss:   8.765351 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:43:03,171 [Epoch: 001 Step: 00000047] Batch Translation Loss:   8.872184 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:43:22,074 [Epoch: 001 Step: 00000048] Batch Translation Loss:   9.267164 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:43:59,350 [Epoch: 001 Step: 00000049] Batch Translation Loss:  11.643961 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 13:44:34,781 [Epoch: 001 Step: 00000050] Batch Translation Loss:  10.112412 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 13:45:11,499 [Epoch: 001 Step: 00000051] Batch Translation Loss:  10.509897 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 13:45:31,317 [Epoch: 001 Step: 00000052] Batch Translation Loss:   8.386682 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:45:51,158 [Epoch: 001 Step: 00000053] Batch Translation Loss:   8.746804 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:46:12,114 [Epoch: 001 Step: 00000054] Batch Translation Loss:   8.685035 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:46:32,180 [Epoch: 001 Step: 00000055] Batch Translation Loss:   8.220812 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:46:52,199 [Epoch: 001 Step: 00000056] Batch Translation Loss:   8.097033 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:47:12,546 [Epoch: 001 Step: 00000057] Batch Translation Loss:   9.140493 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:47:32,132 [Epoch: 001 Step: 00000058] Batch Translation Loss:   8.591164 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:47:52,214 [Epoch: 001 Step: 00000059] Batch Translation Loss:   9.310298 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:48:14,824 [Epoch: 001 Step: 00000060] Batch Translation Loss:   9.432071 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:48:55,998 [Epoch: 001 Step: 00000061] Batch Translation Loss:  12.032253 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 13:49:33,032 [Epoch: 001 Step: 00000062] Batch Translation Loss:   8.471849 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 13:50:00,180 [Epoch: 001 Step: 00000063] Batch Translation Loss:  12.382681 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:50:45,631 [Epoch: 001 Step: 00000064] Batch Translation Loss:  12.124649 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 13:51:05,033 [Epoch: 001 Step: 00000065] Batch Translation Loss:   9.741561 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:51:26,923 [Epoch: 001 Step: 00000066] Batch Translation Loss:   9.204565 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:51:47,495 [Epoch: 001 Step: 00000067] Batch Translation Loss:   9.217177 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:52:36,036 [Epoch: 001 Step: 00000068] Batch Translation Loss:  12.330187 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 13:52:56,205 [Epoch: 001 Step: 00000069] Batch Translation Loss:   8.511222 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:53:23,372 [Epoch: 001 Step: 00000070] Batch Translation Loss:   8.279399 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 13:53:50,969 [Epoch: 001 Step: 00000071] Batch Translation Loss:   8.603988 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 13:54:16,388 [Epoch: 001 Step: 00000072] Batch Translation Loss:   8.475617 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 13:54:40,949 [Epoch: 001 Step: 00000073] Batch Translation Loss:   9.979198 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:55:04,463 [Epoch: 001 Step: 00000074] Batch Translation Loss:   8.105971 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:55:31,244 [Epoch: 001 Step: 00000075] Batch Translation Loss:   8.509741 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 13:55:57,983 [Epoch: 001 Step: 00000076] Batch Translation Loss:  10.683576 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 13:56:48,404 [Epoch: 001 Step: 00000077] Batch Translation Loss:   8.012938 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 13:57:13,777 [Epoch: 001 Step: 00000078] Batch Translation Loss:   7.291479 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 13:57:39,545 [Epoch: 001 Step: 00000079] Batch Translation Loss:   8.075609 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 13:58:09,090 [Epoch: 001 Step: 00000080] Batch Translation Loss:   8.618444 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 13:58:35,919 [Epoch: 001 Step: 00000081] Batch Translation Loss:   9.012377 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 13:59:03,791 [Epoch: 001 Step: 00000082] Batch Translation Loss:  10.034263 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 13:59:32,327 [Epoch: 001 Step: 00000083] Batch Translation Loss:   9.849849 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 14:00:34,826 [Epoch: 001 Step: 00000084] Batch Translation Loss:  10.098852 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 14:01:04,778 [Epoch: 001 Step: 00000085] Batch Translation Loss:  11.829037 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 14:01:42,170 [Epoch: 001 Step: 00000086] Batch Translation Loss:   7.970196 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 14:02:08,873 [Epoch: 001 Step: 00000087] Batch Translation Loss:   8.577779 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 14:03:08,756 [Epoch: 001 Step: 00000088] Batch Translation Loss:  11.932377 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 14:03:36,404 [Epoch: 001 Step: 00000089] Batch Translation Loss:   9.071754 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 14:04:02,324 [Epoch: 001 Step: 00000090] Batch Translation Loss:   9.266253 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 14:05:03,149 [Epoch: 001 Step: 00000091] Batch Translation Loss:  12.059253 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 14:05:52,152 [Epoch: 001 Step: 00000092] Batch Translation Loss:   8.228642 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 14:06:22,567 [Epoch: 001 Step: 00000093] Batch Translation Loss:   8.538840 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 14:06:55,488 [Epoch: 001 Step: 00000094] Batch Translation Loss:   8.484707 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 14:07:24,560 [Epoch: 001 Step: 00000095] Batch Translation Loss:   8.417860 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 14:08:44,122 [Epoch: 001 Step: 00000096] Batch Translation Loss:   9.065269 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 14:09:19,534 [Epoch: 001 Step: 00000097] Batch Translation Loss:   7.969224 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 14:09:49,506 [Epoch: 001 Step: 00000098] Batch Translation Loss:   9.290898 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 14:10:17,209 [Epoch: 001 Step: 00000099] Batch Translation Loss:   9.664099 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 14:10:46,970 [Epoch: 001 Step: 00000100] Batch Translation Loss:   8.563094 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 14:18:52,658 Hooray! New best validation result [eval_metric]!
2021-12-31 14:18:52,724 Saving new checkpoint.
2021-12-31 14:18:55,982 Validation result at epoch   1, step      100: duration: 488.9910s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11119.78027	PPL: 6662.56787
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 2.69	(DEL: 23.91,	INS: 0.00,	SUB: 73.40)
	Sequence Accuracy 2.39
2021-12-31 14:19:03,942 Logging Recognition and Translation Outputs
2021-12-31 14:19:03,968 ========================================================================================================================
2021-12-31 14:19:03,968 Logging Sequence: deafvideo_3-yesyes_4480
2021-12-31 14:19:03,969 	Text Reference  :	en 
2021-12-31 14:19:03,969 	Text Hypothesis :	asl
2021-12-31 14:19:03,969 	Text Alignment  :	S  
2021-12-31 14:19:03,969 ========================================================================================================================
2021-12-31 14:19:03,970 Logging Sequence: youtube_3-ben_bahan_4537
2021-12-31 14:19:03,970 	Text Reference  :	standing rock
2021-12-31 14:19:03,970 	Text Hypothesis :	******** asl 
2021-12-31 14:19:03,971 	Text Alignment  :	D        S   
2021-12-31 14:19:03,971 ========================================================================================================================
2021-12-31 14:19:03,971 Logging Sequence: deafvideo_3-yesyes_3113
2021-12-31 14:19:03,971 	Text Reference  :	car tool
2021-12-31 14:19:03,971 	Text Hypothesis :	*** asl 
2021-12-31 14:19:03,972 	Text Alignment  :	D   S   
2021-12-31 14:19:03,972 ========================================================================================================================
2021-12-31 14:19:03,972 Logging Sequence: deafvideo_3-otismhill82_4600
2021-12-31 14:19:03,972 	Text Reference  :	oregon
2021-12-31 14:19:03,973 	Text Hypothesis :	asl   
2021-12-31 14:19:03,973 	Text Alignment  :	S     
2021-12-31 14:19:03,973 ========================================================================================================================
2021-12-31 14:19:03,973 Logging Sequence: youtube_4-tim_albert_5278
2021-12-31 14:19:03,973 	Text Reference  :	or 
2021-12-31 14:19:03,974 	Text Hypothesis :	asl
2021-12-31 14:19:03,974 	Text Alignment  :	S  
2021-12-31 14:19:03,974 ========================================================================================================================
2021-12-31 14:21:06,558 [Epoch: 001 Step: 00000101] Batch Translation Loss:   8.904764 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:22:38,428 [Epoch: 001 Step: 00000102] Batch Translation Loss:   8.000001 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:24:23,105 [Epoch: 001 Step: 00000103] Batch Translation Loss:  10.766183 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:25:49,718 [Epoch: 001 Step: 00000104] Batch Translation Loss:   9.355282 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:27:02,665 [Epoch: 001 Step: 00000105] Batch Translation Loss:   9.309528 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 14:28:30,858 [Epoch: 001 Step: 00000106] Batch Translation Loss:   9.921078 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:31:29,739 [Epoch: 001 Step: 00000107] Batch Translation Loss:   7.858475 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:34:31,608 [Epoch: 001 Step: 00000108] Batch Translation Loss:   8.735325 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:36:17,516 [Epoch: 001 Step: 00000109] Batch Translation Loss:  10.006241 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:37:56,758 [Epoch: 001 Step: 00000110] Batch Translation Loss:  10.637497 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:41:31,428 [Epoch: 001 Step: 00000111] Batch Translation Loss:   8.004663 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:43:06,428 [Epoch: 001 Step: 00000112] Batch Translation Loss:   8.154918 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:44:55,711 [Epoch: 001 Step: 00000113] Batch Translation Loss:   8.673170 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:46:35,963 [Epoch: 001 Step: 00000114] Batch Translation Loss:   9.601650 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:48:33,847 [Epoch: 001 Step: 00000115] Batch Translation Loss:   7.663401 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:50:04,446 [Epoch: 001 Step: 00000116] Batch Translation Loss:   8.728496 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:52:05,714 [Epoch: 001 Step: 00000117] Batch Translation Loss:   8.281724 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:54:34,475 [Epoch: 001 Step: 00000118] Batch Translation Loss:  10.696797 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:56:55,431 [Epoch: 001 Step: 00000119] Batch Translation Loss:   9.969861 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:58:39,876 [Epoch: 001 Step: 00000120] Batch Translation Loss:   9.531325 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:00:25,810 [Epoch: 001 Step: 00000121] Batch Translation Loss:   9.159098 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:02:15,894 [Epoch: 001 Step: 00000122] Batch Translation Loss:   9.123973 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:04:21,097 [Epoch: 001 Step: 00000123] Batch Translation Loss:   8.397799 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:06:18,417 [Epoch: 001 Step: 00000124] Batch Translation Loss:   8.471588 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:10:06,526 [Epoch: 001 Step: 00000125] Batch Translation Loss:  10.329455 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:11:59,745 [Epoch: 001 Step: 00000126] Batch Translation Loss:  10.048148 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:14:05,574 [Epoch: 001 Step: 00000127] Batch Translation Loss:   9.959226 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:16:03,215 [Epoch: 001 Step: 00000128] Batch Translation Loss:   9.064169 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:17:59,124 [Epoch: 001 Step: 00000129] Batch Translation Loss:   8.440620 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:20:06,712 [Epoch: 001 Step: 00000130] Batch Translation Loss:   8.580664 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:21:49,404 [Epoch: 001 Step: 00000131] Batch Translation Loss:   8.821708 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:23:28,894 [Epoch: 001 Step: 00000132] Batch Translation Loss:   9.207395 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:25:19,659 [Epoch: 001 Step: 00000133] Batch Translation Loss:  10.111501 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:27:06,210 [Epoch: 001 Step: 00000134] Batch Translation Loss:   8.753046 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:28:50,878 [Epoch: 001 Step: 00000135] Batch Translation Loss:  10.067416 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:30:35,417 [Epoch: 001 Step: 00000136] Batch Translation Loss:  10.169600 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:32:26,355 [Epoch: 001 Step: 00000137] Batch Translation Loss:   8.678323 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:33:58,365 [Epoch: 001 Step: 00000138] Batch Translation Loss:   9.842185 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:35:35,426 [Epoch: 001 Step: 00000139] Batch Translation Loss:   6.895499 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:37:37,695 [Epoch: 001 Step: 00000140] Batch Translation Loss:   8.778515 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:41:14,061 [Epoch: 001 Step: 00000141] Batch Translation Loss:   8.865220 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:43:20,188 [Epoch: 001 Step: 00000142] Batch Translation Loss:   8.253670 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:46:31,858 [Epoch: 001 Step: 00000143] Batch Translation Loss:   7.662701 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:48:08,360 [Epoch: 001 Step: 00000144] Batch Translation Loss:   9.022488 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:51:14,407 [Epoch: 001 Step: 00000145] Batch Translation Loss:   7.504574 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:52:54,315 [Epoch: 001 Step: 00000146] Batch Translation Loss:   8.482395 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:54:28,023 [Epoch: 001 Step: 00000147] Batch Translation Loss:   7.636918 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:56:15,179 [Epoch: 001 Step: 00000148] Batch Translation Loss:  12.400591 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:58:07,764 [Epoch: 001 Step: 00000149] Batch Translation Loss:   8.253109 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:59:44,557 [Epoch: 001 Step: 00000150] Batch Translation Loss:   7.765045 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:01:29,046 [Epoch: 001 Step: 00000151] Batch Translation Loss:   8.491833 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:03:20,924 [Epoch: 001 Step: 00000152] Batch Translation Loss:   7.977391 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:04:55,899 [Epoch: 001 Step: 00000153] Batch Translation Loss:   8.704449 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:06:33,253 [Epoch: 001 Step: 00000154] Batch Translation Loss:   8.382501 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:08:11,627 [Epoch: 001 Step: 00000155] Batch Translation Loss:  10.466227 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:09:51,430 [Epoch: 001 Step: 00000156] Batch Translation Loss:   7.988359 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:11:45,054 [Epoch: 001 Step: 00000157] Batch Translation Loss:   9.779314 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:13:24,417 [Epoch: 001 Step: 00000158] Batch Translation Loss:   7.731233 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:15:04,732 [Epoch: 001 Step: 00000159] Batch Translation Loss:   9.680459 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:16:43,548 [Epoch: 001 Step: 00000160] Batch Translation Loss:   7.756194 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:18:25,938 [Epoch: 001 Step: 00000161] Batch Translation Loss:   8.342191 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:20:11,520 [Epoch: 001 Step: 00000162] Batch Translation Loss:   9.175807 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:23:16,839 [Epoch: 001 Step: 00000163] Batch Translation Loss:   9.439098 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:24:33,633 [Epoch: 001 Step: 00000164] Batch Translation Loss:   8.587095 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:27:11,417 [Epoch: 001 Step: 00000165] Batch Translation Loss:   8.209092 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:29:46,637 [Epoch: 001 Step: 00000166] Batch Translation Loss:   8.785286 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:30:52,051 [Epoch: 001 Step: 00000167] Batch Translation Loss:   8.226686 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 16:32:37,325 [Epoch: 001 Step: 00000168] Batch Translation Loss:   7.164379 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:35:53,307 [Epoch: 001 Step: 00000169] Batch Translation Loss:   7.424562 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:35:53,571 Epoch   1: Total Training Recognition Loss -1.00  Total Training Translation Loss 1596.46 
2021-12-31 16:35:53,571 EPOCH 2
2021-12-31 16:36:06,181 [Epoch: 002 Step: 00000170] Batch Translation Loss:   7.925866 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-31 16:36:22,772 [Epoch: 002 Step: 00000171] Batch Translation Loss:   9.565079 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 16:36:46,517 [Epoch: 002 Step: 00000172] Batch Translation Loss:  11.040173 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 16:37:17,744 [Epoch: 002 Step: 00000173] Batch Translation Loss:   8.092032 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 16:37:37,338 [Epoch: 002 Step: 00000174] Batch Translation Loss:   7.116597 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 16:38:15,764 [Epoch: 002 Step: 00000175] Batch Translation Loss:   9.171789 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 16:38:54,331 [Epoch: 002 Step: 00000176] Batch Translation Loss:  11.638361 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 16:39:14,690 [Epoch: 002 Step: 00000177] Batch Translation Loss:  10.672375 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 16:39:38,029 [Epoch: 002 Step: 00000178] Batch Translation Loss:   8.170254 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 16:40:32,631 [Epoch: 002 Step: 00000179] Batch Translation Loss:  13.239369 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 16:40:55,406 [Epoch: 002 Step: 00000180] Batch Translation Loss:  10.797749 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 16:41:16,166 [Epoch: 002 Step: 00000181] Batch Translation Loss:  10.199221 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 16:41:42,769 [Epoch: 002 Step: 00000182] Batch Translation Loss:   7.564997 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 16:42:14,509 [Epoch: 002 Step: 00000183] Batch Translation Loss:  11.258782 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 16:42:34,316 [Epoch: 002 Step: 00000184] Batch Translation Loss:   7.804504 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 16:42:50,042 [Epoch: 002 Step: 00000185] Batch Translation Loss:   9.443129 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 16:43:24,686 [Epoch: 002 Step: 00000186] Batch Translation Loss:   9.394409 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 16:43:45,944 [Epoch: 002 Step: 00000187] Batch Translation Loss:  10.071520 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 16:44:07,323 [Epoch: 002 Step: 00000188] Batch Translation Loss:   8.780434 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 16:44:28,670 [Epoch: 002 Step: 00000189] Batch Translation Loss:   7.080867 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 16:44:55,721 [Epoch: 002 Step: 00000190] Batch Translation Loss:  10.777182 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 16:45:11,249 [Epoch: 002 Step: 00000191] Batch Translation Loss:  10.120902 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-31 16:45:32,459 [Epoch: 002 Step: 00000192] Batch Translation Loss:   9.210808 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 16:46:02,326 [Epoch: 002 Step: 00000193] Batch Translation Loss:   8.718579 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 16:46:35,457 [Epoch: 002 Step: 00000194] Batch Translation Loss:   9.111735 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 16:47:05,177 [Epoch: 002 Step: 00000195] Batch Translation Loss:   8.723013 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 16:47:38,726 [Epoch: 002 Step: 00000196] Batch Translation Loss:   8.010031 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 16:48:22,186 [Epoch: 002 Step: 00000197] Batch Translation Loss:   9.949863 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 16:48:46,453 [Epoch: 002 Step: 00000198] Batch Translation Loss:  12.170506 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 16:49:14,770 [Epoch: 002 Step: 00000199] Batch Translation Loss:   8.145977 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 16:49:53,759 [Epoch: 002 Step: 00000200] Batch Translation Loss:   8.262653 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 16:57:51,251 Hooray! New best validation result [eval_metric]!
2021-12-31 16:57:51,509 Saving new checkpoint.
2021-12-31 16:57:55,105 Validation result at epoch   2, step      200: duration: 481.3118s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 10603.95898	PPL: 5069.21387
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 2.57	(DEL: 22.20,	INS: 0.00,	SUB: 75.22)
	Sequence Accuracy 2.38
2021-12-31 16:58:03,441 Logging Recognition and Translation Outputs
2021-12-31 16:58:03,454 ========================================================================================================================
2021-12-31 16:58:03,454 Logging Sequence: deafvideo_2-sddsimple_1597
2021-12-31 16:58:03,454 	Text Reference  :	asl copupus
2021-12-31 16:58:03,454 	Text Hypothesis :	asl *******
2021-12-31 16:58:03,455 	Text Alignment  :	    D      
2021-12-31 16:58:03,455 ========================================================================================================================
2021-12-31 16:58:03,455 Logging Sequence: deafvideo_2-sddsimple_1548
2021-12-31 16:58:03,456 	Text Reference  :	feak
2021-12-31 16:58:03,456 	Text Hypothesis :	asl 
2021-12-31 16:58:03,457 	Text Alignment  :	S   
2021-12-31 16:58:03,457 ========================================================================================================================
2021-12-31 16:58:03,457 Logging Sequence: youtube_5-roberta_cordano_6148
2021-12-31 16:58:03,457 	Text Reference  :	ok
2021-12-31 16:58:03,458 	Text Hypothesis :	so
2021-12-31 16:58:03,458 	Text Alignment  :	S 
2021-12-31 16:58:03,458 ========================================================================================================================
2021-12-31 16:58:03,458 Logging Sequence: deafvideo_5-morningstar_6259
2021-12-31 16:58:03,459 	Text Reference  :	dr pady ladd
2021-12-31 16:58:03,459 	Text Hypothesis :	** **** asl 
2021-12-31 16:58:03,459 	Text Alignment  :	D  D    S   
2021-12-31 16:58:03,459 ========================================================================================================================
2021-12-31 16:58:03,460 Logging Sequence: youtube_5-roberta_cordano_6149
2021-12-31 16:58:03,460 	Text Reference  :	aked
2021-12-31 16:58:03,460 	Text Hypothesis :	so  
2021-12-31 16:58:03,460 	Text Alignment  :	S   
2021-12-31 16:58:03,461 ========================================================================================================================
2021-12-31 16:59:32,168 [Epoch: 002 Step: 00000201] Batch Translation Loss:   8.591176 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 17:00:12,065 [Epoch: 002 Step: 00000202] Batch Translation Loss:   8.046453 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:01:19,559 [Epoch: 002 Step: 00000203] Batch Translation Loss:   9.212204 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:02:05,050 [Epoch: 002 Step: 00000204] Batch Translation Loss:   8.169394 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:03:15,007 [Epoch: 002 Step: 00000205] Batch Translation Loss:   8.719955 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:03:53,109 [Epoch: 002 Step: 00000206] Batch Translation Loss:   8.511581 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:04:17,196 [Epoch: 002 Step: 00000207] Batch Translation Loss:   8.325128 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 17:04:46,227 [Epoch: 002 Step: 00000208] Batch Translation Loss:  12.230086 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 17:05:18,826 [Epoch: 002 Step: 00000209] Batch Translation Loss:   9.497341 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:06:11,878 [Epoch: 002 Step: 00000210] Batch Translation Loss:   8.307250 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:06:52,438 [Epoch: 002 Step: 00000211] Batch Translation Loss:   7.838306 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:08:11,221 [Epoch: 002 Step: 00000212] Batch Translation Loss:   9.239709 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:08:44,691 [Epoch: 002 Step: 00000213] Batch Translation Loss:   8.494215 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:09:15,591 [Epoch: 002 Step: 00000214] Batch Translation Loss:   8.907212 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:10:53,989 [Epoch: 002 Step: 00000215] Batch Translation Loss:   7.891878 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 17:11:40,459 [Epoch: 002 Step: 00000216] Batch Translation Loss:   6.700221 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:12:20,180 [Epoch: 002 Step: 00000217] Batch Translation Loss:   8.663035 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:12:46,986 [Epoch: 002 Step: 00000218] Batch Translation Loss:   9.820686 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 17:13:25,033 [Epoch: 002 Step: 00000219] Batch Translation Loss:   8.159811 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:14:27,721 [Epoch: 002 Step: 00000220] Batch Translation Loss:   7.780811 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:15:34,613 [Epoch: 002 Step: 00000221] Batch Translation Loss:   8.655745 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:16:08,450 [Epoch: 002 Step: 00000222] Batch Translation Loss:   7.691910 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:16:43,997 [Epoch: 002 Step: 00000223] Batch Translation Loss:   7.690761 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:17:09,847 [Epoch: 002 Step: 00000224] Batch Translation Loss:   8.316203 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 17:18:55,537 [Epoch: 002 Step: 00000225] Batch Translation Loss:   8.336340 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 17:19:35,118 [Epoch: 002 Step: 00000226] Batch Translation Loss:  10.020336 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:20:33,132 [Epoch: 002 Step: 00000227] Batch Translation Loss:   8.861636 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:21:38,439 [Epoch: 002 Step: 00000228] Batch Translation Loss:   8.776208 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:22:40,101 [Epoch: 002 Step: 00000229] Batch Translation Loss:  10.116741 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:23:47,404 [Epoch: 002 Step: 00000230] Batch Translation Loss:   8.045280 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:24:20,661 [Epoch: 002 Step: 00000231] Batch Translation Loss:   8.343372 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:24:48,132 [Epoch: 002 Step: 00000232] Batch Translation Loss:   8.727718 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:25:18,106 [Epoch: 002 Step: 00000233] Batch Translation Loss:   8.334613 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:26:18,699 [Epoch: 002 Step: 00000234] Batch Translation Loss:  10.386030 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:27:46,107 [Epoch: 002 Step: 00000235] Batch Translation Loss:   8.178407 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 17:28:25,752 [Epoch: 002 Step: 00000236] Batch Translation Loss:   8.175676 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:29:01,723 [Epoch: 002 Step: 00000237] Batch Translation Loss:   7.241173 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:29:47,163 [Epoch: 002 Step: 00000238] Batch Translation Loss:   7.644480 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:30:56,532 [Epoch: 002 Step: 00000239] Batch Translation Loss:   9.106651 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:31:46,258 [Epoch: 002 Step: 00000240] Batch Translation Loss:   8.160681 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:32:53,211 [Epoch: 002 Step: 00000241] Batch Translation Loss:   8.460979 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:33:25,321 [Epoch: 002 Step: 00000242] Batch Translation Loss:   9.425148 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:34:27,044 [Epoch: 002 Step: 00000243] Batch Translation Loss:   8.545132 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:35:29,523 [Epoch: 002 Step: 00000244] Batch Translation Loss:   7.467239 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:36:29,959 [Epoch: 002 Step: 00000245] Batch Translation Loss:   8.623564 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:37:27,423 [Epoch: 002 Step: 00000246] Batch Translation Loss:   7.448718 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:38:31,161 [Epoch: 002 Step: 00000247] Batch Translation Loss:   8.830839 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:39:50,196 [Epoch: 002 Step: 00000248] Batch Translation Loss:   8.744340 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 17:40:48,715 [Epoch: 002 Step: 00000249] Batch Translation Loss:   8.674700 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:41:38,943 [Epoch: 002 Step: 00000250] Batch Translation Loss:   8.927017 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:42:17,475 [Epoch: 002 Step: 00000251] Batch Translation Loss:  10.038590 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:43:33,391 [Epoch: 002 Step: 00000252] Batch Translation Loss:   7.501387 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 17:44:52,790 [Epoch: 002 Step: 00000253] Batch Translation Loss:   8.265743 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 17:45:47,552 [Epoch: 002 Step: 00000254] Batch Translation Loss:   8.989904 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:46:25,996 [Epoch: 002 Step: 00000255] Batch Translation Loss:   9.190460 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:47:57,055 [Epoch: 002 Step: 00000256] Batch Translation Loss:   9.426990 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 17:49:06,129 [Epoch: 002 Step: 00000257] Batch Translation Loss:   7.894470 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:50:01,680 [Epoch: 002 Step: 00000258] Batch Translation Loss:   8.452967 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:50:37,006 [Epoch: 002 Step: 00000259] Batch Translation Loss:   9.292900 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:52:00,757 [Epoch: 002 Step: 00000260] Batch Translation Loss:   9.234886 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 17:54:47,925 [Epoch: 002 Step: 00000261] Batch Translation Loss:   8.835437 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 17:56:18,053 [Epoch: 002 Step: 00000262] Batch Translation Loss:   8.245008 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 17:57:36,228 [Epoch: 002 Step: 00000263] Batch Translation Loss:   7.807367 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 17:58:36,951 [Epoch: 002 Step: 00000264] Batch Translation Loss:   7.975367 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 17:59:31,202 [Epoch: 002 Step: 00000265] Batch Translation Loss:  10.563066 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 18:02:17,868 [Epoch: 002 Step: 00000266] Batch Translation Loss:   8.596893 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:03:07,954 [Epoch: 002 Step: 00000267] Batch Translation Loss:   8.180761 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 18:03:47,117 [Epoch: 002 Step: 00000268] Batch Translation Loss:   7.854743 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 18:05:00,917 [Epoch: 002 Step: 00000269] Batch Translation Loss:   9.437983 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 18:06:32,519 [Epoch: 002 Step: 00000270] Batch Translation Loss:   7.522570 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:07:44,464 [Epoch: 002 Step: 00000271] Batch Translation Loss:   8.490732 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 18:08:40,455 [Epoch: 002 Step: 00000272] Batch Translation Loss:   8.622848 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 18:11:38,560 [Epoch: 002 Step: 00000273] Batch Translation Loss:   9.500591 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:12:27,246 [Epoch: 002 Step: 00000274] Batch Translation Loss:   8.890527 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 18:14:00,067 [Epoch: 002 Step: 00000275] Batch Translation Loss:   7.825125 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:15:39,622 [Epoch: 002 Step: 00000276] Batch Translation Loss:   8.210821 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:16:42,375 [Epoch: 002 Step: 00000277] Batch Translation Loss:   8.296202 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 18:19:27,907 [Epoch: 002 Step: 00000278] Batch Translation Loss:   8.440949 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:21:15,607 [Epoch: 002 Step: 00000279] Batch Translation Loss:   7.679410 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:23:56,446 [Epoch: 002 Step: 00000280] Batch Translation Loss:   9.780171 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:25:13,663 [Epoch: 002 Step: 00000281] Batch Translation Loss:   7.940698 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:26:25,187 [Epoch: 002 Step: 00000282] Batch Translation Loss:   7.183988 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:27:57,500 [Epoch: 002 Step: 00000283] Batch Translation Loss:  10.131862 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:29:37,761 [Epoch: 002 Step: 00000284] Batch Translation Loss:   8.817806 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:31:02,063 [Epoch: 002 Step: 00000285] Batch Translation Loss:   7.597886 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:32:13,083 [Epoch: 002 Step: 00000286] Batch Translation Loss:   9.450898 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 18:33:30,039 [Epoch: 002 Step: 00000287] Batch Translation Loss:   8.210384 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 18:34:34,347 [Epoch: 002 Step: 00000288] Batch Translation Loss:   8.321209 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 18:37:18,380 [Epoch: 002 Step: 00000289] Batch Translation Loss:   8.879166 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:39:26,805 [Epoch: 002 Step: 00000290] Batch Translation Loss:   8.009722 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:40:52,395 [Epoch: 002 Step: 00000291] Batch Translation Loss:   9.035977 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:41:58,195 [Epoch: 002 Step: 00000292] Batch Translation Loss:   8.673385 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 18:43:26,779 [Epoch: 002 Step: 00000293] Batch Translation Loss:   9.008842 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:44:46,518 [Epoch: 002 Step: 00000294] Batch Translation Loss:   7.796532 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:45:48,594 [Epoch: 002 Step: 00000295] Batch Translation Loss:   8.321742 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 18:47:11,062 [Epoch: 002 Step: 00000296] Batch Translation Loss:   8.185964 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:48:47,477 [Epoch: 002 Step: 00000297] Batch Translation Loss:   8.771007 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:50:10,176 [Epoch: 002 Step: 00000298] Batch Translation Loss:   8.280884 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:53:11,700 [Epoch: 002 Step: 00000299] Batch Translation Loss:   8.566218 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:54:44,814 [Epoch: 002 Step: 00000300] Batch Translation Loss:   9.410656 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:02:22,152 Hooray! New best validation result [eval_metric]!
2021-12-31 19:02:22,156 Saving new checkpoint.
2021-12-31 19:02:25,472 Validation result at epoch   2, step      300: duration: 460.6570s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 10878.26465	PPL: 5283.33252
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 2.36	(DEL: 24.43,	INS: 0.00,	SUB: 73.21)
	Sequence Accuracy 2.09
2021-12-31 19:02:33,049 Logging Recognition and Translation Outputs
2021-12-31 19:02:33,070 ========================================================================================================================
2021-12-31 19:02:33,071 Logging Sequence: youtube_1-catherine_mackinnon_2828
2021-12-31 19:02:33,071 	Text Reference  :	scatere
2021-12-31 19:02:33,071 	Text Hypothesis :	asl    
2021-12-31 19:02:33,072 	Text Alignment  :	S      
2021-12-31 19:02:33,072 ========================================================================================================================
2021-12-31 19:02:33,072 Logging Sequence: deafvideo_3-otismhill82_4623
2021-12-31 19:02:33,072 	Text Reference  :	respect
2021-12-31 19:02:33,072 	Text Hypothesis :	asl    
2021-12-31 19:02:33,072 	Text Alignment  :	S      
2021-12-31 19:02:33,072 ========================================================================================================================
2021-12-31 19:02:33,072 Logging Sequence: deafvideo_2-sddsimple_1547
2021-12-31 19:02:33,073 	Text Reference  :	kafi lemons
2021-12-31 19:02:33,073 	Text Hypothesis :	**** asl   
2021-12-31 19:02:33,073 	Text Alignment  :	D    S     
2021-12-31 19:02:33,073 ========================================================================================================================
2021-12-31 19:02:33,073 Logging Sequence: youtube_1-catherine_mackinnon_2816
2021-12-31 19:02:33,073 	Text Reference  :	tim albebt
2021-12-31 19:02:33,074 	Text Hypothesis :	*** asl   
2021-12-31 19:02:33,074 	Text Alignment  :	D   S     
2021-12-31 19:02:33,074 ========================================================================================================================
2021-12-31 19:02:33,074 Logging Sequence: youtube_4-tim_albert_5274
2021-12-31 19:02:33,074 	Text Reference  :	baa
2021-12-31 19:02:33,074 	Text Hypothesis :	asl
2021-12-31 19:02:33,074 	Text Alignment  :	S  
2021-12-31 19:02:33,074 ========================================================================================================================
2021-12-31 19:05:20,155 [Epoch: 002 Step: 00000301] Batch Translation Loss:   9.227408 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:07:34,095 [Epoch: 002 Step: 00000302] Batch Translation Loss:   7.725625 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:10:58,102 [Epoch: 002 Step: 00000303] Batch Translation Loss:   8.524330 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:12:49,391 [Epoch: 002 Step: 00000304] Batch Translation Loss:   8.664553 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:14:17,987 [Epoch: 002 Step: 00000305] Batch Translation Loss:   8.326114 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:15:22,998 [Epoch: 002 Step: 00000306] Batch Translation Loss:   7.522234 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 19:16:57,960 [Epoch: 002 Step: 00000307] Batch Translation Loss:   7.476095 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:19:11,129 [Epoch: 002 Step: 00000308] Batch Translation Loss:   9.228723 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:20:39,674 [Epoch: 002 Step: 00000309] Batch Translation Loss:   8.227266 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:22:32,214 [Epoch: 002 Step: 00000310] Batch Translation Loss:   8.179184 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:26:01,140 [Epoch: 002 Step: 00000311] Batch Translation Loss:   9.051275 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:28:16,481 [Epoch: 002 Step: 00000312] Batch Translation Loss:   6.837645 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:30:10,720 [Epoch: 002 Step: 00000313] Batch Translation Loss:   7.722714 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:31:24,828 [Epoch: 002 Step: 00000314] Batch Translation Loss:   7.985543 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 19:33:50,614 [Epoch: 002 Step: 00000315] Batch Translation Loss:   8.486376 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:35:47,464 [Epoch: 002 Step: 00000316] Batch Translation Loss:   6.830530 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:39:58,444 [Epoch: 002 Step: 00000317] Batch Translation Loss:   8.724061 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:41:41,980 [Epoch: 002 Step: 00000318] Batch Translation Loss:   7.992470 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:43:51,395 [Epoch: 002 Step: 00000319] Batch Translation Loss:   8.816813 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:45:35,802 [Epoch: 002 Step: 00000320] Batch Translation Loss:   9.596470 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:47:03,782 [Epoch: 002 Step: 00000321] Batch Translation Loss:   7.807691 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:49:34,134 [Epoch: 002 Step: 00000322] Batch Translation Loss:   8.357932 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:51:29,453 [Epoch: 002 Step: 00000323] Batch Translation Loss:   8.380764 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:53:16,502 [Epoch: 002 Step: 00000324] Batch Translation Loss:   9.451237 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:55:31,414 [Epoch: 002 Step: 00000325] Batch Translation Loss:   6.680332 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:57:08,737 [Epoch: 002 Step: 00000326] Batch Translation Loss:   7.627836 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:59:16,238 [Epoch: 002 Step: 00000327] Batch Translation Loss:   7.544717 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 20:01:06,820 [Epoch: 002 Step: 00000328] Batch Translation Loss:   7.920199 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 20:02:34,401 [Epoch: 002 Step: 00000329] Batch Translation Loss:   8.051406 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 20:04:43,195 [Epoch: 002 Step: 00000330] Batch Translation Loss:   9.189954 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 20:06:17,881 [Epoch: 002 Step: 00000331] Batch Translation Loss:   8.481095 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 20:09:59,200 [Epoch: 002 Step: 00000332] Batch Translation Loss:   7.514550 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 20:12:17,399 [Epoch: 002 Step: 00000333] Batch Translation Loss:   7.422370 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 20:14:19,064 [Epoch: 002 Step: 00000334] Batch Translation Loss:   7.064996 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 20:15:56,793 [Epoch: 002 Step: 00000335] Batch Translation Loss:   7.885948 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 20:17:08,973 [Epoch: 002 Step: 00000336] Batch Translation Loss:   7.216351 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 20:18:40,636 [Epoch: 002 Step: 00000337] Batch Translation Loss:   8.744678 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 20:19:57,407 [Epoch: 002 Step: 00000338] Batch Translation Loss:   8.646899 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 20:21:06,972 [Epoch: 002 Step: 00000339] Batch Translation Loss:   8.832382 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 20:21:07,145 Epoch   2: Total Training Recognition Loss -1.00  Total Training Translation Loss 1468.90 
2021-12-31 20:21:07,145 EPOCH 3
2021-12-31 20:21:16,354 [Epoch: 003 Step: 00000340] Batch Translation Loss:   7.542727 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-31 20:21:31,444 [Epoch: 003 Step: 00000341] Batch Translation Loss:   8.334215 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-31 20:21:45,077 [Epoch: 003 Step: 00000342] Batch Translation Loss:   9.556461 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-31 20:22:09,754 [Epoch: 003 Step: 00000343] Batch Translation Loss:  10.325539 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:22:49,062 [Epoch: 003 Step: 00000344] Batch Translation Loss:   6.661606 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 20:23:14,355 [Epoch: 003 Step: 00000345] Batch Translation Loss:   8.200856 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:23:36,227 [Epoch: 003 Step: 00000346] Batch Translation Loss:   9.018137 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:24:01,853 [Epoch: 003 Step: 00000347] Batch Translation Loss:  11.123487 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:24:23,060 [Epoch: 003 Step: 00000348] Batch Translation Loss:   7.972747 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:24:43,912 [Epoch: 003 Step: 00000349] Batch Translation Loss:  10.038230 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:25:08,472 [Epoch: 003 Step: 00000350] Batch Translation Loss:  10.890230 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:25:23,815 [Epoch: 003 Step: 00000351] Batch Translation Loss:   7.661204 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:26:01,960 [Epoch: 003 Step: 00000352] Batch Translation Loss:   9.104941 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 20:26:40,023 [Epoch: 003 Step: 00000353] Batch Translation Loss:   8.966748 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 20:27:05,730 [Epoch: 003 Step: 00000354] Batch Translation Loss:   8.683034 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 20:27:31,482 [Epoch: 003 Step: 00000355] Batch Translation Loss:   7.884278 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 20:27:58,639 [Epoch: 003 Step: 00000356] Batch Translation Loss:   8.251532 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 20:28:21,776 [Epoch: 003 Step: 00000357] Batch Translation Loss:   9.494676 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:28:48,099 [Epoch: 003 Step: 00000358] Batch Translation Loss:   8.026245 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 20:29:14,166 [Epoch: 003 Step: 00000359] Batch Translation Loss:   7.651444 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 20:29:35,484 [Epoch: 003 Step: 00000360] Batch Translation Loss:   7.692535 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:29:53,317 [Epoch: 003 Step: 00000361] Batch Translation Loss:   8.657090 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:30:15,968 [Epoch: 003 Step: 00000362] Batch Translation Loss:   7.261878 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:30:42,067 [Epoch: 003 Step: 00000363] Batch Translation Loss:   8.508621 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 20:31:03,054 [Epoch: 003 Step: 00000364] Batch Translation Loss:  10.616816 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:31:29,174 [Epoch: 003 Step: 00000365] Batch Translation Loss:   8.768558 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 20:32:04,749 [Epoch: 003 Step: 00000366] Batch Translation Loss:   9.566855 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 20:32:24,532 [Epoch: 003 Step: 00000367] Batch Translation Loss:   8.473361 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:32:47,237 [Epoch: 003 Step: 00000368] Batch Translation Loss:   8.521312 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:33:07,280 [Epoch: 003 Step: 00000369] Batch Translation Loss:   7.488141 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:33:31,390 [Epoch: 003 Step: 00000370] Batch Translation Loss:   8.884438 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:34:01,855 [Epoch: 003 Step: 00000371] Batch Translation Loss:   8.389418 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 20:34:21,105 [Epoch: 003 Step: 00000372] Batch Translation Loss:   8.987988 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:34:37,871 [Epoch: 003 Step: 00000373] Batch Translation Loss:   9.271144 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-31 20:34:58,115 [Epoch: 003 Step: 00000374] Batch Translation Loss:   6.997751 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:35:27,134 [Epoch: 003 Step: 00000375] Batch Translation Loss:  10.572713 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:35:47,523 [Epoch: 003 Step: 00000376] Batch Translation Loss:   9.731865 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:36:07,094 [Epoch: 003 Step: 00000377] Batch Translation Loss:   8.060040 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:36:45,514 [Epoch: 003 Step: 00000378] Batch Translation Loss:   9.190639 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 20:37:08,184 [Epoch: 003 Step: 00000379] Batch Translation Loss:   9.102050 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:37:43,674 [Epoch: 003 Step: 00000380] Batch Translation Loss:   7.205657 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 20:38:39,755 [Epoch: 003 Step: 00000381] Batch Translation Loss:   8.663260 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 20:39:06,101 [Epoch: 003 Step: 00000382] Batch Translation Loss:   8.251987 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 20:39:26,223 [Epoch: 003 Step: 00000383] Batch Translation Loss:   8.827844 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:39:45,600 [Epoch: 003 Step: 00000384] Batch Translation Loss:   9.115763 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:40:05,984 [Epoch: 003 Step: 00000385] Batch Translation Loss:   8.157764 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:40:22,495 [Epoch: 003 Step: 00000386] Batch Translation Loss:   7.681878 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:40:43,268 [Epoch: 003 Step: 00000387] Batch Translation Loss:   8.995214 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:41:59,551 [Epoch: 003 Step: 00000388] Batch Translation Loss:   8.203765 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 20:42:31,767 [Epoch: 003 Step: 00000389] Batch Translation Loss:   8.042721 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 20:43:27,461 [Epoch: 003 Step: 00000390] Batch Translation Loss:   8.020450 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 20:44:17,474 [Epoch: 003 Step: 00000391] Batch Translation Loss:   8.974901 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 20:44:41,399 [Epoch: 003 Step: 00000392] Batch Translation Loss:   7.659693 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:45:02,646 [Epoch: 003 Step: 00000393] Batch Translation Loss:   9.528381 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:45:22,372 [Epoch: 003 Step: 00000394] Batch Translation Loss:   7.300756 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 20:46:00,500 [Epoch: 003 Step: 00000395] Batch Translation Loss:   7.878402 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 20:46:44,882 [Epoch: 003 Step: 00000396] Batch Translation Loss:   7.367759 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 20:47:42,248 [Epoch: 003 Step: 00000397] Batch Translation Loss:   8.057593 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 20:48:28,893 [Epoch: 003 Step: 00000398] Batch Translation Loss:   6.714808 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 20:49:34,827 [Epoch: 003 Step: 00000399] Batch Translation Loss:   8.113059 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 20:50:11,570 [Epoch: 003 Step: 00000400] Batch Translation Loss:   7.016875 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 20:58:52,657 Hooray! New best validation result [eval_metric]!
2021-12-31 20:58:52,665 Saving new checkpoint.
2021-12-31 20:58:55,544 Validation result at epoch   3, step      400: duration: 523.9495s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11083.98145	PPL: 7458.58496
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.93	(DEL: 22.77,	INS: 0.00,	SUB: 75.30)
	Sequence Accuracy 1.88
2021-12-31 20:59:03,165 Logging Recognition and Translation Outputs
2021-12-31 20:59:03,177 ========================================================================================================================
2021-12-31 20:59:03,177 Logging Sequence: youtube_5-sean_berdy_6114
2021-12-31 20:59:03,177 	Text Reference  :	fund
2021-12-31 20:59:03,177 	Text Hypothesis :	asl 
2021-12-31 20:59:03,177 	Text Alignment  :	S   
2021-12-31 20:59:03,177 ========================================================================================================================
2021-12-31 20:59:03,177 Logging Sequence: youtube_5-sean_berdy_6082
2021-12-31 20:59:03,178 	Text Reference  :	ohio
2021-12-31 20:59:03,178 	Text Hypothesis :	asl 
2021-12-31 20:59:03,178 	Text Alignment  :	S   
2021-12-31 20:59:03,178 ========================================================================================================================
2021-12-31 20:59:03,178 Logging Sequence: deafvideo_2-sddsimple_1575
2021-12-31 20:59:03,178 	Text Reference  :	or 
2021-12-31 20:59:03,178 	Text Hypothesis :	asl
2021-12-31 20:59:03,178 	Text Alignment  :	S  
2021-12-31 20:59:03,178 ========================================================================================================================
2021-12-31 20:59:03,178 Logging Sequence: deafvideo_3-otismhill82_4602
2021-12-31 20:59:03,179 	Text Reference  :	salvation
2021-12-31 20:59:03,179 	Text Hypothesis :	asl      
2021-12-31 20:59:03,179 	Text Alignment  :	S        
2021-12-31 20:59:03,179 ========================================================================================================================
2021-12-31 20:59:03,179 Logging Sequence: deafvideo_2-sddsimple_1585
2021-12-31 20:59:03,179 	Text Reference  :	electronics
2021-12-31 20:59:03,179 	Text Hypothesis :	asl        
2021-12-31 20:59:03,179 	Text Alignment  :	S          
2021-12-31 20:59:03,179 ========================================================================================================================
2021-12-31 21:00:33,248 [Epoch: 003 Step: 00000401] Batch Translation Loss:   7.450698 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 21:02:09,889 [Epoch: 003 Step: 00000402] Batch Translation Loss:   8.468092 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 21:02:56,220 [Epoch: 003 Step: 00000403] Batch Translation Loss:   6.825351 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:03:26,308 [Epoch: 003 Step: 00000404] Batch Translation Loss:   7.681050 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:03:53,183 [Epoch: 003 Step: 00000405] Batch Translation Loss:   8.503613 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:04:58,852 [Epoch: 003 Step: 00000406] Batch Translation Loss:   8.410780 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:05:58,801 [Epoch: 003 Step: 00000407] Batch Translation Loss:   9.929444 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:06:50,259 [Epoch: 003 Step: 00000408] Batch Translation Loss:   7.952165 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:07:23,622 [Epoch: 003 Step: 00000409] Batch Translation Loss:   7.453198 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:07:59,434 [Epoch: 003 Step: 00000410] Batch Translation Loss:   7.703273 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:08:26,104 [Epoch: 003 Step: 00000411] Batch Translation Loss:   8.498412 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:09:11,984 [Epoch: 003 Step: 00000412] Batch Translation Loss:   8.914182 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:09:38,277 [Epoch: 003 Step: 00000413] Batch Translation Loss:   7.883450 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:10:28,627 [Epoch: 003 Step: 00000414] Batch Translation Loss:   8.814411 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:11:32,984 [Epoch: 003 Step: 00000415] Batch Translation Loss:   8.711619 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:12:18,941 [Epoch: 003 Step: 00000416] Batch Translation Loss:   7.986800 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:12:58,627 [Epoch: 003 Step: 00000417] Batch Translation Loss:   8.942966 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:13:54,411 [Epoch: 003 Step: 00000418] Batch Translation Loss:   8.039503 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:14:23,462 [Epoch: 003 Step: 00000419] Batch Translation Loss:   8.444213 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:15:01,792 [Epoch: 003 Step: 00000420] Batch Translation Loss:   8.010966 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:15:55,594 [Epoch: 003 Step: 00000421] Batch Translation Loss:   7.792679 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:17:14,038 [Epoch: 003 Step: 00000422] Batch Translation Loss:   7.442938 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 21:18:16,813 [Epoch: 003 Step: 00000423] Batch Translation Loss:   7.296190 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:18:57,270 [Epoch: 003 Step: 00000424] Batch Translation Loss:   8.086429 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:19:32,801 [Epoch: 003 Step: 00000425] Batch Translation Loss:   8.770234 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:20:09,135 [Epoch: 003 Step: 00000426] Batch Translation Loss:   7.013486 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:20:34,567 [Epoch: 003 Step: 00000427] Batch Translation Loss:   8.796006 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 21:21:11,590 [Epoch: 003 Step: 00000428] Batch Translation Loss:   7.828930 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:22:34,606 [Epoch: 003 Step: 00000429] Batch Translation Loss:   7.429149 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 21:23:40,549 [Epoch: 003 Step: 00000430] Batch Translation Loss:   7.765709 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:25:09,069 [Epoch: 003 Step: 00000431] Batch Translation Loss:   6.973922 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 21:25:42,353 [Epoch: 003 Step: 00000432] Batch Translation Loss:   8.478602 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:26:19,147 [Epoch: 003 Step: 00000433] Batch Translation Loss:   7.383713 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:27:06,637 [Epoch: 003 Step: 00000434] Batch Translation Loss:   8.173758 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:28:27,230 [Epoch: 003 Step: 00000435] Batch Translation Loss:   8.713665 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 21:29:35,015 [Epoch: 003 Step: 00000436] Batch Translation Loss:   7.857944 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:30:28,857 [Epoch: 003 Step: 00000437] Batch Translation Loss:   8.608980 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:31:08,154 [Epoch: 003 Step: 00000438] Batch Translation Loss:   7.287206 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:31:41,316 [Epoch: 003 Step: 00000439] Batch Translation Loss:   8.018167 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:32:08,655 [Epoch: 003 Step: 00000440] Batch Translation Loss:   7.140163 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:32:38,957 [Epoch: 003 Step: 00000441] Batch Translation Loss:   8.230176 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:33:40,983 [Epoch: 003 Step: 00000442] Batch Translation Loss:   7.224315 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:35:19,340 [Epoch: 003 Step: 00000443] Batch Translation Loss:   8.164478 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 21:36:18,973 [Epoch: 003 Step: 00000444] Batch Translation Loss:   8.511979 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:37:27,867 [Epoch: 003 Step: 00000445] Batch Translation Loss:   7.299476 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:38:09,115 [Epoch: 003 Step: 00000446] Batch Translation Loss:   7.407709 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:39:06,002 [Epoch: 003 Step: 00000447] Batch Translation Loss:   7.458583 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:40:34,002 [Epoch: 003 Step: 00000448] Batch Translation Loss:   7.194429 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 21:41:45,173 [Epoch: 003 Step: 00000449] Batch Translation Loss:   8.284603 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:42:38,784 [Epoch: 003 Step: 00000450] Batch Translation Loss:   7.777455 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:43:16,215 [Epoch: 003 Step: 00000451] Batch Translation Loss:   7.313078 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:43:55,070 [Epoch: 003 Step: 00000452] Batch Translation Loss:   8.378577 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:44:52,515 [Epoch: 003 Step: 00000453] Batch Translation Loss:   7.579932 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:46:23,193 [Epoch: 003 Step: 00000454] Batch Translation Loss:   7.429449 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 21:47:47,886 [Epoch: 003 Step: 00000455] Batch Translation Loss:   8.335661 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 21:48:45,367 [Epoch: 003 Step: 00000456] Batch Translation Loss:   7.190201 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:49:36,832 [Epoch: 003 Step: 00000457] Batch Translation Loss:   7.246064 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:50:38,977 [Epoch: 003 Step: 00000458] Batch Translation Loss:   7.205994 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:51:42,399 [Epoch: 003 Step: 00000459] Batch Translation Loss:   7.356294 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:53:37,666 [Epoch: 003 Step: 00000460] Batch Translation Loss:   9.018060 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 21:54:45,897 [Epoch: 003 Step: 00000461] Batch Translation Loss:   7.768437 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:55:30,850 [Epoch: 003 Step: 00000462] Batch Translation Loss:   7.308093 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:56:09,551 [Epoch: 003 Step: 00000463] Batch Translation Loss:   7.937964 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:56:44,697 [Epoch: 003 Step: 00000464] Batch Translation Loss:  10.019787 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 21:58:12,986 [Epoch: 003 Step: 00000465] Batch Translation Loss:   6.920791 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 21:59:49,984 [Epoch: 003 Step: 00000466] Batch Translation Loss:   7.495115 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:01:00,063 [Epoch: 003 Step: 00000467] Batch Translation Loss:   7.814423 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 22:02:09,135 [Epoch: 003 Step: 00000468] Batch Translation Loss:   6.689033 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:03:08,058 [Epoch: 003 Step: 00000469] Batch Translation Loss:   8.363548 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 22:04:58,325 [Epoch: 003 Step: 00000470] Batch Translation Loss:   7.691669 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:07:24,241 [Epoch: 003 Step: 00000471] Batch Translation Loss:   7.517530 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:08:10,002 [Epoch: 003 Step: 00000472] Batch Translation Loss:   7.255782 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 22:08:47,785 [Epoch: 003 Step: 00000473] Batch Translation Loss:   7.303282 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 22:10:03,917 [Epoch: 003 Step: 00000474] Batch Translation Loss:   7.752408 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:12:11,312 [Epoch: 003 Step: 00000475] Batch Translation Loss:   7.895284 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:13:32,178 [Epoch: 003 Step: 00000476] Batch Translation Loss:   8.035041 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:14:42,538 [Epoch: 003 Step: 00000477] Batch Translation Loss:   8.247438 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 22:18:21,781 [Epoch: 003 Step: 00000478] Batch Translation Loss:   8.500567 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:20:12,432 [Epoch: 003 Step: 00000479] Batch Translation Loss:   8.125601 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:21:37,804 [Epoch: 003 Step: 00000480] Batch Translation Loss:   7.748784 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:23:56,577 [Epoch: 003 Step: 00000481] Batch Translation Loss:   7.640643 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:25:33,791 [Epoch: 003 Step: 00000482] Batch Translation Loss:   7.936647 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:26:49,529 [Epoch: 003 Step: 00000483] Batch Translation Loss:   7.763221 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:28:47,108 [Epoch: 003 Step: 00000484] Batch Translation Loss:   7.603578 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:30:21,826 [Epoch: 003 Step: 00000485] Batch Translation Loss:   7.500579 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:31:43,278 [Epoch: 003 Step: 00000486] Batch Translation Loss:   6.914539 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:34:56,856 [Epoch: 003 Step: 00000487] Batch Translation Loss:   8.672990 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:38:01,573 [Epoch: 003 Step: 00000488] Batch Translation Loss:   8.366915 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:39:54,327 [Epoch: 003 Step: 00000489] Batch Translation Loss:   7.909023 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:42:32,971 [Epoch: 003 Step: 00000490] Batch Translation Loss:   8.562629 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:43:33,933 [Epoch: 003 Step: 00000491] Batch Translation Loss:   6.756612 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 22:46:48,393 [Epoch: 003 Step: 00000492] Batch Translation Loss:   7.740884 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:48:12,915 [Epoch: 003 Step: 00000493] Batch Translation Loss:   7.384378 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:49:47,831 [Epoch: 003 Step: 00000494] Batch Translation Loss:   7.874211 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:51:35,421 [Epoch: 003 Step: 00000495] Batch Translation Loss:   8.343827 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:53:04,791 [Epoch: 003 Step: 00000496] Batch Translation Loss:   7.520820 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:54:09,124 [Epoch: 003 Step: 00000497] Batch Translation Loss:   7.955545 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 22:57:14,085 [Epoch: 003 Step: 00000498] Batch Translation Loss:   8.917213 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:58:28,793 [Epoch: 003 Step: 00000499] Batch Translation Loss:   7.859468 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:59:35,302 [Epoch: 003 Step: 00000500] Batch Translation Loss:   7.901145 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:07:49,610 Hooray! New best validation result [eval_metric]!
2021-12-31 23:07:49,642 Saving new checkpoint.
2021-12-31 23:07:53,052 Validation result at epoch   3, step      500: duration: 497.6980s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 10940.75977	PPL: 5085.42529
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.33	(DEL: 25.35,	INS: 0.00,	SUB: 73.32)
	Sequence Accuracy 1.67
2021-12-31 23:08:02,133 Logging Recognition and Translation Outputs
2021-12-31 23:08:02,204 ========================================================================================================================
2021-12-31 23:08:02,204 Logging Sequence: deafvideo_3-deafgoldenhair_3077
2021-12-31 23:08:02,205 	Text Reference  :	bus
2021-12-31 23:08:02,206 	Text Hypothesis :	asl
2021-12-31 23:08:02,206 	Text Alignment  :	S  
2021-12-31 23:08:02,206 ========================================================================================================================
2021-12-31 23:08:02,206 Logging Sequence: deafvideo_3-otismhill82_4605
2021-12-31 23:08:02,206 	Text Reference  :	faceles
2021-12-31 23:08:02,207 	Text Hypothesis :	social 
2021-12-31 23:08:02,207 	Text Alignment  :	S      
2021-12-31 23:08:02,207 ========================================================================================================================
2021-12-31 23:08:02,207 Logging Sequence: deafvideo_2-deafpoweronethumbtwo_1782
2021-12-31 23:08:02,207 	Text Reference  :	paste 
2021-12-31 23:08:02,208 	Text Hypothesis :	social
2021-12-31 23:08:02,208 	Text Alignment  :	S     
2021-12-31 23:08:02,208 ========================================================================================================================
2021-12-31 23:08:02,208 Logging Sequence: youtube_1-melvin_patterson_2338
2021-12-31 23:08:02,208 	Text Reference  :	asociate povost
2021-12-31 23:08:02,209 	Text Hypothesis :	******** social
2021-12-31 23:08:02,209 	Text Alignment  :	D        S     
2021-12-31 23:08:02,209 ========================================================================================================================
2021-12-31 23:08:02,209 Logging Sequence: youtube_4-tim_albert_5281
2021-12-31 23:08:02,209 	Text Reference  :	csubia    
2021-12-31 23:08:02,209 	Text Hypothesis :	apocalypse
2021-12-31 23:08:02,210 	Text Alignment  :	S         
2021-12-31 23:08:02,210 ========================================================================================================================
2021-12-31 23:11:00,883 [Epoch: 003 Step: 00000501] Batch Translation Loss:   7.176093 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 23:13:03,420 [Epoch: 003 Step: 00000502] Batch Translation Loss:   7.927899 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 23:15:04,334 [Epoch: 003 Step: 00000503] Batch Translation Loss:   8.230661 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 23:16:49,625 [Epoch: 003 Step: 00000504] Batch Translation Loss:   7.671684 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 23:19:02,030 [Epoch: 003 Step: 00000505] Batch Translation Loss:   7.170892 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 23:21:31,475 [Epoch: 003 Step: 00000506] Batch Translation Loss:   6.791801 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 23:22:36,540 [Epoch: 003 Step: 00000507] Batch Translation Loss:   7.202742 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:27:20,359 [Epoch: 003 Step: 00000508] Batch Translation Loss:  10.267200 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 23:32:15,753 [Epoch: 003 Step: 00000509] Batch Translation Loss:   7.231453 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 23:32:15,870 Epoch   3: Total Training Recognition Loss -1.00  Total Training Translation Loss 1379.18 
2021-12-31 23:32:15,870 EPOCH 4
2021-12-31 23:32:31,752 [Epoch: 004 Step: 00000510] Batch Translation Loss:   8.031082 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 23:32:55,741 [Epoch: 004 Step: 00000511] Batch Translation Loss:   8.929789 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 23:33:17,831 [Epoch: 004 Step: 00000512] Batch Translation Loss:   8.700417 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 23:33:54,851 [Epoch: 004 Step: 00000513] Batch Translation Loss:   9.730792 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:34:27,772 [Epoch: 004 Step: 00000514] Batch Translation Loss:  11.438656 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 23:35:07,400 [Epoch: 004 Step: 00000515] Batch Translation Loss:  10.315104 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:35:24,642 [Epoch: 004 Step: 00000516] Batch Translation Loss:  10.018945 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-31 23:35:50,774 [Epoch: 004 Step: 00000517] Batch Translation Loss:  10.510610 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 23:36:14,971 [Epoch: 004 Step: 00000518] Batch Translation Loss:   7.642443 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 23:36:53,665 [Epoch: 004 Step: 00000519] Batch Translation Loss:   6.692311 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:37:22,042 [Epoch: 004 Step: 00000520] Batch Translation Loss:   6.856295 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:37:48,159 [Epoch: 004 Step: 00000521] Batch Translation Loss:   8.715955 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:38:15,725 [Epoch: 004 Step: 00000522] Batch Translation Loss:   7.494040 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:38:42,404 [Epoch: 004 Step: 00000523] Batch Translation Loss:   8.266885 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 23:39:24,985 [Epoch: 004 Step: 00000524] Batch Translation Loss:  10.220724 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:39:51,762 [Epoch: 004 Step: 00000525] Batch Translation Loss:  10.675867 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 23:40:09,009 [Epoch: 004 Step: 00000526] Batch Translation Loss:   8.390894 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 23:40:23,686 [Epoch: 004 Step: 00000527] Batch Translation Loss:   6.631125 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 23:40:47,048 [Epoch: 004 Step: 00000528] Batch Translation Loss:   9.529121 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 23:41:03,994 [Epoch: 004 Step: 00000529] Batch Translation Loss:   7.449796 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 23:41:31,386 [Epoch: 004 Step: 00000530] Batch Translation Loss:   8.811221 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:41:43,566 [Epoch: 004 Step: 00000531] Batch Translation Loss:   7.796284 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-31 23:42:06,034 [Epoch: 004 Step: 00000532] Batch Translation Loss:   7.684632 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 23:42:30,381 [Epoch: 004 Step: 00000533] Batch Translation Loss:   8.293852 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 23:43:16,058 [Epoch: 004 Step: 00000534] Batch Translation Loss:   7.662294 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:44:12,901 [Epoch: 004 Step: 00000535] Batch Translation Loss:   7.345882 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:44:43,255 [Epoch: 004 Step: 00000536] Batch Translation Loss:   8.237778 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:45:08,664 [Epoch: 004 Step: 00000537] Batch Translation Loss:   7.354820 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:45:41,056 [Epoch: 004 Step: 00000538] Batch Translation Loss:   7.771668 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:46:02,044 [Epoch: 004 Step: 00000539] Batch Translation Loss:   8.592953 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 23:46:45,269 [Epoch: 004 Step: 00000540] Batch Translation Loss:   7.905877 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:47:01,716 [Epoch: 004 Step: 00000541] Batch Translation Loss:  10.280031 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-31 23:47:25,114 [Epoch: 004 Step: 00000542] Batch Translation Loss:   6.873512 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:47:41,964 [Epoch: 004 Step: 00000543] Batch Translation Loss:   6.971169 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 23:48:03,159 [Epoch: 004 Step: 00000544] Batch Translation Loss:   7.125390 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 23:48:26,351 [Epoch: 004 Step: 00000545] Batch Translation Loss:   8.252622 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 23:49:00,405 [Epoch: 004 Step: 00000546] Batch Translation Loss:   6.883348 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:49:49,405 [Epoch: 004 Step: 00000547] Batch Translation Loss:   7.007616 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:50:26,533 [Epoch: 004 Step: 00000548] Batch Translation Loss:   7.822731 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:50:53,860 [Epoch: 004 Step: 00000549] Batch Translation Loss:   8.838731 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 23:51:25,513 [Epoch: 004 Step: 00000550] Batch Translation Loss:   7.794898 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:51:48,566 [Epoch: 004 Step: 00000551] Batch Translation Loss:   7.936575 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 23:52:13,168 [Epoch: 004 Step: 00000552] Batch Translation Loss:   8.148145 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 23:52:33,205 [Epoch: 004 Step: 00000553] Batch Translation Loss:   7.542446 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 23:52:52,078 [Epoch: 004 Step: 00000554] Batch Translation Loss:   8.245953 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 23:53:21,047 [Epoch: 004 Step: 00000555] Batch Translation Loss:   8.075141 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:53:39,748 [Epoch: 004 Step: 00000556] Batch Translation Loss:   8.238390 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 23:54:01,716 [Epoch: 004 Step: 00000557] Batch Translation Loss:   8.146098 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 23:54:24,112 [Epoch: 004 Step: 00000558] Batch Translation Loss:  10.869668 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-31 23:54:51,891 [Epoch: 004 Step: 00000559] Batch Translation Loss:   7.583823 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:55:36,837 [Epoch: 004 Step: 00000560] Batch Translation Loss:   6.339307 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:56:32,812 [Epoch: 004 Step: 00000561] Batch Translation Loss:   8.521115 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:57:14,906 [Epoch: 004 Step: 00000562] Batch Translation Loss:   8.698792 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:57:55,303 [Epoch: 004 Step: 00000563] Batch Translation Loss:  10.130790 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:58:34,322 [Epoch: 004 Step: 00000564] Batch Translation Loss:   7.195060 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:59:04,212 [Epoch: 004 Step: 00000565] Batch Translation Loss:   8.895576 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:59:33,531 [Epoch: 004 Step: 00000566] Batch Translation Loss:   7.152989 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-31 23:59:57,028 [Epoch: 004 Step: 00000567] Batch Translation Loss:   7.995298 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 00:00:19,873 [Epoch: 004 Step: 00000568] Batch Translation Loss:   7.039884 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 00:00:46,745 [Epoch: 004 Step: 00000569] Batch Translation Loss:   7.350339 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:01:13,336 [Epoch: 004 Step: 00000570] Batch Translation Loss:   7.678445 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:01:48,700 [Epoch: 004 Step: 00000571] Batch Translation Loss:   8.077135 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:02:51,651 [Epoch: 004 Step: 00000572] Batch Translation Loss:   8.311256 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:03:40,674 [Epoch: 004 Step: 00000573] Batch Translation Loss:   8.885072 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:04:23,581 [Epoch: 004 Step: 00000574] Batch Translation Loss:   8.211440 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:04:55,865 [Epoch: 004 Step: 00000575] Batch Translation Loss:   6.320298 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:05:26,109 [Epoch: 004 Step: 00000576] Batch Translation Loss:   7.452548 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:05:48,742 [Epoch: 004 Step: 00000577] Batch Translation Loss:   6.381739 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:06:11,167 [Epoch: 004 Step: 00000578] Batch Translation Loss:   7.357133 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 00:06:33,561 [Epoch: 004 Step: 00000579] Batch Translation Loss:   8.555968 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 00:06:56,320 [Epoch: 004 Step: 00000580] Batch Translation Loss:   7.851562 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 00:07:18,412 [Epoch: 004 Step: 00000581] Batch Translation Loss:   8.171560 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 00:07:48,710 [Epoch: 004 Step: 00000582] Batch Translation Loss:   8.670448 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:08:27,266 [Epoch: 004 Step: 00000583] Batch Translation Loss:   9.272895 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:10:18,526 [Epoch: 004 Step: 00000584] Batch Translation Loss:   7.278838 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 00:11:02,360 [Epoch: 004 Step: 00000585] Batch Translation Loss:   7.100374 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:11:33,977 [Epoch: 004 Step: 00000586] Batch Translation Loss:   7.730521 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:12:06,180 [Epoch: 004 Step: 00000587] Batch Translation Loss:   8.118737 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:13:06,165 [Epoch: 004 Step: 00000588] Batch Translation Loss:   7.389990 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:13:36,875 [Epoch: 004 Step: 00000589] Batch Translation Loss:   7.139111 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:14:03,235 [Epoch: 004 Step: 00000590] Batch Translation Loss:  10.205513 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 00:14:29,187 [Epoch: 004 Step: 00000591] Batch Translation Loss:   7.422158 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 00:15:07,851 [Epoch: 004 Step: 00000592] Batch Translation Loss:   8.565151 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:16:25,050 [Epoch: 004 Step: 00000593] Batch Translation Loss:   7.791595 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 00:17:45,597 [Epoch: 004 Step: 00000594] Batch Translation Loss:   7.297103 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 00:18:14,362 [Epoch: 004 Step: 00000595] Batch Translation Loss:   6.777593 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:18:46,634 [Epoch: 004 Step: 00000596] Batch Translation Loss:   7.747645 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:19:13,535 [Epoch: 004 Step: 00000597] Batch Translation Loss:   7.172155 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:19:48,367 [Epoch: 004 Step: 00000598] Batch Translation Loss:   7.561631 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:20:19,679 [Epoch: 004 Step: 00000599] Batch Translation Loss:   7.078780 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:20:52,373 [Epoch: 004 Step: 00000600] Batch Translation Loss:   7.801090 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:28:58,334 Validation result at epoch   4, step      600: duration: 485.9279s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11046.33789	PPL: 5559.22900
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 2.19	(DEL: 24.90,	INS: 0.00,	SUB: 72.91)
	Sequence Accuracy 2.18
2022-01-01 00:29:05,940 Logging Recognition and Translation Outputs
2022-01-01 00:29:05,951 ========================================================================================================================
2022-01-01 00:29:05,951 Logging Sequence: deafvideo_5-morningstar_6257
2022-01-01 00:29:05,951 	Text Reference  :	ok 
2022-01-01 00:29:05,952 	Text Hypothesis :	asl
2022-01-01 00:29:05,952 	Text Alignment  :	S  
2022-01-01 00:29:05,952 ========================================================================================================================
2022-01-01 00:29:05,952 Logging Sequence: deafvideo_5-scottnorby_6456
2022-01-01 00:29:05,952 	Text Reference  :	love
2022-01-01 00:29:05,952 	Text Hypothesis :	asl 
2022-01-01 00:29:05,952 	Text Alignment  :	S   
2022-01-01 00:29:05,952 ========================================================================================================================
2022-01-01 00:29:05,952 Logging Sequence: aslized-suzanne_stecker_0268
2022-01-01 00:29:05,953 	Text Reference  :	filter f lens   
2022-01-01 00:29:05,953 	Text Hypothesis :	****** * episode
2022-01-01 00:29:05,953 	Text Alignment  :	D      D S      
2022-01-01 00:29:05,953 ========================================================================================================================
2022-01-01 00:29:05,953 Logging Sequence: youtube_1-catherine_mackinnon_2816
2022-01-01 00:29:05,953 	Text Reference  :	bandcd
2022-01-01 00:29:05,953 	Text Hypothesis :	asl   
2022-01-01 00:29:05,953 	Text Alignment  :	S     
2022-01-01 00:29:05,953 ========================================================================================================================
2022-01-01 00:29:05,953 Logging Sequence: deafvideo_3-otismhill82_4611
2022-01-01 00:29:05,953 	Text Reference  :	ih 
2022-01-01 00:29:05,954 	Text Hypothesis :	asl
2022-01-01 00:29:05,954 	Text Alignment  :	S  
2022-01-01 00:29:05,954 ========================================================================================================================
2022-01-01 00:31:05,051 [Epoch: 004 Step: 00000601] Batch Translation Loss:   8.492987 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 00:32:29,398 [Epoch: 004 Step: 00000602] Batch Translation Loss:   6.965220 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 00:34:05,094 [Epoch: 004 Step: 00000603] Batch Translation Loss:   6.678569 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 00:36:35,498 [Epoch: 004 Step: 00000604] Batch Translation Loss:   8.227834 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 00:37:25,367 [Epoch: 004 Step: 00000605] Batch Translation Loss:   7.071362 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:38:06,927 [Epoch: 004 Step: 00000606] Batch Translation Loss:   7.215024 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:38:35,130 [Epoch: 004 Step: 00000607] Batch Translation Loss:   7.953650 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:39:06,489 [Epoch: 004 Step: 00000608] Batch Translation Loss:   6.782269 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:39:33,658 [Epoch: 004 Step: 00000609] Batch Translation Loss:   7.453859 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:41:40,564 [Epoch: 004 Step: 00000610] Batch Translation Loss:   8.317433 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 00:43:10,443 [Epoch: 004 Step: 00000611] Batch Translation Loss:   8.331339 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 00:44:09,253 [Epoch: 004 Step: 00000612] Batch Translation Loss:   8.663341 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:44:54,752 [Epoch: 004 Step: 00000613] Batch Translation Loss:   6.396344 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:45:31,881 [Epoch: 004 Step: 00000614] Batch Translation Loss:   7.262269 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:46:09,507 [Epoch: 004 Step: 00000615] Batch Translation Loss:   7.366771 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:46:42,057 [Epoch: 004 Step: 00000616] Batch Translation Loss:   8.023517 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:47:56,142 [Epoch: 004 Step: 00000617] Batch Translation Loss:   7.739937 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:49:37,531 [Epoch: 004 Step: 00000618] Batch Translation Loss:   8.606451 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 00:51:01,352 [Epoch: 004 Step: 00000619] Batch Translation Loss:   7.714779 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 00:52:01,168 [Epoch: 004 Step: 00000620] Batch Translation Loss:   7.375074 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:52:51,590 [Epoch: 004 Step: 00000621] Batch Translation Loss:   6.632750 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:53:30,627 [Epoch: 004 Step: 00000622] Batch Translation Loss:   8.213121 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:54:12,639 [Epoch: 004 Step: 00000623] Batch Translation Loss:   8.451985 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:55:51,926 [Epoch: 004 Step: 00000624] Batch Translation Loss:   7.782894 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 00:57:18,266 [Epoch: 004 Step: 00000625] Batch Translation Loss:   6.974511 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 00:58:24,504 [Epoch: 004 Step: 00000626] Batch Translation Loss:   7.203481 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 00:59:46,017 [Epoch: 004 Step: 00000627] Batch Translation Loss:   6.596595 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 01:00:35,507 [Epoch: 004 Step: 00000628] Batch Translation Loss:   7.948565 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 01:01:11,373 [Epoch: 004 Step: 00000629] Batch Translation Loss:   7.329608 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 01:02:23,509 [Epoch: 004 Step: 00000630] Batch Translation Loss:   7.141873 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 01:04:17,609 [Epoch: 004 Step: 00000631] Batch Translation Loss:   7.123161 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 01:05:55,283 [Epoch: 004 Step: 00000632] Batch Translation Loss:   7.572614 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 01:06:59,752 [Epoch: 004 Step: 00000633] Batch Translation Loss:   7.533541 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 01:08:02,006 [Epoch: 004 Step: 00000634] Batch Translation Loss:   7.455813 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 01:08:52,723 [Epoch: 004 Step: 00000635] Batch Translation Loss:   7.646586 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 01:10:49,427 [Epoch: 004 Step: 00000636] Batch Translation Loss:   8.122804 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 01:12:23,237 [Epoch: 004 Step: 00000637] Batch Translation Loss:   8.161910 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 01:13:33,838 [Epoch: 004 Step: 00000638] Batch Translation Loss:   7.817611 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 01:14:33,145 [Epoch: 004 Step: 00000639] Batch Translation Loss:   7.398678 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 01:15:30,332 [Epoch: 004 Step: 00000640] Batch Translation Loss:   7.055150 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 01:16:34,892 [Epoch: 004 Step: 00000641] Batch Translation Loss:   6.850783 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 01:20:12,937 [Epoch: 004 Step: 00000642] Batch Translation Loss:   8.763743 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 01:22:26,176 [Epoch: 004 Step: 00000643] Batch Translation Loss:   8.131448 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 01:23:26,897 [Epoch: 004 Step: 00000644] Batch Translation Loss:   8.144557 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 01:25:31,238 [Epoch: 004 Step: 00000645] Batch Translation Loss:   7.632950 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 01:27:05,594 [Epoch: 004 Step: 00000646] Batch Translation Loss:   7.234705 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 01:28:05,611 [Epoch: 004 Step: 00000647] Batch Translation Loss:   7.455120 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 01:29:03,895 [Epoch: 004 Step: 00000648] Batch Translation Loss:   9.443451 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 01:30:00,230 [Epoch: 004 Step: 00000649] Batch Translation Loss:   7.341995 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 01:32:14,740 [Epoch: 004 Step: 00000650] Batch Translation Loss:   9.200645 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 01:34:24,746 [Epoch: 004 Step: 00000651] Batch Translation Loss:   7.644931 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 01:36:01,454 [Epoch: 004 Step: 00000652] Batch Translation Loss:   8.418848 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 01:37:00,851 [Epoch: 004 Step: 00000653] Batch Translation Loss:   7.988905 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 01:38:30,525 [Epoch: 004 Step: 00000654] Batch Translation Loss:   9.144154 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 01:41:35,628 [Epoch: 004 Step: 00000655] Batch Translation Loss:   7.251259 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 01:42:25,973 [Epoch: 004 Step: 00000656] Batch Translation Loss:   7.805972 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 01:43:03,037 [Epoch: 004 Step: 00000657] Batch Translation Loss:   8.374867 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 01:43:44,167 [Epoch: 004 Step: 00000658] Batch Translation Loss:   7.892240 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 01:44:25,656 [Epoch: 004 Step: 00000659] Batch Translation Loss:   7.518510 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 01:45:01,837 [Epoch: 004 Step: 00000660] Batch Translation Loss:   6.918452 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 01:45:38,986 [Epoch: 004 Step: 00000661] Batch Translation Loss:   9.469355 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 01:47:14,160 [Epoch: 004 Step: 00000662] Batch Translation Loss:   7.317990 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 01:50:28,048 [Epoch: 004 Step: 00000663] Batch Translation Loss:   8.069438 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 01:51:31,175 [Epoch: 004 Step: 00000664] Batch Translation Loss:   7.483880 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 01:52:17,831 [Epoch: 004 Step: 00000665] Batch Translation Loss:   6.849429 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 01:53:03,017 [Epoch: 004 Step: 00000666] Batch Translation Loss:   6.843988 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 01:54:47,154 [Epoch: 004 Step: 00000667] Batch Translation Loss:   8.945108 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 01:56:46,113 [Epoch: 004 Step: 00000668] Batch Translation Loss:   8.149923 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 01:58:01,166 [Epoch: 004 Step: 00000669] Batch Translation Loss:   7.293925 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 01:59:02,685 [Epoch: 004 Step: 00000670] Batch Translation Loss:   9.330467 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:00:07,280 [Epoch: 004 Step: 00000671] Batch Translation Loss:   7.780688 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:01:22,353 [Epoch: 004 Step: 00000672] Batch Translation Loss:   7.487406 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:04:55,619 [Epoch: 004 Step: 00000673] Batch Translation Loss:   7.402107 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 02:05:46,430 [Epoch: 004 Step: 00000674] Batch Translation Loss:   7.515180 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:06:32,566 [Epoch: 004 Step: 00000675] Batch Translation Loss:   6.966010 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:08:44,517 [Epoch: 004 Step: 00000676] Batch Translation Loss:   6.567490 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 02:10:47,959 [Epoch: 004 Step: 00000677] Batch Translation Loss:   7.894225 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 02:12:22,091 [Epoch: 004 Step: 00000678] Batch Translation Loss:   6.742496 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 02:13:16,930 [Epoch: 004 Step: 00000679] Batch Translation Loss:   8.240677 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 02:13:17,072 Epoch   4: Total Training Recognition Loss -1.00  Total Training Translation Loss 1345.34 
2022-01-01 02:13:17,073 EPOCH 5
2022-01-01 02:13:28,578 [Epoch: 005 Step: 00000680] Batch Translation Loss:   7.296467 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 02:13:37,835 [Epoch: 005 Step: 00000681] Batch Translation Loss:   8.024446 => Txt Tokens per Sec:        4 || Lr: 0.001000
2022-01-01 02:13:54,073 [Epoch: 005 Step: 00000682] Batch Translation Loss:   8.571855 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:14:21,736 [Epoch: 005 Step: 00000683] Batch Translation Loss:   8.961320 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:14:45,077 [Epoch: 005 Step: 00000684] Batch Translation Loss:   9.919741 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:15:17,677 [Epoch: 005 Step: 00000685] Batch Translation Loss:   7.294336 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:16:02,150 [Epoch: 005 Step: 00000686] Batch Translation Loss:   7.107546 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:16:21,603 [Epoch: 005 Step: 00000687] Batch Translation Loss:   7.711688 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:16:51,653 [Epoch: 005 Step: 00000688] Batch Translation Loss:  11.327520 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:17:29,044 [Epoch: 005 Step: 00000689] Batch Translation Loss:   8.241473 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:17:51,996 [Epoch: 005 Step: 00000690] Batch Translation Loss:   8.753247 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:18:08,955 [Epoch: 005 Step: 00000691] Batch Translation Loss:  10.300220 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 02:18:29,764 [Epoch: 005 Step: 00000692] Batch Translation Loss:   8.236458 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:18:47,207 [Epoch: 005 Step: 00000693] Batch Translation Loss:   8.259178 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:19:22,305 [Epoch: 005 Step: 00000694] Batch Translation Loss:  10.577674 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:19:34,539 [Epoch: 005 Step: 00000695] Batch Translation Loss:   7.380579 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 02:20:03,114 [Epoch: 005 Step: 00000696] Batch Translation Loss:   8.207858 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:20:20,572 [Epoch: 005 Step: 00000697] Batch Translation Loss:  10.105304 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 02:20:36,164 [Epoch: 005 Step: 00000698] Batch Translation Loss:   8.143926 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:20:58,669 [Epoch: 005 Step: 00000699] Batch Translation Loss:   5.829462 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:21:20,773 [Epoch: 005 Step: 00000700] Batch Translation Loss:   7.057833 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:29:37,658 Validation result at epoch   5, step      700: duration: 496.7985s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 10711.52051	PPL: 5885.95703
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 2.59	(DEL: 22.37,	INS: 0.00,	SUB: 75.04)
	Sequence Accuracy 2.09
2022-01-01 02:29:46,320 Logging Recognition and Translation Outputs
2022-01-01 02:29:46,324 ========================================================================================================================
2022-01-01 02:29:46,325 Logging Sequence: deafvideo_3-damien23_3603
2022-01-01 02:29:46,325 	Text Reference  :	kafi lemons
2022-01-01 02:29:46,325 	Text Hypothesis :	**** dr    
2022-01-01 02:29:46,326 	Text Alignment  :	D    S     
2022-01-01 02:29:46,326 ========================================================================================================================
2022-01-01 02:29:46,326 Logging Sequence: deafvideo_3-yesyes_3107
2022-01-01 02:29:46,326 	Text Reference  :	if 
2022-01-01 02:29:46,326 	Text Hypothesis :	asl
2022-01-01 02:29:46,326 	Text Alignment  :	S  
2022-01-01 02:29:46,327 ========================================================================================================================
2022-01-01 02:29:46,327 Logging Sequence: aslized-suzanne_stecker_0282
2022-01-01 02:29:46,327 	Text Reference  :	adam eve
2022-01-01 02:29:46,327 	Text Hypothesis :	**** asl
2022-01-01 02:29:46,327 	Text Alignment  :	D    S  
2022-01-01 02:29:46,327 ========================================================================================================================
2022-01-01 02:29:46,328 Logging Sequence: deafvideo_4-tax_tips_by_irs_4964
2022-01-01 02:29:46,328 	Text Reference  :	admin
2022-01-01 02:29:46,328 	Text Hypothesis :	asl  
2022-01-01 02:29:46,328 	Text Alignment  :	S    
2022-01-01 02:29:46,328 ========================================================================================================================
2022-01-01 02:29:46,328 Logging Sequence: youtube_4-lizzie_sorkin_5246
2022-01-01 02:29:46,329 	Text Reference  :	ovn
2022-01-01 02:29:46,329 	Text Hypothesis :	asl
2022-01-01 02:29:46,329 	Text Alignment  :	S  
2022-01-01 02:29:46,329 ========================================================================================================================
2022-01-01 02:30:44,338 [Epoch: 005 Step: 00000701] Batch Translation Loss:   7.713377 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:32:01,899 [Epoch: 005 Step: 00000702] Batch Translation Loss:   8.172664 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:32:31,804 [Epoch: 005 Step: 00000703] Batch Translation Loss:   8.370695 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:33:33,131 [Epoch: 005 Step: 00000704] Batch Translation Loss:   7.502366 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:34:15,895 [Epoch: 005 Step: 00000705] Batch Translation Loss:   7.983939 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:35:08,850 [Epoch: 005 Step: 00000706] Batch Translation Loss:   8.370843 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:35:35,740 [Epoch: 005 Step: 00000707] Batch Translation Loss:   8.818370 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:36:07,601 [Epoch: 005 Step: 00000708] Batch Translation Loss:   7.168381 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:36:42,305 [Epoch: 005 Step: 00000709] Batch Translation Loss:   6.956387 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:37:16,518 [Epoch: 005 Step: 00000710] Batch Translation Loss:   8.900768 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:37:32,670 [Epoch: 005 Step: 00000711] Batch Translation Loss:   7.850504 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:37:51,294 [Epoch: 005 Step: 00000712] Batch Translation Loss:   8.329494 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:38:09,179 [Epoch: 005 Step: 00000713] Batch Translation Loss:   7.770219 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:38:25,180 [Epoch: 005 Step: 00000714] Batch Translation Loss:   8.042807 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:38:53,816 [Epoch: 005 Step: 00000715] Batch Translation Loss:   7.095256 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:39:12,293 [Epoch: 005 Step: 00000716] Batch Translation Loss:   7.008192 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:39:33,632 [Epoch: 005 Step: 00000717] Batch Translation Loss:   7.260547 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:40:03,199 [Epoch: 005 Step: 00000718] Batch Translation Loss:   6.629361 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:40:44,367 [Epoch: 005 Step: 00000719] Batch Translation Loss:   7.771408 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:41:26,918 [Epoch: 005 Step: 00000720] Batch Translation Loss:   7.619665 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:42:18,752 [Epoch: 005 Step: 00000721] Batch Translation Loss:   8.093014 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:43:15,641 [Epoch: 005 Step: 00000722] Batch Translation Loss:   7.477393 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:43:43,179 [Epoch: 005 Step: 00000723] Batch Translation Loss:   7.258400 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:44:04,970 [Epoch: 005 Step: 00000724] Batch Translation Loss:   7.191947 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:44:28,676 [Epoch: 005 Step: 00000725] Batch Translation Loss:   6.894365 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:44:46,172 [Epoch: 005 Step: 00000726] Batch Translation Loss:   7.867746 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:45:06,356 [Epoch: 005 Step: 00000727] Batch Translation Loss:   8.854611 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:45:26,581 [Epoch: 005 Step: 00000728] Batch Translation Loss:   7.083022 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:45:46,613 [Epoch: 005 Step: 00000729] Batch Translation Loss:   7.327725 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:46:26,843 [Epoch: 005 Step: 00000730] Batch Translation Loss:   7.959299 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:46:52,839 [Epoch: 005 Step: 00000731] Batch Translation Loss:   6.605150 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:47:41,151 [Epoch: 005 Step: 00000732] Batch Translation Loss:   7.075774 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:48:33,339 [Epoch: 005 Step: 00000733] Batch Translation Loss:   7.087091 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:49:10,724 [Epoch: 005 Step: 00000734] Batch Translation Loss:   7.521566 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:49:36,548 [Epoch: 005 Step: 00000735] Batch Translation Loss:   7.668573 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:50:05,046 [Epoch: 005 Step: 00000736] Batch Translation Loss:   8.514762 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:50:32,035 [Epoch: 005 Step: 00000737] Batch Translation Loss:   6.736112 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:51:00,643 [Epoch: 005 Step: 00000738] Batch Translation Loss:   8.158157 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:51:20,726 [Epoch: 005 Step: 00000739] Batch Translation Loss:   7.038791 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:51:47,082 [Epoch: 005 Step: 00000740] Batch Translation Loss:   8.476789 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:52:10,665 [Epoch: 005 Step: 00000741] Batch Translation Loss:   8.093534 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:52:33,159 [Epoch: 005 Step: 00000742] Batch Translation Loss:   7.571933 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:52:59,870 [Epoch: 005 Step: 00000743] Batch Translation Loss:   7.792379 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:53:23,333 [Epoch: 005 Step: 00000744] Batch Translation Loss:   6.923102 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:53:50,398 [Epoch: 005 Step: 00000745] Batch Translation Loss:  10.044655 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:54:11,339 [Epoch: 005 Step: 00000746] Batch Translation Loss:   6.870855 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:54:42,321 [Epoch: 005 Step: 00000747] Batch Translation Loss:   7.525186 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:55:46,373 [Epoch: 005 Step: 00000748] Batch Translation Loss:   8.134357 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:57:02,882 [Epoch: 005 Step: 00000749] Batch Translation Loss:   8.022706 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 02:57:36,132 [Epoch: 005 Step: 00000750] Batch Translation Loss:   6.602204 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:58:01,939 [Epoch: 005 Step: 00000751] Batch Translation Loss:   9.324136 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:58:28,987 [Epoch: 005 Step: 00000752] Batch Translation Loss:   7.723010 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:58:51,044 [Epoch: 005 Step: 00000753] Batch Translation Loss:   7.504586 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 02:59:18,848 [Epoch: 005 Step: 00000754] Batch Translation Loss:   7.312365 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 02:59:45,493 [Epoch: 005 Step: 00000755] Batch Translation Loss:   8.174503 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 03:00:35,188 [Epoch: 005 Step: 00000756] Batch Translation Loss:  10.381673 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:00:59,444 [Epoch: 005 Step: 00000757] Batch Translation Loss:   7.616297 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 03:01:25,208 [Epoch: 005 Step: 00000758] Batch Translation Loss:   7.358965 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:01:50,166 [Epoch: 005 Step: 00000759] Batch Translation Loss:   8.403034 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 03:02:25,153 [Epoch: 005 Step: 00000760] Batch Translation Loss:   8.574442 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:04:23,279 [Epoch: 005 Step: 00000761] Batch Translation Loss:   6.450267 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 03:04:55,270 [Epoch: 005 Step: 00000762] Batch Translation Loss:   7.027688 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:05:42,193 [Epoch: 005 Step: 00000763] Batch Translation Loss:   6.841845 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:06:23,953 [Epoch: 005 Step: 00000764] Batch Translation Loss:   8.610183 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:06:54,066 [Epoch: 005 Step: 00000765] Batch Translation Loss:   7.303872 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:07:22,115 [Epoch: 005 Step: 00000766] Batch Translation Loss:   7.486301 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:07:46,927 [Epoch: 005 Step: 00000767] Batch Translation Loss:   7.323692 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:08:09,384 [Epoch: 005 Step: 00000768] Batch Translation Loss:   7.640186 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 03:08:40,038 [Epoch: 005 Step: 00000769] Batch Translation Loss:   7.182175 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:09:10,124 [Epoch: 005 Step: 00000770] Batch Translation Loss:   8.044538 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:09:50,351 [Epoch: 005 Step: 00000771] Batch Translation Loss:   7.649968 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:11:14,717 [Epoch: 005 Step: 00000772] Batch Translation Loss:   7.724730 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 03:12:07,926 [Epoch: 005 Step: 00000773] Batch Translation Loss:   8.265463 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:12:47,370 [Epoch: 005 Step: 00000774] Batch Translation Loss:   7.398487 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:13:24,835 [Epoch: 005 Step: 00000775] Batch Translation Loss:   7.611009 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:13:57,644 [Epoch: 005 Step: 00000776] Batch Translation Loss:   7.616502 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:14:27,577 [Epoch: 005 Step: 00000777] Batch Translation Loss:   7.770792 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:15:21,600 [Epoch: 005 Step: 00000778] Batch Translation Loss:   8.358151 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:15:50,319 [Epoch: 005 Step: 00000779] Batch Translation Loss:   8.696997 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 03:16:19,536 [Epoch: 005 Step: 00000780] Batch Translation Loss:   7.642869 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:16:46,873 [Epoch: 005 Step: 00000781] Batch Translation Loss:   7.461321 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:17:26,193 [Epoch: 005 Step: 00000782] Batch Translation Loss:   7.035183 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:18:56,135 [Epoch: 005 Step: 00000783] Batch Translation Loss:   8.129869 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 03:20:25,435 [Epoch: 005 Step: 00000784] Batch Translation Loss:   6.933457 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 03:21:00,741 [Epoch: 005 Step: 00000785] Batch Translation Loss:   7.515604 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:21:34,837 [Epoch: 005 Step: 00000786] Batch Translation Loss:   6.582542 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:22:09,523 [Epoch: 005 Step: 00000787] Batch Translation Loss:   7.531307 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:23:03,538 [Epoch: 005 Step: 00000788] Batch Translation Loss:   7.910277 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:23:35,399 [Epoch: 005 Step: 00000789] Batch Translation Loss:   7.346220 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:24:07,918 [Epoch: 005 Step: 00000790] Batch Translation Loss:   7.362213 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:24:53,603 [Epoch: 005 Step: 00000791] Batch Translation Loss:   7.755515 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:27:10,922 [Epoch: 005 Step: 00000792] Batch Translation Loss:   9.489165 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 03:29:02,511 [Epoch: 005 Step: 00000793] Batch Translation Loss:   6.898324 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 03:31:31,714 [Epoch: 005 Step: 00000794] Batch Translation Loss:   8.138941 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 03:33:01,189 [Epoch: 005 Step: 00000795] Batch Translation Loss:   7.354242 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 03:34:52,270 [Epoch: 005 Step: 00000796] Batch Translation Loss:   7.377289 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 03:36:22,500 [Epoch: 005 Step: 00000797] Batch Translation Loss:   7.915234 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 03:37:32,634 [Epoch: 005 Step: 00000798] Batch Translation Loss:   7.862575 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:38:44,870 [Epoch: 005 Step: 00000799] Batch Translation Loss:   9.063749 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 03:40:33,527 [Epoch: 005 Step: 00000800] Batch Translation Loss:   8.209785 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 03:50:00,487 Validation result at epoch   5, step      800: duration: 566.9384s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11415.14355	PPL: 5236.97070
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.50	(DEL: 27.98,	INS: 0.00,	SUB: 70.52)
	Sequence Accuracy 1.56
2022-01-01 03:50:07,786 Logging Recognition and Translation Outputs
2022-01-01 03:50:07,827 ========================================================================================================================
2022-01-01 03:50:07,828 Logging Sequence: youtube_4-sean_berdy_5754
2022-01-01 03:50:07,828 	Text Reference  :	task fce
2022-01-01 03:50:07,829 	Text Hypothesis :	**** asl
2022-01-01 03:50:07,829 	Text Alignment  :	D    S  
2022-01-01 03:50:07,829 ========================================================================================================================
2022-01-01 03:50:07,829 Logging Sequence: deafvideo_2-sddsimple_1582
2022-01-01 03:50:07,830 	Text Reference  :	uv 
2022-01-01 03:50:07,830 	Text Hypothesis :	asl
2022-01-01 03:50:07,830 	Text Alignment  :	S  
2022-01-01 03:50:07,830 ========================================================================================================================
2022-01-01 03:50:07,831 Logging Sequence: deafvideo_5-deafpoweronethumbtwo_7292
2022-01-01 03:50:07,831 	Text Reference  :	zack
2022-01-01 03:50:07,831 	Text Hypothesis :	asl 
2022-01-01 03:50:07,832 	Text Alignment  :	S   
2022-01-01 03:50:07,832 ========================================================================================================================
2022-01-01 03:50:07,832 Logging Sequence: deafvideo_3-geoalpha_4563
2022-01-01 03:50:07,832 	Text Reference  :	all
2022-01-01 03:50:07,833 	Text Hypothesis :	so 
2022-01-01 03:50:07,833 	Text Alignment  :	S  
2022-01-01 03:50:07,833 ========================================================================================================================
2022-01-01 03:50:07,833 Logging Sequence: youtube_5-daniel_durant_5885
2022-01-01 03:50:07,834 	Text Reference  :	itheme
2022-01-01 03:50:07,834 	Text Hypothesis :	asl   
2022-01-01 03:50:07,834 	Text Alignment  :	S     
2022-01-01 03:50:07,834 ========================================================================================================================
2022-01-01 03:52:58,608 [Epoch: 005 Step: 00000801] Batch Translation Loss:   7.380394 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 03:55:08,986 [Epoch: 005 Step: 00000802] Batch Translation Loss:   8.183705 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 03:57:12,683 [Epoch: 005 Step: 00000803] Batch Translation Loss:   7.575906 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 03:58:52,739 [Epoch: 005 Step: 00000804] Batch Translation Loss:   8.282343 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 03:59:52,458 [Epoch: 005 Step: 00000805] Batch Translation Loss:   7.290432 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 04:00:39,974 [Epoch: 005 Step: 00000806] Batch Translation Loss:   6.734420 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 04:01:17,805 [Epoch: 005 Step: 00000807] Batch Translation Loss:   6.722910 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 04:01:56,926 [Epoch: 005 Step: 00000808] Batch Translation Loss:   8.001594 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 04:03:31,265 [Epoch: 005 Step: 00000809] Batch Translation Loss:   8.221836 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 04:06:47,940 [Epoch: 005 Step: 00000810] Batch Translation Loss:   8.255485 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 04:07:51,040 [Epoch: 005 Step: 00000811] Batch Translation Loss:   8.486235 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 04:08:38,985 [Epoch: 005 Step: 00000812] Batch Translation Loss:   7.385882 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 04:09:23,339 [Epoch: 005 Step: 00000813] Batch Translation Loss:   6.462114 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 04:10:01,906 [Epoch: 005 Step: 00000814] Batch Translation Loss:   8.135274 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 04:10:51,140 [Epoch: 005 Step: 00000815] Batch Translation Loss:   6.124111 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 04:12:38,492 [Epoch: 005 Step: 00000816] Batch Translation Loss:   7.546201 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 04:14:41,195 [Epoch: 005 Step: 00000817] Batch Translation Loss:   7.582412 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 04:16:09,783 [Epoch: 005 Step: 00000818] Batch Translation Loss:   7.264740 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 04:17:12,573 [Epoch: 005 Step: 00000819] Batch Translation Loss:   7.675216 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 04:18:05,850 [Epoch: 005 Step: 00000820] Batch Translation Loss:   7.652811 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 04:18:41,492 [Epoch: 005 Step: 00000821] Batch Translation Loss:   6.994785 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 04:19:43,526 [Epoch: 005 Step: 00000822] Batch Translation Loss:   8.219770 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 04:22:01,556 [Epoch: 005 Step: 00000823] Batch Translation Loss:   7.662789 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 04:23:42,406 [Epoch: 005 Step: 00000824] Batch Translation Loss:   6.964961 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 04:24:50,816 [Epoch: 005 Step: 00000825] Batch Translation Loss:   6.640659 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 04:25:46,575 [Epoch: 005 Step: 00000826] Batch Translation Loss:   6.309037 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 04:26:38,810 [Epoch: 005 Step: 00000827] Batch Translation Loss:   8.374921 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 04:27:22,589 [Epoch: 005 Step: 00000828] Batch Translation Loss:   7.844661 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 04:28:02,652 [Epoch: 005 Step: 00000829] Batch Translation Loss:   7.619554 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 04:29:20,443 [Epoch: 005 Step: 00000830] Batch Translation Loss:   7.161047 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 04:32:07,198 [Epoch: 005 Step: 00000831] Batch Translation Loss:   7.269178 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 04:33:56,604 [Epoch: 005 Step: 00000832] Batch Translation Loss:  10.132548 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 04:36:07,079 [Epoch: 005 Step: 00000833] Batch Translation Loss:   7.914872 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 04:37:00,381 [Epoch: 005 Step: 00000834] Batch Translation Loss:   7.144096 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 04:38:18,322 [Epoch: 005 Step: 00000835] Batch Translation Loss:   6.975371 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 04:41:01,818 [Epoch: 005 Step: 00000836] Batch Translation Loss:   8.025990 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 04:42:41,235 [Epoch: 005 Step: 00000837] Batch Translation Loss:   7.963318 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 04:44:51,208 [Epoch: 005 Step: 00000838] Batch Translation Loss:   7.485858 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 04:45:38,687 [Epoch: 005 Step: 00000839] Batch Translation Loss:   8.046656 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 04:46:15,052 [Epoch: 005 Step: 00000840] Batch Translation Loss:   6.921309 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 04:47:18,666 [Epoch: 005 Step: 00000841] Batch Translation Loss:   6.655413 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 04:49:46,837 [Epoch: 005 Step: 00000842] Batch Translation Loss:   8.513001 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 04:51:17,976 [Epoch: 005 Step: 00000843] Batch Translation Loss:   6.695799 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 04:52:35,598 [Epoch: 005 Step: 00000844] Batch Translation Loss:   7.528665 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 04:53:28,482 [Epoch: 005 Step: 00000845] Batch Translation Loss:   7.197970 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 04:54:05,634 [Epoch: 005 Step: 00000846] Batch Translation Loss:   7.448111 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 04:54:46,603 [Epoch: 005 Step: 00000847] Batch Translation Loss:   7.212939 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 04:55:36,964 [Epoch: 005 Step: 00000848] Batch Translation Loss:   7.568995 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 04:57:52,329 [Epoch: 005 Step: 00000849] Batch Translation Loss:   8.002060 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 04:57:52,521 Epoch   5: Total Training Recognition Loss -1.00  Total Training Translation Loss 1319.46 
2022-01-01 04:57:52,521 EPOCH 6
2022-01-01 04:58:20,688 [Epoch: 006 Step: 00000850] Batch Translation Loss:   8.565425 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 04:58:42,204 [Epoch: 006 Step: 00000851] Batch Translation Loss:   8.974767 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 04:58:59,884 [Epoch: 006 Step: 00000852] Batch Translation Loss:   8.452199 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 04:59:16,544 [Epoch: 006 Step: 00000853] Batch Translation Loss:   8.106275 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 04:59:50,288 [Epoch: 006 Step: 00000854] Batch Translation Loss:   9.701699 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:00:10,194 [Epoch: 006 Step: 00000855] Batch Translation Loss:   9.034993 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:00:48,256 [Epoch: 006 Step: 00000856] Batch Translation Loss:   8.778713 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:01:19,911 [Epoch: 006 Step: 00000857] Batch Translation Loss:   9.726428 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:01:53,913 [Epoch: 006 Step: 00000858] Batch Translation Loss:   8.946017 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:02:29,357 [Epoch: 006 Step: 00000859] Batch Translation Loss:   9.527038 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:02:59,903 [Epoch: 006 Step: 00000860] Batch Translation Loss:  10.759884 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:03:39,830 [Epoch: 006 Step: 00000861] Batch Translation Loss:  10.019473 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:04:16,051 [Epoch: 006 Step: 00000862] Batch Translation Loss:  10.441589 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:04:47,589 [Epoch: 006 Step: 00000863] Batch Translation Loss:   8.892505 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:05:22,329 [Epoch: 006 Step: 00000864] Batch Translation Loss:   7.487648 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:05:52,509 [Epoch: 006 Step: 00000865] Batch Translation Loss:   7.791142 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:06:16,496 [Epoch: 006 Step: 00000866] Batch Translation Loss:   6.787892 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:07:05,582 [Epoch: 006 Step: 00000867] Batch Translation Loss:   9.265326 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:07:25,946 [Epoch: 006 Step: 00000868] Batch Translation Loss:   7.368018 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:07:53,251 [Epoch: 006 Step: 00000869] Batch Translation Loss:   9.947891 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:08:07,878 [Epoch: 006 Step: 00000870] Batch Translation Loss:   7.038480 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:08:21,586 [Epoch: 006 Step: 00000871] Batch Translation Loss:   7.184147 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 05:08:52,748 [Epoch: 006 Step: 00000872] Batch Translation Loss:   8.060868 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:09:18,806 [Epoch: 006 Step: 00000873] Batch Translation Loss:   9.409877 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:09:38,665 [Epoch: 006 Step: 00000874] Batch Translation Loss:   8.240528 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:09:57,208 [Epoch: 006 Step: 00000875] Batch Translation Loss:   8.217056 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:10:11,899 [Epoch: 006 Step: 00000876] Batch Translation Loss:  10.025523 => Txt Tokens per Sec:        4 || Lr: 0.001000
2022-01-01 05:10:30,984 [Epoch: 006 Step: 00000877] Batch Translation Loss:   7.022033 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:10:50,482 [Epoch: 006 Step: 00000878] Batch Translation Loss:   7.038407 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:11:07,525 [Epoch: 006 Step: 00000879] Batch Translation Loss:   7.652220 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:11:25,740 [Epoch: 006 Step: 00000880] Batch Translation Loss:   8.045054 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:11:55,612 [Epoch: 006 Step: 00000881] Batch Translation Loss:   8.847923 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:12:23,655 [Epoch: 006 Step: 00000882] Batch Translation Loss:   7.257705 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:12:55,488 [Epoch: 006 Step: 00000883] Batch Translation Loss:   6.781264 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:13:42,102 [Epoch: 006 Step: 00000884] Batch Translation Loss:   7.765784 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:14:39,606 [Epoch: 006 Step: 00000885] Batch Translation Loss:   6.863660 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:15:02,037 [Epoch: 006 Step: 00000886] Batch Translation Loss:   7.464024 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:15:35,044 [Epoch: 006 Step: 00000887] Batch Translation Loss:   7.500666 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:16:09,514 [Epoch: 006 Step: 00000888] Batch Translation Loss:   9.030249 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:16:27,339 [Epoch: 006 Step: 00000889] Batch Translation Loss:   7.749803 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:16:44,846 [Epoch: 006 Step: 00000890] Batch Translation Loss:   8.019117 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:16:59,796 [Epoch: 006 Step: 00000891] Batch Translation Loss:   7.580113 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:17:15,600 [Epoch: 006 Step: 00000892] Batch Translation Loss:   8.148044 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 05:17:34,120 [Epoch: 006 Step: 00000893] Batch Translation Loss:   7.762687 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:18:06,205 [Epoch: 006 Step: 00000894] Batch Translation Loss:   8.849109 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:18:39,767 [Epoch: 006 Step: 00000895] Batch Translation Loss:   7.950216 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:19:20,165 [Epoch: 006 Step: 00000896] Batch Translation Loss:   7.642785 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:19:39,755 [Epoch: 006 Step: 00000897] Batch Translation Loss:   7.640959 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:19:57,820 [Epoch: 006 Step: 00000898] Batch Translation Loss:   7.397015 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:20:16,096 [Epoch: 006 Step: 00000899] Batch Translation Loss:   6.817183 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:20:34,415 [Epoch: 006 Step: 00000900] Batch Translation Loss:   7.250963 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:29:14,167 Hooray! New best validation result [eval_metric]!
2022-01-01 05:29:14,182 Saving new checkpoint.
2022-01-01 05:29:19,262 Validation result at epoch   6, step      900: duration: 524.8213s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 10422.30078	PPL: 4785.83301
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 0.65	(DEL: 21.87,	INS: 0.00,	SUB: 77.48)
	Sequence Accuracy 0.83
2022-01-01 05:29:28,436 Logging Recognition and Translation Outputs
2022-01-01 05:29:28,485 ========================================================================================================================
2022-01-01 05:29:28,486 Logging Sequence: deafvideo_3-geoalpha_4549
2022-01-01 05:29:28,486 	Text Reference  :	or
2022-01-01 05:29:28,487 	Text Hypothesis :	so
2022-01-01 05:29:28,487 	Text Alignment  :	S 
2022-01-01 05:29:28,487 ========================================================================================================================
2022-01-01 05:29:28,487 Logging Sequence: youtube_1-catherine_mackinnon_2806
2022-01-01 05:29:28,488 	Text Reference  :	nbda
2022-01-01 05:29:28,488 	Text Hypothesis :	so  
2022-01-01 05:29:28,488 	Text Alignment  :	S   
2022-01-01 05:29:28,488 ========================================================================================================================
2022-01-01 05:29:28,489 Logging Sequence: deafvideo_3-otismhill82_4611
2022-01-01 05:29:28,489 	Text Reference  :	way
2022-01-01 05:29:28,489 	Text Hypothesis :	so 
2022-01-01 05:29:28,489 	Text Alignment  :	S  
2022-01-01 05:29:28,490 ========================================================================================================================
2022-01-01 05:29:28,490 Logging Sequence: deafvideo_4-tax_tips_by_irs_4959
2022-01-01 05:29:28,490 	Text Reference  :	pcs
2022-01-01 05:29:28,490 	Text Hypothesis :	so 
2022-01-01 05:29:28,491 	Text Alignment  :	S  
2022-01-01 05:29:28,491 ========================================================================================================================
2022-01-01 05:29:28,491 Logging Sequence: youtube_1-catherine_mackinnon_2787
2022-01-01 05:29:28,491 	Text Reference  :	clear
2022-01-01 05:29:28,492 	Text Hypothesis :	asl  
2022-01-01 05:29:28,492 	Text Alignment  :	S    
2022-01-01 05:29:28,492 ========================================================================================================================
2022-01-01 05:30:56,966 [Epoch: 006 Step: 00000901] Batch Translation Loss:   6.660811 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 05:31:42,564 [Epoch: 006 Step: 00000902] Batch Translation Loss:   6.957702 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:32:55,883 [Epoch: 006 Step: 00000903] Batch Translation Loss:   8.052693 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:33:28,089 [Epoch: 006 Step: 00000904] Batch Translation Loss:   7.050097 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:34:12,189 [Epoch: 006 Step: 00000905] Batch Translation Loss:   9.181214 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:34:46,923 [Epoch: 006 Step: 00000906] Batch Translation Loss:   8.201156 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:35:07,806 [Epoch: 006 Step: 00000907] Batch Translation Loss:   8.057294 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:35:28,931 [Epoch: 006 Step: 00000908] Batch Translation Loss:   7.140945 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:36:02,726 [Epoch: 006 Step: 00000909] Batch Translation Loss:   8.209052 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:36:51,999 [Epoch: 006 Step: 00000910] Batch Translation Loss:   6.082263 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:37:38,144 [Epoch: 006 Step: 00000911] Batch Translation Loss:   8.010741 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:38:25,002 [Epoch: 006 Step: 00000912] Batch Translation Loss:   7.574312 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:39:02,407 [Epoch: 006 Step: 00000913] Batch Translation Loss:   6.645727 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:39:30,169 [Epoch: 006 Step: 00000914] Batch Translation Loss:   7.293992 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:39:53,084 [Epoch: 006 Step: 00000915] Batch Translation Loss:   6.433038 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:40:16,007 [Epoch: 006 Step: 00000916] Batch Translation Loss:   7.823324 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:40:38,187 [Epoch: 006 Step: 00000917] Batch Translation Loss:   7.690804 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:41:00,620 [Epoch: 006 Step: 00000918] Batch Translation Loss:   7.244002 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:41:27,970 [Epoch: 006 Step: 00000919] Batch Translation Loss:   6.374289 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:41:53,751 [Epoch: 006 Step: 00000920] Batch Translation Loss:   8.374426 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:42:18,560 [Epoch: 006 Step: 00000921] Batch Translation Loss:   7.233007 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:42:40,672 [Epoch: 006 Step: 00000922] Batch Translation Loss:   7.368373 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:43:02,788 [Epoch: 006 Step: 00000923] Batch Translation Loss:   7.036340 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:43:45,342 [Epoch: 006 Step: 00000924] Batch Translation Loss:   7.254283 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:44:07,812 [Epoch: 006 Step: 00000925] Batch Translation Loss:   6.803003 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:44:39,322 [Epoch: 006 Step: 00000926] Batch Translation Loss:   7.898337 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:45:55,191 [Epoch: 006 Step: 00000927] Batch Translation Loss:   7.180782 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 05:47:27,165 [Epoch: 006 Step: 00000928] Batch Translation Loss:   7.117515 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 05:47:59,513 [Epoch: 006 Step: 00000929] Batch Translation Loss:   8.767067 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:48:46,710 [Epoch: 006 Step: 00000930] Batch Translation Loss:   6.754580 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:49:10,634 [Epoch: 006 Step: 00000931] Batch Translation Loss:   7.419112 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:49:35,955 [Epoch: 006 Step: 00000932] Batch Translation Loss:   6.726420 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:49:59,604 [Epoch: 006 Step: 00000933] Batch Translation Loss:   6.607745 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:50:22,667 [Epoch: 006 Step: 00000934] Batch Translation Loss:   7.597334 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:50:46,974 [Epoch: 006 Step: 00000935] Batch Translation Loss:   7.302459 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:51:13,196 [Epoch: 006 Step: 00000936] Batch Translation Loss:   6.546515 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:51:39,706 [Epoch: 006 Step: 00000937] Batch Translation Loss:   6.588203 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:52:12,052 [Epoch: 006 Step: 00000938] Batch Translation Loss:   8.309711 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:52:42,809 [Epoch: 006 Step: 00000939] Batch Translation Loss:   7.711904 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:53:09,539 [Epoch: 006 Step: 00000940] Batch Translation Loss:   8.182143 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 05:53:54,248 [Epoch: 006 Step: 00000941] Batch Translation Loss:   6.846665 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:55:29,497 [Epoch: 006 Step: 00000942] Batch Translation Loss:   7.951877 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 05:57:05,573 [Epoch: 006 Step: 00000943] Batch Translation Loss:   7.725543 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 05:57:44,036 [Epoch: 006 Step: 00000944] Batch Translation Loss:   6.794371 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:58:10,402 [Epoch: 006 Step: 00000945] Batch Translation Loss:   6.659147 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:58:41,633 [Epoch: 006 Step: 00000946] Batch Translation Loss:   7.543351 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:59:11,008 [Epoch: 006 Step: 00000947] Batch Translation Loss:   7.533329 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 05:59:39,828 [Epoch: 006 Step: 00000948] Batch Translation Loss:   7.184034 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:00:07,688 [Epoch: 006 Step: 00000949] Batch Translation Loss:   7.356972 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:00:34,478 [Epoch: 006 Step: 00000950] Batch Translation Loss:   7.786781 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 06:01:02,905 [Epoch: 006 Step: 00000951] Batch Translation Loss:   7.619632 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:01:28,979 [Epoch: 006 Step: 00000952] Batch Translation Loss:   7.884129 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:02:08,910 [Epoch: 006 Step: 00000953] Batch Translation Loss:   7.831321 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:03:37,601 [Epoch: 006 Step: 00000954] Batch Translation Loss:   7.464680 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 06:05:06,008 [Epoch: 006 Step: 00000955] Batch Translation Loss:   8.835238 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 06:06:12,567 [Epoch: 006 Step: 00000956] Batch Translation Loss:   7.610960 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:06:51,374 [Epoch: 006 Step: 00000957] Batch Translation Loss:   7.232205 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:07:26,235 [Epoch: 006 Step: 00000958] Batch Translation Loss:   6.877739 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:07:57,990 [Epoch: 006 Step: 00000959] Batch Translation Loss:   6.979500 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:08:28,778 [Epoch: 006 Step: 00000960] Batch Translation Loss:   7.285902 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:08:59,124 [Epoch: 006 Step: 00000961] Batch Translation Loss:   6.587893 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:09:29,977 [Epoch: 006 Step: 00000962] Batch Translation Loss:   7.526606 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:10:01,079 [Epoch: 006 Step: 00000963] Batch Translation Loss:   7.974420 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:10:30,526 [Epoch: 006 Step: 00000964] Batch Translation Loss:   7.373870 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:10:59,774 [Epoch: 006 Step: 00000965] Batch Translation Loss:   6.297602 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:11:48,848 [Epoch: 006 Step: 00000966] Batch Translation Loss:   8.024788 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:13:47,430 [Epoch: 006 Step: 00000967] Batch Translation Loss:   7.279233 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 06:15:11,197 [Epoch: 006 Step: 00000968] Batch Translation Loss:   8.720573 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:16:10,439 [Epoch: 006 Step: 00000969] Batch Translation Loss:   7.493482 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:16:46,196 [Epoch: 006 Step: 00000970] Batch Translation Loss:   6.495375 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:17:17,259 [Epoch: 006 Step: 00000971] Batch Translation Loss:   7.455973 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:17:49,377 [Epoch: 006 Step: 00000972] Batch Translation Loss:   6.694615 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:18:22,189 [Epoch: 006 Step: 00000973] Batch Translation Loss:   6.901854 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:18:54,593 [Epoch: 006 Step: 00000974] Batch Translation Loss:   6.915675 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:19:29,044 [Epoch: 006 Step: 00000975] Batch Translation Loss:   7.059130 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:20:14,345 [Epoch: 006 Step: 00000976] Batch Translation Loss:   7.712397 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:22:20,749 [Epoch: 006 Step: 00000977] Batch Translation Loss:   7.456477 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 06:23:53,435 [Epoch: 006 Step: 00000978] Batch Translation Loss:   7.230379 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 06:25:08,686 [Epoch: 006 Step: 00000979] Batch Translation Loss:   5.915974 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 06:26:05,016 [Epoch: 006 Step: 00000980] Batch Translation Loss:   8.610948 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:27:24,849 [Epoch: 006 Step: 00000981] Batch Translation Loss:   8.128667 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:28:04,570 [Epoch: 006 Step: 00000982] Batch Translation Loss:   9.318230 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:28:49,192 [Epoch: 006 Step: 00000983] Batch Translation Loss:   7.472660 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:29:41,566 [Epoch: 006 Step: 00000984] Batch Translation Loss:   6.724623 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:31:49,776 [Epoch: 006 Step: 00000985] Batch Translation Loss:   6.379581 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 06:33:25,511 [Epoch: 006 Step: 00000986] Batch Translation Loss:   7.219011 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 06:34:35,915 [Epoch: 006 Step: 00000987] Batch Translation Loss:   7.181038 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:35:38,348 [Epoch: 006 Step: 00000988] Batch Translation Loss:   7.454607 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:36:35,076 [Epoch: 006 Step: 00000989] Batch Translation Loss:   7.153654 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:38:08,730 [Epoch: 006 Step: 00000990] Batch Translation Loss:   7.469924 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 06:39:08,263 [Epoch: 006 Step: 00000991] Batch Translation Loss:   6.830369 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:41:24,124 [Epoch: 006 Step: 00000992] Batch Translation Loss:   7.635576 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 06:42:58,890 [Epoch: 006 Step: 00000993] Batch Translation Loss:   6.892834 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 06:44:12,150 [Epoch: 006 Step: 00000994] Batch Translation Loss:   8.165451 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:45:04,704 [Epoch: 006 Step: 00000995] Batch Translation Loss:   7.755409 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:45:46,807 [Epoch: 006 Step: 00000996] Batch Translation Loss:   7.109778 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:46:22,794 [Epoch: 006 Step: 00000997] Batch Translation Loss:   7.594804 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:47:06,656 [Epoch: 006 Step: 00000998] Batch Translation Loss:   6.306372 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:47:41,547 [Epoch: 006 Step: 00000999] Batch Translation Loss:   7.660338 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:48:55,772 [Epoch: 006 Step: 00001000] Batch Translation Loss:   7.613110 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 06:57:17,623 Validation result at epoch   6, step     1000: duration: 501.7636s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11091.82520	PPL: 6471.59570
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.58	(DEL: 24.13,	INS: 0.00,	SUB: 74.29)
	Sequence Accuracy 1.46
2022-01-01 06:57:24,879 Logging Recognition and Translation Outputs
2022-01-01 06:57:24,894 ========================================================================================================================
2022-01-01 06:57:24,895 Logging Sequence: youtube_1-don_grushkin_2770
2022-01-01 06:57:24,895 	Text Reference  :	grandchildr grandchildren
2022-01-01 06:57:24,896 	Text Hypothesis :	*********** of           
2022-01-01 06:57:24,896 	Text Alignment  :	D           S            
2022-01-01 06:57:24,896 ========================================================================================================================
2022-01-01 06:57:24,896 Logging Sequence: deafvideo_5-scottnorby_6463
2022-01-01 06:57:24,897 	Text Reference  :	nobel price    
2022-01-01 06:57:24,897 	Text Hypothesis :	***** instument
2022-01-01 06:57:24,897 	Text Alignment  :	D     S        
2022-01-01 06:57:24,897 ========================================================================================================================
2022-01-01 06:57:24,897 Logging Sequence: aslized-suzanne_stecker_0263
2022-01-01 06:57:24,898 	Text Reference  :	civic resistnace
2022-01-01 06:57:24,898 	Text Hypothesis :	***** of        
2022-01-01 06:57:24,898 	Text Alignment  :	D     S         
2022-01-01 06:57:24,898 ========================================================================================================================
2022-01-01 06:57:24,898 Logging Sequence: deafvideo_3-deafgoldenhair_3060
2022-01-01 06:57:24,899 	Text Reference  :	dr kristin mulrooney
2022-01-01 06:57:24,899 	Text Hypothesis :	** ******* of       
2022-01-01 06:57:24,899 	Text Alignment  :	D  D       S        
2022-01-01 06:57:24,900 ========================================================================================================================
2022-01-01 06:57:24,900 Logging Sequence: youtube_1-catherine_mackinnon_2809
2022-01-01 06:57:24,900 	Text Reference  :	date
2022-01-01 06:57:24,900 	Text Hypothesis :	asl 
2022-01-01 06:57:24,900 	Text Alignment  :	S   
2022-01-01 06:57:24,901 ========================================================================================================================
2022-01-01 07:00:25,656 [Epoch: 006 Step: 00001001] Batch Translation Loss:   7.190578 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 07:02:44,478 [Epoch: 006 Step: 00001002] Batch Translation Loss:   6.042521 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 07:04:41,287 [Epoch: 006 Step: 00001003] Batch Translation Loss:   7.661397 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 07:08:10,297 [Epoch: 006 Step: 00001004] Batch Translation Loss:   7.815184 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 07:09:55,227 [Epoch: 006 Step: 00001005] Batch Translation Loss:   7.187820 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 07:10:39,583 [Epoch: 006 Step: 00001006] Batch Translation Loss:   6.639405 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:11:17,861 [Epoch: 006 Step: 00001007] Batch Translation Loss:   6.863780 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:11:54,633 [Epoch: 006 Step: 00001008] Batch Translation Loss:   7.147698 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:12:31,330 [Epoch: 006 Step: 00001009] Batch Translation Loss:   6.443486 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:13:08,365 [Epoch: 006 Step: 00001010] Batch Translation Loss:   7.391894 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:14:11,691 [Epoch: 006 Step: 00001011] Batch Translation Loss:   7.276358 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:17:30,172 [Epoch: 006 Step: 00001012] Batch Translation Loss:   6.702053 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 07:18:46,470 [Epoch: 006 Step: 00001013] Batch Translation Loss:   6.623692 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 07:19:34,368 [Epoch: 006 Step: 00001014] Batch Translation Loss:   6.956572 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:21:03,243 [Epoch: 006 Step: 00001015] Batch Translation Loss:   7.164213 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 07:22:26,269 [Epoch: 006 Step: 00001016] Batch Translation Loss:   7.231352 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 07:23:26,796 [Epoch: 006 Step: 00001017] Batch Translation Loss:   6.918841 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:25:31,039 [Epoch: 006 Step: 00001018] Batch Translation Loss:   7.119472 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 07:27:07,845 [Epoch: 006 Step: 00001019] Batch Translation Loss:   8.507277 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 07:27:08,106 Epoch   6: Total Training Recognition Loss -1.00  Total Training Translation Loss 1293.97 
2022-01-01 07:27:08,106 EPOCH 7
2022-01-01 07:27:22,276 [Epoch: 007 Step: 00001020] Batch Translation Loss:   7.048251 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 07:27:39,098 [Epoch: 007 Step: 00001021] Batch Translation Loss:   7.363613 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:27:58,150 [Epoch: 007 Step: 00001022] Batch Translation Loss:   7.614328 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:28:18,843 [Epoch: 007 Step: 00001023] Batch Translation Loss:   8.264986 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:28:37,225 [Epoch: 007 Step: 00001024] Batch Translation Loss:   7.772577 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:29:16,565 [Epoch: 007 Step: 00001025] Batch Translation Loss:   9.117439 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:29:33,964 [Epoch: 007 Step: 00001026] Batch Translation Loss:   7.108963 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:30:12,185 [Epoch: 007 Step: 00001027] Batch Translation Loss:   8.677274 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:30:32,372 [Epoch: 007 Step: 00001028] Batch Translation Loss:   7.907611 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:31:01,779 [Epoch: 007 Step: 00001029] Batch Translation Loss:   8.303176 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:31:32,719 [Epoch: 007 Step: 00001030] Batch Translation Loss:   8.921841 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:31:51,072 [Epoch: 007 Step: 00001031] Batch Translation Loss:   9.013942 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 07:32:27,336 [Epoch: 007 Step: 00001032] Batch Translation Loss:   8.359039 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:32:54,579 [Epoch: 007 Step: 00001033] Batch Translation Loss:   7.431064 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:33:31,613 [Epoch: 007 Step: 00001034] Batch Translation Loss:   8.277264 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:34:00,689 [Epoch: 007 Step: 00001035] Batch Translation Loss:   6.881164 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:34:29,757 [Epoch: 007 Step: 00001036] Batch Translation Loss:   6.503161 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:34:57,562 [Epoch: 007 Step: 00001037] Batch Translation Loss:   7.928116 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:35:28,269 [Epoch: 007 Step: 00001038] Batch Translation Loss:   7.685605 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:35:52,112 [Epoch: 007 Step: 00001039] Batch Translation Loss:   8.080830 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:36:17,743 [Epoch: 007 Step: 00001040] Batch Translation Loss:   8.053568 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:36:54,430 [Epoch: 007 Step: 00001041] Batch Translation Loss:   8.141708 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:37:24,934 [Epoch: 007 Step: 00001042] Batch Translation Loss:   8.160691 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:37:49,165 [Epoch: 007 Step: 00001043] Batch Translation Loss:   8.371733 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:38:04,962 [Epoch: 007 Step: 00001044] Batch Translation Loss:   7.352861 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:38:32,446 [Epoch: 007 Step: 00001045] Batch Translation Loss:   7.545990 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:38:48,232 [Epoch: 007 Step: 00001046] Batch Translation Loss:   7.187060 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:39:04,282 [Epoch: 007 Step: 00001047] Batch Translation Loss:   7.378472 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:39:19,052 [Epoch: 007 Step: 00001048] Batch Translation Loss:   8.886850 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 07:39:36,617 [Epoch: 007 Step: 00001049] Batch Translation Loss:   9.148100 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 07:39:52,804 [Epoch: 007 Step: 00001050] Batch Translation Loss:   8.088899 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 07:40:09,849 [Epoch: 007 Step: 00001051] Batch Translation Loss:   7.623775 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:40:29,954 [Epoch: 007 Step: 00001052] Batch Translation Loss:   6.311845 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:40:46,777 [Epoch: 007 Step: 00001053] Batch Translation Loss:   8.606315 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 07:41:03,241 [Epoch: 007 Step: 00001054] Batch Translation Loss:   7.713054 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:41:35,734 [Epoch: 007 Step: 00001055] Batch Translation Loss:   7.164899 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:42:17,957 [Epoch: 007 Step: 00001056] Batch Translation Loss:   8.514735 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:43:32,752 [Epoch: 007 Step: 00001057] Batch Translation Loss:   7.463352 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:44:00,265 [Epoch: 007 Step: 00001058] Batch Translation Loss:   7.521952 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:44:31,336 [Epoch: 007 Step: 00001059] Batch Translation Loss:   6.414482 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:44:58,478 [Epoch: 007 Step: 00001060] Batch Translation Loss:   8.465114 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:45:23,055 [Epoch: 007 Step: 00001061] Batch Translation Loss:   7.977298 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:45:58,210 [Epoch: 007 Step: 00001062] Batch Translation Loss:   6.265995 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:46:15,615 [Epoch: 007 Step: 00001063] Batch Translation Loss:   7.020947 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:46:33,914 [Epoch: 007 Step: 00001064] Batch Translation Loss:   7.179174 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:46:50,845 [Epoch: 007 Step: 00001065] Batch Translation Loss:   7.337145 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:47:10,616 [Epoch: 007 Step: 00001066] Batch Translation Loss:   7.631171 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:47:31,667 [Epoch: 007 Step: 00001067] Batch Translation Loss:   7.897269 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:47:49,582 [Epoch: 007 Step: 00001068] Batch Translation Loss:   6.935220 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:48:07,845 [Epoch: 007 Step: 00001069] Batch Translation Loss:   6.529405 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:48:28,720 [Epoch: 007 Step: 00001070] Batch Translation Loss:   8.318157 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:48:46,502 [Epoch: 007 Step: 00001071] Batch Translation Loss:   6.787761 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:49:05,133 [Epoch: 007 Step: 00001072] Batch Translation Loss:   7.238267 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:49:25,536 [Epoch: 007 Step: 00001073] Batch Translation Loss:   6.627234 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:49:44,058 [Epoch: 007 Step: 00001074] Batch Translation Loss:   6.916028 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:50:20,485 [Epoch: 007 Step: 00001075] Batch Translation Loss:   8.070411 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:51:07,384 [Epoch: 007 Step: 00001076] Batch Translation Loss:   8.554319 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:52:47,001 [Epoch: 007 Step: 00001077] Batch Translation Loss:   7.226575 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 07:53:25,983 [Epoch: 007 Step: 00001078] Batch Translation Loss:   7.655671 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:53:47,861 [Epoch: 007 Step: 00001079] Batch Translation Loss:   7.235224 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:54:18,292 [Epoch: 007 Step: 00001080] Batch Translation Loss:   7.456323 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:54:40,832 [Epoch: 007 Step: 00001081] Batch Translation Loss:   7.226943 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:55:00,915 [Epoch: 007 Step: 00001082] Batch Translation Loss:   7.148536 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:55:30,832 [Epoch: 007 Step: 00001083] Batch Translation Loss:   6.923126 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:55:50,404 [Epoch: 007 Step: 00001084] Batch Translation Loss:   7.109602 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:56:11,927 [Epoch: 007 Step: 00001085] Batch Translation Loss:   7.836556 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:56:53,562 [Epoch: 007 Step: 00001086] Batch Translation Loss:   6.775012 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:57:16,971 [Epoch: 007 Step: 00001087] Batch Translation Loss:   6.656160 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:57:37,216 [Epoch: 007 Step: 00001088] Batch Translation Loss:   8.022334 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:57:58,003 [Epoch: 007 Step: 00001089] Batch Translation Loss:   7.154558 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:58:20,106 [Epoch: 007 Step: 00001090] Batch Translation Loss:   7.266368 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 07:58:47,476 [Epoch: 007 Step: 00001091] Batch Translation Loss:   7.555405 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 07:59:15,979 [Epoch: 007 Step: 00001092] Batch Translation Loss:   7.798923 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:00:09,778 [Epoch: 007 Step: 00001093] Batch Translation Loss:   6.606644 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:01:37,459 [Epoch: 007 Step: 00001094] Batch Translation Loss:   6.831464 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 08:02:36,929 [Epoch: 007 Step: 00001095] Batch Translation Loss:   6.770004 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:03:26,040 [Epoch: 007 Step: 00001096] Batch Translation Loss:   6.544606 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:03:57,840 [Epoch: 007 Step: 00001097] Batch Translation Loss:   8.179041 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:04:31,148 [Epoch: 007 Step: 00001098] Batch Translation Loss:   6.980511 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:05:04,882 [Epoch: 007 Step: 00001099] Batch Translation Loss:   7.414274 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:05:36,473 [Epoch: 007 Step: 00001100] Batch Translation Loss:   7.701030 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:13:45,977 Validation result at epoch   7, step     1100: duration: 489.4104s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11761.64844	PPL: 7509.02197
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.21	(DEL: 27.47,	INS: 0.00,	SUB: 71.32)
	Sequence Accuracy 1.15
2022-01-01 08:13:54,847 Logging Recognition and Translation Outputs
2022-01-01 08:13:54,887 ========================================================================================================================
2022-01-01 08:13:54,887 Logging Sequence: youtube_1-don_grushkin_2327
2022-01-01 08:13:54,888 	Text Reference  :	johnson cty tenn
2022-01-01 08:13:54,889 	Text Hypothesis :	******* *** dr  
2022-01-01 08:13:54,889 	Text Alignment  :	D       D   S   
2022-01-01 08:13:54,889 ========================================================================================================================
2022-01-01 08:13:54,889 Logging Sequence: youtube_4-sean_berdy_5741
2022-01-01 08:13:54,890 	Text Reference  :	dfhd dfhd
2022-01-01 08:13:54,890 	Text Hypothesis :	**** ok  
2022-01-01 08:13:54,890 	Text Alignment  :	D    S   
2022-01-01 08:13:54,890 ========================================================================================================================
2022-01-01 08:13:54,890 Logging Sequence: deafvideo_3-geoalpha_4559
2022-01-01 08:13:54,891 	Text Reference  :	savior
2022-01-01 08:13:54,891 	Text Hypothesis :	ok    
2022-01-01 08:13:54,891 	Text Alignment  :	S     
2022-01-01 08:13:54,891 ========================================================================================================================
2022-01-01 08:13:54,891 Logging Sequence: youtube_1-catherine_mackinnon_2808
2022-01-01 08:13:54,892 	Text Reference  :	deanne bray
2022-01-01 08:13:54,892 	Text Hypothesis :	****** asl 
2022-01-01 08:13:54,892 	Text Alignment  :	D      S   
2022-01-01 08:13:54,892 ========================================================================================================================
2022-01-01 08:13:54,892 Logging Sequence: youtube_1-don_grushkin_2314
2022-01-01 08:13:54,893 	Text Reference  :	zack
2022-01-01 08:13:54,893 	Text Hypothesis :	awti
2022-01-01 08:13:54,893 	Text Alignment  :	S   
2022-01-01 08:13:54,893 ========================================================================================================================
2022-01-01 08:15:51,850 [Epoch: 007 Step: 00001101] Batch Translation Loss:   6.864357 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 08:17:19,917 [Epoch: 007 Step: 00001102] Batch Translation Loss:   7.608908 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 08:18:44,847 [Epoch: 007 Step: 00001103] Batch Translation Loss:   7.323028 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 08:19:55,586 [Epoch: 007 Step: 00001104] Batch Translation Loss:   6.426179 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 08:20:44,544 [Epoch: 007 Step: 00001105] Batch Translation Loss:   7.048514 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:21:15,099 [Epoch: 007 Step: 00001106] Batch Translation Loss:   7.405265 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:22:02,057 [Epoch: 007 Step: 00001107] Batch Translation Loss:   7.887610 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:22:43,939 [Epoch: 007 Step: 00001108] Batch Translation Loss:   6.833908 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:23:06,829 [Epoch: 007 Step: 00001109] Batch Translation Loss:   6.851108 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 08:23:35,842 [Epoch: 007 Step: 00001110] Batch Translation Loss:   7.718575 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:24:03,211 [Epoch: 007 Step: 00001111] Batch Translation Loss:   7.648128 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 08:24:30,455 [Epoch: 007 Step: 00001112] Batch Translation Loss:   6.729044 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:25:06,519 [Epoch: 007 Step: 00001113] Batch Translation Loss:   6.053938 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:26:28,045 [Epoch: 007 Step: 00001114] Batch Translation Loss:   6.777669 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 08:27:52,386 [Epoch: 007 Step: 00001115] Batch Translation Loss:   7.671938 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 08:28:47,887 [Epoch: 007 Step: 00001116] Batch Translation Loss:   7.672966 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:29:23,516 [Epoch: 007 Step: 00001117] Batch Translation Loss:   6.563295 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:29:54,935 [Epoch: 007 Step: 00001118] Batch Translation Loss:   6.500972 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:30:22,673 [Epoch: 007 Step: 00001119] Batch Translation Loss:   7.375141 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:30:51,341 [Epoch: 007 Step: 00001120] Batch Translation Loss:   7.740793 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:31:20,752 [Epoch: 007 Step: 00001121] Batch Translation Loss:   7.041393 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:31:51,021 [Epoch: 007 Step: 00001122] Batch Translation Loss:   6.720311 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:32:22,539 [Epoch: 007 Step: 00001123] Batch Translation Loss:   7.694125 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:32:51,130 [Epoch: 007 Step: 00001124] Batch Translation Loss:   7.108244 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:33:24,250 [Epoch: 007 Step: 00001125] Batch Translation Loss:   6.592562 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:33:53,562 [Epoch: 007 Step: 00001126] Batch Translation Loss:   6.354626 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:34:34,642 [Epoch: 007 Step: 00001127] Batch Translation Loss:   7.629633 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:36:19,557 [Epoch: 007 Step: 00001128] Batch Translation Loss:   6.937844 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 08:39:03,626 [Epoch: 007 Step: 00001129] Batch Translation Loss:   8.132783 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 08:40:00,472 [Epoch: 007 Step: 00001130] Batch Translation Loss:   6.842234 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:40:42,667 [Epoch: 007 Step: 00001131] Batch Translation Loss:   6.841599 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:41:14,117 [Epoch: 007 Step: 00001132] Batch Translation Loss:   8.058061 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:41:47,836 [Epoch: 007 Step: 00001133] Batch Translation Loss:   9.852355 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 08:42:19,114 [Epoch: 007 Step: 00001134] Batch Translation Loss:   6.267529 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:42:50,867 [Epoch: 007 Step: 00001135] Batch Translation Loss:   6.344866 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:43:22,086 [Epoch: 007 Step: 00001136] Batch Translation Loss:   6.276258 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:44:33,469 [Epoch: 007 Step: 00001137] Batch Translation Loss:   7.073574 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:46:30,468 [Epoch: 007 Step: 00001138] Batch Translation Loss:   7.387656 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 08:49:23,049 [Epoch: 007 Step: 00001139] Batch Translation Loss:   7.294970 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 08:50:39,284 [Epoch: 007 Step: 00001140] Batch Translation Loss:   7.870855 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:51:29,638 [Epoch: 007 Step: 00001141] Batch Translation Loss:   6.892785 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:52:03,961 [Epoch: 007 Step: 00001142] Batch Translation Loss:   6.983859 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:52:39,712 [Epoch: 007 Step: 00001143] Batch Translation Loss:   6.642325 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:53:17,137 [Epoch: 007 Step: 00001144] Batch Translation Loss:   6.233103 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:53:51,978 [Epoch: 007 Step: 00001145] Batch Translation Loss:   6.542290 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:55:26,403 [Epoch: 007 Step: 00001146] Batch Translation Loss:   6.572115 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 08:56:50,172 [Epoch: 007 Step: 00001147] Batch Translation Loss:   6.757862 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 08:57:58,221 [Epoch: 007 Step: 00001148] Batch Translation Loss:   6.711953 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 08:58:47,429 [Epoch: 007 Step: 00001149] Batch Translation Loss:   7.597149 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 08:59:28,444 [Epoch: 007 Step: 00001150] Batch Translation Loss:   6.808939 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:00:15,593 [Epoch: 007 Step: 00001151] Batch Translation Loss:   7.809333 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:00:54,127 [Epoch: 007 Step: 00001152] Batch Translation Loss:   6.764819 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:01:30,980 [Epoch: 007 Step: 00001153] Batch Translation Loss:   7.257635 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:02:22,333 [Epoch: 007 Step: 00001154] Batch Translation Loss:   7.250491 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:03:10,706 [Epoch: 007 Step: 00001155] Batch Translation Loss:   8.255961 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:04:36,103 [Epoch: 007 Step: 00001156] Batch Translation Loss:   6.324499 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 09:07:03,388 [Epoch: 007 Step: 00001157] Batch Translation Loss:   6.245761 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 09:08:51,247 [Epoch: 007 Step: 00001158] Batch Translation Loss:   7.671813 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 09:10:02,101 [Epoch: 007 Step: 00001159] Batch Translation Loss:   7.088831 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:10:52,371 [Epoch: 007 Step: 00001160] Batch Translation Loss:   7.021802 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:11:35,468 [Epoch: 007 Step: 00001161] Batch Translation Loss:   7.397478 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:12:18,380 [Epoch: 007 Step: 00001162] Batch Translation Loss:   6.888279 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:12:59,877 [Epoch: 007 Step: 00001163] Batch Translation Loss:   7.475883 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:16:35,260 [Epoch: 007 Step: 00001164] Batch Translation Loss:   6.836827 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 09:17:41,921 [Epoch: 007 Step: 00001165] Batch Translation Loss:   7.600027 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:18:32,918 [Epoch: 007 Step: 00001166] Batch Translation Loss:   7.378688 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:19:14,235 [Epoch: 007 Step: 00001167] Batch Translation Loss:   6.685100 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:19:55,325 [Epoch: 007 Step: 00001168] Batch Translation Loss:   6.190502 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:20:36,117 [Epoch: 007 Step: 00001169] Batch Translation Loss:   7.123030 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:21:17,220 [Epoch: 007 Step: 00001170] Batch Translation Loss:   6.206429 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:21:53,754 [Epoch: 007 Step: 00001171] Batch Translation Loss:   7.113081 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:22:56,215 [Epoch: 007 Step: 00001172] Batch Translation Loss:   7.235964 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:25:09,709 [Epoch: 007 Step: 00001173] Batch Translation Loss:   6.343297 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 09:26:43,057 [Epoch: 007 Step: 00001174] Batch Translation Loss:   6.780066 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 09:28:11,035 [Epoch: 007 Step: 00001175] Batch Translation Loss:   6.357245 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 09:29:28,147 [Epoch: 007 Step: 00001176] Batch Translation Loss:   7.777030 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 09:30:16,571 [Epoch: 007 Step: 00001177] Batch Translation Loss:   6.683458 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:30:55,639 [Epoch: 007 Step: 00001178] Batch Translation Loss:   7.396815 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:31:33,120 [Epoch: 007 Step: 00001179] Batch Translation Loss:   6.770175 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:32:49,048 [Epoch: 007 Step: 00001180] Batch Translation Loss:   6.857594 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:34:51,879 [Epoch: 007 Step: 00001181] Batch Translation Loss:   6.822032 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 09:36:14,485 [Epoch: 007 Step: 00001182] Batch Translation Loss:   6.729396 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 09:37:25,573 [Epoch: 007 Step: 00001183] Batch Translation Loss:   7.003663 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:38:09,747 [Epoch: 007 Step: 00001184] Batch Translation Loss:   7.473527 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:38:46,731 [Epoch: 007 Step: 00001185] Batch Translation Loss:   6.949703 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:39:24,277 [Epoch: 007 Step: 00001186] Batch Translation Loss:   6.141362 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:40:34,758 [Epoch: 007 Step: 00001187] Batch Translation Loss:   6.715152 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:43:25,027 [Epoch: 007 Step: 00001188] Batch Translation Loss:   7.042450 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 09:45:24,151 [Epoch: 007 Step: 00001189] Batch Translation Loss:   7.562951 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 09:45:24,368 Epoch   7: Total Training Recognition Loss -1.00  Total Training Translation Loss 1241.73 
2022-01-01 09:45:24,368 EPOCH 8
2022-01-01 09:45:40,599 [Epoch: 008 Step: 00001190] Batch Translation Loss:   7.037240 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 09:45:55,877 [Epoch: 008 Step: 00001191] Batch Translation Loss:   7.472813 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 09:46:11,010 [Epoch: 008 Step: 00001192] Batch Translation Loss:   6.766615 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 09:46:28,910 [Epoch: 008 Step: 00001193] Batch Translation Loss:   7.356578 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 09:47:01,459 [Epoch: 008 Step: 00001194] Batch Translation Loss:   7.295484 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:47:18,634 [Epoch: 008 Step: 00001195] Batch Translation Loss:   7.820417 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 09:47:47,920 [Epoch: 008 Step: 00001196] Batch Translation Loss:   8.316086 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 09:48:22,924 [Epoch: 008 Step: 00001197] Batch Translation Loss:   7.994157 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 09:48:40,433 [Epoch: 008 Step: 00001198] Batch Translation Loss:   7.432231 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 09:49:08,575 [Epoch: 008 Step: 00001199] Batch Translation Loss:   7.974501 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 09:49:21,401 [Epoch: 008 Step: 00001200] Batch Translation Loss:   7.505334 => Txt Tokens per Sec:        4 || Lr: 0.001000
2022-01-01 09:57:19,480 Validation result at epoch   8, step     1200: duration: 478.0225s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11268.72852	PPL: 7443.77539
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 2.53	(DEL: 23.34,	INS: 0.00,	SUB: 74.13)
	Sequence Accuracy 2.06
2022-01-01 09:57:28,621 Logging Recognition and Translation Outputs
2022-01-01 09:57:28,646 ========================================================================================================================
2022-01-01 09:57:28,646 Logging Sequence: youtube_1-catherine_mackinnon_2798
2022-01-01 09:57:28,647 	Text Reference  :	dept
2022-01-01 09:57:28,647 	Text Hypothesis :	or  
2022-01-01 09:57:28,647 	Text Alignment  :	S   
2022-01-01 09:57:28,647 ========================================================================================================================
2022-01-01 09:57:28,647 Logging Sequence: deafvideo_3-otismhill82_4611
2022-01-01 09:57:28,648 	Text Reference  :	tool
2022-01-01 09:57:28,648 	Text Hypothesis :	asl 
2022-01-01 09:57:28,648 	Text Alignment  :	S   
2022-01-01 09:57:28,648 ========================================================================================================================
2022-01-01 09:57:28,649 Logging Sequence: deafvideo_2-sddsimple_1575
2022-01-01 09:57:28,649 	Text Reference  :	ed
2022-01-01 09:57:28,649 	Text Hypothesis :	or
2022-01-01 09:57:28,649 	Text Alignment  :	S 
2022-01-01 09:57:28,650 ========================================================================================================================
2022-01-01 09:57:28,650 Logging Sequence: youtube_1-catherine_mackinnon_2789
2022-01-01 09:57:28,650 	Text Reference  :	aslized
2022-01-01 09:57:28,650 	Text Hypothesis :	or     
2022-01-01 09:57:28,651 	Text Alignment  :	S      
2022-01-01 09:57:28,651 ========================================================================================================================
2022-01-01 09:57:28,651 Logging Sequence: youtube_5-debra_patkin_5794
2022-01-01 09:57:28,651 	Text Reference  :	i dash i 
2022-01-01 09:57:28,652 	Text Hypothesis :	* **** or
2022-01-01 09:57:28,652 	Text Alignment  :	D D    S 
2022-01-01 09:57:28,652 ========================================================================================================================
2022-01-01 09:59:07,798 [Epoch: 008 Step: 00001201] Batch Translation Loss:   7.174776 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 10:00:05,911 [Epoch: 008 Step: 00001202] Batch Translation Loss:   7.006157 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:01:04,701 [Epoch: 008 Step: 00001203] Batch Translation Loss:   6.713392 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:01:27,586 [Epoch: 008 Step: 00001204] Batch Translation Loss:   6.372045 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:02:14,235 [Epoch: 008 Step: 00001205] Batch Translation Loss:   7.739790 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:03:03,368 [Epoch: 008 Step: 00001206] Batch Translation Loss:   6.640886 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:03:17,440 [Epoch: 008 Step: 00001207] Batch Translation Loss:   7.325971 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 10:03:46,901 [Epoch: 008 Step: 00001208] Batch Translation Loss:   6.988065 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:04:02,295 [Epoch: 008 Step: 00001209] Batch Translation Loss:   7.672681 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 10:04:23,043 [Epoch: 008 Step: 00001210] Batch Translation Loss:   7.262698 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:04:36,171 [Epoch: 008 Step: 00001211] Batch Translation Loss:   6.729556 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 10:04:47,413 [Epoch: 008 Step: 00001212] Batch Translation Loss:   6.450809 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 10:05:06,633 [Epoch: 008 Step: 00001213] Batch Translation Loss:   7.544644 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:05:27,065 [Epoch: 008 Step: 00001214] Batch Translation Loss:   6.563055 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:05:42,559 [Epoch: 008 Step: 00001215] Batch Translation Loss:   8.453289 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 10:05:58,745 [Epoch: 008 Step: 00001216] Batch Translation Loss:   7.656271 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 10:06:29,080 [Epoch: 008 Step: 00001217] Batch Translation Loss:   7.496807 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:06:42,892 [Epoch: 008 Step: 00001218] Batch Translation Loss:   7.789475 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 10:06:59,816 [Epoch: 008 Step: 00001219] Batch Translation Loss:   6.836026 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:07:13,417 [Epoch: 008 Step: 00001220] Batch Translation Loss:   7.491890 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 10:07:30,314 [Epoch: 008 Step: 00001221] Batch Translation Loss:   7.895244 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:07:55,297 [Epoch: 008 Step: 00001222] Batch Translation Loss:   7.361856 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:09:08,718 [Epoch: 008 Step: 00001223] Batch Translation Loss:   8.586394 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:09:39,801 [Epoch: 008 Step: 00001224] Batch Translation Loss:   6.319460 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:10:12,568 [Epoch: 008 Step: 00001225] Batch Translation Loss:   7.254853 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:10:39,370 [Epoch: 008 Step: 00001226] Batch Translation Loss:   6.775134 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:11:02,110 [Epoch: 008 Step: 00001227] Batch Translation Loss:   7.548341 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:11:41,173 [Epoch: 008 Step: 00001228] Batch Translation Loss:   7.776957 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:12:11,862 [Epoch: 008 Step: 00001229] Batch Translation Loss:   7.151589 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:12:32,633 [Epoch: 008 Step: 00001230] Batch Translation Loss:   6.586802 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:13:02,915 [Epoch: 008 Step: 00001231] Batch Translation Loss:   7.802462 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:13:29,027 [Epoch: 008 Step: 00001232] Batch Translation Loss:   5.932180 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:13:44,726 [Epoch: 008 Step: 00001233] Batch Translation Loss:   6.646808 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:14:17,684 [Epoch: 008 Step: 00001234] Batch Translation Loss:   6.823872 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:14:34,184 [Epoch: 008 Step: 00001235] Batch Translation Loss:   7.483868 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 10:14:52,896 [Epoch: 008 Step: 00001236] Batch Translation Loss:   7.133161 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:15:14,294 [Epoch: 008 Step: 00001237] Batch Translation Loss:   6.673263 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:15:32,227 [Epoch: 008 Step: 00001238] Batch Translation Loss:   6.105240 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:16:03,744 [Epoch: 008 Step: 00001239] Batch Translation Loss:   7.695126 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:16:24,946 [Epoch: 008 Step: 00001240] Batch Translation Loss:   7.387253 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:16:49,506 [Epoch: 008 Step: 00001241] Batch Translation Loss:   6.441462 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:17:28,786 [Epoch: 008 Step: 00001242] Batch Translation Loss:   5.549273 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:18:29,008 [Epoch: 008 Step: 00001243] Batch Translation Loss:   6.893487 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:19:09,962 [Epoch: 008 Step: 00001244] Batch Translation Loss:   6.732171 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:19:44,682 [Epoch: 008 Step: 00001245] Batch Translation Loss:   6.217085 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:20:15,106 [Epoch: 008 Step: 00001246] Batch Translation Loss:   7.560509 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:20:36,811 [Epoch: 008 Step: 00001247] Batch Translation Loss:   6.711508 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:21:00,741 [Epoch: 008 Step: 00001248] Batch Translation Loss:   7.118951 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:21:20,990 [Epoch: 008 Step: 00001249] Batch Translation Loss:   7.835373 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:21:44,746 [Epoch: 008 Step: 00001250] Batch Translation Loss:   7.193951 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:22:11,596 [Epoch: 008 Step: 00001251] Batch Translation Loss:   7.198366 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:22:32,328 [Epoch: 008 Step: 00001252] Batch Translation Loss:   6.678901 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:22:54,287 [Epoch: 008 Step: 00001253] Batch Translation Loss:   8.052998 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:23:31,021 [Epoch: 008 Step: 00001254] Batch Translation Loss:   7.197019 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:23:50,112 [Epoch: 008 Step: 00001255] Batch Translation Loss:   7.576040 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:24:12,280 [Epoch: 008 Step: 00001256] Batch Translation Loss:   7.122171 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:24:33,099 [Epoch: 008 Step: 00001257] Batch Translation Loss:   7.733388 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:24:56,392 [Epoch: 008 Step: 00001258] Batch Translation Loss:   7.387608 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:25:18,015 [Epoch: 008 Step: 00001259] Batch Translation Loss:   6.921353 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:25:41,512 [Epoch: 008 Step: 00001260] Batch Translation Loss:   6.994006 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:26:04,793 [Epoch: 008 Step: 00001261] Batch Translation Loss:   8.337337 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:26:33,448 [Epoch: 008 Step: 00001262] Batch Translation Loss:   6.399199 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:27:19,400 [Epoch: 008 Step: 00001263] Batch Translation Loss:   6.795761 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:28:31,525 [Epoch: 008 Step: 00001264] Batch Translation Loss:   6.238556 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:29:22,181 [Epoch: 008 Step: 00001265] Batch Translation Loss:   7.133694 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:29:59,713 [Epoch: 008 Step: 00001266] Batch Translation Loss:   7.024039 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:30:30,185 [Epoch: 008 Step: 00001267] Batch Translation Loss:   7.531778 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:30:54,237 [Epoch: 008 Step: 00001268] Batch Translation Loss:   6.888146 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:31:23,785 [Epoch: 008 Step: 00001269] Batch Translation Loss:   6.549350 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:31:48,219 [Epoch: 008 Step: 00001270] Batch Translation Loss:   7.131635 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:32:14,140 [Epoch: 008 Step: 00001271] Batch Translation Loss:   7.060033 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:32:40,489 [Epoch: 008 Step: 00001272] Batch Translation Loss:   6.260700 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:33:27,188 [Epoch: 008 Step: 00001273] Batch Translation Loss:   7.165470 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:33:50,959 [Epoch: 008 Step: 00001274] Batch Translation Loss:   6.404819 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:34:35,787 [Epoch: 008 Step: 00001275] Batch Translation Loss:   6.850440 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:35:00,767 [Epoch: 008 Step: 00001276] Batch Translation Loss:   7.042836 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:35:25,683 [Epoch: 008 Step: 00001277] Batch Translation Loss:   6.097471 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:35:51,938 [Epoch: 008 Step: 00001278] Batch Translation Loss:   6.356493 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:36:25,683 [Epoch: 008 Step: 00001279] Batch Translation Loss:   6.358713 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:37:49,603 [Epoch: 008 Step: 00001280] Batch Translation Loss:   6.585694 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 10:38:48,753 [Epoch: 008 Step: 00001281] Batch Translation Loss:   7.279716 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:39:36,014 [Epoch: 008 Step: 00001282] Batch Translation Loss:   7.208812 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:40:03,306 [Epoch: 008 Step: 00001283] Batch Translation Loss:   7.305273 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:40:35,737 [Epoch: 008 Step: 00001284] Batch Translation Loss:   7.739803 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:41:22,820 [Epoch: 008 Step: 00001285] Batch Translation Loss:   6.605241 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:41:54,304 [Epoch: 008 Step: 00001286] Batch Translation Loss:   6.687104 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:42:20,473 [Epoch: 008 Step: 00001287] Batch Translation Loss:   7.502993 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:42:46,744 [Epoch: 008 Step: 00001288] Batch Translation Loss:   6.501661 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 10:43:14,256 [Epoch: 008 Step: 00001289] Batch Translation Loss:   6.231254 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:43:43,401 [Epoch: 008 Step: 00001290] Batch Translation Loss:   7.020923 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:44:11,861 [Epoch: 008 Step: 00001291] Batch Translation Loss:   6.991940 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:44:40,348 [Epoch: 008 Step: 00001292] Batch Translation Loss:   6.501516 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:45:09,873 [Epoch: 008 Step: 00001293] Batch Translation Loss:   7.045917 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:45:38,149 [Epoch: 008 Step: 00001294] Batch Translation Loss:   6.928425 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:46:13,713 [Epoch: 008 Step: 00001295] Batch Translation Loss:   6.705827 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:48:48,747 [Epoch: 008 Step: 00001296] Batch Translation Loss:   6.789846 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 10:49:37,859 [Epoch: 008 Step: 00001297] Batch Translation Loss:   6.870814 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:50:21,905 [Epoch: 008 Step: 00001298] Batch Translation Loss:   6.798813 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:50:56,478 [Epoch: 008 Step: 00001299] Batch Translation Loss:   7.573035 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:51:23,799 [Epoch: 008 Step: 00001300] Batch Translation Loss:   6.939097 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 10:59:37,085 Validation result at epoch   8, step     1300: duration: 493.2604s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 10689.44531	PPL: 5622.02441
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 2.67	(DEL: 22.54,	INS: 0.00,	SUB: 74.80)
	Sequence Accuracy 2.82
2022-01-01 10:59:44,807 Logging Recognition and Translation Outputs
2022-01-01 10:59:44,837 ========================================================================================================================
2022-01-01 10:59:44,837 Logging Sequence: youtube_1-catherine_mackinnon_2823
2022-01-01 10:59:44,837 	Text Reference  :	nad
2022-01-01 10:59:44,838 	Text Hypothesis :	asl
2022-01-01 10:59:44,838 	Text Alignment  :	S  
2022-01-01 10:59:44,838 ========================================================================================================================
2022-01-01 10:59:44,838 Logging Sequence: youtube_1-catherine_mackinnon_2834
2022-01-01 10:59:44,838 	Text Reference  :	lexi merin
2022-01-01 10:59:44,838 	Text Hypothesis :	**** asl  
2022-01-01 10:59:44,838 	Text Alignment  :	D    S    
2022-01-01 10:59:44,838 ========================================================================================================================
2022-01-01 10:59:44,838 Logging Sequence: youtube_1-melvin_patterson_2358
2022-01-01 10:59:44,838 	Text Reference  :	melvin paterson
2022-01-01 10:59:44,839 	Text Hypothesis :	****** asl     
2022-01-01 10:59:44,839 	Text Alignment  :	D      S       
2022-01-01 10:59:44,839 ========================================================================================================================
2022-01-01 10:59:44,839 Logging Sequence: youtube_6-myles_de_bastion_6521
2022-01-01 10:59:44,839 	Text Reference  :	tool
2022-01-01 10:59:44,839 	Text Hypothesis :	asl 
2022-01-01 10:59:44,839 	Text Alignment  :	S   
2022-01-01 10:59:44,839 ========================================================================================================================
2022-01-01 10:59:44,839 Logging Sequence: deafvideo_2-fairytales9_2295
2022-01-01 10:59:44,839 	Text Reference  :	go sem
2022-01-01 10:59:44,839 	Text Hypothesis :	** asl
2022-01-01 10:59:44,839 	Text Alignment  :	D  S  
2022-01-01 10:59:44,840 ========================================================================================================================
2022-01-01 11:02:07,777 [Epoch: 008 Step: 00001301] Batch Translation Loss:   7.062830 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 11:03:41,088 [Epoch: 008 Step: 00001302] Batch Translation Loss:   7.604534 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 11:05:39,116 [Epoch: 008 Step: 00001303] Batch Translation Loss:   7.952441 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 11:07:07,656 [Epoch: 008 Step: 00001304] Batch Translation Loss:   6.452514 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 11:08:23,396 [Epoch: 008 Step: 00001305] Batch Translation Loss:   7.253046 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 11:09:24,576 [Epoch: 008 Step: 00001306] Batch Translation Loss:   6.970492 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 11:10:19,394 [Epoch: 008 Step: 00001307] Batch Translation Loss:   6.462972 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 11:10:57,443 [Epoch: 008 Step: 00001308] Batch Translation Loss:   6.920246 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 11:11:41,671 [Epoch: 008 Step: 00001309] Batch Translation Loss:   6.376523 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 11:12:35,589 [Epoch: 008 Step: 00001310] Batch Translation Loss:   6.609066 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 11:13:08,040 [Epoch: 008 Step: 00001311] Batch Translation Loss:   6.235136 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 11:13:45,142 [Epoch: 008 Step: 00001312] Batch Translation Loss:   6.198551 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 11:14:31,636 [Epoch: 008 Step: 00001313] Batch Translation Loss:   7.298151 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 11:15:26,971 [Epoch: 008 Step: 00001314] Batch Translation Loss:   7.011896 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 11:17:38,613 [Epoch: 008 Step: 00001315] Batch Translation Loss:   6.095850 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 11:19:21,520 [Epoch: 008 Step: 00001316] Batch Translation Loss:   8.341808 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 11:20:49,359 [Epoch: 008 Step: 00001317] Batch Translation Loss:   7.347808 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 11:22:05,504 [Epoch: 008 Step: 00001318] Batch Translation Loss:   6.691294 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 11:23:45,877 [Epoch: 008 Step: 00001319] Batch Translation Loss:   6.610879 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 11:25:18,083 [Epoch: 008 Step: 00001320] Batch Translation Loss:   6.308065 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 11:27:37,411 [Epoch: 008 Step: 00001321] Batch Translation Loss:   6.618385 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 11:29:27,829 [Epoch: 008 Step: 00001322] Batch Translation Loss:   6.870913 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 11:30:58,978 [Epoch: 008 Step: 00001323] Batch Translation Loss:   6.757572 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 11:32:08,437 [Epoch: 008 Step: 00001324] Batch Translation Loss:   7.200988 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 11:32:59,064 [Epoch: 008 Step: 00001325] Batch Translation Loss:   6.799780 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 11:33:44,001 [Epoch: 008 Step: 00001326] Batch Translation Loss:   7.282326 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 11:34:47,330 [Epoch: 008 Step: 00001327] Batch Translation Loss:   7.314631 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 11:36:06,141 [Epoch: 008 Step: 00001328] Batch Translation Loss:   6.717185 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 11:38:29,696 [Epoch: 008 Step: 00001329] Batch Translation Loss:   6.818343 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 11:40:12,668 [Epoch: 008 Step: 00001330] Batch Translation Loss:   7.133509 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 11:41:40,177 [Epoch: 008 Step: 00001331] Batch Translation Loss:   6.929080 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 11:42:41,718 [Epoch: 008 Step: 00001332] Batch Translation Loss:   6.587969 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 11:43:25,352 [Epoch: 008 Step: 00001333] Batch Translation Loss:   6.455095 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 11:44:04,724 [Epoch: 008 Step: 00001334] Batch Translation Loss:   7.223635 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 11:46:05,942 [Epoch: 008 Step: 00001335] Batch Translation Loss:   6.115631 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 11:48:24,816 [Epoch: 008 Step: 00001336] Batch Translation Loss:   6.985975 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 11:50:10,948 [Epoch: 008 Step: 00001337] Batch Translation Loss:   7.050046 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 11:51:18,048 [Epoch: 008 Step: 00001338] Batch Translation Loss:   6.916579 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 11:52:22,502 [Epoch: 008 Step: 00001339] Batch Translation Loss:   6.593519 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 11:53:50,105 [Epoch: 008 Step: 00001340] Batch Translation Loss:   7.098750 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 11:54:37,749 [Epoch: 008 Step: 00001341] Batch Translation Loss:   6.783504 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 11:55:24,515 [Epoch: 008 Step: 00001342] Batch Translation Loss:   7.055783 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 11:56:27,197 [Epoch: 008 Step: 00001343] Batch Translation Loss:   6.803389 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 11:59:12,150 [Epoch: 008 Step: 00001344] Batch Translation Loss:   6.458412 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 12:01:13,547 [Epoch: 008 Step: 00001345] Batch Translation Loss:   6.559978 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 12:02:31,766 [Epoch: 008 Step: 00001346] Batch Translation Loss:   6.881772 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 12:03:26,343 [Epoch: 008 Step: 00001347] Batch Translation Loss:   7.378611 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:04:10,784 [Epoch: 008 Step: 00001348] Batch Translation Loss:   6.887232 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:05:05,296 [Epoch: 008 Step: 00001349] Batch Translation Loss:   6.506725 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:06:04,133 [Epoch: 008 Step: 00001350] Batch Translation Loss:   7.895529 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:10:17,444 [Epoch: 008 Step: 00001351] Batch Translation Loss:   7.145602 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 12:12:10,715 [Epoch: 008 Step: 00001352] Batch Translation Loss:   6.709806 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 12:14:43,489 [Epoch: 008 Step: 00001353] Batch Translation Loss:   7.396792 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 12:15:22,434 [Epoch: 008 Step: 00001354] Batch Translation Loss:   5.873166 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:16:01,095 [Epoch: 008 Step: 00001355] Batch Translation Loss:   6.601357 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:17:11,747 [Epoch: 008 Step: 00001356] Batch Translation Loss:   7.555109 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:18:37,365 [Epoch: 008 Step: 00001357] Batch Translation Loss:   6.716549 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 12:20:50,266 [Epoch: 008 Step: 00001358] Batch Translation Loss:   7.581882 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 12:23:14,911 [Epoch: 008 Step: 00001359] Batch Translation Loss:   6.594354 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 12:23:15,088 Epoch   8: Total Training Recognition Loss -1.00  Total Training Translation Loss 1193.03 
2022-01-01 12:23:15,088 EPOCH 9
2022-01-01 12:23:37,331 [Epoch: 009 Step: 00001360] Batch Translation Loss:   6.433348 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 12:23:54,964 [Epoch: 009 Step: 00001361] Batch Translation Loss:   7.131919 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 12:24:12,652 [Epoch: 009 Step: 00001362] Batch Translation Loss:   7.443397 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 12:24:28,924 [Epoch: 009 Step: 00001363] Batch Translation Loss:   7.286568 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 12:25:02,412 [Epoch: 009 Step: 00001364] Batch Translation Loss:   7.657222 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:25:39,445 [Epoch: 009 Step: 00001365] Batch Translation Loss:   7.102054 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:26:03,465 [Epoch: 009 Step: 00001366] Batch Translation Loss:   7.041691 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 12:26:22,108 [Epoch: 009 Step: 00001367] Batch Translation Loss:   7.108086 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 12:26:41,221 [Epoch: 009 Step: 00001368] Batch Translation Loss:   7.602304 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 12:26:59,883 [Epoch: 009 Step: 00001369] Batch Translation Loss:   6.790305 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 12:27:17,976 [Epoch: 009 Step: 00001370] Batch Translation Loss:   7.464216 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 12:27:37,328 [Epoch: 009 Step: 00001371] Batch Translation Loss:   7.325305 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 12:28:22,186 [Epoch: 009 Step: 00001372] Batch Translation Loss:   6.496960 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:28:53,582 [Epoch: 009 Step: 00001373] Batch Translation Loss:   6.315309 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:29:23,815 [Epoch: 009 Step: 00001374] Batch Translation Loss:   7.348696 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 12:29:46,811 [Epoch: 009 Step: 00001375] Batch Translation Loss:   6.716884 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 12:30:08,234 [Epoch: 009 Step: 00001376] Batch Translation Loss:   7.058416 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 12:30:33,766 [Epoch: 009 Step: 00001377] Batch Translation Loss:   7.602226 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 12:31:13,602 [Epoch: 009 Step: 00001378] Batch Translation Loss:   7.806565 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:31:32,770 [Epoch: 009 Step: 00001379] Batch Translation Loss:   6.965204 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 12:31:52,540 [Epoch: 009 Step: 00001380] Batch Translation Loss:   6.197048 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 12:32:13,278 [Epoch: 009 Step: 00001381] Batch Translation Loss:   7.791105 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 12:32:34,009 [Epoch: 009 Step: 00001382] Batch Translation Loss:   7.173429 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 12:32:49,054 [Epoch: 009 Step: 00001383] Batch Translation Loss:   6.423981 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 12:33:28,735 [Epoch: 009 Step: 00001384] Batch Translation Loss:   6.880481 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:33:58,706 [Epoch: 009 Step: 00001385] Batch Translation Loss:   6.667972 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 12:34:12,960 [Epoch: 009 Step: 00001386] Batch Translation Loss:   6.560237 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 12:34:35,357 [Epoch: 009 Step: 00001387] Batch Translation Loss:   7.602546 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 12:34:55,230 [Epoch: 009 Step: 00001388] Batch Translation Loss:   6.928639 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 12:35:23,408 [Epoch: 009 Step: 00001389] Batch Translation Loss:   6.748960 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:35:44,048 [Epoch: 009 Step: 00001390] Batch Translation Loss:   6.420636 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 12:36:00,508 [Epoch: 009 Step: 00001391] Batch Translation Loss:   6.539010 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 12:36:16,837 [Epoch: 009 Step: 00001392] Batch Translation Loss:   7.551027 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 12:36:30,545 [Epoch: 009 Step: 00001393] Batch Translation Loss:   6.783700 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 12:36:56,027 [Epoch: 009 Step: 00001394] Batch Translation Loss:   7.844668 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 12:37:17,060 [Epoch: 009 Step: 00001395] Batch Translation Loss:   6.830041 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 12:37:41,612 [Epoch: 009 Step: 00001396] Batch Translation Loss:   6.489703 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:38:28,099 [Epoch: 009 Step: 00001397] Batch Translation Loss:   6.884928 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:39:07,182 [Epoch: 009 Step: 00001398] Batch Translation Loss:   7.002036 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:39:38,919 [Epoch: 009 Step: 00001399] Batch Translation Loss:   6.495442 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:40:33,941 [Epoch: 009 Step: 00001400] Batch Translation Loss:   7.406811 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:48:03,548 Validation result at epoch   9, step     1400: duration: 449.5652s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 10847.05078	PPL: 7058.37402
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 2.86	(DEL: 21.00,	INS: 0.00,	SUB: 76.14)
	Sequence Accuracy 2.38
2022-01-01 12:48:11,256 Logging Recognition and Translation Outputs
2022-01-01 12:48:11,272 ========================================================================================================================
2022-01-01 12:48:11,272 Logging Sequence: deafvideo_3-yesyes_4478
2022-01-01 12:48:11,272 	Text Reference  :	hpaleo herew
2022-01-01 12:48:11,272 	Text Hypothesis :	****** dr   
2022-01-01 12:48:11,273 	Text Alignment  :	D      S    
2022-01-01 12:48:11,273 ========================================================================================================================
2022-01-01 12:48:11,273 Logging Sequence: youtube_1-don_grushkin_2330
2022-01-01 12:48:11,273 	Text Reference  :	ok it 
2022-01-01 12:48:11,273 	Text Hypothesis :	** asl
2022-01-01 12:48:11,273 	Text Alignment  :	D  S  
2022-01-01 12:48:11,273 ========================================================================================================================
2022-01-01 12:48:11,273 Logging Sequence: deafvideo_2-goatman_1533
2022-01-01 12:48:11,273 	Text Reference  :	arphangelsk
2022-01-01 12:48:11,274 	Text Hypothesis :	asl        
2022-01-01 12:48:11,274 	Text Alignment  :	S          
2022-01-01 12:48:11,274 ========================================================================================================================
2022-01-01 12:48:11,274 Logging Sequence: aslized-suzanne_stecker_0201
2022-01-01 12:48:11,274 	Text Reference  :	feb
2022-01-01 12:48:11,274 	Text Hypothesis :	or 
2022-01-01 12:48:11,274 	Text Alignment  :	S  
2022-01-01 12:48:11,274 ========================================================================================================================
2022-01-01 12:48:11,274 Logging Sequence: deafvideo_3-deafgoldenhair_3079
2022-01-01 12:48:11,274 	Text Reference  :	it
2022-01-01 12:48:11,274 	Text Hypothesis :	or
2022-01-01 12:48:11,275 	Text Alignment  :	S 
2022-01-01 12:48:11,275 ========================================================================================================================
2022-01-01 12:49:34,719 [Epoch: 009 Step: 00001401] Batch Translation Loss:   6.869293 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 12:50:32,283 [Epoch: 009 Step: 00001402] Batch Translation Loss:   5.711734 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:51:18,700 [Epoch: 009 Step: 00001403] Batch Translation Loss:   6.827745 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:51:54,236 [Epoch: 009 Step: 00001404] Batch Translation Loss:   5.749436 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:52:27,825 [Epoch: 009 Step: 00001405] Batch Translation Loss:   6.538577 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:52:56,390 [Epoch: 009 Step: 00001406] Batch Translation Loss:   7.404347 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:53:33,426 [Epoch: 009 Step: 00001407] Batch Translation Loss:   6.861980 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:54:01,124 [Epoch: 009 Step: 00001408] Batch Translation Loss:   5.987790 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:54:34,416 [Epoch: 009 Step: 00001409] Batch Translation Loss:   6.975513 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:54:55,797 [Epoch: 009 Step: 00001410] Batch Translation Loss:   6.475567 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 12:55:21,526 [Epoch: 009 Step: 00001411] Batch Translation Loss:   6.655725 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:55:47,595 [Epoch: 009 Step: 00001412] Batch Translation Loss:   7.125047 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 12:56:21,268 [Epoch: 009 Step: 00001413] Batch Translation Loss:   6.691153 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:57:21,277 [Epoch: 009 Step: 00001414] Batch Translation Loss:   6.686398 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:58:04,869 [Epoch: 009 Step: 00001415] Batch Translation Loss:   6.986932 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:58:46,664 [Epoch: 009 Step: 00001416] Batch Translation Loss:   7.441510 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:59:31,899 [Epoch: 009 Step: 00001417] Batch Translation Loss:   6.294080 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 12:59:58,844 [Epoch: 009 Step: 00001418] Batch Translation Loss:   6.926014 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:00:17,796 [Epoch: 009 Step: 00001419] Batch Translation Loss:   6.507937 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 13:00:37,327 [Epoch: 009 Step: 00001420] Batch Translation Loss:   6.961335 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 13:01:09,041 [Epoch: 009 Step: 00001421] Batch Translation Loss:   6.480955 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:01:28,988 [Epoch: 009 Step: 00001422] Batch Translation Loss:   6.319485 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 13:01:50,084 [Epoch: 009 Step: 00001423] Batch Translation Loss:   7.058794 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 13:02:13,810 [Epoch: 009 Step: 00001424] Batch Translation Loss:   6.877208 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 13:02:37,192 [Epoch: 009 Step: 00001425] Batch Translation Loss:   6.400432 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:02:59,480 [Epoch: 009 Step: 00001426] Batch Translation Loss:   7.423677 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 13:03:17,818 [Epoch: 009 Step: 00001427] Batch Translation Loss:   6.148435 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 13:04:00,842 [Epoch: 009 Step: 00001428] Batch Translation Loss:   7.695075 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:04:26,699 [Epoch: 009 Step: 00001429] Batch Translation Loss:   7.171664 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:04:56,832 [Epoch: 009 Step: 00001430] Batch Translation Loss:   7.980324 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:05:29,060 [Epoch: 009 Step: 00001431] Batch Translation Loss:   6.979737 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:06:51,453 [Epoch: 009 Step: 00001432] Batch Translation Loss:   6.482470 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 13:07:56,017 [Epoch: 009 Step: 00001433] Batch Translation Loss:   6.965922 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:08:43,027 [Epoch: 009 Step: 00001434] Batch Translation Loss:   6.788290 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:09:20,683 [Epoch: 009 Step: 00001435] Batch Translation Loss:   6.400274 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:09:48,851 [Epoch: 009 Step: 00001436] Batch Translation Loss:   7.585556 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:10:28,293 [Epoch: 009 Step: 00001437] Batch Translation Loss:   6.204966 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:11:00,676 [Epoch: 009 Step: 00001438] Batch Translation Loss:   7.330213 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:11:39,497 [Epoch: 009 Step: 00001439] Batch Translation Loss:   5.913889 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:12:03,747 [Epoch: 009 Step: 00001440] Batch Translation Loss:   6.362412 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 13:12:25,944 [Epoch: 009 Step: 00001441] Batch Translation Loss:   6.837285 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 13:12:51,221 [Epoch: 009 Step: 00001442] Batch Translation Loss:   6.878012 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 13:13:17,049 [Epoch: 009 Step: 00001443] Batch Translation Loss:   6.946103 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 13:14:10,026 [Epoch: 009 Step: 00001444] Batch Translation Loss:   7.569314 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:14:34,263 [Epoch: 009 Step: 00001445] Batch Translation Loss:   6.128923 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 13:15:06,676 [Epoch: 009 Step: 00001446] Batch Translation Loss:   6.977620 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:16:10,897 [Epoch: 009 Step: 00001447] Batch Translation Loss:   6.785322 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:16:58,932 [Epoch: 009 Step: 00001448] Batch Translation Loss:   6.621035 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:18:24,562 [Epoch: 009 Step: 00001449] Batch Translation Loss:   7.167212 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 13:19:18,271 [Epoch: 009 Step: 00001450] Batch Translation Loss:   7.356170 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:19:55,061 [Epoch: 009 Step: 00001451] Batch Translation Loss:   7.467886 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:20:51,955 [Epoch: 009 Step: 00001452] Batch Translation Loss:   7.073164 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:21:21,927 [Epoch: 009 Step: 00001453] Batch Translation Loss:   6.808649 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:21:48,425 [Epoch: 009 Step: 00001454] Batch Translation Loss:   6.729463 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:22:34,896 [Epoch: 009 Step: 00001455] Batch Translation Loss:   7.031740 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:23:17,780 [Epoch: 009 Step: 00001456] Batch Translation Loss:   7.154877 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:24:46,854 [Epoch: 009 Step: 00001457] Batch Translation Loss:   6.595014 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 13:25:52,763 [Epoch: 009 Step: 00001458] Batch Translation Loss:   6.382100 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:26:51,687 [Epoch: 009 Step: 00001459] Batch Translation Loss:   6.456084 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:30:03,430 [Epoch: 009 Step: 00001460] Batch Translation Loss:   6.552469 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 13:31:30,347 [Epoch: 009 Step: 00001461] Batch Translation Loss:   6.890762 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 13:32:36,437 [Epoch: 009 Step: 00001462] Batch Translation Loss:   7.123497 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:33:43,204 [Epoch: 009 Step: 00001463] Batch Translation Loss:   6.639739 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 13:34:35,492 [Epoch: 009 Step: 00001464] Batch Translation Loss:   6.216135 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:35:08,505 [Epoch: 009 Step: 00001465] Batch Translation Loss:   7.229864 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:35:40,449 [Epoch: 009 Step: 00001466] Batch Translation Loss:   6.942204 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:36:11,424 [Epoch: 009 Step: 00001467] Batch Translation Loss:   6.083906 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:37:05,003 [Epoch: 009 Step: 00001468] Batch Translation Loss:   6.258491 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:37:57,329 [Epoch: 009 Step: 00001469] Batch Translation Loss:   6.726252 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:38:39,627 [Epoch: 009 Step: 00001470] Batch Translation Loss:   6.398911 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:40:20,665 [Epoch: 009 Step: 00001471] Batch Translation Loss:   6.473125 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 13:41:50,112 [Epoch: 009 Step: 00001472] Batch Translation Loss:   7.644063 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 13:43:04,241 [Epoch: 009 Step: 00001473] Batch Translation Loss:   6.526641 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 13:44:15,413 [Epoch: 009 Step: 00001474] Batch Translation Loss:   6.690788 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:45:09,088 [Epoch: 009 Step: 00001475] Batch Translation Loss:   6.250858 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:45:55,672 [Epoch: 009 Step: 00001476] Batch Translation Loss:   6.250917 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:46:39,978 [Epoch: 009 Step: 00001477] Batch Translation Loss:   7.102697 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:47:18,531 [Epoch: 009 Step: 00001478] Batch Translation Loss:   6.416107 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:47:52,402 [Epoch: 009 Step: 00001479] Batch Translation Loss:   6.682767 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:48:28,479 [Epoch: 009 Step: 00001480] Batch Translation Loss:   6.745456 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:49:04,952 [Epoch: 009 Step: 00001481] Batch Translation Loss:   6.947361 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:52:28,825 [Epoch: 009 Step: 00001482] Batch Translation Loss:   6.827347 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 13:54:04,015 [Epoch: 009 Step: 00001483] Batch Translation Loss:   6.642211 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 13:55:19,580 [Epoch: 009 Step: 00001484] Batch Translation Loss:   6.909186 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:56:32,933 [Epoch: 009 Step: 00001485] Batch Translation Loss:   6.894267 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 13:57:54,102 [Epoch: 009 Step: 00001486] Batch Translation Loss:   6.314159 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 13:59:33,242 [Epoch: 009 Step: 00001487] Batch Translation Loss:   6.400520 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 14:01:26,953 [Epoch: 009 Step: 00001488] Batch Translation Loss:   6.481924 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 14:02:53,432 [Epoch: 009 Step: 00001489] Batch Translation Loss:   6.880347 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 14:05:16,521 [Epoch: 009 Step: 00001490] Batch Translation Loss:   6.323779 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 14:06:24,961 [Epoch: 009 Step: 00001491] Batch Translation Loss:   6.187510 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 14:07:16,525 [Epoch: 009 Step: 00001492] Batch Translation Loss:   6.323566 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 14:07:58,914 [Epoch: 009 Step: 00001493] Batch Translation Loss:   6.756066 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 14:08:42,177 [Epoch: 009 Step: 00001494] Batch Translation Loss:   7.125047 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 14:09:28,112 [Epoch: 009 Step: 00001495] Batch Translation Loss:   6.571310 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 14:11:13,359 [Epoch: 009 Step: 00001496] Batch Translation Loss:   6.751113 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 14:13:25,420 [Epoch: 009 Step: 00001497] Batch Translation Loss:   7.321084 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 14:14:56,770 [Epoch: 009 Step: 00001498] Batch Translation Loss:   6.714077 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 14:16:09,353 [Epoch: 009 Step: 00001499] Batch Translation Loss:   7.036035 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 14:17:01,151 [Epoch: 009 Step: 00001500] Batch Translation Loss:   6.862370 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 14:25:31,810 Validation result at epoch   9, step     1500: duration: 510.6157s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11277.05664	PPL: 8775.82227
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.13	(DEL: 22.71,	INS: 0.00,	SUB: 76.17)
	Sequence Accuracy 1.25
2022-01-01 14:25:40,162 Logging Recognition and Translation Outputs
2022-01-01 14:25:40,176 ========================================================================================================================
2022-01-01 14:25:40,176 Logging Sequence: aslized-suzanne_stecker_0272
2022-01-01 14:25:40,177 	Text Reference  :	fun
2022-01-01 14:25:40,177 	Text Hypothesis :	ok 
2022-01-01 14:25:40,177 	Text Alignment  :	S  
2022-01-01 14:25:40,178 ========================================================================================================================
2022-01-01 14:25:40,178 Logging Sequence: deafvideo_2-deafpoweronethumbtwo_1796
2022-01-01 14:25:40,178 	Text Reference  :	mic
2022-01-01 14:25:40,178 	Text Hypothesis :	or 
2022-01-01 14:25:40,179 	Text Alignment  :	S  
2022-01-01 14:25:40,179 ========================================================================================================================
2022-01-01 14:25:40,179 Logging Sequence: youtube_6-myles_de_bastion_6529
2022-01-01 14:25:40,179 	Text Reference  :	ok
2022-01-01 14:25:40,180 	Text Hypothesis :	or
2022-01-01 14:25:40,180 	Text Alignment  :	S 
2022-01-01 14:25:40,180 ========================================================================================================================
2022-01-01 14:25:40,180 Logging Sequence: deafvideo_3-titans_4699
2022-01-01 14:25:40,180 	Text Reference  :	tony
2022-01-01 14:25:40,181 	Text Hypothesis :	or  
2022-01-01 14:25:40,181 	Text Alignment  :	S   
2022-01-01 14:25:40,181 ========================================================================================================================
2022-01-01 14:25:40,181 Logging Sequence: deafvideo_5-scottnorby_6465
2022-01-01 14:25:40,181 	Text Reference  :	copy
2022-01-01 14:25:40,182 	Text Hypothesis :	ok  
2022-01-01 14:25:40,182 	Text Alignment  :	S   
2022-01-01 14:25:40,182 ========================================================================================================================
2022-01-01 14:28:44,828 [Epoch: 009 Step: 00001501] Batch Translation Loss:   6.840647 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 14:30:58,347 [Epoch: 009 Step: 00001502] Batch Translation Loss:   7.124999 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 14:33:02,347 [Epoch: 009 Step: 00001503] Batch Translation Loss:   5.890928 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 14:34:51,544 [Epoch: 009 Step: 00001504] Batch Translation Loss:   6.300898 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 14:37:30,030 [Epoch: 009 Step: 00001505] Batch Translation Loss:   6.226392 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 14:38:56,499 [Epoch: 009 Step: 00001506] Batch Translation Loss:   6.580677 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 14:41:57,783 [Epoch: 009 Step: 00001507] Batch Translation Loss:   6.484542 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 14:42:42,259 [Epoch: 009 Step: 00001508] Batch Translation Loss:   6.323172 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 14:43:25,343 [Epoch: 009 Step: 00001509] Batch Translation Loss:   5.836832 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 14:44:11,175 [Epoch: 009 Step: 00001510] Batch Translation Loss:   7.020649 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 14:44:50,238 [Epoch: 009 Step: 00001511] Batch Translation Loss:   6.382992 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 14:45:26,358 [Epoch: 009 Step: 00001512] Batch Translation Loss:   6.562606 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 14:46:04,985 [Epoch: 009 Step: 00001513] Batch Translation Loss:   6.674712 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 14:47:00,142 [Epoch: 009 Step: 00001514] Batch Translation Loss:   6.701006 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 14:48:02,094 [Epoch: 009 Step: 00001515] Batch Translation Loss:   6.883817 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 14:48:55,741 [Epoch: 009 Step: 00001516] Batch Translation Loss:   6.640128 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 14:49:46,377 [Epoch: 009 Step: 00001517] Batch Translation Loss:   6.867918 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 14:51:32,267 [Epoch: 009 Step: 00001518] Batch Translation Loss:   6.251736 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 14:53:13,195 [Epoch: 009 Step: 00001519] Batch Translation Loss:   7.234340 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 14:54:17,775 [Epoch: 009 Step: 00001520] Batch Translation Loss:   6.837000 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 14:55:07,009 [Epoch: 009 Step: 00001521] Batch Translation Loss:   6.363478 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 14:56:13,069 [Epoch: 009 Step: 00001522] Batch Translation Loss:   7.187129 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 14:57:32,458 [Epoch: 009 Step: 00001523] Batch Translation Loss:   5.841967 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 14:58:22,218 [Epoch: 009 Step: 00001524] Batch Translation Loss:   6.437592 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 14:59:06,640 [Epoch: 009 Step: 00001525] Batch Translation Loss:   6.315005 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 14:59:51,289 [Epoch: 009 Step: 00001526] Batch Translation Loss:   6.742838 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:01:33,732 [Epoch: 009 Step: 00001527] Batch Translation Loss:   6.789331 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 15:03:11,785 [Epoch: 009 Step: 00001528] Batch Translation Loss:   6.723450 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 15:04:16,074 [Epoch: 009 Step: 00001529] Batch Translation Loss:   6.440968 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 15:04:16,230 Epoch   9: Total Training Recognition Loss -1.00  Total Training Translation Loss 1153.76 
2022-01-01 15:04:16,230 EPOCH 10
2022-01-01 15:04:25,214 [Epoch: 010 Step: 00001530] Batch Translation Loss:   6.358602 => Txt Tokens per Sec:        4 || Lr: 0.001000
2022-01-01 15:04:43,905 [Epoch: 010 Step: 00001531] Batch Translation Loss:   7.303110 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 15:05:01,487 [Epoch: 010 Step: 00001532] Batch Translation Loss:   7.260453 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 15:05:17,260 [Epoch: 010 Step: 00001533] Batch Translation Loss:   7.364812 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 15:05:52,648 [Epoch: 010 Step: 00001534] Batch Translation Loss:   7.779050 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:06:10,068 [Epoch: 010 Step: 00001535] Batch Translation Loss:   8.157125 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 15:06:27,389 [Epoch: 010 Step: 00001536] Batch Translation Loss:   7.316567 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 15:06:46,701 [Epoch: 010 Step: 00001537] Batch Translation Loss:   7.941161 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 15:07:06,369 [Epoch: 010 Step: 00001538] Batch Translation Loss:   6.387866 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 15:07:27,998 [Epoch: 010 Step: 00001539] Batch Translation Loss:   6.312759 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 15:07:47,855 [Epoch: 010 Step: 00001540] Batch Translation Loss:   6.799809 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 15:08:07,397 [Epoch: 010 Step: 00001541] Batch Translation Loss:   7.330829 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 15:08:36,021 [Epoch: 010 Step: 00001542] Batch Translation Loss:   6.896568 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:08:53,699 [Epoch: 010 Step: 00001543] Batch Translation Loss:   7.115069 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 15:09:07,613 [Epoch: 010 Step: 00001544] Batch Translation Loss:   7.581227 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 15:09:20,544 [Epoch: 010 Step: 00001545] Batch Translation Loss:   6.993995 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-01 15:09:42,798 [Epoch: 010 Step: 00001546] Batch Translation Loss:   6.612747 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 15:10:22,644 [Epoch: 010 Step: 00001547] Batch Translation Loss:   7.252784 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:11:00,674 [Epoch: 010 Step: 00001548] Batch Translation Loss:   6.236126 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:11:27,153 [Epoch: 010 Step: 00001549] Batch Translation Loss:   7.077804 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:12:27,512 [Epoch: 010 Step: 00001550] Batch Translation Loss:   6.467521 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:13:21,851 [Epoch: 010 Step: 00001551] Batch Translation Loss:   6.659226 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:13:50,859 [Epoch: 010 Step: 00001552] Batch Translation Loss:   6.124540 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:14:28,415 [Epoch: 010 Step: 00001553] Batch Translation Loss:   6.442320 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:15:07,914 [Epoch: 010 Step: 00001554] Batch Translation Loss:   6.721958 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:15:28,396 [Epoch: 010 Step: 00001555] Batch Translation Loss:   6.027285 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 15:15:53,007 [Epoch: 010 Step: 00001556] Batch Translation Loss:   6.578583 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 15:16:17,874 [Epoch: 010 Step: 00001557] Batch Translation Loss:   6.959026 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 15:16:48,728 [Epoch: 010 Step: 00001558] Batch Translation Loss:   6.505314 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:17:10,100 [Epoch: 010 Step: 00001559] Batch Translation Loss:   6.398352 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 15:17:34,149 [Epoch: 010 Step: 00001560] Batch Translation Loss:   7.489641 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 15:17:59,989 [Epoch: 010 Step: 00001561] Batch Translation Loss:   6.990201 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 15:18:27,156 [Epoch: 010 Step: 00001562] Batch Translation Loss:   7.638493 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 15:18:51,971 [Epoch: 010 Step: 00001563] Batch Translation Loss:   6.339314 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 15:19:16,917 [Epoch: 010 Step: 00001564] Batch Translation Loss:   6.592403 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 15:20:21,041 [Epoch: 010 Step: 00001565] Batch Translation Loss:   6.278641 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:21:00,397 [Epoch: 010 Step: 00001566] Batch Translation Loss:   6.552086 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:22:03,988 [Epoch: 010 Step: 00001567] Batch Translation Loss:   7.017387 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:22:58,697 [Epoch: 010 Step: 00001568] Batch Translation Loss:   6.285135 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:23:56,182 [Epoch: 010 Step: 00001569] Batch Translation Loss:   6.611401 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:24:49,994 [Epoch: 010 Step: 00001570] Batch Translation Loss:   5.705536 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:25:41,521 [Epoch: 010 Step: 00001571] Batch Translation Loss:   6.894007 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:26:33,283 [Epoch: 010 Step: 00001572] Batch Translation Loss:   6.647603 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:27:14,171 [Epoch: 010 Step: 00001573] Batch Translation Loss:   7.424112 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:27:50,775 [Epoch: 010 Step: 00001574] Batch Translation Loss:   7.419962 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:29:26,321 [Epoch: 010 Step: 00001575] Batch Translation Loss:   6.571739 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 15:30:14,095 [Epoch: 010 Step: 00001576] Batch Translation Loss:   6.354326 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:31:04,199 [Epoch: 010 Step: 00001577] Batch Translation Loss:   7.151525 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:32:07,068 [Epoch: 010 Step: 00001578] Batch Translation Loss:   6.600950 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:33:41,539 [Epoch: 010 Step: 00001579] Batch Translation Loss:   7.294423 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 15:34:21,555 [Epoch: 010 Step: 00001580] Batch Translation Loss:   6.443158 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:34:57,453 [Epoch: 010 Step: 00001581] Batch Translation Loss:   6.986415 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:36:05,346 [Epoch: 010 Step: 00001582] Batch Translation Loss:   6.633124 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:36:51,710 [Epoch: 010 Step: 00001583] Batch Translation Loss:   6.439221 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:37:28,037 [Epoch: 010 Step: 00001584] Batch Translation Loss:   7.065609 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:38:09,982 [Epoch: 010 Step: 00001585] Batch Translation Loss:   6.660770 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:38:45,370 [Epoch: 010 Step: 00001586] Batch Translation Loss:   6.239192 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:39:14,108 [Epoch: 010 Step: 00001587] Batch Translation Loss:   6.617202 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:39:49,680 [Epoch: 010 Step: 00001588] Batch Translation Loss:   6.848044 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:40:53,955 [Epoch: 010 Step: 00001589] Batch Translation Loss:   6.903883 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:42:01,791 [Epoch: 010 Step: 00001590] Batch Translation Loss:   7.317829 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:42:56,684 [Epoch: 010 Step: 00001591] Batch Translation Loss:   6.025163 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:43:53,177 [Epoch: 010 Step: 00001592] Batch Translation Loss:   6.966064 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:44:41,970 [Epoch: 010 Step: 00001593] Batch Translation Loss:   6.477725 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:45:30,178 [Epoch: 010 Step: 00001594] Batch Translation Loss:   7.075665 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:46:22,738 [Epoch: 010 Step: 00001595] Batch Translation Loss:   6.588303 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:47:05,403 [Epoch: 010 Step: 00001596] Batch Translation Loss:   6.891447 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:47:45,354 [Epoch: 010 Step: 00001597] Batch Translation Loss:   7.265343 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:48:27,580 [Epoch: 010 Step: 00001598] Batch Translation Loss:   6.563911 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:49:07,879 [Epoch: 010 Step: 00001599] Batch Translation Loss:   6.684861 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:49:52,239 [Epoch: 010 Step: 00001600] Batch Translation Loss:   6.425846 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 15:58:37,468 Validation result at epoch  10, step     1600: duration: 524.9429s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11389.11621	PPL: 8547.13477
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.75	(DEL: 23.29,	INS: 0.00,	SUB: 74.96)
	Sequence Accuracy 1.76
2022-01-01 15:58:45,989 Logging Recognition and Translation Outputs
2022-01-01 15:58:46,018 ========================================================================================================================
2022-01-01 15:58:46,018 Logging Sequence: youtube_1-shoshannah_stern_2375
2022-01-01 15:58:46,019 	Text Reference  :	to
2022-01-01 15:58:46,019 	Text Hypothesis :	so
2022-01-01 15:58:46,019 	Text Alignment  :	S 
2022-01-01 15:58:46,019 ========================================================================================================================
2022-01-01 15:58:46,019 Logging Sequence: deafvideo_5-scottnorby_6447
2022-01-01 15:58:46,020 	Text Reference  :	dona carell
2022-01-01 15:58:46,020 	Text Hypothesis :	**** of    
2022-01-01 15:58:46,020 	Text Alignment  :	D    S     
2022-01-01 15:58:46,020 ========================================================================================================================
2022-01-01 15:58:46,020 Logging Sequence: deafvideo_3-titans_4692
2022-01-01 15:58:46,020 	Text Reference  :	raja rajeshwari
2022-01-01 15:58:46,021 	Text Hypothesis :	**** ok        
2022-01-01 15:58:46,021 	Text Alignment  :	D    S         
2022-01-01 15:58:46,021 ========================================================================================================================
2022-01-01 15:58:46,021 Logging Sequence: aslized-suzanne_stecker_0253
2022-01-01 15:58:46,021 	Text Reference  :	cards
2022-01-01 15:58:46,021 	Text Hypothesis :	ok   
2022-01-01 15:58:46,022 	Text Alignment  :	S    
2022-01-01 15:58:46,022 ========================================================================================================================
2022-01-01 15:58:46,022 Logging Sequence: deafvideo_3-crossover_3864
2022-01-01 15:58:46,022 	Text Reference  :	us
2022-01-01 15:58:46,022 	Text Hypothesis :	ok
2022-01-01 15:58:46,022 	Text Alignment  :	S 
2022-01-01 15:58:46,022 ========================================================================================================================
2022-01-01 16:00:27,962 [Epoch: 010 Step: 00001601] Batch Translation Loss:   6.283688 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 16:01:40,522 [Epoch: 010 Step: 00001602] Batch Translation Loss:   7.011220 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 16:02:47,256 [Epoch: 010 Step: 00001603] Batch Translation Loss:   5.933448 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 16:03:51,892 [Epoch: 010 Step: 00001604] Batch Translation Loss:   6.145279 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 16:04:42,217 [Epoch: 010 Step: 00001605] Batch Translation Loss:   6.175141 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 16:05:18,075 [Epoch: 010 Step: 00001606] Batch Translation Loss:   6.404717 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 16:06:01,735 [Epoch: 010 Step: 00001607] Batch Translation Loss:   7.023180 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 16:06:47,995 [Epoch: 010 Step: 00001608] Batch Translation Loss:   7.308950 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 16:07:32,732 [Epoch: 010 Step: 00001609] Batch Translation Loss:   6.108960 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 16:08:23,141 [Epoch: 010 Step: 00001610] Batch Translation Loss:   6.968794 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 16:09:29,073 [Epoch: 010 Step: 00001611] Batch Translation Loss:   7.225523 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 16:10:37,887 [Epoch: 010 Step: 00001612] Batch Translation Loss:   6.636482 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 16:12:07,870 [Epoch: 010 Step: 00001613] Batch Translation Loss:   6.618045 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 16:13:19,270 [Epoch: 010 Step: 00001614] Batch Translation Loss:   6.087376 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 16:14:21,127 [Epoch: 010 Step: 00001615] Batch Translation Loss:   6.168581 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 16:15:11,188 [Epoch: 010 Step: 00001616] Batch Translation Loss:   6.711697 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 16:16:06,180 [Epoch: 010 Step: 00001617] Batch Translation Loss:   7.175863 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 16:17:03,741 [Epoch: 010 Step: 00001618] Batch Translation Loss:   6.527129 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 16:18:11,230 [Epoch: 010 Step: 00001619] Batch Translation Loss:   6.395535 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 16:19:21,547 [Epoch: 010 Step: 00001620] Batch Translation Loss:   6.278639 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 16:20:51,511 [Epoch: 010 Step: 00001621] Batch Translation Loss:   6.626553 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 16:22:24,982 [Epoch: 010 Step: 00001622] Batch Translation Loss:   6.533442 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 16:24:09,025 [Epoch: 010 Step: 00001623] Batch Translation Loss:   7.303526 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 16:25:40,225 [Epoch: 010 Step: 00001624] Batch Translation Loss:   6.825149 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 16:26:52,730 [Epoch: 010 Step: 00001625] Batch Translation Loss:   6.990212 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 16:28:21,499 [Epoch: 010 Step: 00001626] Batch Translation Loss:   7.163679 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 16:29:46,793 [Epoch: 010 Step: 00001627] Batch Translation Loss:   6.500103 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 16:30:56,033 [Epoch: 010 Step: 00001628] Batch Translation Loss:   7.294133 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 16:32:07,141 [Epoch: 010 Step: 00001629] Batch Translation Loss:   6.558776 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 16:33:15,487 [Epoch: 010 Step: 00001630] Batch Translation Loss:   6.176248 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 16:35:15,909 [Epoch: 010 Step: 00001631] Batch Translation Loss:   6.433955 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 16:37:06,360 [Epoch: 010 Step: 00001632] Batch Translation Loss:   6.886543 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 16:38:39,513 [Epoch: 010 Step: 00001633] Batch Translation Loss:   6.400377 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 16:40:04,249 [Epoch: 010 Step: 00001634] Batch Translation Loss:   7.079158 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 16:41:14,563 [Epoch: 010 Step: 00001635] Batch Translation Loss:   6.102334 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 16:43:38,441 [Epoch: 010 Step: 00001636] Batch Translation Loss:   6.523891 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 16:44:50,856 [Epoch: 010 Step: 00001637] Batch Translation Loss:   6.575132 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 16:46:24,833 [Epoch: 010 Step: 00001638] Batch Translation Loss:   6.940476 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 16:50:09,209 [Epoch: 010 Step: 00001639] Batch Translation Loss:   5.910981 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 16:51:34,398 [Epoch: 010 Step: 00001640] Batch Translation Loss:   6.631422 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 16:53:02,562 [Epoch: 010 Step: 00001641] Batch Translation Loss:   6.220949 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 16:54:26,135 [Epoch: 010 Step: 00001642] Batch Translation Loss:   6.672255 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 16:55:46,318 [Epoch: 010 Step: 00001643] Batch Translation Loss:   7.026636 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 16:58:51,928 [Epoch: 010 Step: 00001644] Batch Translation Loss:   6.398264 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:00:49,680 [Epoch: 010 Step: 00001645] Batch Translation Loss:   6.644434 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:02:32,916 [Epoch: 010 Step: 00001646] Batch Translation Loss:   6.632223 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:04:14,794 [Epoch: 010 Step: 00001647] Batch Translation Loss:   6.760793 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:05:40,123 [Epoch: 010 Step: 00001648] Batch Translation Loss:   6.711570 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:07:08,281 [Epoch: 010 Step: 00001649] Batch Translation Loss:   6.870598 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:08:41,176 [Epoch: 010 Step: 00001650] Batch Translation Loss:   6.475188 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:10:43,750 [Epoch: 010 Step: 00001651] Batch Translation Loss:   6.686866 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:12:37,426 [Epoch: 010 Step: 00001652] Batch Translation Loss:   7.167377 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:14:36,017 [Epoch: 010 Step: 00001653] Batch Translation Loss:   6.257432 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:16:10,931 [Epoch: 010 Step: 00001654] Batch Translation Loss:   7.200029 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:17:32,864 [Epoch: 010 Step: 00001655] Batch Translation Loss:   6.462862 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:18:48,974 [Epoch: 010 Step: 00001656] Batch Translation Loss:   7.440974 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:20:08,912 [Epoch: 010 Step: 00001657] Batch Translation Loss:   5.610198 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:22:36,258 [Epoch: 010 Step: 00001658] Batch Translation Loss:   6.164412 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:24:45,217 [Epoch: 010 Step: 00001659] Batch Translation Loss:   7.227735 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:26:29,914 [Epoch: 010 Step: 00001660] Batch Translation Loss:   6.522884 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:27:54,227 [Epoch: 010 Step: 00001661] Batch Translation Loss:   6.672059 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:30:47,135 [Epoch: 010 Step: 00001662] Batch Translation Loss:   6.467919 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:33:15,275 [Epoch: 010 Step: 00001663] Batch Translation Loss:   6.572531 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:35:11,347 [Epoch: 010 Step: 00001664] Batch Translation Loss:   6.277157 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:36:46,596 [Epoch: 010 Step: 00001665] Batch Translation Loss:   6.911763 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:38:20,349 [Epoch: 010 Step: 00001666] Batch Translation Loss:   6.326669 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:39:44,432 [Epoch: 010 Step: 00001667] Batch Translation Loss:   6.704636 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:41:35,370 [Epoch: 010 Step: 00001668] Batch Translation Loss:   5.958618 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:43:15,189 [Epoch: 010 Step: 00001669] Batch Translation Loss:   6.546900 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:44:42,341 [Epoch: 010 Step: 00001670] Batch Translation Loss:   7.515638 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:46:01,440 [Epoch: 010 Step: 00001671] Batch Translation Loss:   6.605111 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 17:47:28,237 [Epoch: 010 Step: 00001672] Batch Translation Loss:   6.730995 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:48:59,361 [Epoch: 010 Step: 00001673] Batch Translation Loss:   6.906090 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:50:46,009 [Epoch: 010 Step: 00001674] Batch Translation Loss:   6.328562 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:54:10,039 [Epoch: 010 Step: 00001675] Batch Translation Loss:   7.156713 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:55:38,880 [Epoch: 010 Step: 00001676] Batch Translation Loss:   6.692534 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:57:08,395 [Epoch: 010 Step: 00001677] Batch Translation Loss:   6.690099 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:59:06,978 [Epoch: 010 Step: 00001678] Batch Translation Loss:   6.796715 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 18:00:55,603 [Epoch: 010 Step: 00001679] Batch Translation Loss:   6.758400 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 18:02:35,953 [Epoch: 010 Step: 00001680] Batch Translation Loss:   7.428444 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 18:04:04,020 [Epoch: 010 Step: 00001681] Batch Translation Loss:   6.624768 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 18:05:36,233 [Epoch: 010 Step: 00001682] Batch Translation Loss:   6.711190 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 18:08:56,514 [Epoch: 010 Step: 00001683] Batch Translation Loss:   6.941047 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 18:10:39,731 [Epoch: 010 Step: 00001684] Batch Translation Loss:   6.123181 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 18:13:33,526 [Epoch: 010 Step: 00001685] Batch Translation Loss:   6.575583 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 18:14:47,128 [Epoch: 010 Step: 00001686] Batch Translation Loss:   6.889819 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 18:16:37,332 [Epoch: 010 Step: 00001687] Batch Translation Loss:   6.778870 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 18:18:17,477 [Epoch: 010 Step: 00001688] Batch Translation Loss:   6.980848 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 18:19:45,093 [Epoch: 010 Step: 00001689] Batch Translation Loss:   6.389940 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 18:21:01,073 [Epoch: 010 Step: 00001690] Batch Translation Loss:   6.912094 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 18:22:18,199 [Epoch: 010 Step: 00001691] Batch Translation Loss:   6.564451 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 18:23:39,594 [Epoch: 010 Step: 00001692] Batch Translation Loss:   6.501718 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 18:25:27,962 [Epoch: 010 Step: 00001693] Batch Translation Loss:   6.280702 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 18:27:10,080 [Epoch: 010 Step: 00001694] Batch Translation Loss:   6.391376 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 18:28:43,600 [Epoch: 010 Step: 00001695] Batch Translation Loss:   6.974847 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 18:30:02,623 [Epoch: 010 Step: 00001696] Batch Translation Loss:   6.513001 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 18:33:04,059 [Epoch: 010 Step: 00001697] Batch Translation Loss:   6.326344 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 18:34:41,189 [Epoch: 010 Step: 00001698] Batch Translation Loss:   7.392590 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 18:36:16,344 [Epoch: 010 Step: 00001699] Batch Translation Loss:   7.041353 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 18:36:16,535 Epoch  10: Total Training Recognition Loss -1.00  Total Training Translation Loss 1142.70 
2022-01-01 18:36:16,535 EPOCH 11
2022-01-01 18:36:39,132 [Epoch: 011 Step: 00001700] Batch Translation Loss:   6.482875 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 18:45:06,495 Validation result at epoch  11, step     1700: duration: 507.3452s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11852.13965	PPL: 10503.71582
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.48	(DEL: 24.77,	INS: 0.00,	SUB: 73.75)
	Sequence Accuracy 1.45
2022-01-01 18:45:13,929 Logging Recognition and Translation Outputs
2022-01-01 18:45:13,958 ========================================================================================================================
2022-01-01 18:45:13,958 Logging Sequence: youtube_5-caroline_jackson_5860
2022-01-01 18:45:13,958 	Text Reference  :	of all
2022-01-01 18:45:13,959 	Text Hypothesis :	** so 
2022-01-01 18:45:13,959 	Text Alignment  :	D  S  
2022-01-01 18:45:13,959 ========================================================================================================================
2022-01-01 18:45:13,959 Logging Sequence: youtube_5-jeffrey_spinale_6056
2022-01-01 18:45:13,959 	Text Reference  :	free
2022-01-01 18:45:13,960 	Text Hypothesis :	asl 
2022-01-01 18:45:13,960 	Text Alignment  :	S   
2022-01-01 18:45:13,960 ========================================================================================================================
2022-01-01 18:45:13,960 Logging Sequence: youtube_1-shoshannah_stern_2379
2022-01-01 18:45:13,960 	Text Reference  :	date
2022-01-01 18:45:13,960 	Text Hypothesis :	asl 
2022-01-01 18:45:13,960 	Text Alignment  :	S   
2022-01-01 18:45:13,960 ========================================================================================================================
2022-01-01 18:45:13,960 Logging Sequence: deafvideo_2-deafpoweronethumbtwo_1787
2022-01-01 18:45:13,961 	Text Reference  :	dr pady ladd
2022-01-01 18:45:13,961 	Text Hypothesis :	** **** so  
2022-01-01 18:45:13,961 	Text Alignment  :	D  D    S   
2022-01-01 18:45:13,961 ========================================================================================================================
2022-01-01 18:45:13,961 Logging Sequence: deafvideo_5-morningstar_6261
2022-01-01 18:45:13,961 	Text Reference  :	deafhood foundation
2022-01-01 18:45:13,961 	Text Hypothesis :	******** so        
2022-01-01 18:45:13,961 	Text Alignment  :	D        S         
2022-01-01 18:45:13,962 ========================================================================================================================
2022-01-01 18:45:54,962 [Epoch: 011 Step: 00001701] Batch Translation Loss:   7.300322 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 18:46:34,324 [Epoch: 011 Step: 00001702] Batch Translation Loss:   6.795686 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 18:47:08,365 [Epoch: 011 Step: 00001703] Batch Translation Loss:   7.338451 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 18:47:41,270 [Epoch: 011 Step: 00001704] Batch Translation Loss:   6.763476 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 18:48:10,698 [Epoch: 011 Step: 00001705] Batch Translation Loss:   6.407336 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 18:48:39,649 [Epoch: 011 Step: 00001706] Batch Translation Loss:   7.030741 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 18:49:08,553 [Epoch: 011 Step: 00001707] Batch Translation Loss:   6.463168 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 18:49:36,500 [Epoch: 011 Step: 00001708] Batch Translation Loss:   7.029667 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 18:50:23,926 [Epoch: 011 Step: 00001709] Batch Translation Loss:   6.626633 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 18:50:56,046 [Epoch: 011 Step: 00001710] Batch Translation Loss:   6.514149 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 18:51:55,602 [Epoch: 011 Step: 00001711] Batch Translation Loss:   6.711111 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 18:52:41,170 [Epoch: 011 Step: 00001712] Batch Translation Loss:   6.798139 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 18:53:27,946 [Epoch: 011 Step: 00001713] Batch Translation Loss:   5.974914 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 18:53:54,209 [Epoch: 011 Step: 00001714] Batch Translation Loss:   6.633970 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 18:54:15,073 [Epoch: 011 Step: 00001715] Batch Translation Loss:   7.042303 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 18:54:39,587 [Epoch: 011 Step: 00001716] Batch Translation Loss:   6.960374 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 18:55:16,710 [Epoch: 011 Step: 00001717] Batch Translation Loss:   7.171690 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 18:55:40,869 [Epoch: 011 Step: 00001718] Batch Translation Loss:   7.283531 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 18:56:04,940 [Epoch: 011 Step: 00001719] Batch Translation Loss:   6.513447 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 18:56:32,346 [Epoch: 011 Step: 00001720] Batch Translation Loss:   6.785332 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 18:56:59,213 [Epoch: 011 Step: 00001721] Batch Translation Loss:   6.603857 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 18:57:44,202 [Epoch: 011 Step: 00001722] Batch Translation Loss:   6.601602 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 18:58:22,104 [Epoch: 011 Step: 00001723] Batch Translation Loss:   6.262240 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 18:58:47,959 [Epoch: 011 Step: 00001724] Batch Translation Loss:   6.447322 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 18:59:11,851 [Epoch: 011 Step: 00001725] Batch Translation Loss:   6.521995 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 18:59:40,240 [Epoch: 011 Step: 00001726] Batch Translation Loss:   7.206744 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 19:00:09,422 [Epoch: 011 Step: 00001727] Batch Translation Loss:   6.540146 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:00:38,503 [Epoch: 011 Step: 00001728] Batch Translation Loss:   6.768881 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 19:01:01,048 [Epoch: 011 Step: 00001729] Batch Translation Loss:   6.879622 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-01 19:02:42,692 [Epoch: 011 Step: 00001730] Batch Translation Loss:   7.150776 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 19:03:30,123 [Epoch: 011 Step: 00001731] Batch Translation Loss:   6.567753 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:04:17,243 [Epoch: 011 Step: 00001732] Batch Translation Loss:   6.412762 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:04:56,567 [Epoch: 011 Step: 00001733] Batch Translation Loss:   6.890883 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:05:36,740 [Epoch: 011 Step: 00001734] Batch Translation Loss:   6.347599 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:06:06,877 [Epoch: 011 Step: 00001735] Batch Translation Loss:   6.788671 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:06:36,993 [Epoch: 011 Step: 00001736] Batch Translation Loss:   6.942337 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:07:41,218 [Epoch: 011 Step: 00001737] Batch Translation Loss:   6.390271 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:08:18,977 [Epoch: 011 Step: 00001738] Batch Translation Loss:   6.133042 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:08:54,445 [Epoch: 011 Step: 00001739] Batch Translation Loss:   7.145718 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:09:27,737 [Epoch: 011 Step: 00001740] Batch Translation Loss:   7.075769 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:10:03,633 [Epoch: 011 Step: 00001741] Batch Translation Loss:   6.524546 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:10:35,183 [Epoch: 011 Step: 00001742] Batch Translation Loss:   6.532005 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:11:08,935 [Epoch: 011 Step: 00001743] Batch Translation Loss:   6.456109 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:11:42,442 [Epoch: 011 Step: 00001744] Batch Translation Loss:   6.724145 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:12:17,672 [Epoch: 011 Step: 00001745] Batch Translation Loss:   6.590126 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:12:55,411 [Epoch: 011 Step: 00001746] Batch Translation Loss:   6.526134 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:14:02,022 [Epoch: 011 Step: 00001747] Batch Translation Loss:   6.797838 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:15:00,016 [Epoch: 011 Step: 00001748] Batch Translation Loss:   6.751629 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:15:55,087 [Epoch: 011 Step: 00001749] Batch Translation Loss:   6.508292 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:16:43,807 [Epoch: 011 Step: 00001750] Batch Translation Loss:   6.156939 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:17:28,340 [Epoch: 011 Step: 00001751] Batch Translation Loss:   6.309362 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:18:44,905 [Epoch: 011 Step: 00001752] Batch Translation Loss:   6.513990 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:19:30,298 [Epoch: 011 Step: 00001753] Batch Translation Loss:   6.764173 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:20:07,103 [Epoch: 011 Step: 00001754] Batch Translation Loss:   6.478189 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:20:47,863 [Epoch: 011 Step: 00001755] Batch Translation Loss:   6.705182 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:21:29,052 [Epoch: 011 Step: 00001756] Batch Translation Loss:   6.661626 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:22:14,402 [Epoch: 011 Step: 00001757] Batch Translation Loss:   6.580305 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:23:01,484 [Epoch: 011 Step: 00001758] Batch Translation Loss:   6.393733 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:23:43,463 [Epoch: 011 Step: 00001759] Batch Translation Loss:   6.458494 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:24:27,039 [Epoch: 011 Step: 00001760] Batch Translation Loss:   7.389040 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:25:51,082 [Epoch: 011 Step: 00001761] Batch Translation Loss:   6.277720 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 19:27:02,379 [Epoch: 011 Step: 00001762] Batch Translation Loss:   6.376959 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:28:11,794 [Epoch: 011 Step: 00001763] Batch Translation Loss:   6.432271 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:29:08,678 [Epoch: 011 Step: 00001764] Batch Translation Loss:   6.929597 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:30:01,447 [Epoch: 011 Step: 00001765] Batch Translation Loss:   6.923669 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:30:53,989 [Epoch: 011 Step: 00001766] Batch Translation Loss:   7.145946 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:31:40,240 [Epoch: 011 Step: 00001767] Batch Translation Loss:   6.632988 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:32:22,365 [Epoch: 011 Step: 00001768] Batch Translation Loss:   6.730837 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:33:02,326 [Epoch: 011 Step: 00001769] Batch Translation Loss:   6.489879 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:33:45,430 [Epoch: 011 Step: 00001770] Batch Translation Loss:   6.448503 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:34:27,378 [Epoch: 011 Step: 00001771] Batch Translation Loss:   6.637440 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:35:52,645 [Epoch: 011 Step: 00001772] Batch Translation Loss:   5.838764 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 19:36:42,437 [Epoch: 011 Step: 00001773] Batch Translation Loss:   6.404109 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:38:17,844 [Epoch: 011 Step: 00001774] Batch Translation Loss:   6.338785 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 19:40:22,921 [Epoch: 011 Step: 00001775] Batch Translation Loss:   6.304017 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 19:41:14,394 [Epoch: 011 Step: 00001776] Batch Translation Loss:   7.441324 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:42:06,703 [Epoch: 011 Step: 00001777] Batch Translation Loss:   6.283989 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:43:02,773 [Epoch: 011 Step: 00001778] Batch Translation Loss:   7.269136 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:44:49,557 [Epoch: 011 Step: 00001779] Batch Translation Loss:   7.136082 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 19:45:46,946 [Epoch: 011 Step: 00001780] Batch Translation Loss:   6.683727 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:46:47,711 [Epoch: 011 Step: 00001781] Batch Translation Loss:   6.861160 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:47:49,804 [Epoch: 011 Step: 00001782] Batch Translation Loss:   6.081551 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:49:18,434 [Epoch: 011 Step: 00001783] Batch Translation Loss:   6.867364 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 19:52:09,976 [Epoch: 011 Step: 00001784] Batch Translation Loss:   6.008038 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 19:53:17,431 [Epoch: 011 Step: 00001785] Batch Translation Loss:   6.600072 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:54:16,174 [Epoch: 011 Step: 00001786] Batch Translation Loss:   6.347571 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:55:16,668 [Epoch: 011 Step: 00001787] Batch Translation Loss:   6.811746 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:56:19,866 [Epoch: 011 Step: 00001788] Batch Translation Loss:   6.040002 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 19:57:59,867 [Epoch: 011 Step: 00001789] Batch Translation Loss:   7.024819 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 19:59:48,747 [Epoch: 011 Step: 00001790] Batch Translation Loss:   6.985889 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 20:01:17,839 [Epoch: 011 Step: 00001791] Batch Translation Loss:   6.674582 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 20:02:22,579 [Epoch: 011 Step: 00001792] Batch Translation Loss:   6.316696 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 20:03:21,987 [Epoch: 011 Step: 00001793] Batch Translation Loss:   6.632170 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 20:04:10,971 [Epoch: 011 Step: 00001794] Batch Translation Loss:   7.043927 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 20:04:52,962 [Epoch: 011 Step: 00001795] Batch Translation Loss:   6.098592 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 20:05:41,547 [Epoch: 011 Step: 00001796] Batch Translation Loss:   6.439302 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 20:06:45,531 [Epoch: 011 Step: 00001797] Batch Translation Loss:   6.451845 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 20:07:45,985 [Epoch: 011 Step: 00001798] Batch Translation Loss:   7.047217 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 20:08:43,648 [Epoch: 011 Step: 00001799] Batch Translation Loss:   6.872435 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 20:09:32,428 [Epoch: 011 Step: 00001800] Batch Translation Loss:   6.349865 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-01 20:17:22,676 Validation result at epoch  11, step     1800: duration: 470.2233s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11447.80762	PPL: 9354.52734
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 0.72	(DEL: 23.40,	INS: 0.00,	SUB: 75.88)
	Sequence Accuracy 0.31
2022-01-01 20:17:30,271 Logging Recognition and Translation Outputs
2022-01-01 20:17:30,294 ========================================================================================================================
2022-01-01 20:17:30,295 Logging Sequence: deafvideo_3-geoalpha_4554
2022-01-01 20:17:30,295 	Text Reference  :	st patrick
2022-01-01 20:17:30,295 	Text Hypothesis :	** of     
2022-01-01 20:17:30,296 	Text Alignment  :	D  S      
2022-01-01 20:17:30,296 ========================================================================================================================
2022-01-01 20:17:30,296 Logging Sequence: youtube_4-tim_albert_5270
2022-01-01 20:17:30,296 	Text Reference  :	n zone nfl
2022-01-01 20:17:30,296 	Text Hypothesis :	* **** ed 
2022-01-01 20:17:30,297 	Text Alignment  :	D D    S  
2022-01-01 20:17:30,297 ========================================================================================================================
2022-01-01 20:17:30,297 Logging Sequence: youtube_1-catherine_mackinnon_2800
2022-01-01 20:17:30,297 	Text Reference  :	speak asl
2022-01-01 20:17:30,297 	Text Hypothesis :	***** asl
2022-01-01 20:17:30,298 	Text Alignment  :	D        
2022-01-01 20:17:30,298 ========================================================================================================================
2022-01-01 20:17:30,298 Logging Sequence: deafvideo_2-goatman_1519
2022-01-01 20:17:30,298 	Text Reference  :	all
2022-01-01 20:17:30,298 	Text Hypothesis :	ed 
2022-01-01 20:17:30,298 	Text Alignment  :	S  
2022-01-01 20:17:30,299 ========================================================================================================================
2022-01-01 20:17:30,299 Logging Sequence: youtube_4-sean_berdy_5736
2022-01-01 20:17:30,299 	Text Reference  :	cuonil de manos
2022-01-01 20:17:30,299 	Text Hypothesis :	****** ** of   
2022-01-01 20:17:30,299 	Text Alignment  :	D      D  S    
2022-01-01 20:17:30,300 ========================================================================================================================
2022-01-01 20:19:58,890 [Epoch: 011 Step: 00001801] Batch Translation Loss:   6.392230 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 20:21:46,098 [Epoch: 011 Step: 00001802] Batch Translation Loss:   6.306733 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 20:23:25,413 [Epoch: 011 Step: 00001803] Batch Translation Loss:   6.207483 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 20:24:30,725 [Epoch: 011 Step: 00001804] Batch Translation Loss:   6.021880 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 20:25:28,270 [Epoch: 011 Step: 00001805] Batch Translation Loss:   6.721339 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 20:26:27,021 [Epoch: 011 Step: 00001806] Batch Translation Loss:   6.351591 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 20:27:44,626 [Epoch: 011 Step: 00001807] Batch Translation Loss:   6.650686 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 20:28:52,861 [Epoch: 011 Step: 00001808] Batch Translation Loss:   6.454966 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 20:30:03,574 [Epoch: 011 Step: 00001809] Batch Translation Loss:   6.317877 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 20:31:16,108 [Epoch: 011 Step: 00001810] Batch Translation Loss:   6.463152 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 20:33:14,418 [Epoch: 011 Step: 00001811] Batch Translation Loss:   6.812784 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 20:34:57,164 [Epoch: 011 Step: 00001812] Batch Translation Loss:   6.527001 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 20:36:27,152 [Epoch: 011 Step: 00001813] Batch Translation Loss:   7.136943 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 20:37:57,169 [Epoch: 011 Step: 00001814] Batch Translation Loss:   6.474449 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 20:39:08,842 [Epoch: 011 Step: 00001815] Batch Translation Loss:   6.527647 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 20:40:23,629 [Epoch: 011 Step: 00001816] Batch Translation Loss:   6.637170 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 20:41:46,271 [Epoch: 011 Step: 00001817] Batch Translation Loss:   6.739706 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 20:43:04,424 [Epoch: 011 Step: 00001818] Batch Translation Loss:   6.202818 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 20:44:45,920 [Epoch: 011 Step: 00001819] Batch Translation Loss:   6.021948 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 20:47:09,072 [Epoch: 011 Step: 00001820] Batch Translation Loss:   6.832700 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 20:49:01,048 [Epoch: 011 Step: 00001821] Batch Translation Loss:   6.451912 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 20:50:59,726 [Epoch: 011 Step: 00001822] Batch Translation Loss:   6.316107 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 20:52:38,015 [Epoch: 011 Step: 00001823] Batch Translation Loss:   5.921201 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 20:54:13,008 [Epoch: 011 Step: 00001824] Batch Translation Loss:   6.185730 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 20:55:48,198 [Epoch: 011 Step: 00001825] Batch Translation Loss:   5.814025 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 20:58:00,432 [Epoch: 011 Step: 00001826] Batch Translation Loss:   5.547462 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 21:00:02,132 [Epoch: 011 Step: 00001827] Batch Translation Loss:   6.191059 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 21:01:58,639 [Epoch: 011 Step: 00001828] Batch Translation Loss:   6.585417 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 21:04:26,145 [Epoch: 011 Step: 00001829] Batch Translation Loss:   5.884136 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 21:06:35,015 [Epoch: 011 Step: 00001830] Batch Translation Loss:   6.580921 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 21:08:19,863 [Epoch: 011 Step: 00001831] Batch Translation Loss:   6.495317 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 21:11:02,724 [Epoch: 011 Step: 00001832] Batch Translation Loss:   7.190368 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 21:13:06,634 [Epoch: 011 Step: 00001833] Batch Translation Loss:   6.434661 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 21:14:55,061 [Epoch: 011 Step: 00001834] Batch Translation Loss:   6.898406 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 21:16:40,107 [Epoch: 011 Step: 00001835] Batch Translation Loss:   5.737622 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 21:18:26,349 [Epoch: 011 Step: 00001836] Batch Translation Loss:   6.807734 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 21:22:47,257 [Epoch: 011 Step: 00001837] Batch Translation Loss:   7.746768 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 21:25:01,303 [Epoch: 011 Step: 00001838] Batch Translation Loss:   6.507256 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 21:26:45,970 [Epoch: 011 Step: 00001839] Batch Translation Loss:   6.713039 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 21:28:22,329 [Epoch: 011 Step: 00001840] Batch Translation Loss:   6.847908 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 21:30:07,052 [Epoch: 011 Step: 00001841] Batch Translation Loss:   7.021794 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 21:31:51,433 [Epoch: 011 Step: 00001842] Batch Translation Loss:   6.368605 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 21:33:50,363 [Epoch: 011 Step: 00001843] Batch Translation Loss:   6.355287 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 21:38:48,834 [Epoch: 011 Step: 00001844] Batch Translation Loss:   6.554955 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 21:40:45,365 [Epoch: 011 Step: 00001845] Batch Translation Loss:   6.649388 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 21:44:17,108 [Epoch: 011 Step: 00001846] Batch Translation Loss:   6.841214 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 21:46:22,622 [Epoch: 011 Step: 00001847] Batch Translation Loss:   6.640099 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 21:48:36,144 [Epoch: 011 Step: 00001848] Batch Translation Loss:   6.042687 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 21:50:58,401 [Epoch: 011 Step: 00001849] Batch Translation Loss:   6.080537 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 21:52:44,618 [Epoch: 011 Step: 00001850] Batch Translation Loss:   6.187666 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 21:54:25,545 [Epoch: 011 Step: 00001851] Batch Translation Loss:   6.352206 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 21:56:08,161 [Epoch: 011 Step: 00001852] Batch Translation Loss:   6.451015 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 21:57:59,153 [Epoch: 011 Step: 00001853] Batch Translation Loss:   6.247036 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 22:00:00,589 [Epoch: 011 Step: 00001854] Batch Translation Loss:   5.863176 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 22:01:48,107 [Epoch: 011 Step: 00001855] Batch Translation Loss:   6.905833 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 22:03:12,241 [Epoch: 011 Step: 00001856] Batch Translation Loss:   6.801943 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 22:04:29,591 [Epoch: 011 Step: 00001857] Batch Translation Loss:   7.335038 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 22:05:54,249 [Epoch: 011 Step: 00001858] Batch Translation Loss:   6.778983 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 22:07:26,918 [Epoch: 011 Step: 00001859] Batch Translation Loss:   6.745255 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 22:09:15,153 [Epoch: 011 Step: 00001860] Batch Translation Loss:   7.342578 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 22:10:56,866 [Epoch: 011 Step: 00001861] Batch Translation Loss:   6.816140 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 22:13:52,629 [Epoch: 011 Step: 00001862] Batch Translation Loss:   6.435350 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 22:16:41,973 [Epoch: 011 Step: 00001863] Batch Translation Loss:   6.119463 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 22:18:29,175 [Epoch: 011 Step: 00001864] Batch Translation Loss:   6.127423 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 22:21:34,998 [Epoch: 011 Step: 00001865] Batch Translation Loss:   7.045380 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 22:24:21,656 [Epoch: 011 Step: 00001866] Batch Translation Loss:   6.306865 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 22:25:45,228 [Epoch: 011 Step: 00001867] Batch Translation Loss:   6.570655 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 22:27:27,514 [Epoch: 011 Step: 00001868] Batch Translation Loss:   6.136640 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 22:30:29,684 [Epoch: 011 Step: 00001869] Batch Translation Loss:   6.659803 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 22:30:29,887 Epoch  11: Total Training Recognition Loss -1.00  Total Training Translation Loss 1120.85 
2022-01-01 22:30:29,887 EPOCH 12
2022-01-01 22:30:43,245 [Epoch: 012 Step: 00001870] Batch Translation Loss:   6.777184 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-01 22:31:08,146 [Epoch: 012 Step: 00001871] Batch Translation Loss:   7.378326 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 22:31:43,700 [Epoch: 012 Step: 00001872] Batch Translation Loss:   7.033355 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 22:32:04,149 [Epoch: 012 Step: 00001873] Batch Translation Loss:   6.353927 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 22:32:29,103 [Epoch: 012 Step: 00001874] Batch Translation Loss:   7.673620 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 22:33:00,383 [Epoch: 012 Step: 00001875] Batch Translation Loss:   6.444567 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 22:33:22,435 [Epoch: 012 Step: 00001876] Batch Translation Loss:   6.305203 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 22:33:58,963 [Epoch: 012 Step: 00001877] Batch Translation Loss:   6.698122 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 22:34:21,106 [Epoch: 012 Step: 00001878] Batch Translation Loss:   7.666662 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 22:34:41,025 [Epoch: 012 Step: 00001879] Batch Translation Loss:   6.297967 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 22:35:00,222 [Epoch: 012 Step: 00001880] Batch Translation Loss:   6.458251 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 22:35:25,773 [Epoch: 012 Step: 00001881] Batch Translation Loss:   7.553814 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 22:35:53,931 [Epoch: 012 Step: 00001882] Batch Translation Loss:   7.011221 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 22:36:28,642 [Epoch: 012 Step: 00001883] Batch Translation Loss:   6.595719 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 22:37:10,593 [Epoch: 012 Step: 00001884] Batch Translation Loss:   6.478316 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 22:37:42,511 [Epoch: 012 Step: 00001885] Batch Translation Loss:   6.639728 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 22:38:05,660 [Epoch: 012 Step: 00001886] Batch Translation Loss:   7.088402 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 22:38:30,417 [Epoch: 012 Step: 00001887] Batch Translation Loss:   6.913831 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 22:38:51,265 [Epoch: 012 Step: 00001888] Batch Translation Loss:   6.414163 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 22:39:13,472 [Epoch: 012 Step: 00001889] Batch Translation Loss:   6.307851 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 22:39:36,417 [Epoch: 012 Step: 00001890] Batch Translation Loss:   6.680573 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 22:39:55,989 [Epoch: 012 Step: 00001891] Batch Translation Loss:   6.248389 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 22:40:19,125 [Epoch: 012 Step: 00001892] Batch Translation Loss:   6.616704 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 22:40:46,653 [Epoch: 012 Step: 00001893] Batch Translation Loss:   6.633732 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 22:41:09,158 [Epoch: 012 Step: 00001894] Batch Translation Loss:   6.790182 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 22:41:52,543 [Epoch: 012 Step: 00001895] Batch Translation Loss:   6.817080 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 22:42:14,431 [Epoch: 012 Step: 00001896] Batch Translation Loss:   6.585354 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 22:42:38,846 [Epoch: 012 Step: 00001897] Batch Translation Loss:   6.801366 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 22:43:00,832 [Epoch: 012 Step: 00001898] Batch Translation Loss:   6.159301 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 22:43:23,310 [Epoch: 012 Step: 00001899] Batch Translation Loss:   6.792609 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 22:43:45,310 [Epoch: 012 Step: 00001900] Batch Translation Loss:   6.721836 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 22:52:01,600 Validation result at epoch  12, step     1900: duration: 496.2622s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11037.94141	PPL: 7136.25195
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 2.09	(DEL: 23.39,	INS: 0.00,	SUB: 74.52)
	Sequence Accuracy 2.31
2022-01-01 22:52:09,664 Logging Recognition and Translation Outputs
2022-01-01 22:52:09,755 ========================================================================================================================
2022-01-01 22:52:09,755 Logging Sequence: youtube_5-daniel_durant_5896
2022-01-01 22:52:09,755 	Text Reference  :	if
2022-01-01 22:52:09,755 	Text Hypothesis :	so
2022-01-01 22:52:09,756 	Text Alignment  :	S 
2022-01-01 22:52:09,756 ========================================================================================================================
2022-01-01 22:52:09,756 Logging Sequence: youtube_1-catherine_mackinnon_2791
2022-01-01 22:52:09,756 	Text Reference  :	grandchildr grandchildren
2022-01-01 22:52:09,756 	Text Hypothesis :	*********** awardness    
2022-01-01 22:52:09,756 	Text Alignment  :	D           S            
2022-01-01 22:52:09,756 ========================================================================================================================
2022-01-01 22:52:09,756 Logging Sequence: deafvideo_5-morningstar_6265
2022-01-01 22:52:09,757 	Text Reference  :	deal
2022-01-01 22:52:09,757 	Text Hypothesis :	asl 
2022-01-01 22:52:09,757 	Text Alignment  :	S   
2022-01-01 22:52:09,757 ========================================================================================================================
2022-01-01 22:52:09,757 Logging Sequence: deafvideo_3-titans_4697
2022-01-01 22:52:09,757 	Text Reference  :	unicode
2022-01-01 22:52:09,757 	Text Hypothesis :	asl    
2022-01-01 22:52:09,758 	Text Alignment  :	S      
2022-01-01 22:52:09,758 ========================================================================================================================
2022-01-01 22:52:09,758 Logging Sequence: youtube_1-shoshannah_stern_2398
2022-01-01 22:52:09,758 	Text Reference  :	deafhooyd yoga
2022-01-01 22:52:09,758 	Text Hypothesis :	********* asl 
2022-01-01 22:52:09,758 	Text Alignment  :	D         S   
2022-01-01 22:52:09,758 ========================================================================================================================
2022-01-01 22:53:14,101 [Epoch: 012 Step: 00001901] Batch Translation Loss:   6.611573 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 22:54:01,733 [Epoch: 012 Step: 00001902] Batch Translation Loss:   6.382824 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 22:54:57,039 [Epoch: 012 Step: 00001903] Batch Translation Loss:   6.858642 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 22:56:21,318 [Epoch: 012 Step: 00001904] Batch Translation Loss:   6.917916 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 22:57:04,106 [Epoch: 012 Step: 00001905] Batch Translation Loss:   6.274480 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 22:58:07,849 [Epoch: 012 Step: 00001906] Batch Translation Loss:   6.901309 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 22:58:41,502 [Epoch: 012 Step: 00001907] Batch Translation Loss:   5.907693 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 22:59:14,946 [Epoch: 012 Step: 00001908] Batch Translation Loss:   5.881682 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 22:59:43,027 [Epoch: 012 Step: 00001909] Batch Translation Loss:   6.543061 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:00:43,340 [Epoch: 012 Step: 00001910] Batch Translation Loss:   6.537176 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:01:16,231 [Epoch: 012 Step: 00001911] Batch Translation Loss:   6.893853 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:01:51,458 [Epoch: 012 Step: 00001912] Batch Translation Loss:   6.417061 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:02:52,944 [Epoch: 012 Step: 00001913] Batch Translation Loss:   6.633368 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:03:21,284 [Epoch: 012 Step: 00001914] Batch Translation Loss:   6.424141 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:03:56,716 [Epoch: 012 Step: 00001915] Batch Translation Loss:   6.412796 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:05:12,621 [Epoch: 012 Step: 00001916] Batch Translation Loss:   6.762122 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:05:52,362 [Epoch: 012 Step: 00001917] Batch Translation Loss:   6.252237 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:06:33,392 [Epoch: 012 Step: 00001918] Batch Translation Loss:   6.161076 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:07:49,319 [Epoch: 012 Step: 00001919] Batch Translation Loss:   7.258098 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:08:53,028 [Epoch: 012 Step: 00001920] Batch Translation Loss:   6.668861 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:09:49,318 [Epoch: 012 Step: 00001921] Batch Translation Loss:   5.791602 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:10:40,086 [Epoch: 012 Step: 00001922] Batch Translation Loss:   7.341105 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:11:12,490 [Epoch: 012 Step: 00001923] Batch Translation Loss:   6.484447 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:11:45,588 [Epoch: 012 Step: 00001924] Batch Translation Loss:   6.755455 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:12:08,604 [Epoch: 012 Step: 00001925] Batch Translation Loss:   6.693896 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 23:12:29,102 [Epoch: 012 Step: 00001926] Batch Translation Loss:   6.547325 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 23:12:50,199 [Epoch: 012 Step: 00001927] Batch Translation Loss:   6.146552 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 23:13:10,151 [Epoch: 012 Step: 00001928] Batch Translation Loss:   6.789665 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 23:13:49,984 [Epoch: 012 Step: 00001929] Batch Translation Loss:   6.343919 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:14:17,018 [Epoch: 012 Step: 00001930] Batch Translation Loss:   6.094518 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:14:37,253 [Epoch: 012 Step: 00001931] Batch Translation Loss:   6.282051 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 23:15:13,913 [Epoch: 012 Step: 00001932] Batch Translation Loss:   7.235249 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:15:34,684 [Epoch: 012 Step: 00001933] Batch Translation Loss:   5.548835 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 23:15:55,331 [Epoch: 012 Step: 00001934] Batch Translation Loss:   6.323683 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 23:16:17,087 [Epoch: 012 Step: 00001935] Batch Translation Loss:   6.581410 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 23:16:41,580 [Epoch: 012 Step: 00001936] Batch Translation Loss:   6.949827 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 23:17:08,143 [Epoch: 012 Step: 00001937] Batch Translation Loss:   6.452267 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:17:28,278 [Epoch: 012 Step: 00001938] Batch Translation Loss:   6.947479 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 23:17:56,258 [Epoch: 012 Step: 00001939] Batch Translation Loss:   6.447846 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 23:18:32,551 [Epoch: 012 Step: 00001940] Batch Translation Loss:   6.853532 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:19:41,082 [Epoch: 012 Step: 00001941] Batch Translation Loss:   6.434917 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:20:40,853 [Epoch: 012 Step: 00001942] Batch Translation Loss:   6.691779 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:21:28,983 [Epoch: 012 Step: 00001943] Batch Translation Loss:   6.349385 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:22:00,126 [Epoch: 012 Step: 00001944] Batch Translation Loss:   6.849911 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:22:37,479 [Epoch: 012 Step: 00001945] Batch Translation Loss:   6.287296 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:22:59,588 [Epoch: 012 Step: 00001946] Batch Translation Loss:   5.796330 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 23:23:44,989 [Epoch: 012 Step: 00001947] Batch Translation Loss:   6.465115 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:24:09,283 [Epoch: 012 Step: 00001948] Batch Translation Loss:   5.588586 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:24:35,668 [Epoch: 012 Step: 00001949] Batch Translation Loss:   6.186583 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 23:24:59,200 [Epoch: 012 Step: 00001950] Batch Translation Loss:   6.352319 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 23:25:23,643 [Epoch: 012 Step: 00001951] Batch Translation Loss:   6.144997 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:25:49,242 [Epoch: 012 Step: 00001952] Batch Translation Loss:   5.938533 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:26:14,429 [Epoch: 012 Step: 00001953] Batch Translation Loss:   6.065841 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 23:27:04,180 [Epoch: 012 Step: 00001954] Batch Translation Loss:   6.759771 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:27:30,750 [Epoch: 012 Step: 00001955] Batch Translation Loss:   6.736929 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:27:56,154 [Epoch: 012 Step: 00001956] Batch Translation Loss:   6.101107 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:28:24,468 [Epoch: 012 Step: 00001957] Batch Translation Loss:   5.791668 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:28:49,496 [Epoch: 012 Step: 00001958] Batch Translation Loss:   6.655390 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 23:29:16,729 [Epoch: 012 Step: 00001959] Batch Translation Loss:   6.303752 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:29:47,018 [Epoch: 012 Step: 00001960] Batch Translation Loss:   6.344617 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:30:19,028 [Epoch: 012 Step: 00001961] Batch Translation Loss:   6.649321 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:31:25,252 [Epoch: 012 Step: 00001962] Batch Translation Loss:   6.937397 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:32:24,609 [Epoch: 012 Step: 00001963] Batch Translation Loss:   6.740935 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:33:20,609 [Epoch: 012 Step: 00001964] Batch Translation Loss:   6.116027 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:34:01,666 [Epoch: 012 Step: 00001965] Batch Translation Loss:   7.332581 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:34:28,570 [Epoch: 012 Step: 00001966] Batch Translation Loss:   6.344227 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:34:55,638 [Epoch: 012 Step: 00001967] Batch Translation Loss:   6.597520 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-01 23:35:22,465 [Epoch: 012 Step: 00001968] Batch Translation Loss:   5.961684 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:35:50,716 [Epoch: 012 Step: 00001969] Batch Translation Loss:   6.364693 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:36:17,480 [Epoch: 012 Step: 00001970] Batch Translation Loss:   5.955571 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:36:50,780 [Epoch: 012 Step: 00001971] Batch Translation Loss:   6.640058 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:37:19,564 [Epoch: 012 Step: 00001972] Batch Translation Loss:   5.653085 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:37:53,402 [Epoch: 012 Step: 00001973] Batch Translation Loss:   6.666745 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:38:48,990 [Epoch: 012 Step: 00001974] Batch Translation Loss:   6.575613 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:39:21,742 [Epoch: 012 Step: 00001975] Batch Translation Loss:   6.190967 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:39:51,455 [Epoch: 012 Step: 00001976] Batch Translation Loss:   7.301471 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:40:21,072 [Epoch: 012 Step: 00001977] Batch Translation Loss:   6.187428 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:40:54,856 [Epoch: 012 Step: 00001978] Batch Translation Loss:   6.444279 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:41:23,846 [Epoch: 012 Step: 00001979] Batch Translation Loss:   5.370958 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:42:22,767 [Epoch: 012 Step: 00001980] Batch Translation Loss:   6.514680 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:44:01,792 [Epoch: 012 Step: 00001981] Batch Translation Loss:   6.523648 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 23:45:10,196 [Epoch: 012 Step: 00001982] Batch Translation Loss:   6.298339 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:46:06,494 [Epoch: 012 Step: 00001983] Batch Translation Loss:   6.469184 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:46:54,035 [Epoch: 012 Step: 00001984] Batch Translation Loss:   6.673164 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:48:01,104 [Epoch: 012 Step: 00001985] Batch Translation Loss:   6.300784 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:48:34,813 [Epoch: 012 Step: 00001986] Batch Translation Loss:   6.481719 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:49:07,600 [Epoch: 012 Step: 00001987] Batch Translation Loss:   5.488060 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:49:42,070 [Epoch: 012 Step: 00001988] Batch Translation Loss:   6.844472 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:50:21,761 [Epoch: 012 Step: 00001989] Batch Translation Loss:   6.084436 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:50:57,902 [Epoch: 012 Step: 00001990] Batch Translation Loss:   6.530400 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:51:30,136 [Epoch: 012 Step: 00001991] Batch Translation Loss:   6.680719 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:52:04,741 [Epoch: 012 Step: 00001992] Batch Translation Loss:   5.397357 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:52:36,203 [Epoch: 012 Step: 00001993] Batch Translation Loss:   6.360767 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:53:22,008 [Epoch: 012 Step: 00001994] Batch Translation Loss:   6.483491 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:56:27,822 [Epoch: 012 Step: 00001995] Batch Translation Loss:   7.208258 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-01 23:57:24,748 [Epoch: 012 Step: 00001996] Batch Translation Loss:   6.161563 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:58:05,022 [Epoch: 012 Step: 00001997] Batch Translation Loss:   6.044287 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:58:46,028 [Epoch: 012 Step: 00001998] Batch Translation Loss:   6.052503 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-01 23:59:34,218 [Epoch: 012 Step: 00001999] Batch Translation Loss:   5.496891 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 00:00:20,940 [Epoch: 012 Step: 00002000] Batch Translation Loss:   6.504666 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 00:08:09,298 Validation result at epoch  12, step     2000: duration: 468.3413s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11779.97461	PPL: 11237.12988
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 0.95	(DEL: 24.31,	INS: 0.00,	SUB: 74.74)
	Sequence Accuracy 1.05
2022-01-02 00:08:16,287 Logging Recognition and Translation Outputs
2022-01-02 00:08:16,316 ========================================================================================================================
2022-01-02 00:08:16,316 Logging Sequence: youtube_5-jeffrey_spinale_6042
2022-01-02 00:08:16,317 	Text Reference  :	land
2022-01-02 00:08:16,317 	Text Hypothesis :	ok  
2022-01-02 00:08:16,317 	Text Alignment  :	S   
2022-01-02 00:08:16,317 ========================================================================================================================
2022-01-02 00:08:16,317 Logging Sequence: deafvideo_2-deafpoweronethumbtwo_1790
2022-01-02 00:08:16,317 	Text Reference  :	hammer
2022-01-02 00:08:16,318 	Text Hypothesis :	ok    
2022-01-02 00:08:16,318 	Text Alignment  :	S     
2022-01-02 00:08:16,318 ========================================================================================================================
2022-01-02 00:08:16,318 Logging Sequence: youtube_3-ben_bahan_4525
2022-01-02 00:08:16,318 	Text Reference  :	care
2022-01-02 00:08:16,318 	Text Hypothesis :	ok  
2022-01-02 00:08:16,319 	Text Alignment  :	S   
2022-01-02 00:08:16,319 ========================================================================================================================
2022-01-02 00:08:16,319 Logging Sequence: deafvideo_5-morningstar_6254
2022-01-02 00:08:16,319 	Text Reference  :	nbda
2022-01-02 00:08:16,319 	Text Hypothesis :	ok  
2022-01-02 00:08:16,319 	Text Alignment  :	S   
2022-01-02 00:08:16,319 ========================================================================================================================
2022-01-02 00:08:16,319 Logging Sequence: deafvideo_2-sddsimple_1586
2022-01-02 00:08:16,319 	Text Reference  :	in
2022-01-02 00:08:16,320 	Text Hypothesis :	ok
2022-01-02 00:08:16,320 	Text Alignment  :	S 
2022-01-02 00:08:16,320 ========================================================================================================================
2022-01-02 00:11:01,230 [Epoch: 012 Step: 00002001] Batch Translation Loss:   7.118107 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 00:13:04,450 [Epoch: 012 Step: 00002002] Batch Translation Loss:   6.177819 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 00:14:55,210 [Epoch: 012 Step: 00002003] Batch Translation Loss:   6.126904 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 00:17:03,082 [Epoch: 012 Step: 00002004] Batch Translation Loss:   6.240199 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 00:19:05,923 [Epoch: 012 Step: 00002005] Batch Translation Loss:   6.505537 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 00:20:41,489 [Epoch: 012 Step: 00002006] Batch Translation Loss:   6.842475 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 00:22:24,985 [Epoch: 012 Step: 00002007] Batch Translation Loss:   6.319723 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 00:24:07,337 [Epoch: 012 Step: 00002008] Batch Translation Loss:   5.664438 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 00:25:48,768 [Epoch: 012 Step: 00002009] Batch Translation Loss:   7.277568 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 00:27:35,654 [Epoch: 012 Step: 00002010] Batch Translation Loss:   6.963173 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 00:29:56,423 [Epoch: 012 Step: 00002011] Batch Translation Loss:   6.276443 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 00:32:14,248 [Epoch: 012 Step: 00002012] Batch Translation Loss:   6.428028 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 00:33:42,631 [Epoch: 012 Step: 00002013] Batch Translation Loss:   6.600039 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 00:34:50,828 [Epoch: 012 Step: 00002014] Batch Translation Loss:   7.055198 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 00:35:41,407 [Epoch: 012 Step: 00002015] Batch Translation Loss:   6.807606 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 00:36:29,821 [Epoch: 012 Step: 00002016] Batch Translation Loss:   6.821869 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 00:37:17,066 [Epoch: 012 Step: 00002017] Batch Translation Loss:   6.344594 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 00:37:59,854 [Epoch: 012 Step: 00002018] Batch Translation Loss:   6.426495 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 00:38:49,646 [Epoch: 012 Step: 00002019] Batch Translation Loss:   6.332561 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 00:39:29,724 [Epoch: 012 Step: 00002020] Batch Translation Loss:   7.139453 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 00:43:17,660 [Epoch: 012 Step: 00002021] Batch Translation Loss:   6.777986 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 00:44:51,068 [Epoch: 012 Step: 00002022] Batch Translation Loss:   6.903397 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 00:46:01,224 [Epoch: 012 Step: 00002023] Batch Translation Loss:   6.537054 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 00:46:51,539 [Epoch: 012 Step: 00002024] Batch Translation Loss:   6.367866 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 00:48:12,266 [Epoch: 012 Step: 00002025] Batch Translation Loss:   6.309692 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 00:49:00,326 [Epoch: 012 Step: 00002026] Batch Translation Loss:   6.214005 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 00:49:37,797 [Epoch: 012 Step: 00002027] Batch Translation Loss:   6.539367 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 00:50:15,503 [Epoch: 012 Step: 00002028] Batch Translation Loss:   6.700566 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 00:50:59,930 [Epoch: 012 Step: 00002029] Batch Translation Loss:   6.169287 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 00:53:13,200 [Epoch: 012 Step: 00002030] Batch Translation Loss:   6.618162 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 00:55:15,286 [Epoch: 012 Step: 00002031] Batch Translation Loss:   6.511261 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 00:56:42,467 [Epoch: 012 Step: 00002032] Batch Translation Loss:   6.667521 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 00:58:02,323 [Epoch: 012 Step: 00002033] Batch Translation Loss:   5.818058 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 00:59:04,243 [Epoch: 012 Step: 00002034] Batch Translation Loss:   6.054632 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 00:59:43,486 [Epoch: 012 Step: 00002035] Batch Translation Loss:   6.263856 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:00:22,596 [Epoch: 012 Step: 00002036] Batch Translation Loss:   6.672472 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:01:07,822 [Epoch: 012 Step: 00002037] Batch Translation Loss:   6.118746 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:01:48,096 [Epoch: 012 Step: 00002038] Batch Translation Loss:   6.327131 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:02:29,694 [Epoch: 012 Step: 00002039] Batch Translation Loss:   6.864935 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:02:29,900 Epoch  12: Total Training Recognition Loss -1.00  Total Training Translation Loss 1104.63 
2022-01-02 01:02:29,900 EPOCH 13
2022-01-02 01:02:38,327 [Epoch: 013 Step: 00002040] Batch Translation Loss:   6.471576 => Txt Tokens per Sec:        4 || Lr: 0.000700
2022-01-02 01:02:46,992 [Epoch: 013 Step: 00002041] Batch Translation Loss:   6.520843 => Txt Tokens per Sec:        4 || Lr: 0.000700
2022-01-02 01:02:57,582 [Epoch: 013 Step: 00002042] Batch Translation Loss:   7.041085 => Txt Tokens per Sec:        5 || Lr: 0.000700
2022-01-02 01:03:11,652 [Epoch: 013 Step: 00002043] Batch Translation Loss:   7.175067 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-02 01:03:32,430 [Epoch: 013 Step: 00002044] Batch Translation Loss:   6.598552 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:03:59,655 [Epoch: 013 Step: 00002045] Batch Translation Loss:   6.052520 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:04:20,663 [Epoch: 013 Step: 00002046] Batch Translation Loss:   6.676993 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:04:59,106 [Epoch: 013 Step: 00002047] Batch Translation Loss:   5.965626 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:05:42,980 [Epoch: 013 Step: 00002048] Batch Translation Loss:   5.838329 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:06:09,987 [Epoch: 013 Step: 00002049] Batch Translation Loss:   6.506351 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:06:38,166 [Epoch: 013 Step: 00002050] Batch Translation Loss:   6.805659 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:06:59,353 [Epoch: 013 Step: 00002051] Batch Translation Loss:   6.142612 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:07:22,874 [Epoch: 013 Step: 00002052] Batch Translation Loss:   6.675733 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:07:44,148 [Epoch: 013 Step: 00002053] Batch Translation Loss:   6.595248 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:08:07,493 [Epoch: 013 Step: 00002054] Batch Translation Loss:   6.169967 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:08:25,105 [Epoch: 013 Step: 00002055] Batch Translation Loss:   6.940812 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:08:39,606 [Epoch: 013 Step: 00002056] Batch Translation Loss:   6.373514 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:08:55,745 [Epoch: 013 Step: 00002057] Batch Translation Loss:   5.982925 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:09:26,724 [Epoch: 013 Step: 00002058] Batch Translation Loss:   6.718000 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:09:53,512 [Epoch: 013 Step: 00002059] Batch Translation Loss:   6.594957 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:10:19,274 [Epoch: 013 Step: 00002060] Batch Translation Loss:   6.378486 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:10:32,966 [Epoch: 013 Step: 00002061] Batch Translation Loss:   6.256225 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-02 01:10:45,350 [Epoch: 013 Step: 00002062] Batch Translation Loss:   6.454957 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-02 01:10:58,988 [Epoch: 013 Step: 00002063] Batch Translation Loss:   6.652382 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-02 01:11:24,176 [Epoch: 013 Step: 00002064] Batch Translation Loss:   6.564960 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:12:21,282 [Epoch: 013 Step: 00002065] Batch Translation Loss:   6.317665 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:12:54,975 [Epoch: 013 Step: 00002066] Batch Translation Loss:   6.325654 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:13:18,072 [Epoch: 013 Step: 00002067] Batch Translation Loss:   6.873085 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:13:51,451 [Epoch: 013 Step: 00002068] Batch Translation Loss:   6.449829 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:14:06,453 [Epoch: 013 Step: 00002069] Batch Translation Loss:   6.734829 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:14:22,142 [Epoch: 013 Step: 00002070] Batch Translation Loss:   5.736204 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:14:40,238 [Epoch: 013 Step: 00002071] Batch Translation Loss:   6.621343 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:14:55,733 [Epoch: 013 Step: 00002072] Batch Translation Loss:   6.268620 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-02 01:15:20,128 [Epoch: 013 Step: 00002073] Batch Translation Loss:   6.578676 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:15:45,625 [Epoch: 013 Step: 00002074] Batch Translation Loss:   6.433623 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:16:52,805 [Epoch: 013 Step: 00002075] Batch Translation Loss:   6.230412 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:17:14,775 [Epoch: 013 Step: 00002076] Batch Translation Loss:   6.418706 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:17:35,555 [Epoch: 013 Step: 00002077] Batch Translation Loss:   6.569658 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:18:03,239 [Epoch: 013 Step: 00002078] Batch Translation Loss:   6.598326 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:18:23,808 [Epoch: 013 Step: 00002079] Batch Translation Loss:   5.948171 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:18:46,079 [Epoch: 013 Step: 00002080] Batch Translation Loss:   5.998713 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:19:02,563 [Epoch: 013 Step: 00002081] Batch Translation Loss:   6.453072 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:19:36,346 [Epoch: 013 Step: 00002082] Batch Translation Loss:   6.787434 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:19:53,363 [Epoch: 013 Step: 00002083] Batch Translation Loss:   6.346714 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:20:13,688 [Epoch: 013 Step: 00002084] Batch Translation Loss:   6.582556 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:20:36,371 [Epoch: 013 Step: 00002085] Batch Translation Loss:   6.105686 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:21:11,005 [Epoch: 013 Step: 00002086] Batch Translation Loss:   6.937824 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:21:43,636 [Epoch: 013 Step: 00002087] Batch Translation Loss:   6.319661 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:22:20,524 [Epoch: 013 Step: 00002088] Batch Translation Loss:   5.941779 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:22:44,751 [Epoch: 013 Step: 00002089] Batch Translation Loss:   6.908895 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:23:22,365 [Epoch: 013 Step: 00002090] Batch Translation Loss:   6.373391 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:23:55,599 [Epoch: 013 Step: 00002091] Batch Translation Loss:   6.522748 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:24:15,090 [Epoch: 013 Step: 00002092] Batch Translation Loss:   6.559603 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:24:35,977 [Epoch: 013 Step: 00002093] Batch Translation Loss:   6.497976 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:24:58,067 [Epoch: 013 Step: 00002094] Batch Translation Loss:   6.528799 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:25:19,075 [Epoch: 013 Step: 00002095] Batch Translation Loss:   6.604787 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:25:40,920 [Epoch: 013 Step: 00002096] Batch Translation Loss:   6.404329 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:26:04,824 [Epoch: 013 Step: 00002097] Batch Translation Loss:   6.433530 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:26:28,204 [Epoch: 013 Step: 00002098] Batch Translation Loss:   6.067440 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:27:15,879 [Epoch: 013 Step: 00002099] Batch Translation Loss:   6.741998 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:28:20,423 [Epoch: 013 Step: 00002100] Batch Translation Loss:   6.002081 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:35:42,977 Validation result at epoch  13, step     2100: duration: 442.5362s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11169.43359	PPL: 8530.51465
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 2.03	(DEL: 21.56,	INS: 0.00,	SUB: 76.42)
	Sequence Accuracy 2.27
2022-01-02 01:35:52,237 Logging Recognition and Translation Outputs
2022-01-02 01:35:52,261 ========================================================================================================================
2022-01-02 01:35:52,261 Logging Sequence: deafvideo_3-damien23_3600
2022-01-02 01:35:52,262 	Text Reference  :	him
2022-01-02 01:35:52,262 	Text Hypothesis :	asl
2022-01-02 01:35:52,262 	Text Alignment  :	S  
2022-01-02 01:35:52,262 ========================================================================================================================
2022-01-02 01:35:52,262 Logging Sequence: deafvideo_2-sddsimple_1569
2022-01-02 01:35:52,262 	Text Reference  :	sydney catell
2022-01-02 01:35:52,262 	Text Hypothesis :	****** drafts
2022-01-02 01:35:52,262 	Text Alignment  :	D      S     
2022-01-02 01:35:52,262 ========================================================================================================================
2022-01-02 01:35:52,262 Logging Sequence: deafvideo_3-titans_4700
2022-01-02 01:35:52,263 	Text Reference  :	deanne bray
2022-01-02 01:35:52,263 	Text Hypothesis :	****** asl 
2022-01-02 01:35:52,263 	Text Alignment  :	D      S   
2022-01-02 01:35:52,263 ========================================================================================================================
2022-01-02 01:35:52,263 Logging Sequence: youtube_5-daniel_durant_5896
2022-01-02 01:35:52,263 	Text Reference  :	uv 
2022-01-02 01:35:52,263 	Text Hypothesis :	asl
2022-01-02 01:35:52,263 	Text Alignment  :	S  
2022-01-02 01:35:52,263 ========================================================================================================================
2022-01-02 01:35:52,263 Logging Sequence: youtube_1-catherine_mackinnon_2821
2022-01-02 01:35:52,264 	Text Reference  :	web page  
2022-01-02 01:35:52,264 	Text Hypothesis :	*** drafts
2022-01-02 01:35:52,264 	Text Alignment  :	D   S     
2022-01-02 01:35:52,264 ========================================================================================================================
2022-01-02 01:37:34,266 [Epoch: 013 Step: 00002101] Batch Translation Loss:   6.361508 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 01:38:36,055 [Epoch: 013 Step: 00002102] Batch Translation Loss:   6.812183 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:39:39,379 [Epoch: 013 Step: 00002103] Batch Translation Loss:   6.239173 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:40:23,012 [Epoch: 013 Step: 00002104] Batch Translation Loss:   6.865091 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:41:07,555 [Epoch: 013 Step: 00002105] Batch Translation Loss:   6.247846 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:41:50,571 [Epoch: 013 Step: 00002106] Batch Translation Loss:   6.225759 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:42:36,114 [Epoch: 013 Step: 00002107] Batch Translation Loss:   6.122097 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:42:58,978 [Epoch: 013 Step: 00002108] Batch Translation Loss:   6.236544 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:43:20,075 [Epoch: 013 Step: 00002109] Batch Translation Loss:   6.313397 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:43:42,899 [Epoch: 013 Step: 00002110] Batch Translation Loss:   6.409705 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:44:06,623 [Epoch: 013 Step: 00002111] Batch Translation Loss:   6.589222 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:44:50,862 [Epoch: 013 Step: 00002112] Batch Translation Loss:   6.386782 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:45:21,203 [Epoch: 013 Step: 00002113] Batch Translation Loss:   6.178101 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:45:47,712 [Epoch: 013 Step: 00002114] Batch Translation Loss:   6.347186 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:46:14,211 [Epoch: 013 Step: 00002115] Batch Translation Loss:   6.638333 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:46:40,001 [Epoch: 013 Step: 00002116] Batch Translation Loss:   6.719781 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:47:02,968 [Epoch: 013 Step: 00002117] Batch Translation Loss:   6.457086 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:47:28,229 [Epoch: 013 Step: 00002118] Batch Translation Loss:   6.290652 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:47:54,196 [Epoch: 013 Step: 00002119] Batch Translation Loss:   7.157557 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:48:21,793 [Epoch: 013 Step: 00002120] Batch Translation Loss:   6.741168 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:49:17,756 [Epoch: 013 Step: 00002121] Batch Translation Loss:   6.647725 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:50:43,430 [Epoch: 013 Step: 00002122] Batch Translation Loss:   6.725860 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 01:51:40,334 [Epoch: 013 Step: 00002123] Batch Translation Loss:   6.848185 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:52:30,311 [Epoch: 013 Step: 00002124] Batch Translation Loss:   5.664913 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:53:12,339 [Epoch: 013 Step: 00002125] Batch Translation Loss:   6.488280 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:53:46,997 [Epoch: 013 Step: 00002126] Batch Translation Loss:   6.920663 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:54:17,155 [Epoch: 013 Step: 00002127] Batch Translation Loss:   5.979758 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:54:42,364 [Epoch: 013 Step: 00002128] Batch Translation Loss:   6.408641 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:55:07,081 [Epoch: 013 Step: 00002129] Batch Translation Loss:   6.445180 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:55:37,506 [Epoch: 013 Step: 00002130] Batch Translation Loss:   6.295886 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:56:16,520 [Epoch: 013 Step: 00002131] Batch Translation Loss:   6.733329 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:56:41,975 [Epoch: 013 Step: 00002132] Batch Translation Loss:   6.234997 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:57:14,712 [Epoch: 013 Step: 00002133] Batch Translation Loss:   6.808053 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:57:41,910 [Epoch: 013 Step: 00002134] Batch Translation Loss:   6.619989 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:58:09,223 [Epoch: 013 Step: 00002135] Batch Translation Loss:   6.527895 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 01:58:57,734 [Epoch: 013 Step: 00002136] Batch Translation Loss:   5.954519 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:59:27,936 [Epoch: 013 Step: 00002137] Batch Translation Loss:   6.685085 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 01:59:54,871 [Epoch: 013 Step: 00002138] Batch Translation Loss:   6.527743 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:00:21,366 [Epoch: 013 Step: 00002139] Batch Translation Loss:   6.338925 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:02:52,105 [Epoch: 013 Step: 00002140] Batch Translation Loss:   6.576572 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 02:04:15,020 [Epoch: 013 Step: 00002141] Batch Translation Loss:   6.569234 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 02:05:14,303 [Epoch: 013 Step: 00002142] Batch Translation Loss:   6.867480 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:06:08,997 [Epoch: 013 Step: 00002143] Batch Translation Loss:   6.287309 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:07:03,121 [Epoch: 013 Step: 00002144] Batch Translation Loss:   6.886858 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:07:51,867 [Epoch: 013 Step: 00002145] Batch Translation Loss:   6.516085 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:08:27,869 [Epoch: 013 Step: 00002146] Batch Translation Loss:   6.296127 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:08:58,852 [Epoch: 013 Step: 00002147] Batch Translation Loss:   6.569856 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:09:29,779 [Epoch: 013 Step: 00002148] Batch Translation Loss:   6.510085 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:10:00,677 [Epoch: 013 Step: 00002149] Batch Translation Loss:   6.267549 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:10:58,326 [Epoch: 013 Step: 00002150] Batch Translation Loss:   5.975649 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:12:07,430 [Epoch: 013 Step: 00002151] Batch Translation Loss:   7.452523 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:13:11,736 [Epoch: 013 Step: 00002152] Batch Translation Loss:   6.044053 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:13:56,663 [Epoch: 013 Step: 00002153] Batch Translation Loss:   6.490706 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:14:43,824 [Epoch: 013 Step: 00002154] Batch Translation Loss:   6.703454 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:16:43,075 [Epoch: 013 Step: 00002155] Batch Translation Loss:   6.446850 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 02:18:10,894 [Epoch: 013 Step: 00002156] Batch Translation Loss:   6.282545 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:19:22,404 [Epoch: 013 Step: 00002157] Batch Translation Loss:   6.386937 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:20:17,627 [Epoch: 013 Step: 00002158] Batch Translation Loss:   6.746057 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:21:00,345 [Epoch: 013 Step: 00002159] Batch Translation Loss:   6.513691 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:21:43,666 [Epoch: 013 Step: 00002160] Batch Translation Loss:   6.050816 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:22:19,659 [Epoch: 013 Step: 00002161] Batch Translation Loss:   6.382140 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:22:57,286 [Epoch: 013 Step: 00002162] Batch Translation Loss:   6.149474 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:23:33,800 [Epoch: 013 Step: 00002163] Batch Translation Loss:   6.839010 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:24:39,244 [Epoch: 013 Step: 00002164] Batch Translation Loss:   6.422391 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:25:15,969 [Epoch: 013 Step: 00002165] Batch Translation Loss:   6.410267 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:25:52,334 [Epoch: 013 Step: 00002166] Batch Translation Loss:   7.034549 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:26:59,129 [Epoch: 013 Step: 00002167] Batch Translation Loss:   6.441349 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:28:43,488 [Epoch: 013 Step: 00002168] Batch Translation Loss:   6.219296 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 02:29:56,681 [Epoch: 013 Step: 00002169] Batch Translation Loss:   6.390737 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 02:31:07,911 [Epoch: 013 Step: 00002170] Batch Translation Loss:   6.342336 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 02:31:54,374 [Epoch: 013 Step: 00002171] Batch Translation Loss:   6.666262 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:32:41,917 [Epoch: 013 Step: 00002172] Batch Translation Loss:   6.690567 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:33:59,101 [Epoch: 013 Step: 00002173] Batch Translation Loss:   6.757109 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 02:34:37,861 [Epoch: 013 Step: 00002174] Batch Translation Loss:   6.180108 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:35:16,283 [Epoch: 013 Step: 00002175] Batch Translation Loss:   6.095055 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:36:01,579 [Epoch: 013 Step: 00002176] Batch Translation Loss:   6.756707 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:37:23,704 [Epoch: 013 Step: 00002177] Batch Translation Loss:   7.178150 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:38:11,273 [Epoch: 013 Step: 00002178] Batch Translation Loss:   6.176514 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:39:09,097 [Epoch: 013 Step: 00002179] Batch Translation Loss:   6.541741 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:40:57,129 [Epoch: 013 Step: 00002180] Batch Translation Loss:   6.367680 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 02:42:22,028 [Epoch: 013 Step: 00002181] Batch Translation Loss:   6.542723 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 02:43:49,200 [Epoch: 013 Step: 00002182] Batch Translation Loss:   6.202177 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 02:45:10,119 [Epoch: 013 Step: 00002183] Batch Translation Loss:   6.955588 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:46:26,642 [Epoch: 013 Step: 00002184] Batch Translation Loss:   6.941771 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 02:47:48,365 [Epoch: 013 Step: 00002185] Batch Translation Loss:   6.284111 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 02:49:00,074 [Epoch: 013 Step: 00002186] Batch Translation Loss:   5.724251 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:50:06,524 [Epoch: 013 Step: 00002187] Batch Translation Loss:   6.287911 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:51:28,103 [Epoch: 013 Step: 00002188] Batch Translation Loss:   6.497386 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 02:52:46,280 [Epoch: 013 Step: 00002189] Batch Translation Loss:   6.293576 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 02:53:52,595 [Epoch: 013 Step: 00002190] Batch Translation Loss:   6.679833 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:54:44,934 [Epoch: 013 Step: 00002191] Batch Translation Loss:   7.176978 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:55:29,957 [Epoch: 013 Step: 00002192] Batch Translation Loss:   6.180514 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:56:15,451 [Epoch: 013 Step: 00002193] Batch Translation Loss:   6.927110 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:57:06,741 [Epoch: 013 Step: 00002194] Batch Translation Loss:   6.412954 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 02:58:35,480 [Epoch: 013 Step: 00002195] Batch Translation Loss:   6.208863 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 02:59:27,829 [Epoch: 013 Step: 00002196] Batch Translation Loss:   6.332892 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 03:00:18,612 [Epoch: 013 Step: 00002197] Batch Translation Loss:   6.176940 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 03:01:09,427 [Epoch: 013 Step: 00002198] Batch Translation Loss:   6.283459 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 03:02:38,018 [Epoch: 013 Step: 00002199] Batch Translation Loss:   6.555570 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 03:03:59,282 [Epoch: 013 Step: 00002200] Batch Translation Loss:   6.106381 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 03:15:40,542 Validation result at epoch  13, step     2200: duration: 701.1699s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11503.32715	PPL: 9427.76172
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.03	(DEL: 23.55,	INS: 0.00,	SUB: 75.42)
	Sequence Accuracy 1.35
2022-01-02 03:15:49,225 Logging Recognition and Translation Outputs
2022-01-02 03:15:49,269 ========================================================================================================================
2022-01-02 03:15:49,269 Logging Sequence: deafvideo_3-titans_4701
2022-01-02 03:15:49,270 	Text Reference  :	sckre of
2022-01-02 03:15:49,270 	Text Hypothesis :	***** so
2022-01-02 03:15:49,270 	Text Alignment  :	D     S 
2022-01-02 03:15:49,270 ========================================================================================================================
2022-01-02 03:15:49,270 Logging Sequence: youtube_5-roberta_cordano_6152
2022-01-02 03:15:49,270 	Text Reference  :	filter f lens
2022-01-02 03:15:49,270 	Text Hypothesis :	****** * so  
2022-01-02 03:15:49,270 	Text Alignment  :	D      D S   
2022-01-02 03:15:49,271 ========================================================================================================================
2022-01-02 03:15:49,271 Logging Sequence: youtube_4-tim_albert_5271
2022-01-02 03:15:49,271 	Text Reference  :	cast
2022-01-02 03:15:49,271 	Text Hypothesis :	so  
2022-01-02 03:15:49,271 	Text Alignment  :	S   
2022-01-02 03:15:49,271 ========================================================================================================================
2022-01-02 03:15:49,271 Logging Sequence: youtube_5-roberta_cordano_6138
2022-01-02 03:15:49,271 	Text Reference  :	asl
2022-01-02 03:15:49,271 	Text Hypothesis :	so 
2022-01-02 03:15:49,272 	Text Alignment  :	S  
2022-01-02 03:15:49,272 ========================================================================================================================
2022-01-02 03:15:49,272 Logging Sequence: deafvideo_3-deafgoldenhair_3079
2022-01-02 03:15:49,272 	Text Reference  :	ark
2022-01-02 03:15:49,272 	Text Hypothesis :	so 
2022-01-02 03:15:49,272 	Text Alignment  :	S  
2022-01-02 03:15:49,272 ========================================================================================================================
2022-01-02 03:18:16,163 [Epoch: 013 Step: 00002201] Batch Translation Loss:   6.117704 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 03:19:56,337 [Epoch: 013 Step: 00002202] Batch Translation Loss:   6.748993 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 03:23:51,938 [Epoch: 013 Step: 00002203] Batch Translation Loss:   6.477217 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 03:25:41,906 [Epoch: 013 Step: 00002204] Batch Translation Loss:   6.392445 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 03:28:02,956 [Epoch: 013 Step: 00002205] Batch Translation Loss:   7.057136 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 03:29:42,062 [Epoch: 013 Step: 00002206] Batch Translation Loss:   6.852118 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 03:31:28,592 [Epoch: 013 Step: 00002207] Batch Translation Loss:   6.176470 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 03:33:24,173 [Epoch: 013 Step: 00002208] Batch Translation Loss:   6.265063 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 03:35:22,498 [Epoch: 013 Step: 00002209] Batch Translation Loss:   7.083885 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 03:35:22,757 Epoch  13: Total Training Recognition Loss -1.00  Total Training Translation Loss 1100.00 
2022-01-02 03:35:22,757 EPOCH 14
2022-01-02 03:35:51,974 [Epoch: 014 Step: 00002210] Batch Translation Loss:   5.878345 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 03:36:47,025 [Epoch: 014 Step: 00002211] Batch Translation Loss:   6.917555 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 03:37:24,403 [Epoch: 014 Step: 00002212] Batch Translation Loss:   6.530214 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 03:38:35,167 [Epoch: 014 Step: 00002213] Batch Translation Loss:   6.477704 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 03:39:12,394 [Epoch: 014 Step: 00002214] Batch Translation Loss:   6.584164 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 03:39:49,974 [Epoch: 014 Step: 00002215] Batch Translation Loss:   6.878634 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 03:40:05,853 [Epoch: 014 Step: 00002216] Batch Translation Loss:   7.341089 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-02 03:40:21,989 [Epoch: 014 Step: 00002217] Batch Translation Loss:   6.693907 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-02 03:40:38,945 [Epoch: 014 Step: 00002218] Batch Translation Loss:   6.583391 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-02 03:40:55,805 [Epoch: 014 Step: 00002219] Batch Translation Loss:   6.715109 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-02 03:41:13,475 [Epoch: 014 Step: 00002220] Batch Translation Loss:   6.365345 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-02 03:41:33,519 [Epoch: 014 Step: 00002221] Batch Translation Loss:   5.877958 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 03:41:45,030 [Epoch: 014 Step: 00002222] Batch Translation Loss:   5.518620 => Txt Tokens per Sec:        4 || Lr: 0.000700
2022-01-02 03:42:09,139 [Epoch: 014 Step: 00002223] Batch Translation Loss:   6.956587 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 03:42:34,208 [Epoch: 014 Step: 00002224] Batch Translation Loss:   6.531631 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 03:42:52,523 [Epoch: 014 Step: 00002225] Batch Translation Loss:   5.925452 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 03:43:12,090 [Epoch: 014 Step: 00002226] Batch Translation Loss:   6.580721 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 03:43:31,026 [Epoch: 014 Step: 00002227] Batch Translation Loss:   6.779718 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 03:43:50,105 [Epoch: 014 Step: 00002228] Batch Translation Loss:   6.307468 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 03:44:02,385 [Epoch: 014 Step: 00002229] Batch Translation Loss:   6.729510 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-02 03:44:23,931 [Epoch: 014 Step: 00002230] Batch Translation Loss:   5.987682 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 03:44:46,196 [Epoch: 014 Step: 00002231] Batch Translation Loss:   6.101112 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 03:45:08,660 [Epoch: 014 Step: 00002232] Batch Translation Loss:   6.153835 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 03:45:28,510 [Epoch: 014 Step: 00002233] Batch Translation Loss:   6.552892 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 03:45:58,053 [Epoch: 014 Step: 00002234] Batch Translation Loss:   6.990932 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 03:46:30,023 [Epoch: 014 Step: 00002235] Batch Translation Loss:   5.859850 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 03:46:50,672 [Epoch: 014 Step: 00002236] Batch Translation Loss:   6.428254 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 03:47:09,140 [Epoch: 014 Step: 00002237] Batch Translation Loss:   6.742259 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 03:47:34,609 [Epoch: 014 Step: 00002238] Batch Translation Loss:   6.555967 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 03:47:52,464 [Epoch: 014 Step: 00002239] Batch Translation Loss:   6.693142 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 03:48:17,772 [Epoch: 014 Step: 00002240] Batch Translation Loss:   6.221638 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 03:48:35,672 [Epoch: 014 Step: 00002241] Batch Translation Loss:   6.286869 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 03:49:12,889 [Epoch: 014 Step: 00002242] Batch Translation Loss:   6.512612 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 03:49:50,832 [Epoch: 014 Step: 00002243] Batch Translation Loss:   6.697985 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 03:50:18,840 [Epoch: 014 Step: 00002244] Batch Translation Loss:   6.952425 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 03:50:42,255 [Epoch: 014 Step: 00002245] Batch Translation Loss:   6.320749 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 03:51:19,331 [Epoch: 014 Step: 00002246] Batch Translation Loss:   6.822103 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 03:51:47,372 [Epoch: 014 Step: 00002247] Batch Translation Loss:   6.281793 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 03:52:13,849 [Epoch: 014 Step: 00002248] Batch Translation Loss:   6.049704 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 03:52:52,827 [Epoch: 014 Step: 00002249] Batch Translation Loss:   6.170615 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 03:53:21,168 [Epoch: 014 Step: 00002250] Batch Translation Loss:   6.360819 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 03:53:48,961 [Epoch: 014 Step: 00002251] Batch Translation Loss:   6.763545 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 03:54:15,010 [Epoch: 014 Step: 00002252] Batch Translation Loss:   6.119427 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 03:54:38,933 [Epoch: 014 Step: 00002253] Batch Translation Loss:   6.642635 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 03:55:25,241 [Epoch: 014 Step: 00002254] Batch Translation Loss:   5.995481 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 03:55:51,907 [Epoch: 014 Step: 00002255] Batch Translation Loss:   7.083490 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 03:56:19,990 [Epoch: 014 Step: 00002256] Batch Translation Loss:   5.999864 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 03:56:43,545 [Epoch: 014 Step: 00002257] Batch Translation Loss:   6.799787 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 03:57:21,170 [Epoch: 014 Step: 00002258] Batch Translation Loss:   6.203192 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 03:57:51,627 [Epoch: 014 Step: 00002259] Batch Translation Loss:   6.625470 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 03:58:14,578 [Epoch: 014 Step: 00002260] Batch Translation Loss:   6.203468 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 03:58:41,862 [Epoch: 014 Step: 00002261] Batch Translation Loss:   6.510941 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 03:59:10,475 [Epoch: 014 Step: 00002262] Batch Translation Loss:   6.295387 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 03:59:39,696 [Epoch: 014 Step: 00002263] Batch Translation Loss:   6.604222 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:00:04,197 [Epoch: 014 Step: 00002264] Batch Translation Loss:   6.585489 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:00:28,718 [Epoch: 014 Step: 00002265] Batch Translation Loss:   6.439259 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 04:01:00,561 [Epoch: 014 Step: 00002266] Batch Translation Loss:   6.584737 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:01:34,579 [Epoch: 014 Step: 00002267] Batch Translation Loss:   6.341315 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:02:51,890 [Epoch: 014 Step: 00002268] Batch Translation Loss:   6.312421 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:03:20,165 [Epoch: 014 Step: 00002269] Batch Translation Loss:   6.335359 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:03:56,636 [Epoch: 014 Step: 00002270] Batch Translation Loss:   6.094478 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:04:28,725 [Epoch: 014 Step: 00002271] Batch Translation Loss:   6.140872 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:05:21,640 [Epoch: 014 Step: 00002272] Batch Translation Loss:   6.396944 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:05:50,310 [Epoch: 014 Step: 00002273] Batch Translation Loss:   6.512524 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:06:17,046 [Epoch: 014 Step: 00002274] Batch Translation Loss:   5.999088 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:06:46,304 [Epoch: 014 Step: 00002275] Batch Translation Loss:   6.907376 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 04:07:15,765 [Epoch: 014 Step: 00002276] Batch Translation Loss:   6.061153 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:07:44,610 [Epoch: 014 Step: 00002277] Batch Translation Loss:   6.308590 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:08:40,009 [Epoch: 014 Step: 00002278] Batch Translation Loss:   6.697482 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:09:12,532 [Epoch: 014 Step: 00002279] Batch Translation Loss:   6.458928 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:09:40,990 [Epoch: 014 Step: 00002280] Batch Translation Loss:   6.574931 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:10:09,189 [Epoch: 014 Step: 00002281] Batch Translation Loss:   6.088787 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:10:43,721 [Epoch: 014 Step: 00002282] Batch Translation Loss:   6.645452 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:11:40,734 [Epoch: 014 Step: 00002283] Batch Translation Loss:   6.760935 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:12:15,711 [Epoch: 014 Step: 00002284] Batch Translation Loss:   6.779305 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:13:05,894 [Epoch: 014 Step: 00002285] Batch Translation Loss:   6.628415 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:13:41,744 [Epoch: 014 Step: 00002286] Batch Translation Loss:   6.087227 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:14:20,948 [Epoch: 014 Step: 00002287] Batch Translation Loss:   6.017288 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:15:01,807 [Epoch: 014 Step: 00002288] Batch Translation Loss:   6.336787 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:15:46,252 [Epoch: 014 Step: 00002289] Batch Translation Loss:   6.077129 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:16:16,468 [Epoch: 014 Step: 00002290] Batch Translation Loss:   5.917760 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:17:12,710 [Epoch: 014 Step: 00002291] Batch Translation Loss:   6.540043 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:18:07,153 [Epoch: 014 Step: 00002292] Batch Translation Loss:   5.936155 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:18:42,730 [Epoch: 014 Step: 00002293] Batch Translation Loss:   6.912714 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:19:38,490 [Epoch: 014 Step: 00002294] Batch Translation Loss:   6.225424 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:20:34,279 [Epoch: 014 Step: 00002295] Batch Translation Loss:   6.114651 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:21:23,480 [Epoch: 014 Step: 00002296] Batch Translation Loss:   6.019135 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:22:20,588 [Epoch: 014 Step: 00002297] Batch Translation Loss:   5.818489 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:23:05,485 [Epoch: 014 Step: 00002298] Batch Translation Loss:   6.118252 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:23:54,922 [Epoch: 014 Step: 00002299] Batch Translation Loss:   6.156168 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:24:55,025 [Epoch: 014 Step: 00002300] Batch Translation Loss:   6.335457 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:34:25,311 Validation result at epoch  14, step     2300: duration: 570.2751s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 12295.01172	PPL: 15651.10156
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.96	(DEL: 24.67,	INS: 0.00,	SUB: 73.37)
	Sequence Accuracy 1.77
2022-01-02 04:34:31,994 Logging Recognition and Translation Outputs
2022-01-02 04:34:32,048 ========================================================================================================================
2022-01-02 04:34:32,048 Logging Sequence: deafvideo_3-otismhill82_4609
2022-01-02 04:34:32,049 	Text Reference  :	stairs
2022-01-02 04:34:32,049 	Text Hypothesis :	ok    
2022-01-02 04:34:32,049 	Text Alignment  :	S     
2022-01-02 04:34:32,049 ========================================================================================================================
2022-01-02 04:34:32,050 Logging Sequence: youtube_1-shoshannah_stern_2379
2022-01-02 04:34:32,050 	Text Reference  :	do
2022-01-02 04:34:32,050 	Text Hypothesis :	ok
2022-01-02 04:34:32,050 	Text Alignment  :	S 
2022-01-02 04:34:32,050 ========================================================================================================================
2022-01-02 04:34:32,051 Logging Sequence: youtube_5-roberta_cordano_6131
2022-01-02 04:34:32,051 	Text Reference  :	ok
2022-01-02 04:34:32,051 	Text Hypothesis :	ok
2022-01-02 04:34:32,051 	Text Alignment  :	  
2022-01-02 04:34:32,051 ========================================================================================================================
2022-01-02 04:34:32,051 Logging Sequence: youtube_1-shoshannah_stern_2380
2022-01-02 04:34:32,052 	Text Reference  :	tump
2022-01-02 04:34:32,052 	Text Hypothesis :	ok  
2022-01-02 04:34:32,052 	Text Alignment  :	S   
2022-01-02 04:34:32,052 ========================================================================================================================
2022-01-02 04:34:32,052 Logging Sequence: youtube_5-sean_berdy_6080
2022-01-02 04:34:32,053 	Text Reference  :	savior
2022-01-02 04:34:32,053 	Text Hypothesis :	ok    
2022-01-02 04:34:32,053 	Text Alignment  :	S     
2022-01-02 04:34:32,053 ========================================================================================================================
2022-01-02 04:35:26,533 [Epoch: 014 Step: 00002301] Batch Translation Loss:   6.404571 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:36:05,939 [Epoch: 014 Step: 00002302] Batch Translation Loss:   6.197424 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:36:53,255 [Epoch: 014 Step: 00002303] Batch Translation Loss:   6.342543 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:37:39,910 [Epoch: 014 Step: 00002304] Batch Translation Loss:   6.716684 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:38:39,984 [Epoch: 014 Step: 00002305] Batch Translation Loss:   6.247080 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:39:30,578 [Epoch: 014 Step: 00002306] Batch Translation Loss:   6.139492 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:40:20,609 [Epoch: 014 Step: 00002307] Batch Translation Loss:   6.657240 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:41:40,205 [Epoch: 014 Step: 00002308] Batch Translation Loss:   6.932125 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 04:42:33,024 [Epoch: 014 Step: 00002309] Batch Translation Loss:   6.128974 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:43:22,289 [Epoch: 014 Step: 00002310] Batch Translation Loss:   6.368443 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:44:13,039 [Epoch: 014 Step: 00002311] Batch Translation Loss:   6.058024 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:44:59,989 [Epoch: 014 Step: 00002312] Batch Translation Loss:   6.341691 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:45:43,086 [Epoch: 014 Step: 00002313] Batch Translation Loss:   5.930197 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:46:34,134 [Epoch: 014 Step: 00002314] Batch Translation Loss:   5.669298 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:47:12,336 [Epoch: 014 Step: 00002315] Batch Translation Loss:   6.524132 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:48:03,804 [Epoch: 014 Step: 00002316] Batch Translation Loss:   6.511740 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:48:43,413 [Epoch: 014 Step: 00002317] Batch Translation Loss:   6.641820 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:49:30,034 [Epoch: 014 Step: 00002318] Batch Translation Loss:   6.302623 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:50:16,253 [Epoch: 014 Step: 00002319] Batch Translation Loss:   5.863623 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:50:41,795 [Epoch: 014 Step: 00002320] Batch Translation Loss:   6.878015 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 04:51:33,736 [Epoch: 014 Step: 00002321] Batch Translation Loss:   6.099992 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:52:21,532 [Epoch: 014 Step: 00002322] Batch Translation Loss:   5.823498 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:53:13,316 [Epoch: 014 Step: 00002323] Batch Translation Loss:   6.351691 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:53:50,641 [Epoch: 014 Step: 00002324] Batch Translation Loss:   6.436257 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:55:20,674 [Epoch: 014 Step: 00002325] Batch Translation Loss:   6.454963 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 04:56:05,423 [Epoch: 014 Step: 00002326] Batch Translation Loss:   6.580205 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:56:54,014 [Epoch: 014 Step: 00002327] Batch Translation Loss:   6.288253 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:57:35,420 [Epoch: 014 Step: 00002328] Batch Translation Loss:   5.743684 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:58:21,657 [Epoch: 014 Step: 00002329] Batch Translation Loss:   6.325581 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 04:59:17,356 [Epoch: 014 Step: 00002330] Batch Translation Loss:   6.785206 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:00:08,570 [Epoch: 014 Step: 00002331] Batch Translation Loss:   6.071088 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:00:53,079 [Epoch: 014 Step: 00002332] Batch Translation Loss:   6.629051 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:01:26,604 [Epoch: 014 Step: 00002333] Batch Translation Loss:   5.684837 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:02:18,125 [Epoch: 014 Step: 00002334] Batch Translation Loss:   6.311141 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:03:09,463 [Epoch: 014 Step: 00002335] Batch Translation Loss:   6.533853 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:04:41,314 [Epoch: 014 Step: 00002336] Batch Translation Loss:   6.523428 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 05:05:36,838 [Epoch: 014 Step: 00002337] Batch Translation Loss:   6.259810 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:06:34,841 [Epoch: 014 Step: 00002338] Batch Translation Loss:   6.635221 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:07:25,117 [Epoch: 014 Step: 00002339] Batch Translation Loss:   5.935259 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:08:13,208 [Epoch: 014 Step: 00002340] Batch Translation Loss:   5.769884 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:09:05,038 [Epoch: 014 Step: 00002341] Batch Translation Loss:   7.173955 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:09:59,141 [Epoch: 014 Step: 00002342] Batch Translation Loss:   6.428495 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:10:49,986 [Epoch: 014 Step: 00002343] Batch Translation Loss:   6.659771 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:12:00,714 [Epoch: 014 Step: 00002344] Batch Translation Loss:   5.880085 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 05:13:36,916 [Epoch: 014 Step: 00002345] Batch Translation Loss:   6.646493 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 05:14:31,621 [Epoch: 014 Step: 00002346] Batch Translation Loss:   5.963809 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:15:12,765 [Epoch: 014 Step: 00002347] Batch Translation Loss:   5.788731 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:15:59,614 [Epoch: 014 Step: 00002348] Batch Translation Loss:   6.190103 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:16:31,155 [Epoch: 014 Step: 00002349] Batch Translation Loss:   5.675008 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:18:01,878 [Epoch: 014 Step: 00002350] Batch Translation Loss:   6.628368 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 05:19:01,184 [Epoch: 014 Step: 00002351] Batch Translation Loss:   6.357641 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:20:02,647 [Epoch: 014 Step: 00002352] Batch Translation Loss:   6.033693 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:21:02,668 [Epoch: 014 Step: 00002353] Batch Translation Loss:   6.650760 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:21:42,474 [Epoch: 014 Step: 00002354] Batch Translation Loss:   6.068204 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:22:41,987 [Epoch: 014 Step: 00002355] Batch Translation Loss:   6.232842 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:23:45,394 [Epoch: 014 Step: 00002356] Batch Translation Loss:   6.176188 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:24:43,200 [Epoch: 014 Step: 00002357] Batch Translation Loss:   6.075364 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:25:52,978 [Epoch: 014 Step: 00002358] Batch Translation Loss:   6.695783 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:27:05,565 [Epoch: 014 Step: 00002359] Batch Translation Loss:   5.785335 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:28:05,649 [Epoch: 014 Step: 00002360] Batch Translation Loss:   6.276627 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:29:25,870 [Epoch: 014 Step: 00002361] Batch Translation Loss:   6.134923 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 05:30:29,995 [Epoch: 014 Step: 00002362] Batch Translation Loss:   5.983738 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:32:02,166 [Epoch: 014 Step: 00002363] Batch Translation Loss:   6.721239 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 05:33:05,285 [Epoch: 014 Step: 00002364] Batch Translation Loss:   6.414822 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:33:58,145 [Epoch: 014 Step: 00002365] Batch Translation Loss:   5.082836 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:34:53,336 [Epoch: 014 Step: 00002366] Batch Translation Loss:   6.362003 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:36:54,421 [Epoch: 014 Step: 00002367] Batch Translation Loss:   7.221427 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 05:37:43,492 [Epoch: 014 Step: 00002368] Batch Translation Loss:   6.446584 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:38:51,650 [Epoch: 014 Step: 00002369] Batch Translation Loss:   6.513654 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:39:50,711 [Epoch: 014 Step: 00002370] Batch Translation Loss:   6.440043 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:41:25,364 [Epoch: 014 Step: 00002371] Batch Translation Loss:   6.399800 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 05:42:32,928 [Epoch: 014 Step: 00002372] Batch Translation Loss:   6.975716 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:43:11,252 [Epoch: 014 Step: 00002373] Batch Translation Loss:   5.684860 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:44:55,251 [Epoch: 014 Step: 00002374] Batch Translation Loss:   6.238807 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 05:45:46,969 [Epoch: 014 Step: 00002375] Batch Translation Loss:   5.856613 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:46:31,574 [Epoch: 014 Step: 00002376] Batch Translation Loss:   6.540545 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:47:12,000 [Epoch: 014 Step: 00002377] Batch Translation Loss:   6.470571 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:47:51,554 [Epoch: 014 Step: 00002378] Batch Translation Loss:   6.495413 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:48:32,114 [Epoch: 014 Step: 00002379] Batch Translation Loss:   6.198301 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:48:32,232 Epoch  14: Total Training Recognition Loss -1.00  Total Training Translation Loss 1080.70 
2022-01-02 05:48:32,233 EPOCH 15
2022-01-02 05:48:44,145 [Epoch: 015 Step: 00002380] Batch Translation Loss:   6.403263 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-02 05:48:54,780 [Epoch: 015 Step: 00002381] Batch Translation Loss:   6.668831 => Txt Tokens per Sec:        4 || Lr: 0.000700
2022-01-02 05:49:08,939 [Epoch: 015 Step: 00002382] Batch Translation Loss:   6.764656 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-02 05:49:24,524 [Epoch: 015 Step: 00002383] Batch Translation Loss:   6.734075 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-02 05:49:38,420 [Epoch: 015 Step: 00002384] Batch Translation Loss:   6.311680 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-02 05:49:50,872 [Epoch: 015 Step: 00002385] Batch Translation Loss:   6.890029 => Txt Tokens per Sec:        4 || Lr: 0.000700
2022-01-02 05:50:01,868 [Epoch: 015 Step: 00002386] Batch Translation Loss:   6.519560 => Txt Tokens per Sec:        4 || Lr: 0.000700
2022-01-02 05:50:21,756 [Epoch: 015 Step: 00002387] Batch Translation Loss:   6.420840 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 05:50:36,490 [Epoch: 015 Step: 00002388] Batch Translation Loss:   6.948293 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-02 05:50:50,516 [Epoch: 015 Step: 00002389] Batch Translation Loss:   6.668159 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-02 05:51:09,543 [Epoch: 015 Step: 00002390] Batch Translation Loss:   6.128371 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 05:51:22,823 [Epoch: 015 Step: 00002391] Batch Translation Loss:   6.673768 => Txt Tokens per Sec:        4 || Lr: 0.000700
2022-01-02 05:51:39,938 [Epoch: 015 Step: 00002392] Batch Translation Loss:   6.578036 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 05:52:07,243 [Epoch: 015 Step: 00002393] Batch Translation Loss:   6.751240 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 05:52:22,907 [Epoch: 015 Step: 00002394] Batch Translation Loss:   6.224410 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-02 05:52:43,084 [Epoch: 015 Step: 00002395] Batch Translation Loss:   6.297110 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 05:53:03,069 [Epoch: 015 Step: 00002396] Batch Translation Loss:   6.330590 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 05:53:20,262 [Epoch: 015 Step: 00002397] Batch Translation Loss:   6.939379 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 05:53:48,771 [Epoch: 015 Step: 00002398] Batch Translation Loss:   6.397182 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 05:54:07,381 [Epoch: 015 Step: 00002399] Batch Translation Loss:   6.019057 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 05:54:24,431 [Epoch: 015 Step: 00002400] Batch Translation Loss:   6.138983 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 06:04:53,376 Validation result at epoch  15, step     2400: duration: 628.9204s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 12348.08594	PPL: 12587.16016
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.45	(DEL: 27.29,	INS: 0.00,	SUB: 71.25)
	Sequence Accuracy 1.58
2022-01-02 06:05:01,510 Logging Recognition and Translation Outputs
2022-01-02 06:05:01,578 ========================================================================================================================
2022-01-02 06:05:01,578 Logging Sequence: youtube_5-roberta_cordano_6131
2022-01-02 06:05:01,579 	Text Reference  :	mat seatle
2022-01-02 06:05:01,579 	Text Hypothesis :	*** asl   
2022-01-02 06:05:01,579 	Text Alignment  :	D   S     
2022-01-02 06:05:01,579 ========================================================================================================================
2022-01-02 06:05:01,579 Logging Sequence: youtube_1-melvin_patterson_2358
2022-01-02 06:05:01,580 	Text Reference  :	ficton
2022-01-02 06:05:01,580 	Text Hypothesis :	asl   
2022-01-02 06:05:01,580 	Text Alignment  :	S     
2022-01-02 06:05:01,580 ========================================================================================================================
2022-01-02 06:05:01,581 Logging Sequence: deafvideo_3-otismhill82_4611
2022-01-02 06:05:01,581 	Text Reference  :	doman
2022-01-02 06:05:01,581 	Text Hypothesis :	asl  
2022-01-02 06:05:01,581 	Text Alignment  :	S    
2022-01-02 06:05:01,582 ========================================================================================================================
2022-01-02 06:05:01,582 Logging Sequence: youtube_4-howard_rosenblum_5566
2022-01-02 06:05:01,582 	Text Reference  :	email
2022-01-02 06:05:01,582 	Text Hypothesis :	ok   
2022-01-02 06:05:01,582 	Text Alignment  :	S    
2022-01-02 06:05:01,583 ========================================================================================================================
2022-01-02 06:05:01,583 Logging Sequence: aslized-joy_maisel_6419
2022-01-02 06:05:01,583 	Text Reference  :	agent
2022-01-02 06:05:01,583 	Text Hypothesis :	ok   
2022-01-02 06:05:01,583 	Text Alignment  :	S    
2022-01-02 06:05:01,584 ========================================================================================================================
2022-01-02 06:05:58,130 [Epoch: 015 Step: 00002401] Batch Translation Loss:   6.951284 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:06:32,040 [Epoch: 015 Step: 00002402] Batch Translation Loss:   6.335819 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:07:12,301 [Epoch: 015 Step: 00002403] Batch Translation Loss:   6.065441 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:07:40,366 [Epoch: 015 Step: 00002404] Batch Translation Loss:   6.907720 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 06:07:58,297 [Epoch: 015 Step: 00002405] Batch Translation Loss:   6.761351 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 06:08:21,041 [Epoch: 015 Step: 00002406] Batch Translation Loss:   5.619735 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:08:38,541 [Epoch: 015 Step: 00002407] Batch Translation Loss:   5.866936 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 06:08:58,027 [Epoch: 015 Step: 00002408] Batch Translation Loss:   6.404712 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 06:09:15,408 [Epoch: 015 Step: 00002409] Batch Translation Loss:   6.434285 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 06:09:33,009 [Epoch: 015 Step: 00002410] Batch Translation Loss:   6.795733 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 06:09:54,485 [Epoch: 015 Step: 00002411] Batch Translation Loss:   6.738996 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 06:10:16,330 [Epoch: 015 Step: 00002412] Batch Translation Loss:   6.912932 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 06:10:35,238 [Epoch: 015 Step: 00002413] Batch Translation Loss:   6.328958 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 06:11:11,036 [Epoch: 015 Step: 00002414] Batch Translation Loss:   6.779865 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:11:32,347 [Epoch: 015 Step: 00002415] Batch Translation Loss:   6.188480 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 06:12:04,159 [Epoch: 015 Step: 00002416] Batch Translation Loss:   6.429487 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:12:24,324 [Epoch: 015 Step: 00002417] Batch Translation Loss:   6.539430 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 06:13:02,418 [Epoch: 015 Step: 00002418] Batch Translation Loss:   6.253952 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:13:43,981 [Epoch: 015 Step: 00002419] Batch Translation Loss:   6.419709 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:14:13,818 [Epoch: 015 Step: 00002420] Batch Translation Loss:   6.180546 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:14:42,139 [Epoch: 015 Step: 00002421] Batch Translation Loss:   6.459326 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:15:40,053 [Epoch: 015 Step: 00002422] Batch Translation Loss:   6.303542 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:16:09,214 [Epoch: 015 Step: 00002423] Batch Translation Loss:   6.510732 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:16:52,395 [Epoch: 015 Step: 00002424] Batch Translation Loss:   6.865592 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:17:17,551 [Epoch: 015 Step: 00002425] Batch Translation Loss:   6.222712 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 06:17:45,538 [Epoch: 015 Step: 00002426] Batch Translation Loss:   6.322449 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 06:18:33,675 [Epoch: 015 Step: 00002427] Batch Translation Loss:   6.719754 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:19:02,218 [Epoch: 015 Step: 00002428] Batch Translation Loss:   5.946772 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:19:33,752 [Epoch: 015 Step: 00002429] Batch Translation Loss:   6.222929 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 06:20:01,078 [Epoch: 015 Step: 00002430] Batch Translation Loss:   7.568457 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 06:20:32,543 [Epoch: 015 Step: 00002431] Batch Translation Loss:   6.893767 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:21:00,025 [Epoch: 015 Step: 00002432] Batch Translation Loss:   6.476536 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:21:28,748 [Epoch: 015 Step: 00002433] Batch Translation Loss:   6.351235 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:22:15,896 [Epoch: 015 Step: 00002434] Batch Translation Loss:   6.770160 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:22:48,166 [Epoch: 015 Step: 00002435] Batch Translation Loss:   5.840972 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:23:10,391 [Epoch: 015 Step: 00002436] Batch Translation Loss:   5.900222 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:24:09,309 [Epoch: 015 Step: 00002437] Batch Translation Loss:   6.610707 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:24:41,169 [Epoch: 015 Step: 00002438] Batch Translation Loss:   6.812224 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:25:09,622 [Epoch: 015 Step: 00002439] Batch Translation Loss:   6.205924 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:25:41,514 [Epoch: 015 Step: 00002440] Batch Translation Loss:   5.793078 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:26:06,361 [Epoch: 015 Step: 00002441] Batch Translation Loss:   6.575634 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:26:25,978 [Epoch: 015 Step: 00002442] Batch Translation Loss:   6.143063 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 06:26:59,957 [Epoch: 015 Step: 00002443] Batch Translation Loss:   6.320484 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:27:32,231 [Epoch: 015 Step: 00002444] Batch Translation Loss:   6.010153 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:28:22,518 [Epoch: 015 Step: 00002445] Batch Translation Loss:   6.160197 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:28:54,021 [Epoch: 015 Step: 00002446] Batch Translation Loss:   6.356333 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:29:27,940 [Epoch: 015 Step: 00002447] Batch Translation Loss:   6.659785 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:30:05,019 [Epoch: 015 Step: 00002448] Batch Translation Loss:   6.116455 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:30:28,310 [Epoch: 015 Step: 00002449] Batch Translation Loss:   6.368945 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 06:31:11,534 [Epoch: 015 Step: 00002450] Batch Translation Loss:   6.611677 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:31:42,360 [Epoch: 015 Step: 00002451] Batch Translation Loss:   6.721033 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:32:14,325 [Epoch: 015 Step: 00002452] Batch Translation Loss:   5.494972 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:32:53,757 [Epoch: 015 Step: 00002453] Batch Translation Loss:   7.065276 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:33:27,400 [Epoch: 015 Step: 00002454] Batch Translation Loss:   6.240047 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:34:04,541 [Epoch: 015 Step: 00002455] Batch Translation Loss:   6.228412 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:34:33,559 [Epoch: 015 Step: 00002456] Batch Translation Loss:   6.201552 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:35:10,705 [Epoch: 015 Step: 00002457] Batch Translation Loss:   5.684989 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:35:51,569 [Epoch: 015 Step: 00002458] Batch Translation Loss:   6.224894 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:36:19,153 [Epoch: 015 Step: 00002459] Batch Translation Loss:   6.458083 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:36:53,025 [Epoch: 015 Step: 00002460] Batch Translation Loss:   6.794975 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:37:27,130 [Epoch: 015 Step: 00002461] Batch Translation Loss:   6.246764 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:38:08,243 [Epoch: 015 Step: 00002462] Batch Translation Loss:   6.661621 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:38:37,232 [Epoch: 015 Step: 00002463] Batch Translation Loss:   6.550586 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:39:15,174 [Epoch: 015 Step: 00002464] Batch Translation Loss:   6.378101 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:39:52,681 [Epoch: 015 Step: 00002465] Batch Translation Loss:   6.475269 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:40:50,443 [Epoch: 015 Step: 00002466] Batch Translation Loss:   6.268822 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:41:29,201 [Epoch: 015 Step: 00002467] Batch Translation Loss:   6.012478 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:42:14,296 [Epoch: 015 Step: 00002468] Batch Translation Loss:   6.317209 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:42:51,841 [Epoch: 015 Step: 00002469] Batch Translation Loss:   6.154939 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:43:32,485 [Epoch: 015 Step: 00002470] Batch Translation Loss:   6.309626 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:44:42,156 [Epoch: 015 Step: 00002471] Batch Translation Loss:   6.456702 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:45:29,957 [Epoch: 015 Step: 00002472] Batch Translation Loss:   6.323029 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:46:12,399 [Epoch: 015 Step: 00002473] Batch Translation Loss:   6.675941 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:46:46,528 [Epoch: 015 Step: 00002474] Batch Translation Loss:   6.670887 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:47:19,128 [Epoch: 015 Step: 00002475] Batch Translation Loss:   6.366995 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:48:21,796 [Epoch: 015 Step: 00002476] Batch Translation Loss:   5.546993 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:48:58,275 [Epoch: 015 Step: 00002477] Batch Translation Loss:   6.106393 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:49:34,819 [Epoch: 015 Step: 00002478] Batch Translation Loss:   5.641380 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:50:18,504 [Epoch: 015 Step: 00002479] Batch Translation Loss:   5.636273 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:51:02,253 [Epoch: 015 Step: 00002480] Batch Translation Loss:   6.445390 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:51:48,302 [Epoch: 015 Step: 00002481] Batch Translation Loss:   5.699317 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:52:31,354 [Epoch: 015 Step: 00002482] Batch Translation Loss:   5.810551 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:53:20,382 [Epoch: 015 Step: 00002483] Batch Translation Loss:   6.558969 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:54:07,370 [Epoch: 015 Step: 00002484] Batch Translation Loss:   5.857739 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:54:55,209 [Epoch: 015 Step: 00002485] Batch Translation Loss:   5.692006 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:56:26,546 [Epoch: 015 Step: 00002486] Batch Translation Loss:   6.876712 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 06:57:02,863 [Epoch: 015 Step: 00002487] Batch Translation Loss:   5.967093 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:58:04,652 [Epoch: 015 Step: 00002488] Batch Translation Loss:   6.805920 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:58:45,748 [Epoch: 015 Step: 00002489] Batch Translation Loss:   6.167155 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 06:59:26,006 [Epoch: 015 Step: 00002490] Batch Translation Loss:   6.609118 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:00:15,178 [Epoch: 015 Step: 00002491] Batch Translation Loss:   6.013047 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:01:01,668 [Epoch: 015 Step: 00002492] Batch Translation Loss:   6.867668 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:01:56,244 [Epoch: 015 Step: 00002493] Batch Translation Loss:   5.910261 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:02:47,102 [Epoch: 015 Step: 00002494] Batch Translation Loss:   6.289310 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:03:36,208 [Epoch: 015 Step: 00002495] Batch Translation Loss:   6.320862 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:04:35,004 [Epoch: 015 Step: 00002496] Batch Translation Loss:   6.134267 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:05:21,466 [Epoch: 015 Step: 00002497] Batch Translation Loss:   6.482735 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:06:03,585 [Epoch: 015 Step: 00002498] Batch Translation Loss:   5.731732 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:06:52,799 [Epoch: 015 Step: 00002499] Batch Translation Loss:   6.583580 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:07:48,004 [Epoch: 015 Step: 00002500] Batch Translation Loss:   6.295407 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:17:28,800 Validation result at epoch  15, step     2500: duration: 580.7108s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11512.87695	PPL: 12444.77539
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.06	(DEL: 21.38,	INS: 0.00,	SUB: 77.56)
	Sequence Accuracy 1.35
2022-01-02 07:17:36,467 Logging Recognition and Translation Outputs
2022-01-02 07:17:36,542 ========================================================================================================================
2022-01-02 07:17:36,542 Logging Sequence: deafvideo_2-fairytales9_2297
2022-01-02 07:17:36,542 	Text Reference  :	files
2022-01-02 07:17:36,543 	Text Hypothesis :	it   
2022-01-02 07:17:36,543 	Text Alignment  :	S    
2022-01-02 07:17:36,543 ========================================================================================================================
2022-01-02 07:17:36,543 Logging Sequence: deafvideo_2-goatman_1538
2022-01-02 07:17:36,543 	Text Reference  :	deafhood foundation
2022-01-02 07:17:36,544 	Text Hypothesis :	******** it        
2022-01-02 07:17:36,544 	Text Alignment  :	D        S         
2022-01-02 07:17:36,544 ========================================================================================================================
2022-01-02 07:17:36,544 Logging Sequence: youtube_6-roberta_cordano_6470
2022-01-02 07:17:36,544 	Text Reference  :	ylt
2022-01-02 07:17:36,544 	Text Hypothesis :	so 
2022-01-02 07:17:36,545 	Text Alignment  :	S  
2022-01-02 07:17:36,545 ========================================================================================================================
2022-01-02 07:17:36,545 Logging Sequence: youtube_5-jeffrey_spinale_6048
2022-01-02 07:17:36,545 	Text Reference  :	toll
2022-01-02 07:17:36,545 	Text Hypothesis :	asl 
2022-01-02 07:17:36,546 	Text Alignment  :	S   
2022-01-02 07:17:36,546 ========================================================================================================================
2022-01-02 07:17:36,546 Logging Sequence: deafvideo_2-fairytales9_2300
2022-01-02 07:17:36,546 	Text Reference  :	st paul minn 
2022-01-02 07:17:36,547 	Text Hypothesis :	** **** fetal
2022-01-02 07:17:36,547 	Text Alignment  :	D  D    S    
2022-01-02 07:17:36,547 ========================================================================================================================
2022-01-02 07:19:18,986 [Epoch: 015 Step: 00002501] Batch Translation Loss:   6.012245 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 07:22:14,284 [Epoch: 015 Step: 00002502] Batch Translation Loss:   6.459292 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 07:23:33,594 [Epoch: 015 Step: 00002503] Batch Translation Loss:   6.144083 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 07:24:49,268 [Epoch: 015 Step: 00002504] Batch Translation Loss:   6.706914 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 07:25:39,452 [Epoch: 015 Step: 00002505] Batch Translation Loss:   6.163746 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:26:58,197 [Epoch: 015 Step: 00002506] Batch Translation Loss:   5.790651 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 07:27:48,235 [Epoch: 015 Step: 00002507] Batch Translation Loss:   6.195063 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:28:36,580 [Epoch: 015 Step: 00002508] Batch Translation Loss:   6.770738 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:29:21,637 [Epoch: 015 Step: 00002509] Batch Translation Loss:   5.689085 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:31:27,039 [Epoch: 015 Step: 00002510] Batch Translation Loss:   6.589427 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 07:33:01,361 [Epoch: 015 Step: 00002511] Batch Translation Loss:   6.926322 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 07:33:59,023 [Epoch: 015 Step: 00002512] Batch Translation Loss:   6.806467 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:35:21,782 [Epoch: 015 Step: 00002513] Batch Translation Loss:   5.935236 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 07:36:07,781 [Epoch: 015 Step: 00002514] Batch Translation Loss:   5.830337 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:37:00,701 [Epoch: 015 Step: 00002515] Batch Translation Loss:   6.299516 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:37:47,992 [Epoch: 015 Step: 00002516] Batch Translation Loss:   6.906907 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:38:46,558 [Epoch: 015 Step: 00002517] Batch Translation Loss:   6.350882 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:39:30,219 [Epoch: 015 Step: 00002518] Batch Translation Loss:   6.527790 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:40:28,573 [Epoch: 015 Step: 00002519] Batch Translation Loss:   6.392319 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:41:18,232 [Epoch: 015 Step: 00002520] Batch Translation Loss:   6.062692 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:42:47,754 [Epoch: 015 Step: 00002521] Batch Translation Loss:   6.335378 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 07:43:27,457 [Epoch: 015 Step: 00002522] Batch Translation Loss:   6.358896 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:44:17,111 [Epoch: 015 Step: 00002523] Batch Translation Loss:   6.295214 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:45:02,343 [Epoch: 015 Step: 00002524] Batch Translation Loss:   6.438803 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:45:58,986 [Epoch: 015 Step: 00002525] Batch Translation Loss:   6.206505 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:46:47,177 [Epoch: 015 Step: 00002526] Batch Translation Loss:   6.383759 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:47:46,273 [Epoch: 015 Step: 00002527] Batch Translation Loss:   6.457340 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:48:41,126 [Epoch: 015 Step: 00002528] Batch Translation Loss:   6.987187 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:49:33,361 [Epoch: 015 Step: 00002529] Batch Translation Loss:   6.038802 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:50:28,090 [Epoch: 015 Step: 00002530] Batch Translation Loss:   6.306507 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:51:28,858 [Epoch: 015 Step: 00002531] Batch Translation Loss:   5.981145 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:52:14,348 [Epoch: 015 Step: 00002532] Batch Translation Loss:   6.693425 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:53:06,757 [Epoch: 015 Step: 00002533] Batch Translation Loss:   6.103826 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:54:02,872 [Epoch: 015 Step: 00002534] Batch Translation Loss:   6.147794 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:55:39,340 [Epoch: 015 Step: 00002535] Batch Translation Loss:   5.629378 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 07:56:38,684 [Epoch: 015 Step: 00002536] Batch Translation Loss:   6.780262 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 07:58:32,936 [Epoch: 015 Step: 00002537] Batch Translation Loss:   6.549137 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 08:00:03,857 [Epoch: 015 Step: 00002538] Batch Translation Loss:   6.212679 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 08:00:56,616 [Epoch: 015 Step: 00002539] Batch Translation Loss:   6.284786 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:02:03,695 [Epoch: 015 Step: 00002540] Batch Translation Loss:   6.721513 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:03:39,437 [Epoch: 015 Step: 00002541] Batch Translation Loss:   6.461160 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 08:04:50,216 [Epoch: 015 Step: 00002542] Batch Translation Loss:   5.938104 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:05:56,559 [Epoch: 015 Step: 00002543] Batch Translation Loss:   6.593904 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:07:02,697 [Epoch: 015 Step: 00002544] Batch Translation Loss:   6.936404 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:08:37,281 [Epoch: 015 Step: 00002545] Batch Translation Loss:   6.010215 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 08:09:44,150 [Epoch: 015 Step: 00002546] Batch Translation Loss:   6.493984 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:10:54,990 [Epoch: 015 Step: 00002547] Batch Translation Loss:   5.926163 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:11:34,703 [Epoch: 015 Step: 00002548] Batch Translation Loss:   6.344531 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:12:30,757 [Epoch: 015 Step: 00002549] Batch Translation Loss:   7.439494 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 08:12:30,864 Epoch  15: Total Training Recognition Loss -1.00  Total Training Translation Loss 1082.49 
2022-01-02 08:12:30,864 EPOCH 16
2022-01-02 08:12:42,766 [Epoch: 016 Step: 00002550] Batch Translation Loss:   6.672966 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-02 08:12:59,602 [Epoch: 016 Step: 00002551] Batch Translation Loss:   6.903296 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:13:13,530 [Epoch: 016 Step: 00002552] Batch Translation Loss:   6.901529 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-02 08:13:27,825 [Epoch: 016 Step: 00002553] Batch Translation Loss:   6.820852 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-02 08:13:46,517 [Epoch: 016 Step: 00002554] Batch Translation Loss:   6.719114 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:14:09,826 [Epoch: 016 Step: 00002555] Batch Translation Loss:   6.718413 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:14:18,695 [Epoch: 016 Step: 00002556] Batch Translation Loss:   6.426817 => Txt Tokens per Sec:        6 || Lr: 0.000700
2022-01-02 08:14:35,953 [Epoch: 016 Step: 00002557] Batch Translation Loss:   7.220257 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-02 08:14:51,911 [Epoch: 016 Step: 00002558] Batch Translation Loss:   6.471560 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-02 08:15:07,510 [Epoch: 016 Step: 00002559] Batch Translation Loss:   6.417137 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-02 08:15:26,397 [Epoch: 016 Step: 00002560] Batch Translation Loss:   6.637912 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-02 08:15:42,031 [Epoch: 016 Step: 00002561] Batch Translation Loss:   6.241788 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:16:08,798 [Epoch: 016 Step: 00002562] Batch Translation Loss:   6.900814 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:16:23,642 [Epoch: 016 Step: 00002563] Batch Translation Loss:   6.640254 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-02 08:16:40,364 [Epoch: 016 Step: 00002564] Batch Translation Loss:   6.776415 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-02 08:17:05,685 [Epoch: 016 Step: 00002565] Batch Translation Loss:   6.373672 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:17:19,368 [Epoch: 016 Step: 00002566] Batch Translation Loss:   6.564712 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-02 08:17:37,604 [Epoch: 016 Step: 00002567] Batch Translation Loss:   6.197145 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:17:55,950 [Epoch: 016 Step: 00002568] Batch Translation Loss:   7.168163 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-02 08:18:30,253 [Epoch: 016 Step: 00002569] Batch Translation Loss:   6.125561 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:18:46,442 [Epoch: 016 Step: 00002570] Batch Translation Loss:   6.406193 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:19:05,502 [Epoch: 016 Step: 00002571] Batch Translation Loss:   5.795088 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:19:30,583 [Epoch: 016 Step: 00002572] Batch Translation Loss:   6.508232 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:19:49,334 [Epoch: 016 Step: 00002573] Batch Translation Loss:   6.412038 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:20:25,051 [Epoch: 016 Step: 00002574] Batch Translation Loss:   6.007816 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:20:45,090 [Epoch: 016 Step: 00002575] Batch Translation Loss:   5.911534 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:21:04,045 [Epoch: 016 Step: 00002576] Batch Translation Loss:   6.956003 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:21:35,518 [Epoch: 016 Step: 00002577] Batch Translation Loss:   6.698021 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:22:07,975 [Epoch: 016 Step: 00002578] Batch Translation Loss:   6.640297 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:22:28,353 [Epoch: 016 Step: 00002579] Batch Translation Loss:   6.287929 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:22:50,258 [Epoch: 016 Step: 00002580] Batch Translation Loss:   6.465344 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:23:07,120 [Epoch: 016 Step: 00002581] Batch Translation Loss:   6.350328 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:23:23,060 [Epoch: 016 Step: 00002582] Batch Translation Loss:   6.072798 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:23:43,149 [Epoch: 016 Step: 00002583] Batch Translation Loss:   6.048468 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:24:06,557 [Epoch: 016 Step: 00002584] Batch Translation Loss:   5.957392 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:24:28,940 [Epoch: 016 Step: 00002585] Batch Translation Loss:   6.474480 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:24:50,673 [Epoch: 016 Step: 00002586] Batch Translation Loss:   6.128730 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:25:12,616 [Epoch: 016 Step: 00002587] Batch Translation Loss:   5.803485 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:25:37,055 [Epoch: 016 Step: 00002588] Batch Translation Loss:   6.473828 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:26:10,374 [Epoch: 016 Step: 00002589] Batch Translation Loss:   6.339746 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:26:29,387 [Epoch: 016 Step: 00002590] Batch Translation Loss:   6.323814 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:26:55,235 [Epoch: 016 Step: 00002591] Batch Translation Loss:   6.205828 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:27:40,961 [Epoch: 016 Step: 00002592] Batch Translation Loss:   6.435483 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:28:05,563 [Epoch: 016 Step: 00002593] Batch Translation Loss:   6.153489 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:28:38,086 [Epoch: 016 Step: 00002594] Batch Translation Loss:   6.496021 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:29:02,741 [Epoch: 016 Step: 00002595] Batch Translation Loss:   6.153709 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:29:29,644 [Epoch: 016 Step: 00002596] Batch Translation Loss:   6.493596 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:29:47,358 [Epoch: 016 Step: 00002597] Batch Translation Loss:   5.291309 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:30:35,899 [Epoch: 016 Step: 00002598] Batch Translation Loss:   6.424214 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:31:11,317 [Epoch: 016 Step: 00002599] Batch Translation Loss:   6.843532 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:31:36,183 [Epoch: 016 Step: 00002600] Batch Translation Loss:   5.888788 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:41:12,868 Validation result at epoch  16, step     2600: duration: 576.6554s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11720.09180	PPL: 12537.34668
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.05	(DEL: 22.54,	INS: 0.00,	SUB: 76.41)
	Sequence Accuracy 1.35
2022-01-02 08:41:24,125 Logging Recognition and Translation Outputs
2022-01-02 08:41:24,146 ========================================================================================================================
2022-01-02 08:41:24,146 Logging Sequence: deafvideo_2-goatman_1538
2022-01-02 08:41:24,147 	Text Reference  :	titus
2022-01-02 08:41:24,147 	Text Hypothesis :	so   
2022-01-02 08:41:24,147 	Text Alignment  :	S    
2022-01-02 08:41:24,147 ========================================================================================================================
2022-01-02 08:41:24,147 Logging Sequence: youtube_4-howard_rosenblum_5559
2022-01-02 08:41:24,148 	Text Reference  :	dirctory
2022-01-02 08:41:24,148 	Text Hypothesis :	asl     
2022-01-02 08:41:24,148 	Text Alignment  :	S       
2022-01-02 08:41:24,148 ========================================================================================================================
2022-01-02 08:41:24,148 Logging Sequence: youtube_4-tim_albert_5280
2022-01-02 08:41:24,148 	Text Reference  :	use
2022-01-02 08:41:24,148 	Text Hypothesis :	so 
2022-01-02 08:41:24,148 	Text Alignment  :	S  
2022-01-02 08:41:24,148 ========================================================================================================================
2022-01-02 08:41:24,149 Logging Sequence: youtube_3-ben_bahan_4536
2022-01-02 08:41:24,149 	Text Reference  :	fun
2022-01-02 08:41:24,149 	Text Hypothesis :	so 
2022-01-02 08:41:24,149 	Text Alignment  :	S  
2022-01-02 08:41:24,149 ========================================================================================================================
2022-01-02 08:41:24,149 Logging Sequence: youtube_5-melissa_draganac-hawk_5833
2022-01-02 08:41:24,149 	Text Reference  :	johnson cty tenn
2022-01-02 08:41:24,149 	Text Hypothesis :	******* *** so  
2022-01-02 08:41:24,150 	Text Alignment  :	D       D   S   
2022-01-02 08:41:24,150 ========================================================================================================================
2022-01-02 08:43:30,350 [Epoch: 016 Step: 00002601] Batch Translation Loss:   6.973647 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 08:44:31,596 [Epoch: 016 Step: 00002602] Batch Translation Loss:   6.442218 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:45:12,916 [Epoch: 016 Step: 00002603] Batch Translation Loss:   6.549377 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:45:41,951 [Epoch: 016 Step: 00002604] Batch Translation Loss:   6.204046 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:46:36,736 [Epoch: 016 Step: 00002605] Batch Translation Loss:   6.048374 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:47:08,802 [Epoch: 016 Step: 00002606] Batch Translation Loss:   6.503864 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:47:46,132 [Epoch: 016 Step: 00002607] Batch Translation Loss:   6.516469 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:48:12,654 [Epoch: 016 Step: 00002608] Batch Translation Loss:   6.483642 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:48:39,560 [Epoch: 016 Step: 00002609] Batch Translation Loss:   6.320170 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-02 08:49:09,644 [Epoch: 016 Step: 00002610] Batch Translation Loss:   7.015593 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:49:59,630 [Epoch: 016 Step: 00002611] Batch Translation Loss:   6.185442 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:50:32,263 [Epoch: 016 Step: 00002612] Batch Translation Loss:   6.363992 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:51:03,047 [Epoch: 016 Step: 00002613] Batch Translation Loss:   5.497957 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:51:33,048 [Epoch: 016 Step: 00002614] Batch Translation Loss:   7.118555 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:52:27,188 [Epoch: 016 Step: 00002615] Batch Translation Loss:   6.191674 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:52:56,647 [Epoch: 016 Step: 00002616] Batch Translation Loss:   6.894970 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:53:52,665 [Epoch: 016 Step: 00002617] Batch Translation Loss:   5.950819 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:55:01,295 [Epoch: 016 Step: 00002618] Batch Translation Loss:   6.503546 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:55:39,398 [Epoch: 016 Step: 00002619] Batch Translation Loss:   6.007122 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:56:10,549 [Epoch: 016 Step: 00002620] Batch Translation Loss:   5.927798 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:56:37,121 [Epoch: 016 Step: 00002621] Batch Translation Loss:   6.553116 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:57:12,438 [Epoch: 016 Step: 00002622] Batch Translation Loss:   6.532863 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:58:04,465 [Epoch: 016 Step: 00002623] Batch Translation Loss:   6.266039 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:58:32,465 [Epoch: 016 Step: 00002624] Batch Translation Loss:   6.383036 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:59:05,574 [Epoch: 016 Step: 00002625] Batch Translation Loss:   6.838796 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 08:59:35,368 [Epoch: 016 Step: 00002626] Batch Translation Loss:   6.474295 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:00:10,910 [Epoch: 016 Step: 00002627] Batch Translation Loss:   5.469206 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:01:14,005 [Epoch: 016 Step: 00002628] Batch Translation Loss:   6.246542 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:01:47,963 [Epoch: 016 Step: 00002629] Batch Translation Loss:   6.407792 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:02:44,741 [Epoch: 016 Step: 00002630] Batch Translation Loss:   6.135837 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:03:24,116 [Epoch: 016 Step: 00002631] Batch Translation Loss:   6.390678 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:04:04,272 [Epoch: 016 Step: 00002632] Batch Translation Loss:   6.262552 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:04:45,405 [Epoch: 016 Step: 00002633] Batch Translation Loss:   6.561014 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:05:23,265 [Epoch: 016 Step: 00002634] Batch Translation Loss:   6.452943 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:06:00,329 [Epoch: 016 Step: 00002635] Batch Translation Loss:   5.651612 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:07:01,022 [Epoch: 016 Step: 00002636] Batch Translation Loss:   6.677158 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:08:37,234 [Epoch: 016 Step: 00002637] Batch Translation Loss:   6.180280 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 09:09:13,998 [Epoch: 016 Step: 00002638] Batch Translation Loss:   6.167864 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:09:47,247 [Epoch: 016 Step: 00002639] Batch Translation Loss:   6.375974 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:10:21,578 [Epoch: 016 Step: 00002640] Batch Translation Loss:   6.102208 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:11:10,867 [Epoch: 016 Step: 00002641] Batch Translation Loss:   7.204520 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:12:05,905 [Epoch: 016 Step: 00002642] Batch Translation Loss:   6.764755 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:12:48,192 [Epoch: 016 Step: 00002643] Batch Translation Loss:   6.526292 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:13:26,401 [Epoch: 016 Step: 00002644] Batch Translation Loss:   5.931699 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:14:09,836 [Epoch: 016 Step: 00002645] Batch Translation Loss:   6.454522 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:15:00,906 [Epoch: 016 Step: 00002646] Batch Translation Loss:   6.128070 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:15:54,589 [Epoch: 016 Step: 00002647] Batch Translation Loss:   5.921856 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:16:31,933 [Epoch: 016 Step: 00002648] Batch Translation Loss:   5.120796 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:17:24,111 [Epoch: 016 Step: 00002649] Batch Translation Loss:   6.471650 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:18:08,670 [Epoch: 016 Step: 00002650] Batch Translation Loss:   6.168840 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:19:02,481 [Epoch: 016 Step: 00002651] Batch Translation Loss:   6.065979 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:20:20,215 [Epoch: 016 Step: 00002652] Batch Translation Loss:   6.837603 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 09:21:13,650 [Epoch: 016 Step: 00002653] Batch Translation Loss:   6.116879 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:21:54,672 [Epoch: 016 Step: 00002654] Batch Translation Loss:   6.632138 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:23:10,104 [Epoch: 016 Step: 00002655] Batch Translation Loss:   6.219833 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 09:24:03,941 [Epoch: 016 Step: 00002656] Batch Translation Loss:   6.166459 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:24:43,891 [Epoch: 016 Step: 00002657] Batch Translation Loss:   5.832392 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:25:20,618 [Epoch: 016 Step: 00002658] Batch Translation Loss:   6.615642 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:26:59,352 [Epoch: 016 Step: 00002659] Batch Translation Loss:   6.296892 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 09:28:20,519 [Epoch: 016 Step: 00002660] Batch Translation Loss:   6.954496 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 09:29:15,261 [Epoch: 016 Step: 00002661] Batch Translation Loss:   6.106045 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:29:58,488 [Epoch: 016 Step: 00002662] Batch Translation Loss:   5.463324 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:30:44,903 [Epoch: 016 Step: 00002663] Batch Translation Loss:   6.803423 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:31:34,366 [Epoch: 016 Step: 00002664] Batch Translation Loss:   6.159709 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:32:27,265 [Epoch: 016 Step: 00002665] Batch Translation Loss:   6.907069 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:33:11,335 [Epoch: 016 Step: 00002666] Batch Translation Loss:   6.417852 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:33:58,022 [Epoch: 016 Step: 00002667] Batch Translation Loss:   6.271646 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:35:00,754 [Epoch: 016 Step: 00002668] Batch Translation Loss:   6.372371 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:36:41,857 [Epoch: 016 Step: 00002669] Batch Translation Loss:   5.793270 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 09:37:36,712 [Epoch: 016 Step: 00002670] Batch Translation Loss:   6.857801 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:38:22,679 [Epoch: 016 Step: 00002671] Batch Translation Loss:   6.978194 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:39:01,740 [Epoch: 016 Step: 00002672] Batch Translation Loss:   6.720554 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:39:40,196 [Epoch: 016 Step: 00002673] Batch Translation Loss:   6.863214 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:40:33,939 [Epoch: 016 Step: 00002674] Batch Translation Loss:   6.892927 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:41:21,419 [Epoch: 016 Step: 00002675] Batch Translation Loss:   6.473495 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:41:57,530 [Epoch: 016 Step: 00002676] Batch Translation Loss:   6.636763 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:43:18,078 [Epoch: 016 Step: 00002677] Batch Translation Loss:   5.692443 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 09:44:09,957 [Epoch: 016 Step: 00002678] Batch Translation Loss:   6.126786 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:45:04,266 [Epoch: 016 Step: 00002679] Batch Translation Loss:   6.262120 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:45:45,311 [Epoch: 016 Step: 00002680] Batch Translation Loss:   5.682159 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:46:52,561 [Epoch: 016 Step: 00002681] Batch Translation Loss:   5.912955 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:47:52,473 [Epoch: 016 Step: 00002682] Batch Translation Loss:   6.415481 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:50:05,412 [Epoch: 016 Step: 00002683] Batch Translation Loss:   5.348324 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 09:51:12,459 [Epoch: 016 Step: 00002684] Batch Translation Loss:   5.740640 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:52:05,852 [Epoch: 016 Step: 00002685] Batch Translation Loss:   6.361905 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:53:11,020 [Epoch: 016 Step: 00002686] Batch Translation Loss:   5.947122 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:55:34,526 [Epoch: 016 Step: 00002687] Batch Translation Loss:   6.262307 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 09:56:32,021 [Epoch: 016 Step: 00002688] Batch Translation Loss:   6.339250 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:57:26,719 [Epoch: 016 Step: 00002689] Batch Translation Loss:   6.190134 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 09:59:11,765 [Epoch: 016 Step: 00002690] Batch Translation Loss:   5.908175 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 10:00:09,818 [Epoch: 016 Step: 00002691] Batch Translation Loss:   6.321969 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 10:01:07,480 [Epoch: 016 Step: 00002692] Batch Translation Loss:   6.445319 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 10:01:59,419 [Epoch: 016 Step: 00002693] Batch Translation Loss:   5.845555 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 10:02:40,296 [Epoch: 016 Step: 00002694] Batch Translation Loss:   5.812532 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 10:03:30,277 [Epoch: 016 Step: 00002695] Batch Translation Loss:   6.360026 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 10:04:56,524 [Epoch: 016 Step: 00002696] Batch Translation Loss:   6.005411 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 10:05:50,062 [Epoch: 016 Step: 00002697] Batch Translation Loss:   5.805386 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 10:08:15,719 [Epoch: 016 Step: 00002698] Batch Translation Loss:   5.751455 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-02 10:09:17,695 [Epoch: 016 Step: 00002699] Batch Translation Loss:   6.141917 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 10:10:16,109 [Epoch: 016 Step: 00002700] Batch Translation Loss:   6.240874 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-02 10:20:56,752 Validation result at epoch  16, step     2700: duration: 640.6131s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11842.85938	PPL: 15070.87891
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.46	(DEL: 21.61,	INS: 0.00,	SUB: 76.93)
	Sequence Accuracy 1.66
2022-01-02 10:21:04,216 Logging Recognition and Translation Outputs
2022-01-02 10:21:04,229 ========================================================================================================================
2022-01-02 10:21:04,229 Logging Sequence: youtube_1-shoshannah_stern_2386
2022-01-02 10:21:04,230 	Text Reference  :	or
2022-01-02 10:21:04,230 	Text Hypothesis :	so
2022-01-02 10:21:04,230 	Text Alignment  :	S 
2022-01-02 10:21:04,230 ========================================================================================================================
2022-01-02 10:21:04,230 Logging Sequence: youtube_5-melissa_draganac-hawk_5833
2022-01-02 10:21:04,230 	Text Reference  :	youtube link       
2022-01-02 10:21:04,230 	Text Hypothesis :	******* sustainable
2022-01-02 10:21:04,230 	Text Alignment  :	D       S          
2022-01-02 10:21:04,230 ========================================================================================================================
2022-01-02 10:21:04,230 Logging Sequence: deafvideo_2-sddsimple_1570
2022-01-02 10:21:04,231 	Text Reference  :	disobey
2022-01-02 10:21:04,231 	Text Hypothesis :	asl    
2022-01-02 10:21:04,231 	Text Alignment  :	S      
2022-01-02 10:21:04,231 ========================================================================================================================
2022-01-02 10:21:04,231 Logging Sequence: youtube_5-sean_berdy_6103
2022-01-02 10:21:04,231 	Text Reference  :	fiction
2022-01-02 10:21:04,231 	Text Hypothesis :	coda   
2022-01-02 10:21:04,231 	Text Alignment  :	S      
2022-01-02 10:21:04,231 ========================================================================================================================
2022-01-02 10:21:04,231 Logging Sequence: deafvideo_3-otismhill82_4604
2022-01-02 10:21:04,231 	Text Reference  :	or
2022-01-02 10:21:04,232 	Text Hypothesis :	ok
2022-01-02 10:21:04,232 	Text Alignment  :	S 
2022-01-02 10:21:04,232 ========================================================================================================================
2022-01-02 10:21:04,852 Training ended since there were no improvements inthe last learning rate step: 0.000700
2022-01-02 10:21:04,852 Best validation result at step      900:   0.65 eval_metric.
2022-01-02 10:24:10,118 ============================================================
2022-01-02 10:34:44,923 [DEV] partition [Translation] results:
	New Best Translation Beam Size: 1 and Alpha: -1
	WAcc (Word Accuracy Rate) 1.34	(DEL: 24.49,	INS: 0.00,	SUB: 74.17)
	Sequence Accuracy 1.77
2022-01-02 10:34:44,979 ------------------------------------------------------------
2022-01-02 10:51:29,388 [DEV] partition [Translation] results:
	New Best Translation Beam Size: 1 and Alpha: 1
	WAcc (Word Accuracy Rate) 1.36	(DEL: 23.00,	INS: 0.00,	SUB: 75.64)
	Sequence Accuracy 1.46
2022-01-02 10:51:29,501 ------------------------------------------------------------
2022-01-02 11:00:19,427 [DEV] partition [Translation] results:
	New Best Translation Beam Size: 1 and Alpha: 2
	WAcc (Word Accuracy Rate) 1.59	(DEL: 22.89,	INS: 0.00,	SUB: 75.52)
	Sequence Accuracy 1.75
2022-01-02 11:00:19,446 ------------------------------------------------------------
2022-01-02 11:45:23,046 [DEV] partition [Translation] results:
	New Best Translation Beam Size: 2 and Alpha: 0
	WAcc (Word Accuracy Rate) 1.64	(DEL: 25.00,	INS: 0.00,	SUB: 73.36)
	Sequence Accuracy 1.88
2022-01-02 11:45:23,056 ------------------------------------------------------------
2022-01-02 12:04:39,490 [DEV] partition [Translation] results:
	New Best Translation Beam Size: 2 and Alpha: 2
	WAcc (Word Accuracy Rate) 1.67	(DEL: 23.65,	INS: 0.00,	SUB: 74.68)
	Sequence Accuracy 2.09
2022-01-02 12:04:39,512 ------------------------------------------------------------
2022-01-02 12:52:10,692 [DEV] partition [Translation] results:
	New Best Translation Beam Size: 3 and Alpha: 0
	WAcc (Word Accuracy Rate) 1.94	(DEL: 25.56,	INS: 0.00,	SUB: 72.49)
	Sequence Accuracy 2.30
2022-01-02 12:52:10,721 ------------------------------------------------------------
2022-01-02 19:14:29,341 [DEV] partition [Translation] results:
	New Best Translation Beam Size: 8 and Alpha: 5
	WAcc (Word Accuracy Rate) 1.96	(DEL: 21.39,	INS: 0.00,	SUB: 76.65)
	Sequence Accuracy 2.28
2022-01-02 19:14:29,454 ------------------------------------------------------------
2022-01-02 22:27:44,259 ************************************************************
2022-01-02 22:27:44,319 [DEV] partition [Recognition & Translation] results:
	Best CTC Decode Beam Size: -1
	Best Translation Beam Size: 8 and Alpha: 5
	WAcc (Word Accuracy Rate) 1.96	(DEL: 21.39,	INS: 0.00,	SUB: 76.65)
	Sequence Accuracy 2.28
2022-01-02 22:27:44,319 ************************************************************
2022-01-02 22:36:24,971 [TEST] partition [Recognition & Translation] results:
	Best CTC Decode Beam Size: -1
	Best Translation Beam Size: 8 and Alpha: 5
	WAcc (Word Accuracy Rate) 1.00	(DEL: 28.14,	INS: 0.00,	SUB: 70.86)
	Sequence Accuracy 1.39
2022-01-02 22:36:25,010 ************************************************************
