2021-12-29 13:06:08,403 Hello! This is Joey-NMT.
2021-12-29 13:06:08,412 Total params: 27946760
2021-12-29 13:06:08,413 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.output_layer.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'image_encoder.classifier.0.bias', 'image_encoder.classifier.0.weight', 'image_encoder.classifier.3.bias', 'image_encoder.classifier.3.weight', 'image_encoder.features.0.0.weight', 'image_encoder.features.0.1.bias', 'image_encoder.features.0.1.weight', 'image_encoder.features.1.block.0.0.weight', 'image_encoder.features.1.block.0.1.bias', 'image_encoder.features.1.block.0.1.weight', 'image_encoder.features.1.block.1.fc1.bias', 'image_encoder.features.1.block.1.fc1.weight', 'image_encoder.features.1.block.1.fc2.bias', 'image_encoder.features.1.block.1.fc2.weight', 'image_encoder.features.1.block.2.0.weight', 'image_encoder.features.1.block.2.1.bias', 'image_encoder.features.1.block.2.1.weight', 'image_encoder.features.10.block.0.0.weight', 'image_encoder.features.10.block.0.1.bias', 'image_encoder.features.10.block.0.1.weight', 'image_encoder.features.10.block.1.0.weight', 'image_encoder.features.10.block.1.1.bias', 'image_encoder.features.10.block.1.1.weight', 'image_encoder.features.10.block.2.fc1.bias', 'image_encoder.features.10.block.2.fc1.weight', 'image_encoder.features.10.block.2.fc2.bias', 'image_encoder.features.10.block.2.fc2.weight', 'image_encoder.features.10.block.3.0.weight', 'image_encoder.features.10.block.3.1.bias', 'image_encoder.features.10.block.3.1.weight', 'image_encoder.features.11.block.0.0.weight', 'image_encoder.features.11.block.0.1.bias', 'image_encoder.features.11.block.0.1.weight', 'image_encoder.features.11.block.1.0.weight', 'image_encoder.features.11.block.1.1.bias', 'image_encoder.features.11.block.1.1.weight', 'image_encoder.features.11.block.2.fc1.bias', 'image_encoder.features.11.block.2.fc1.weight', 'image_encoder.features.11.block.2.fc2.bias', 'image_encoder.features.11.block.2.fc2.weight', 'image_encoder.features.11.block.3.0.weight', 'image_encoder.features.11.block.3.1.bias', 'image_encoder.features.11.block.3.1.weight', 'image_encoder.features.12.0.weight', 'image_encoder.features.12.1.bias', 'image_encoder.features.12.1.weight', 'image_encoder.features.2.block.0.0.weight', 'image_encoder.features.2.block.0.1.bias', 'image_encoder.features.2.block.0.1.weight', 'image_encoder.features.2.block.1.0.weight', 'image_encoder.features.2.block.1.1.bias', 'image_encoder.features.2.block.1.1.weight', 'image_encoder.features.2.block.2.0.weight', 'image_encoder.features.2.block.2.1.bias', 'image_encoder.features.2.block.2.1.weight', 'image_encoder.features.3.block.0.0.weight', 'image_encoder.features.3.block.0.1.bias', 'image_encoder.features.3.block.0.1.weight', 'image_encoder.features.3.block.1.0.weight', 'image_encoder.features.3.block.1.1.bias', 'image_encoder.features.3.block.1.1.weight', 'image_encoder.features.3.block.2.0.weight', 'image_encoder.features.3.block.2.1.bias', 'image_encoder.features.3.block.2.1.weight', 'image_encoder.features.4.block.0.0.weight', 'image_encoder.features.4.block.0.1.bias', 'image_encoder.features.4.block.0.1.weight', 'image_encoder.features.4.block.1.0.weight', 'image_encoder.features.4.block.1.1.bias', 'image_encoder.features.4.block.1.1.weight', 'image_encoder.features.4.block.2.fc1.bias', 'image_encoder.features.4.block.2.fc1.weight', 'image_encoder.features.4.block.2.fc2.bias', 'image_encoder.features.4.block.2.fc2.weight', 'image_encoder.features.4.block.3.0.weight', 'image_encoder.features.4.block.3.1.bias', 'image_encoder.features.4.block.3.1.weight', 'image_encoder.features.5.block.0.0.weight', 'image_encoder.features.5.block.0.1.bias', 'image_encoder.features.5.block.0.1.weight', 'image_encoder.features.5.block.1.0.weight', 'image_encoder.features.5.block.1.1.bias', 'image_encoder.features.5.block.1.1.weight', 'image_encoder.features.5.block.2.fc1.bias', 'image_encoder.features.5.block.2.fc1.weight', 'image_encoder.features.5.block.2.fc2.bias', 'image_encoder.features.5.block.2.fc2.weight', 'image_encoder.features.5.block.3.0.weight', 'image_encoder.features.5.block.3.1.bias', 'image_encoder.features.5.block.3.1.weight', 'image_encoder.features.6.block.0.0.weight', 'image_encoder.features.6.block.0.1.bias', 'image_encoder.features.6.block.0.1.weight', 'image_encoder.features.6.block.1.0.weight', 'image_encoder.features.6.block.1.1.bias', 'image_encoder.features.6.block.1.1.weight', 'image_encoder.features.6.block.2.fc1.bias', 'image_encoder.features.6.block.2.fc1.weight', 'image_encoder.features.6.block.2.fc2.bias', 'image_encoder.features.6.block.2.fc2.weight', 'image_encoder.features.6.block.3.0.weight', 'image_encoder.features.6.block.3.1.bias', 'image_encoder.features.6.block.3.1.weight', 'image_encoder.features.7.block.0.0.weight', 'image_encoder.features.7.block.0.1.bias', 'image_encoder.features.7.block.0.1.weight', 'image_encoder.features.7.block.1.0.weight', 'image_encoder.features.7.block.1.1.bias', 'image_encoder.features.7.block.1.1.weight', 'image_encoder.features.7.block.2.fc1.bias', 'image_encoder.features.7.block.2.fc1.weight', 'image_encoder.features.7.block.2.fc2.bias', 'image_encoder.features.7.block.2.fc2.weight', 'image_encoder.features.7.block.3.0.weight', 'image_encoder.features.7.block.3.1.bias', 'image_encoder.features.7.block.3.1.weight', 'image_encoder.features.8.block.0.0.weight', 'image_encoder.features.8.block.0.1.bias', 'image_encoder.features.8.block.0.1.weight', 'image_encoder.features.8.block.1.0.weight', 'image_encoder.features.8.block.1.1.bias', 'image_encoder.features.8.block.1.1.weight', 'image_encoder.features.8.block.2.fc1.bias', 'image_encoder.features.8.block.2.fc1.weight', 'image_encoder.features.8.block.2.fc2.bias', 'image_encoder.features.8.block.2.fc2.weight', 'image_encoder.features.8.block.3.0.weight', 'image_encoder.features.8.block.3.1.bias', 'image_encoder.features.8.block.3.1.weight', 'image_encoder.features.9.block.0.0.weight', 'image_encoder.features.9.block.0.1.bias', 'image_encoder.features.9.block.0.1.weight', 'image_encoder.features.9.block.1.0.weight', 'image_encoder.features.9.block.1.1.bias', 'image_encoder.features.9.block.1.1.weight', 'image_encoder.features.9.block.2.fc1.bias', 'image_encoder.features.9.block.2.fc1.weight', 'image_encoder.features.9.block.2.fc2.bias', 'image_encoder.features.9.block.2.fc2.weight', 'image_encoder.features.9.block.3.0.weight', 'image_encoder.features.9.block.3.1.bias', 'image_encoder.features.9.block.3.1.weight', 'sgn_embed.ln.bias', 'sgn_embed.ln.weight', 'sgn_embed.norm.norm.bias', 'sgn_embed.norm.norm.weight', 'txt_embed.lut.weight', 'txt_embed.norm.norm.bias', 'txt_embed.norm.norm.weight']
2021-12-29 13:06:11,557 cfg.name                           : ChicagoFSWild Experiment
2021-12-29 13:06:11,558 cfg.data.data_path                 : ./data/
2021-12-29 13:06:11,558 cfg.data.version                   : ChicagoFSWild
2021-12-29 13:06:11,558 cfg.data.sgn                       : sign
2021-12-29 13:06:11,558 cfg.data.gls                       : gloss
2021-12-29 13:06:11,558 cfg.data.feature_size              : 1000
2021-12-29 13:06:11,558 cfg.data.level                     : word
2021-12-29 13:06:11,558 cfg.data.max_sent_length           : 400
2021-12-29 13:06:11,558 cfg.data.random_train_subset       : -1
2021-12-29 13:06:11,558 cfg.data.random_dev_subset         : -1
2021-12-29 13:06:11,558 cfg.testing.recognition_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2021-12-29 13:06:11,558 cfg.testing.translation_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2021-12-29 13:06:11,558 cfg.testing.translation_beam_alphas : [-1, 0, 1, 2, 3, 4, 5]
2021-12-29 13:06:11,558 cfg.training.reset_best_ckpt       : False
2021-12-29 13:06:11,558 cfg.training.reset_scheduler       : False
2021-12-29 13:06:11,559 cfg.training.reset_optimizer       : False
2021-12-29 13:06:11,559 cfg.training.random_seed           : 42
2021-12-29 13:06:11,559 cfg.training.model_dir             : ./ChicagoFSWild Experiments/ChicagoFSWild_experiment_17
2021-12-29 13:06:11,559 cfg.training.recognition_loss_weight : 0.0
2021-12-29 13:06:11,559 cfg.training.translation_loss_weight : 1.0
2021-12-29 13:06:11,559 cfg.training.eval_metric           : bleu
2021-12-29 13:06:11,559 cfg.training.optimizer             : adam
2021-12-29 13:06:11,559 cfg.training.learning_rate         : 0.001
2021-12-29 13:06:11,559 cfg.training.batch_size            : 32
2021-12-29 13:06:11,559 cfg.training.num_valid_log         : 5
2021-12-29 13:06:11,559 cfg.training.epochs                : 5000000
2021-12-29 13:06:11,559 cfg.training.early_stopping_metric : eval_metric
2021-12-29 13:06:11,559 cfg.training.batch_type            : token
2021-12-29 13:06:11,559 cfg.training.translation_normalization : batch
2021-12-29 13:06:11,559 cfg.training.eval_recognition_beam_size : 9
2021-12-29 13:06:11,559 cfg.training.eval_translation_beam_size : 9
2021-12-29 13:06:11,559 cfg.training.eval_translation_beam_alpha : 1
2021-12-29 13:06:11,559 cfg.training.overwrite             : True
2021-12-29 13:06:11,559 cfg.training.shuffle               : True
2021-12-29 13:06:11,559 cfg.training.use_cuda              : True
2021-12-29 13:06:11,559 cfg.training.translation_max_output_length : 1
2021-12-29 13:06:11,560 cfg.training.keep_last_ckpts       : 1
2021-12-29 13:06:11,560 cfg.training.batch_multiplier      : 1
2021-12-29 13:06:11,560 cfg.training.logging_freq          : 1
2021-12-29 13:06:11,560 cfg.training.validation_freq       : 100
2021-12-29 13:06:11,560 cfg.training.betas                 : [0.9, 0.998]
2021-12-29 13:06:11,560 cfg.training.scheduling            : plateau
2021-12-29 13:06:11,560 cfg.training.learning_rate_min     : 1e-06
2021-12-29 13:06:11,560 cfg.training.weight_decay          : 0.001
2021-12-29 13:06:11,560 cfg.training.patience              : 8
2021-12-29 13:06:11,560 cfg.training.decrease_factor       : 0.7
2021-12-29 13:06:11,560 cfg.training.label_smoothing       : 0.0
2021-12-29 13:06:11,560 cfg.model.initializer              : xavier
2021-12-29 13:06:11,560 cfg.model.bias_initializer         : zeros
2021-12-29 13:06:11,560 cfg.model.init_gain                : 1.0
2021-12-29 13:06:11,560 cfg.model.embed_initializer        : xavier
2021-12-29 13:06:11,560 cfg.model.embed_init_gain          : 1.0
2021-12-29 13:06:11,560 cfg.model.tied_softmax             : False
2021-12-29 13:06:11,560 cfg.model.encoder.type             : transformer
2021-12-29 13:06:11,560 cfg.model.encoder.num_layers       : 3
2021-12-29 13:06:11,560 cfg.model.encoder.num_heads        : 8
2021-12-29 13:06:11,560 cfg.model.encoder.embeddings.embedding_dim : 512
2021-12-29 13:06:11,560 cfg.model.encoder.embeddings.scale : False
2021-12-29 13:06:11,560 cfg.model.encoder.embeddings.dropout : 0.1
2021-12-29 13:06:11,561 cfg.model.encoder.embeddings.norm_type : batch
2021-12-29 13:06:11,561 cfg.model.encoder.embeddings.activation_type : softsign
2021-12-29 13:06:11,561 cfg.model.encoder.hidden_size      : 512
2021-12-29 13:06:11,561 cfg.model.encoder.ff_size          : 2048
2021-12-29 13:06:11,561 cfg.model.encoder.dropout          : 0.1
2021-12-29 13:06:11,561 cfg.model.decoder.type             : transformer
2021-12-29 13:06:11,561 cfg.model.decoder.num_layers       : 3
2021-12-29 13:06:11,561 cfg.model.decoder.num_heads        : 8
2021-12-29 13:06:11,561 cfg.model.decoder.embeddings.embedding_dim : 512
2021-12-29 13:06:11,561 cfg.model.decoder.embeddings.scale : False
2021-12-29 13:06:11,561 cfg.model.decoder.embeddings.dropout : 0.1
2021-12-29 13:06:11,561 cfg.model.decoder.embeddings.norm_type : batch
2021-12-29 13:06:11,561 cfg.model.decoder.embeddings.activation_type : softsign
2021-12-29 13:06:11,561 cfg.model.decoder.hidden_size      : 512
2021-12-29 13:06:11,561 cfg.model.decoder.ff_size          : 2048
2021-12-29 13:06:11,561 cfg.model.decoder.dropout          : 0.1
2021-12-29 13:06:11,561 SignModel(
	encoder=TransformerEncoder(num_layers=3, num_heads=8),
	decoder=TransformerDecoder(num_layers=3, num_heads=8),
	sgn_embed=SpatialEmbeddings(embedding_dim=512, input_size=1000),
	txt_embed=Embeddings(embedding_dim=512, vocab_size=2752))
2021-12-29 13:06:11,566 EPOCH 1
2021-12-29 13:06:17,652 [Epoch: 001 Step: 00000001] Batch Translation Loss:   9.797852 => Txt Tokens per Sec:        6 || Lr: 0.001000
2021-12-29 13:06:23,784 [Epoch: 001 Step: 00000002] Batch Translation Loss:   8.844599 => Txt Tokens per Sec:        6 || Lr: 0.001000
2021-12-29 13:06:29,986 [Epoch: 001 Step: 00000003] Batch Translation Loss:   9.309759 => Txt Tokens per Sec:        6 || Lr: 0.001000
2021-12-29 13:06:39,957 [Epoch: 001 Step: 00000004] Batch Translation Loss:  11.375624 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 13:06:47,251 [Epoch: 001 Step: 00000005] Batch Translation Loss:  12.062263 => Txt Tokens per Sec:        7 || Lr: 0.001000
2021-12-29 13:06:58,414 [Epoch: 001 Step: 00000006] Batch Translation Loss:  12.179475 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 13:07:07,304 [Epoch: 001 Step: 00000007] Batch Translation Loss:  11.383160 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 13:07:18,234 [Epoch: 001 Step: 00000008] Batch Translation Loss:  14.638927 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 13:07:26,623 [Epoch: 001 Step: 00000009] Batch Translation Loss:  13.253161 => Txt Tokens per Sec:        6 || Lr: 0.001000
2021-12-29 13:07:36,250 [Epoch: 001 Step: 00000010] Batch Translation Loss:  10.649360 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 13:07:49,752 [Epoch: 001 Step: 00000011] Batch Translation Loss:  12.434606 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 13:07:57,869 [Epoch: 001 Step: 00000012] Batch Translation Loss:  10.666606 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 13:08:09,328 [Epoch: 001 Step: 00000013] Batch Translation Loss:  10.860455 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 13:08:19,236 [Epoch: 001 Step: 00000014] Batch Translation Loss:  11.525311 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 13:08:29,164 [Epoch: 001 Step: 00000015] Batch Translation Loss:  10.258247 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 13:08:41,919 [Epoch: 001 Step: 00000016] Batch Translation Loss:  10.731564 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 13:08:56,863 [Epoch: 001 Step: 00000017] Batch Translation Loss:  10.498707 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 13:09:11,981 [Epoch: 001 Step: 00000018] Batch Translation Loss:  10.717937 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 13:09:20,582 [Epoch: 001 Step: 00000019] Batch Translation Loss:   8.768655 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 13:09:30,068 [Epoch: 001 Step: 00000020] Batch Translation Loss:  12.050914 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 13:09:39,802 [Epoch: 001 Step: 00000021] Batch Translation Loss:  10.103093 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 13:09:53,336 [Epoch: 001 Step: 00000022] Batch Translation Loss:  10.756855 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 13:10:08,655 [Epoch: 001 Step: 00000023] Batch Translation Loss:   9.627116 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 13:10:25,117 [Epoch: 001 Step: 00000024] Batch Translation Loss:  11.288731 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 13:10:43,255 [Epoch: 001 Step: 00000025] Batch Translation Loss:  10.620065 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:10:54,234 [Epoch: 001 Step: 00000026] Batch Translation Loss:   7.291104 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 13:11:11,066 [Epoch: 001 Step: 00000027] Batch Translation Loss:  13.654120 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 13:11:22,279 [Epoch: 001 Step: 00000028] Batch Translation Loss:   8.925072 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 13:11:35,232 [Epoch: 001 Step: 00000029] Batch Translation Loss:  12.474953 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 13:11:54,216 [Epoch: 001 Step: 00000030] Batch Translation Loss:   9.980642 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:12:05,720 [Epoch: 001 Step: 00000031] Batch Translation Loss:   9.717731 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 13:12:16,734 [Epoch: 001 Step: 00000032] Batch Translation Loss:   9.694170 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 13:12:28,160 [Epoch: 001 Step: 00000033] Batch Translation Loss:   9.365752 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 13:12:42,959 [Epoch: 001 Step: 00000034] Batch Translation Loss:  12.720795 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 13:12:53,553 [Epoch: 001 Step: 00000035] Batch Translation Loss:   8.705399 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 13:13:04,509 [Epoch: 001 Step: 00000036] Batch Translation Loss:  10.015697 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 13:13:24,963 [Epoch: 001 Step: 00000037] Batch Translation Loss:  11.413478 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:13:47,681 [Epoch: 001 Step: 00000038] Batch Translation Loss:  10.357963 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:13:59,209 [Epoch: 001 Step: 00000039] Batch Translation Loss:   8.400066 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 13:14:21,094 [Epoch: 001 Step: 00000040] Batch Translation Loss:  10.471082 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:14:43,524 [Epoch: 001 Step: 00000041] Batch Translation Loss:  10.199175 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:14:56,616 [Epoch: 001 Step: 00000042] Batch Translation Loss:   9.781895 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 13:15:20,524 [Epoch: 001 Step: 00000043] Batch Translation Loss:  12.080436 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:15:32,784 [Epoch: 001 Step: 00000044] Batch Translation Loss:   8.187927 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 13:15:45,618 [Epoch: 001 Step: 00000045] Batch Translation Loss:   8.837747 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 13:15:58,722 [Epoch: 001 Step: 00000046] Batch Translation Loss:  10.113775 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 13:16:23,833 [Epoch: 001 Step: 00000047] Batch Translation Loss:  12.191931 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:16:46,542 [Epoch: 001 Step: 00000048] Batch Translation Loss:  10.839843 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:17:09,515 [Epoch: 001 Step: 00000049] Batch Translation Loss:  10.229643 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:17:36,350 [Epoch: 001 Step: 00000050] Batch Translation Loss:  12.489794 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:17:49,955 [Epoch: 001 Step: 00000051] Batch Translation Loss:   8.878603 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 13:18:03,954 [Epoch: 001 Step: 00000052] Batch Translation Loss:  10.537704 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 13:18:18,875 [Epoch: 001 Step: 00000053] Batch Translation Loss:   8.665989 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:18:44,049 [Epoch: 001 Step: 00000054] Batch Translation Loss:  12.047711 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:18:58,717 [Epoch: 001 Step: 00000055] Batch Translation Loss:   8.657135 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:19:21,529 [Epoch: 001 Step: 00000056] Batch Translation Loss:   8.392765 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:19:35,277 [Epoch: 001 Step: 00000057] Batch Translation Loss:   8.843551 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 13:19:50,371 [Epoch: 001 Step: 00000058] Batch Translation Loss:  10.701860 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 13:20:06,079 [Epoch: 001 Step: 00000059] Batch Translation Loss:   8.459374 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:20:31,017 [Epoch: 001 Step: 00000060] Batch Translation Loss:   9.592388 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:20:46,352 [Epoch: 001 Step: 00000061] Batch Translation Loss:   7.603009 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:21:15,136 [Epoch: 001 Step: 00000062] Batch Translation Loss:  11.146460 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:21:30,621 [Epoch: 001 Step: 00000063] Batch Translation Loss:   8.285574 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:21:45,878 [Epoch: 001 Step: 00000064] Batch Translation Loss:   9.570493 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 13:22:15,740 [Epoch: 001 Step: 00000065] Batch Translation Loss:  12.308990 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:22:58,387 [Epoch: 001 Step: 00000066] Batch Translation Loss:  10.591647 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 13:23:25,999 [Epoch: 001 Step: 00000067] Batch Translation Loss:   7.836785 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 13:23:41,845 [Epoch: 001 Step: 00000068] Batch Translation Loss:   9.361947 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:24:08,586 [Epoch: 001 Step: 00000069] Batch Translation Loss:   8.209769 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 13:24:24,349 [Epoch: 001 Step: 00000070] Batch Translation Loss:   9.243974 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:24:40,492 [Epoch: 001 Step: 00000071] Batch Translation Loss:   9.190454 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:25:08,073 [Epoch: 001 Step: 00000072] Batch Translation Loss:   8.723715 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 13:25:24,031 [Epoch: 001 Step: 00000073] Batch Translation Loss:   9.184424 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:25:41,130 [Epoch: 001 Step: 00000074] Batch Translation Loss:   9.438292 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:25:57,231 [Epoch: 001 Step: 00000075] Batch Translation Loss:   8.694998 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:26:15,357 [Epoch: 001 Step: 00000076] Batch Translation Loss:   7.754056 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:26:52,866 [Epoch: 001 Step: 00000077] Batch Translation Loss:   8.098646 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 13:27:10,114 [Epoch: 001 Step: 00000078] Batch Translation Loss:   9.799452 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:27:27,664 [Epoch: 001 Step: 00000079] Batch Translation Loss:   9.005762 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:27:45,332 [Epoch: 001 Step: 00000080] Batch Translation Loss:   9.587750 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:28:03,254 [Epoch: 001 Step: 00000081] Batch Translation Loss:   8.534426 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:28:20,083 [Epoch: 001 Step: 00000082] Batch Translation Loss:   7.776897 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:28:53,492 [Epoch: 001 Step: 00000083] Batch Translation Loss:   9.765060 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 13:29:11,770 [Epoch: 001 Step: 00000084] Batch Translation Loss:   8.167710 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:29:44,234 [Epoch: 001 Step: 00000085] Batch Translation Loss:  10.012201 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 13:30:03,239 [Epoch: 001 Step: 00000086] Batch Translation Loss:   9.550955 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:30:21,837 [Epoch: 001 Step: 00000087] Batch Translation Loss:   9.880954 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:30:40,196 [Epoch: 001 Step: 00000088] Batch Translation Loss:   9.628918 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:30:58,911 [Epoch: 001 Step: 00000089] Batch Translation Loss:   9.745429 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:31:31,400 [Epoch: 001 Step: 00000090] Batch Translation Loss:   8.705635 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 13:31:55,279 [Epoch: 001 Step: 00000091] Batch Translation Loss:   9.270642 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:32:14,451 [Epoch: 001 Step: 00000092] Batch Translation Loss:   8.690300 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:32:34,526 [Epoch: 001 Step: 00000093] Batch Translation Loss:   8.249855 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:32:54,058 [Epoch: 001 Step: 00000094] Batch Translation Loss:  10.215346 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:33:13,550 [Epoch: 001 Step: 00000095] Batch Translation Loss:   9.882981 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:33:32,569 [Epoch: 001 Step: 00000096] Batch Translation Loss:   8.872259 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:33:52,740 [Epoch: 001 Step: 00000097] Batch Translation Loss:   8.916920 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:34:12,522 [Epoch: 001 Step: 00000098] Batch Translation Loss:   8.246724 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:34:32,021 [Epoch: 001 Step: 00000099] Batch Translation Loss:   7.739636 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:34:57,275 [Epoch: 001 Step: 00000100] Batch Translation Loss:   8.667187 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 13:40:34,783 Hooray! New best validation result [eval_metric]!
2021-12-29 13:40:34,784 Saving new checkpoint.
2021-12-29 13:40:36,111 Validation result at epoch   1, step      100: duration: 338.8351s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11483.39453	PPL: 6953.43848
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 0.95,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 4.52	ROUGE 1.14
2021-12-29 13:40:41,592 Logging Recognition and Translation Outputs
2021-12-29 13:40:41,593 ========================================================================================================================
2021-12-29 13:40:41,593 Logging Sequence: deafvideo_3-titans_4695
2021-12-29 13:40:41,594 	Text Reference  :	gadfi
2021-12-29 13:40:41,594 	Text Hypothesis :	ok   
2021-12-29 13:40:41,595 	Text Alignment  :	S    
2021-12-29 13:40:41,595 ========================================================================================================================
2021-12-29 13:40:41,595 Logging Sequence: youtube_1-don_grushkin_2304
2021-12-29 13:40:41,596 	Text Reference  :	open source
2021-12-29 13:40:41,596 	Text Hypothesis :	**** ok    
2021-12-29 13:40:41,596 	Text Alignment  :	D    S     
2021-12-29 13:40:41,596 ========================================================================================================================
2021-12-29 13:40:41,597 Logging Sequence: youtube_4-howard_rosenblum_5578
2021-12-29 13:40:41,597 	Text Reference  :	tim
2021-12-29 13:40:41,597 	Text Hypothesis :	ok 
2021-12-29 13:40:41,597 	Text Alignment  :	S  
2021-12-29 13:40:41,598 ========================================================================================================================
2021-12-29 13:40:41,598 Logging Sequence: youtube_5-daniel_durant_5891
2021-12-29 13:40:41,598 	Text Reference  :	do
2021-12-29 13:40:41,598 	Text Hypothesis :	ok
2021-12-29 13:40:41,599 	Text Alignment  :	S 
2021-12-29 13:40:41,599 ========================================================================================================================
2021-12-29 13:40:41,599 Logging Sequence: deafvideo_2-confederateboy_1662
2021-12-29 13:40:41,600 	Text Reference  :	nail
2021-12-29 13:40:41,600 	Text Hypothesis :	ok  
2021-12-29 13:40:41,600 	Text Alignment  :	S   
2021-12-29 13:40:41,600 ========================================================================================================================
2021-12-29 13:41:01,033 [Epoch: 001 Step: 00000101] Batch Translation Loss:   8.675062 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 13:41:36,446 [Epoch: 001 Step: 00000102] Batch Translation Loss:   8.824964 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 13:41:56,856 [Epoch: 001 Step: 00000103] Batch Translation Loss:   8.379294 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:42:17,214 [Epoch: 001 Step: 00000104] Batch Translation Loss:   8.566393 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:42:37,774 [Epoch: 001 Step: 00000105] Batch Translation Loss:   9.480433 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:42:58,116 [Epoch: 001 Step: 00000106] Batch Translation Loss:   7.730648 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:43:18,979 [Epoch: 001 Step: 00000107] Batch Translation Loss:   8.044280 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:43:40,034 [Epoch: 001 Step: 00000108] Batch Translation Loss:   8.849785 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:44:01,086 [Epoch: 001 Step: 00000109] Batch Translation Loss:   9.013157 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:44:23,088 [Epoch: 001 Step: 00000110] Batch Translation Loss:   7.794668 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:44:44,240 [Epoch: 001 Step: 00000111] Batch Translation Loss:   8.880404 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:45:05,651 [Epoch: 001 Step: 00000112] Batch Translation Loss:   8.830297 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:45:26,356 [Epoch: 001 Step: 00000113] Batch Translation Loss:   8.061601 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:45:48,990 [Epoch: 001 Step: 00000114] Batch Translation Loss:   8.626527 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:46:12,188 [Epoch: 001 Step: 00000115] Batch Translation Loss:   8.312722 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:46:33,626 [Epoch: 001 Step: 00000116] Batch Translation Loss:   8.000080 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:46:55,480 [Epoch: 001 Step: 00000117] Batch Translation Loss:   9.692644 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:47:17,918 [Epoch: 001 Step: 00000118] Batch Translation Loss:   8.816872 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:47:40,600 [Epoch: 001 Step: 00000119] Batch Translation Loss:   8.973728 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:48:02,543 [Epoch: 001 Step: 00000120] Batch Translation Loss:   9.820278 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:48:25,074 [Epoch: 001 Step: 00000121] Batch Translation Loss:   8.901994 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:48:47,644 [Epoch: 001 Step: 00000122] Batch Translation Loss:   9.171458 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:49:11,711 [Epoch: 001 Step: 00000123] Batch Translation Loss:   8.544511 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:49:35,723 [Epoch: 001 Step: 00000124] Batch Translation Loss:   8.566330 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 13:49:58,385 [Epoch: 001 Step: 00000125] Batch Translation Loss:   8.076902 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:50:22,333 [Epoch: 001 Step: 00000126] Batch Translation Loss:   7.517244 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 13:50:46,548 [Epoch: 001 Step: 00000127] Batch Translation Loss:   9.449272 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:51:10,761 [Epoch: 001 Step: 00000128] Batch Translation Loss:   9.018596 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:51:36,221 [Epoch: 001 Step: 00000129] Batch Translation Loss:   9.766257 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:51:59,764 [Epoch: 001 Step: 00000130] Batch Translation Loss:   7.724576 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 13:52:24,822 [Epoch: 001 Step: 00000131] Batch Translation Loss:  10.193179 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:52:50,039 [Epoch: 001 Step: 00000132] Batch Translation Loss:   9.280365 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:53:14,292 [Epoch: 001 Step: 00000133] Batch Translation Loss:   8.690841 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:53:38,786 [Epoch: 001 Step: 00000134] Batch Translation Loss:   8.493448 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:54:04,111 [Epoch: 001 Step: 00000135] Batch Translation Loss:  11.558560 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:54:29,734 [Epoch: 001 Step: 00000136] Batch Translation Loss:   7.928823 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 13:54:54,090 [Epoch: 001 Step: 00000137] Batch Translation Loss:   8.266180 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:55:18,759 [Epoch: 001 Step: 00000138] Batch Translation Loss:   9.571762 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:55:43,835 [Epoch: 001 Step: 00000139] Batch Translation Loss:   7.583285 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 13:56:09,620 [Epoch: 001 Step: 00000140] Batch Translation Loss:   7.522098 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 13:56:35,130 [Epoch: 001 Step: 00000141] Batch Translation Loss:   7.844769 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 13:57:22,791 [Epoch: 001 Step: 00000142] Batch Translation Loss:   9.573545 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 13:57:49,035 [Epoch: 001 Step: 00000143] Batch Translation Loss:   9.563830 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 13:58:14,582 [Epoch: 001 Step: 00000144] Batch Translation Loss:   7.220280 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 13:58:39,948 [Epoch: 001 Step: 00000145] Batch Translation Loss:   8.972543 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 13:59:24,996 [Epoch: 001 Step: 00000146] Batch Translation Loss:   7.703744 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 13:59:50,626 [Epoch: 001 Step: 00000147] Batch Translation Loss:   9.328843 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:00:16,561 [Epoch: 001 Step: 00000148] Batch Translation Loss:   9.340160 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:00:42,880 [Epoch: 001 Step: 00000149] Batch Translation Loss:   8.199764 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:01:09,949 [Epoch: 001 Step: 00000150] Batch Translation Loss:   7.951005 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:01:35,988 [Epoch: 001 Step: 00000151] Batch Translation Loss:   8.247674 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:02:02,801 [Epoch: 001 Step: 00000152] Batch Translation Loss:   7.801517 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:02:29,144 [Epoch: 001 Step: 00000153] Batch Translation Loss:   7.862787 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:02:55,450 [Epoch: 001 Step: 00000154] Batch Translation Loss:   8.768860 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:03:21,892 [Epoch: 001 Step: 00000155] Batch Translation Loss:   9.251924 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:03:49,894 [Epoch: 001 Step: 00000156] Batch Translation Loss:   8.505475 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:04:16,495 [Epoch: 001 Step: 00000157] Batch Translation Loss:   7.692276 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:04:43,229 [Epoch: 001 Step: 00000158] Batch Translation Loss:   8.388636 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:05:09,856 [Epoch: 001 Step: 00000159] Batch Translation Loss:   7.214502 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:05:37,058 [Epoch: 001 Step: 00000160] Batch Translation Loss:   8.494380 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:06:06,226 [Epoch: 001 Step: 00000161] Batch Translation Loss:   8.645027 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:06:34,131 [Epoch: 001 Step: 00000162] Batch Translation Loss:   9.599004 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:07:25,892 [Epoch: 001 Step: 00000163] Batch Translation Loss:   7.838581 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:07:53,205 [Epoch: 001 Step: 00000164] Batch Translation Loss:   7.295365 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:08:21,247 [Epoch: 001 Step: 00000165] Batch Translation Loss:   8.159206 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:08:48,959 [Epoch: 001 Step: 00000166] Batch Translation Loss:   8.847380 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:09:18,038 [Epoch: 001 Step: 00000167] Batch Translation Loss:   8.591350 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:09:46,035 [Epoch: 001 Step: 00000168] Batch Translation Loss:   8.445150 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:10:15,132 [Epoch: 001 Step: 00000169] Batch Translation Loss:  14.318638 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:10:15,446 Epoch   1: Total Training Recognition Loss -1.00  Total Training Translation Loss 1590.34 
2021-12-29 14:10:15,446 EPOCH 2
2021-12-29 14:10:21,014 [Epoch: 002 Step: 00000170] Batch Translation Loss:   6.961933 => Txt Tokens per Sec:        6 || Lr: 0.001000
2021-12-29 14:10:27,511 [Epoch: 002 Step: 00000171] Batch Translation Loss:   9.158280 => Txt Tokens per Sec:        6 || Lr: 0.001000
2021-12-29 14:10:34,502 [Epoch: 002 Step: 00000172] Batch Translation Loss:   9.113641 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 14:10:41,795 [Epoch: 002 Step: 00000173] Batch Translation Loss:   9.721257 => Txt Tokens per Sec:        6 || Lr: 0.001000
2021-12-29 14:10:50,397 [Epoch: 002 Step: 00000174] Batch Translation Loss:  10.154233 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 14:10:57,838 [Epoch: 002 Step: 00000175] Batch Translation Loss:   9.550591 => Txt Tokens per Sec:        6 || Lr: 0.001000
2021-12-29 14:11:07,851 [Epoch: 002 Step: 00000176] Batch Translation Loss:  10.034654 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 14:11:17,960 [Epoch: 002 Step: 00000177] Batch Translation Loss:  10.914365 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 14:11:24,660 [Epoch: 002 Step: 00000178] Batch Translation Loss:   8.255810 => Txt Tokens per Sec:        6 || Lr: 0.001000
2021-12-29 14:11:33,623 [Epoch: 002 Step: 00000179] Batch Translation Loss:   9.797219 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 14:11:41,583 [Epoch: 002 Step: 00000180] Batch Translation Loss:   7.892671 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 14:11:49,635 [Epoch: 002 Step: 00000181] Batch Translation Loss:   8.656033 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 14:11:57,611 [Epoch: 002 Step: 00000182] Batch Translation Loss:   8.983542 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 14:12:07,239 [Epoch: 002 Step: 00000183] Batch Translation Loss:   9.974895 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 14:12:19,626 [Epoch: 002 Step: 00000184] Batch Translation Loss:  11.008810 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 14:12:29,206 [Epoch: 002 Step: 00000185] Batch Translation Loss:   9.846746 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 14:12:39,248 [Epoch: 002 Step: 00000186] Batch Translation Loss:   9.678776 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 14:12:47,079 [Epoch: 002 Step: 00000187] Batch Translation Loss:   7.907657 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 14:12:56,090 [Epoch: 002 Step: 00000188] Batch Translation Loss:   9.918418 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 14:13:10,643 [Epoch: 002 Step: 00000189] Batch Translation Loss:  11.951963 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:13:25,345 [Epoch: 002 Step: 00000190] Batch Translation Loss:  10.272099 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:13:39,558 [Epoch: 002 Step: 00000191] Batch Translation Loss:  10.349103 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 14:13:54,801 [Epoch: 002 Step: 00000192] Batch Translation Loss:  10.528951 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:14:10,329 [Epoch: 002 Step: 00000193] Batch Translation Loss:   9.952953 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:14:19,528 [Epoch: 002 Step: 00000194] Batch Translation Loss:   7.588578 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 14:14:30,764 [Epoch: 002 Step: 00000195] Batch Translation Loss:   8.320935 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:14:45,648 [Epoch: 002 Step: 00000196] Batch Translation Loss:   9.117826 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:14:57,470 [Epoch: 002 Step: 00000197] Batch Translation Loss:   7.140296 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:15:08,642 [Epoch: 002 Step: 00000198] Batch Translation Loss:   8.878286 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:15:19,702 [Epoch: 002 Step: 00000199] Batch Translation Loss:   7.631748 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:15:30,640 [Epoch: 002 Step: 00000200] Batch Translation Loss:   7.836337 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:20:51,814 Validation result at epoch   2, step      200: duration: 321.1726s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 10703.97754	PPL: 5768.55127
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 1.41,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 6.76	ROUGE 1.63
2021-12-29 14:20:57,297 Logging Recognition and Translation Outputs
2021-12-29 14:20:57,298 ========================================================================================================================
2021-12-29 14:20:57,298 Logging Sequence: youtube_4-howard_rosenblum_5562
2021-12-29 14:20:57,298 	Text Reference  :	co chairs
2021-12-29 14:20:57,298 	Text Hypothesis :	** asl   
2021-12-29 14:20:57,298 	Text Alignment  :	D  S     
2021-12-29 14:20:57,298 ========================================================================================================================
2021-12-29 14:20:57,298 Logging Sequence: youtube_5-sean_berdy_6090
2021-12-29 14:20:57,299 	Text Reference  :	paste
2021-12-29 14:20:57,299 	Text Hypothesis :	asl  
2021-12-29 14:20:57,299 	Text Alignment  :	S    
2021-12-29 14:20:57,299 ========================================================================================================================
2021-12-29 14:20:57,299 Logging Sequence: deafvideo_2-confederateboy_1667
2021-12-29 14:20:57,299 	Text Reference  :	so
2021-12-29 14:20:57,299 	Text Hypothesis :	or
2021-12-29 14:20:57,299 	Text Alignment  :	S 
2021-12-29 14:20:57,299 ========================================================================================================================
2021-12-29 14:20:57,299 Logging Sequence: deafvideo_3-yesyes_3108
2021-12-29 14:20:57,299 	Text Reference  :	gov
2021-12-29 14:20:57,300 	Text Hypothesis :	asl
2021-12-29 14:20:57,300 	Text Alignment  :	S  
2021-12-29 14:20:57,300 ========================================================================================================================
2021-12-29 14:20:57,300 Logging Sequence: aslized-suzanne_stecker_0244
2021-12-29 14:20:57,300 	Text Reference  :	scs
2021-12-29 14:20:57,300 	Text Hypothesis :	or 
2021-12-29 14:20:57,300 	Text Alignment  :	S  
2021-12-29 14:20:57,300 ========================================================================================================================
2021-12-29 14:21:14,429 [Epoch: 002 Step: 00000201] Batch Translation Loss:  12.546263 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:21:34,541 [Epoch: 002 Step: 00000202] Batch Translation Loss:   9.301841 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:21:53,406 [Epoch: 002 Step: 00000203] Batch Translation Loss:  11.112321 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:22:14,499 [Epoch: 002 Step: 00000204] Batch Translation Loss:  10.036463 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:22:25,814 [Epoch: 002 Step: 00000205] Batch Translation Loss:   8.386599 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 14:22:36,122 [Epoch: 002 Step: 00000206] Batch Translation Loss:   6.845501 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:22:47,392 [Epoch: 002 Step: 00000207] Batch Translation Loss:   8.657985 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 14:22:58,359 [Epoch: 002 Step: 00000208] Batch Translation Loss:   6.974866 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:23:11,244 [Epoch: 002 Step: 00000209] Batch Translation Loss:   8.058524 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:23:34,341 [Epoch: 002 Step: 00000210] Batch Translation Loss:   8.807743 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:23:53,958 [Epoch: 002 Step: 00000211] Batch Translation Loss:   7.874246 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:24:06,194 [Epoch: 002 Step: 00000212] Batch Translation Loss:   8.789725 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:24:20,378 [Epoch: 002 Step: 00000213] Batch Translation Loss:   9.465699 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:24:33,453 [Epoch: 002 Step: 00000214] Batch Translation Loss:   8.669409 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:24:45,088 [Epoch: 002 Step: 00000215] Batch Translation Loss:   8.011190 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:24:58,560 [Epoch: 002 Step: 00000216] Batch Translation Loss:  10.154902 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:25:11,179 [Epoch: 002 Step: 00000217] Batch Translation Loss:   9.054036 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:25:35,713 [Epoch: 002 Step: 00000218] Batch Translation Loss:  11.317116 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:25:47,689 [Epoch: 002 Step: 00000219] Batch Translation Loss:   7.689020 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:26:00,107 [Epoch: 002 Step: 00000220] Batch Translation Loss:   7.669243 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:26:14,078 [Epoch: 002 Step: 00000221] Batch Translation Loss:   7.841515 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:26:27,386 [Epoch: 002 Step: 00000222] Batch Translation Loss:   9.486850 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:26:40,671 [Epoch: 002 Step: 00000223] Batch Translation Loss:   7.684036 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:27:03,155 [Epoch: 002 Step: 00000224] Batch Translation Loss:   8.126647 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:27:19,423 [Epoch: 002 Step: 00000225] Batch Translation Loss:   9.060981 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:27:33,386 [Epoch: 002 Step: 00000226] Batch Translation Loss:   8.495784 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:27:46,856 [Epoch: 002 Step: 00000227] Batch Translation Loss:   7.114658 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:28:02,978 [Epoch: 002 Step: 00000228] Batch Translation Loss:  11.050068 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:28:17,837 [Epoch: 002 Step: 00000229] Batch Translation Loss:   8.998701 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:28:32,139 [Epoch: 002 Step: 00000230] Batch Translation Loss:   8.926709 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:28:58,369 [Epoch: 002 Step: 00000231] Batch Translation Loss:  10.312411 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:29:24,587 [Epoch: 002 Step: 00000232] Batch Translation Loss:   7.782092 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:29:49,499 [Epoch: 002 Step: 00000233] Batch Translation Loss:   8.500196 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:30:05,728 [Epoch: 002 Step: 00000234] Batch Translation Loss:   8.321630 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:30:20,647 [Epoch: 002 Step: 00000235] Batch Translation Loss:   8.298643 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:30:35,997 [Epoch: 002 Step: 00000236] Batch Translation Loss:   7.864060 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:30:50,728 [Epoch: 002 Step: 00000237] Batch Translation Loss:   9.637479 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:31:06,865 [Epoch: 002 Step: 00000238] Batch Translation Loss:   8.141647 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:31:23,082 [Epoch: 002 Step: 00000239] Batch Translation Loss:   8.931211 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:31:38,513 [Epoch: 002 Step: 00000240] Batch Translation Loss:   8.128800 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:31:53,862 [Epoch: 002 Step: 00000241] Batch Translation Loss:   8.478284 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 14:32:10,254 [Epoch: 002 Step: 00000242] Batch Translation Loss:   8.485790 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:32:27,623 [Epoch: 002 Step: 00000243] Batch Translation Loss:   8.044480 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:32:43,977 [Epoch: 002 Step: 00000244] Batch Translation Loss:   8.250206 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:33:01,461 [Epoch: 002 Step: 00000245] Batch Translation Loss:   7.775935 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:33:18,710 [Epoch: 002 Step: 00000246] Batch Translation Loss:   7.600011 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:33:35,845 [Epoch: 002 Step: 00000247] Batch Translation Loss:   8.561461 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:34:06,855 [Epoch: 002 Step: 00000248] Batch Translation Loss:  11.064215 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:34:23,489 [Epoch: 002 Step: 00000249] Batch Translation Loss:   8.081313 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:34:41,665 [Epoch: 002 Step: 00000250] Batch Translation Loss:   7.234037 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:34:59,267 [Epoch: 002 Step: 00000251] Batch Translation Loss:   8.979568 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:35:18,942 [Epoch: 002 Step: 00000252] Batch Translation Loss:   9.310772 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:35:37,397 [Epoch: 002 Step: 00000253] Batch Translation Loss:   7.330012 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:35:54,842 [Epoch: 002 Step: 00000254] Batch Translation Loss:   7.869569 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:36:12,692 [Epoch: 002 Step: 00000255] Batch Translation Loss:   8.193521 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:36:30,893 [Epoch: 002 Step: 00000256] Batch Translation Loss:   8.165195 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:37:02,062 [Epoch: 002 Step: 00000257] Batch Translation Loss:   8.819792 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:37:19,576 [Epoch: 002 Step: 00000258] Batch Translation Loss:   7.728409 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:37:52,187 [Epoch: 002 Step: 00000259] Batch Translation Loss:   7.788679 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:38:10,847 [Epoch: 002 Step: 00000260] Batch Translation Loss:   8.286570 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:38:47,610 [Epoch: 002 Step: 00000261] Batch Translation Loss:   7.613520 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:39:06,116 [Epoch: 002 Step: 00000262] Batch Translation Loss:   8.331111 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:39:24,970 [Epoch: 002 Step: 00000263] Batch Translation Loss:   7.471259 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:39:44,979 [Epoch: 002 Step: 00000264] Batch Translation Loss:   8.212238 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:40:04,348 [Epoch: 002 Step: 00000265] Batch Translation Loss:   7.784823 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:40:23,681 [Epoch: 002 Step: 00000266] Batch Translation Loss:   8.245046 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:40:43,721 [Epoch: 002 Step: 00000267] Batch Translation Loss:   9.018325 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:41:04,526 [Epoch: 002 Step: 00000268] Batch Translation Loss:   6.843350 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:41:24,450 [Epoch: 002 Step: 00000269] Batch Translation Loss:   9.574655 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:41:44,697 [Epoch: 002 Step: 00000270] Batch Translation Loss:   7.658673 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:42:20,277 [Epoch: 002 Step: 00000271] Batch Translation Loss:   9.035271 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:42:41,439 [Epoch: 002 Step: 00000272] Batch Translation Loss:   8.489959 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:43:01,845 [Epoch: 002 Step: 00000273] Batch Translation Loss:   8.367534 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:43:21,988 [Epoch: 002 Step: 00000274] Batch Translation Loss:   7.758796 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:43:43,113 [Epoch: 002 Step: 00000275] Batch Translation Loss:   8.211658 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:44:07,406 [Epoch: 002 Step: 00000276] Batch Translation Loss:   7.121127 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:44:30,399 [Epoch: 002 Step: 00000277] Batch Translation Loss:   8.152292 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:44:53,815 [Epoch: 002 Step: 00000278] Batch Translation Loss:   9.416132 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:45:15,270 [Epoch: 002 Step: 00000279] Batch Translation Loss:   7.113301 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:45:36,685 [Epoch: 002 Step: 00000280] Batch Translation Loss:   8.516774 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:45:58,617 [Epoch: 002 Step: 00000281] Batch Translation Loss:   8.703867 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:46:23,625 [Epoch: 002 Step: 00000282] Batch Translation Loss:   8.286698 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:46:45,648 [Epoch: 002 Step: 00000283] Batch Translation Loss:   8.867640 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:47:08,684 [Epoch: 002 Step: 00000284] Batch Translation Loss:   7.645020 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:47:30,478 [Epoch: 002 Step: 00000285] Batch Translation Loss:   9.392535 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:47:51,918 [Epoch: 002 Step: 00000286] Batch Translation Loss:   7.749801 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:48:14,667 [Epoch: 002 Step: 00000287] Batch Translation Loss:   7.788618 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:48:37,587 [Epoch: 002 Step: 00000288] Batch Translation Loss:   8.797189 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:48:59,377 [Epoch: 002 Step: 00000289] Batch Translation Loss:   8.601749 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:49:21,443 [Epoch: 002 Step: 00000290] Batch Translation Loss:   7.243013 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:49:43,936 [Epoch: 002 Step: 00000291] Batch Translation Loss:   7.980912 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:50:06,828 [Epoch: 002 Step: 00000292] Batch Translation Loss:   7.657529 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:50:29,562 [Epoch: 002 Step: 00000293] Batch Translation Loss:   8.749638 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:50:52,340 [Epoch: 002 Step: 00000294] Batch Translation Loss:   7.830547 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:51:17,552 [Epoch: 002 Step: 00000295] Batch Translation Loss:   6.963855 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:51:43,211 [Epoch: 002 Step: 00000296] Batch Translation Loss:   9.280847 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:52:08,738 [Epoch: 002 Step: 00000297] Batch Translation Loss:   8.709314 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:52:32,454 [Epoch: 002 Step: 00000298] Batch Translation Loss:   7.253117 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:52:56,228 [Epoch: 002 Step: 00000299] Batch Translation Loss:   8.348847 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 14:53:20,072 [Epoch: 002 Step: 00000300] Batch Translation Loss:   7.276895 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:58:44,607 Validation result at epoch   2, step      300: duration: 324.5340s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 10937.70020	PPL: 5728.70068
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 1.97,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 4.18	ROUGE 2.36
2021-12-29 14:58:49,797 Logging Recognition and Translation Outputs
2021-12-29 14:58:49,798 ========================================================================================================================
2021-12-29 14:58:49,798 Logging Sequence: youtube_1-catherine_mackinnon_2825
2021-12-29 14:58:49,798 	Text Reference  :	episodes
2021-12-29 14:58:49,798 	Text Hypothesis :	ok      
2021-12-29 14:58:49,799 	Text Alignment  :	S       
2021-12-29 14:58:49,799 ========================================================================================================================
2021-12-29 14:58:49,799 Logging Sequence: aslized-suzanne_stecker_0241
2021-12-29 14:58:49,799 	Text Reference  :	or
2021-12-29 14:58:49,799 	Text Hypothesis :	ok
2021-12-29 14:58:49,800 	Text Alignment  :	S 
2021-12-29 14:58:49,800 ========================================================================================================================
2021-12-29 14:58:49,800 Logging Sequence: youtube_5-jeffrey_spinale_6052
2021-12-29 14:58:49,800 	Text Reference  :	deaf
2021-12-29 14:58:49,800 	Text Hypothesis :	ok  
2021-12-29 14:58:49,800 	Text Alignment  :	S   
2021-12-29 14:58:49,801 ========================================================================================================================
2021-12-29 14:58:49,801 Logging Sequence: youtube_1-don_grushkin_2773
2021-12-29 14:58:49,801 	Text Reference  :	standing rock
2021-12-29 14:58:49,801 	Text Hypothesis :	******** asl 
2021-12-29 14:58:49,801 	Text Alignment  :	D        S   
2021-12-29 14:58:49,801 ========================================================================================================================
2021-12-29 14:58:49,802 Logging Sequence: deafvideo_5-morningstar_6250
2021-12-29 14:58:49,802 	Text Reference  :	adam eve
2021-12-29 14:58:49,802 	Text Hypothesis :	**** asl
2021-12-29 14:58:49,802 	Text Alignment  :	D    S  
2021-12-29 14:58:49,802 ========================================================================================================================
2021-12-29 14:59:13,946 [Epoch: 002 Step: 00000301] Batch Translation Loss:   8.083010 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 14:59:39,198 [Epoch: 002 Step: 00000302] Batch Translation Loss:   9.710738 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:00:03,630 [Epoch: 002 Step: 00000303] Batch Translation Loss:   8.673042 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:00:28,372 [Epoch: 002 Step: 00000304] Batch Translation Loss:   8.470922 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:00:53,742 [Epoch: 002 Step: 00000305] Batch Translation Loss:   8.160643 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:01:21,266 [Epoch: 002 Step: 00000306] Batch Translation Loss:   8.168429 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:01:45,894 [Epoch: 002 Step: 00000307] Batch Translation Loss:   7.477037 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:02:10,701 [Epoch: 002 Step: 00000308] Batch Translation Loss:   9.065859 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:02:36,091 [Epoch: 002 Step: 00000309] Batch Translation Loss:   8.672344 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:03:01,714 [Epoch: 002 Step: 00000310] Batch Translation Loss:   8.395484 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:03:28,725 [Epoch: 002 Step: 00000311] Batch Translation Loss:   9.446112 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:03:54,723 [Epoch: 002 Step: 00000312] Batch Translation Loss:   8.283999 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:04:20,691 [Epoch: 002 Step: 00000313] Batch Translation Loss:   7.117465 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:04:46,151 [Epoch: 002 Step: 00000314] Batch Translation Loss:   7.940466 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:05:11,975 [Epoch: 002 Step: 00000315] Batch Translation Loss:   8.328660 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:05:38,663 [Epoch: 002 Step: 00000316] Batch Translation Loss:  11.255655 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:06:28,947 [Epoch: 002 Step: 00000317] Batch Translation Loss:   8.960564 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:06:54,902 [Epoch: 002 Step: 00000318] Batch Translation Loss:   6.937454 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:07:21,320 [Epoch: 002 Step: 00000319] Batch Translation Loss:   7.517060 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:07:47,358 [Epoch: 002 Step: 00000320] Batch Translation Loss:   9.052826 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:08:14,867 [Epoch: 002 Step: 00000321] Batch Translation Loss:   8.823177 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:08:42,745 [Epoch: 002 Step: 00000322] Batch Translation Loss:   7.200313 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:09:09,142 [Epoch: 002 Step: 00000323] Batch Translation Loss:   7.619058 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:09:36,954 [Epoch: 002 Step: 00000324] Batch Translation Loss:   9.067130 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:10:03,406 [Epoch: 002 Step: 00000325] Batch Translation Loss:   7.707310 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:10:30,104 [Epoch: 002 Step: 00000326] Batch Translation Loss:   8.113593 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:11:22,497 [Epoch: 002 Step: 00000327] Batch Translation Loss:   7.270887 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:11:50,662 [Epoch: 002 Step: 00000328] Batch Translation Loss:   9.162613 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:12:17,453 [Epoch: 002 Step: 00000329] Batch Translation Loss:   7.244885 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:12:45,449 [Epoch: 002 Step: 00000330] Batch Translation Loss:   7.787651 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:13:12,563 [Epoch: 002 Step: 00000331] Batch Translation Loss:   7.999001 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:13:40,560 [Epoch: 002 Step: 00000332] Batch Translation Loss:   9.759222 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:14:09,645 [Epoch: 002 Step: 00000333] Batch Translation Loss:   7.084147 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:14:37,491 [Epoch: 002 Step: 00000334] Batch Translation Loss:   8.463362 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:15:07,423 [Epoch: 002 Step: 00000335] Batch Translation Loss:   8.888712 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:15:36,342 [Epoch: 002 Step: 00000336] Batch Translation Loss:   8.509000 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:16:05,767 [Epoch: 002 Step: 00000337] Batch Translation Loss:   8.180697 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:16:39,391 [Epoch: 002 Step: 00000338] Batch Translation Loss:   7.344698 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:17:04,748 [Epoch: 002 Step: 00000339] Batch Translation Loss:  10.013161 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:17:04,826 Epoch   2: Total Training Recognition Loss -1.00  Total Training Translation Loss 1457.29 
2021-12-29 15:17:04,826 EPOCH 3
2021-12-29 15:17:10,452 [Epoch: 003 Step: 00000340] Batch Translation Loss:   8.263739 => Txt Tokens per Sec:        7 || Lr: 0.001000
2021-12-29 15:17:17,764 [Epoch: 003 Step: 00000341] Batch Translation Loss:   9.144944 => Txt Tokens per Sec:        6 || Lr: 0.001000
2021-12-29 15:17:25,194 [Epoch: 003 Step: 00000342] Batch Translation Loss:   8.024847 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 15:17:32,732 [Epoch: 003 Step: 00000343] Batch Translation Loss:   8.818714 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 15:17:39,770 [Epoch: 003 Step: 00000344] Batch Translation Loss:   8.536788 => Txt Tokens per Sec:        6 || Lr: 0.001000
2021-12-29 15:17:49,268 [Epoch: 003 Step: 00000345] Batch Translation Loss:  10.398246 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 15:17:56,950 [Epoch: 003 Step: 00000346] Batch Translation Loss:   8.740459 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 15:18:10,040 [Epoch: 003 Step: 00000347] Batch Translation Loss:  10.107375 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 15:18:21,394 [Epoch: 003 Step: 00000348] Batch Translation Loss:  10.749962 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 15:18:29,976 [Epoch: 003 Step: 00000349] Batch Translation Loss:   9.495619 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 15:18:37,221 [Epoch: 003 Step: 00000350] Batch Translation Loss:   7.898530 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 15:18:44,776 [Epoch: 003 Step: 00000351] Batch Translation Loss:   7.860586 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 15:18:54,148 [Epoch: 003 Step: 00000352] Batch Translation Loss:  10.811830 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 15:19:02,989 [Epoch: 003 Step: 00000353] Batch Translation Loss:   9.577859 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 15:19:10,464 [Epoch: 003 Step: 00000354] Batch Translation Loss:   7.515521 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 15:19:21,393 [Epoch: 003 Step: 00000355] Batch Translation Loss:   8.436303 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 15:19:30,166 [Epoch: 003 Step: 00000356] Batch Translation Loss:   7.417176 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 15:19:38,530 [Epoch: 003 Step: 00000357] Batch Translation Loss:   7.996636 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 15:19:46,389 [Epoch: 003 Step: 00000358] Batch Translation Loss:   8.371768 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 15:20:01,578 [Epoch: 003 Step: 00000359] Batch Translation Loss:   8.956872 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 15:20:09,708 [Epoch: 003 Step: 00000360] Batch Translation Loss:   8.976722 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 15:20:18,317 [Epoch: 003 Step: 00000361] Batch Translation Loss:   8.093965 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 15:20:27,762 [Epoch: 003 Step: 00000362] Batch Translation Loss:   7.532030 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 15:20:37,249 [Epoch: 003 Step: 00000363] Batch Translation Loss:   7.324543 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 15:20:47,079 [Epoch: 003 Step: 00000364] Batch Translation Loss:   8.501253 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 15:20:57,336 [Epoch: 003 Step: 00000365] Batch Translation Loss:   8.261112 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 15:21:09,041 [Epoch: 003 Step: 00000366] Batch Translation Loss:   9.746726 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 15:21:24,757 [Epoch: 003 Step: 00000367] Batch Translation Loss:   8.679529 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 15:21:43,024 [Epoch: 003 Step: 00000368] Batch Translation Loss:   8.840333 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:21:52,799 [Epoch: 003 Step: 00000369] Batch Translation Loss:   8.164531 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 15:22:03,070 [Epoch: 003 Step: 00000370] Batch Translation Loss:   6.725574 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 15:22:13,380 [Epoch: 003 Step: 00000371] Batch Translation Loss:   7.835396 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 15:22:29,526 [Epoch: 003 Step: 00000372] Batch Translation Loss:   8.260561 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:22:47,824 [Epoch: 003 Step: 00000373] Batch Translation Loss:   8.339770 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:23:07,569 [Epoch: 003 Step: 00000374] Batch Translation Loss:  10.072770 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:23:22,007 [Epoch: 003 Step: 00000375] Batch Translation Loss:  11.098716 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 15:23:33,595 [Epoch: 003 Step: 00000376] Batch Translation Loss:   8.250522 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 15:23:54,804 [Epoch: 003 Step: 00000377] Batch Translation Loss:  10.515624 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:24:06,446 [Epoch: 003 Step: 00000378] Batch Translation Loss:   8.299660 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 15:24:18,328 [Epoch: 003 Step: 00000379] Batch Translation Loss:   8.373426 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 15:24:38,744 [Epoch: 003 Step: 00000380] Batch Translation Loss:   9.479041 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:24:51,906 [Epoch: 003 Step: 00000381] Batch Translation Loss:   8.473324 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 15:25:12,995 [Epoch: 003 Step: 00000382] Batch Translation Loss:   9.977644 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:25:33,301 [Epoch: 003 Step: 00000383] Batch Translation Loss:   9.003025 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:25:55,838 [Epoch: 003 Step: 00000384] Batch Translation Loss:   9.457371 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:26:08,744 [Epoch: 003 Step: 00000385] Batch Translation Loss:   7.248389 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 15:26:21,874 [Epoch: 003 Step: 00000386] Batch Translation Loss:   8.455831 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 15:26:35,628 [Epoch: 003 Step: 00000387] Batch Translation Loss:   9.023223 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 15:26:50,235 [Epoch: 003 Step: 00000388] Batch Translation Loss:   6.971667 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:27:14,309 [Epoch: 003 Step: 00000389] Batch Translation Loss:   7.417913 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:27:27,230 [Epoch: 003 Step: 00000390] Batch Translation Loss:   7.613432 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 15:27:41,780 [Epoch: 003 Step: 00000391] Batch Translation Loss:   7.931586 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 15:27:54,359 [Epoch: 003 Step: 00000392] Batch Translation Loss:   7.945219 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 15:28:07,706 [Epoch: 003 Step: 00000393] Batch Translation Loss:   8.361838 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 15:28:21,833 [Epoch: 003 Step: 00000394] Batch Translation Loss:   7.360526 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:28:35,627 [Epoch: 003 Step: 00000395] Batch Translation Loss:   9.664433 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 15:28:49,740 [Epoch: 003 Step: 00000396] Batch Translation Loss:   7.556209 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 15:29:03,032 [Epoch: 003 Step: 00000397] Batch Translation Loss:   7.809483 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 15:29:29,225 [Epoch: 003 Step: 00000398] Batch Translation Loss:   9.601230 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:29:44,026 [Epoch: 003 Step: 00000399] Batch Translation Loss:   7.393538 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:30:00,065 [Epoch: 003 Step: 00000400] Batch Translation Loss:   6.868586 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:34:41,381 Validation result at epoch   3, step      400: duration: 281.3152s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 10328.31641	PPL: 4373.73779
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 2.99,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 9.44	ROUGE 3.45
2021-12-29 15:34:46,760 Logging Recognition and Translation Outputs
2021-12-29 15:34:46,761 ========================================================================================================================
2021-12-29 15:34:46,761 Logging Sequence: youtube_1-don_grushkin_2316
2021-12-29 15:34:46,761 	Text Reference  :	unicode
2021-12-29 15:34:46,761 	Text Hypothesis :	asl    
2021-12-29 15:34:46,761 	Text Alignment  :	S      
2021-12-29 15:34:46,761 ========================================================================================================================
2021-12-29 15:34:46,761 Logging Sequence: deafvideo_5-silentoneye_7315
2021-12-29 15:34:46,762 	Text Reference  :	land
2021-12-29 15:34:46,762 	Text Hypothesis :	asl 
2021-12-29 15:34:46,762 	Text Alignment  :	S   
2021-12-29 15:34:46,762 ========================================================================================================================
2021-12-29 15:34:46,762 Logging Sequence: deafvideo_3-geoalpha_4551
2021-12-29 15:34:46,762 	Text Reference  :	fish eye lens
2021-12-29 15:34:46,762 	Text Hypothesis :	**** *** asl 
2021-12-29 15:34:46,762 	Text Alignment  :	D    D   S   
2021-12-29 15:34:46,762 ========================================================================================================================
2021-12-29 15:34:46,762 Logging Sequence: youtube_5-sean_berdy_6116
2021-12-29 15:34:46,762 	Text Reference  :	pugins
2021-12-29 15:34:46,763 	Text Hypothesis :	asl   
2021-12-29 15:34:46,763 	Text Alignment  :	S     
2021-12-29 15:34:46,763 ========================================================================================================================
2021-12-29 15:34:46,763 Logging Sequence: deafvideo_3-deafgoldenhair_3080
2021-12-29 15:34:46,763 	Text Reference  :	council of 
2021-12-29 15:34:46,763 	Text Hypothesis :	******* asl
2021-12-29 15:34:46,763 	Text Alignment  :	D       S  
2021-12-29 15:34:46,763 ========================================================================================================================
2021-12-29 15:35:00,692 [Epoch: 003 Step: 00000401] Batch Translation Loss:   6.631654 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:35:15,773 [Epoch: 003 Step: 00000402] Batch Translation Loss:   7.326202 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:35:31,495 [Epoch: 003 Step: 00000403] Batch Translation Loss:   8.979868 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 15:35:50,430 [Epoch: 003 Step: 00000404] Batch Translation Loss:  10.155397 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 15:36:05,525 [Epoch: 003 Step: 00000405] Batch Translation Loss:   7.985039 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:36:32,390 [Epoch: 003 Step: 00000406] Batch Translation Loss:   8.270275 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:36:48,919 [Epoch: 003 Step: 00000407] Batch Translation Loss:   8.564093 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:37:06,530 [Epoch: 003 Step: 00000408] Batch Translation Loss:  10.930687 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 15:37:22,207 [Epoch: 003 Step: 00000409] Batch Translation Loss:   7.471386 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:37:37,349 [Epoch: 003 Step: 00000410] Batch Translation Loss:   7.243527 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:37:52,970 [Epoch: 003 Step: 00000411] Batch Translation Loss:   7.075121 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:38:09,967 [Epoch: 003 Step: 00000412] Batch Translation Loss:   7.432076 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:38:26,925 [Epoch: 003 Step: 00000413] Batch Translation Loss:   8.149968 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:38:44,727 [Epoch: 003 Step: 00000414] Batch Translation Loss:   7.066543 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:39:01,002 [Epoch: 003 Step: 00000415] Batch Translation Loss:   8.024733 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:39:19,397 [Epoch: 003 Step: 00000416] Batch Translation Loss:   9.725490 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 15:39:36,020 [Epoch: 003 Step: 00000417] Batch Translation Loss:   7.000647 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:39:52,002 [Epoch: 003 Step: 00000418] Batch Translation Loss:   7.318289 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:40:10,155 [Epoch: 003 Step: 00000419] Batch Translation Loss:   8.292922 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:40:43,753 [Epoch: 003 Step: 00000420] Batch Translation Loss:  10.110602 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:41:02,387 [Epoch: 003 Step: 00000421] Batch Translation Loss:   8.311810 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:41:19,775 [Epoch: 003 Step: 00000422] Batch Translation Loss:   8.202513 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:41:37,615 [Epoch: 003 Step: 00000423] Batch Translation Loss:   6.602770 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:41:56,017 [Epoch: 003 Step: 00000424] Batch Translation Loss:   7.933978 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:42:13,282 [Epoch: 003 Step: 00000425] Batch Translation Loss:   7.932456 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:42:30,463 [Epoch: 003 Step: 00000426] Batch Translation Loss:   6.700019 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:42:48,394 [Epoch: 003 Step: 00000427] Batch Translation Loss:   8.261328 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:43:06,628 [Epoch: 003 Step: 00000428] Batch Translation Loss:   7.726770 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:43:26,024 [Epoch: 003 Step: 00000429] Batch Translation Loss:   7.750414 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:43:59,640 [Epoch: 003 Step: 00000430] Batch Translation Loss:   8.784449 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:44:17,560 [Epoch: 003 Step: 00000431] Batch Translation Loss:   7.087245 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:44:35,372 [Epoch: 003 Step: 00000432] Batch Translation Loss:   6.311460 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:45:14,278 [Epoch: 003 Step: 00000433] Batch Translation Loss:   7.061786 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:45:32,827 [Epoch: 003 Step: 00000434] Batch Translation Loss:   7.687999 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:46:13,764 [Epoch: 003 Step: 00000435] Batch Translation Loss:   6.994373 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:46:47,536 [Epoch: 003 Step: 00000436] Batch Translation Loss:   8.220880 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:47:08,119 [Epoch: 003 Step: 00000437] Batch Translation Loss:   7.218942 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:47:27,396 [Epoch: 003 Step: 00000438] Batch Translation Loss:   7.323841 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:47:47,154 [Epoch: 003 Step: 00000439] Batch Translation Loss:   7.284714 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:48:07,118 [Epoch: 003 Step: 00000440] Batch Translation Loss:   7.189291 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:48:28,664 [Epoch: 003 Step: 00000441] Batch Translation Loss:   7.759920 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:48:48,630 [Epoch: 003 Step: 00000442] Batch Translation Loss:   7.278001 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:49:08,901 [Epoch: 003 Step: 00000443] Batch Translation Loss:   8.807695 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:49:30,234 [Epoch: 003 Step: 00000444] Batch Translation Loss:   7.719995 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:49:50,052 [Epoch: 003 Step: 00000445] Batch Translation Loss:   8.130926 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:50:10,207 [Epoch: 003 Step: 00000446] Batch Translation Loss:   7.619761 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:50:30,818 [Epoch: 003 Step: 00000447] Batch Translation Loss:   7.780583 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:50:51,222 [Epoch: 003 Step: 00000448] Batch Translation Loss:   8.052772 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:51:13,010 [Epoch: 003 Step: 00000449] Batch Translation Loss:   6.725124 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:51:33,509 [Epoch: 003 Step: 00000450] Batch Translation Loss:   8.624567 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:52:01,412 [Epoch: 003 Step: 00000451] Batch Translation Loss:   7.780211 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:52:24,335 [Epoch: 003 Step: 00000452] Batch Translation Loss:   6.880478 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:52:46,221 [Epoch: 003 Step: 00000453] Batch Translation Loss:   8.469531 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:53:08,085 [Epoch: 003 Step: 00000454] Batch Translation Loss:   7.490884 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:53:29,669 [Epoch: 003 Step: 00000455] Batch Translation Loss:   8.288793 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:53:50,957 [Epoch: 003 Step: 00000456] Batch Translation Loss:   6.528829 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:54:12,475 [Epoch: 003 Step: 00000457] Batch Translation Loss:   7.084784 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:54:34,663 [Epoch: 003 Step: 00000458] Batch Translation Loss:   7.592269 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:54:57,199 [Epoch: 003 Step: 00000459] Batch Translation Loss:   8.318541 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:55:19,814 [Epoch: 003 Step: 00000460] Batch Translation Loss:   8.174840 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:55:42,892 [Epoch: 003 Step: 00000461] Batch Translation Loss:   7.788567 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:56:05,314 [Epoch: 003 Step: 00000462] Batch Translation Loss:   7.967197 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:56:27,769 [Epoch: 003 Step: 00000463] Batch Translation Loss:   8.336585 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:56:49,681 [Epoch: 003 Step: 00000464] Batch Translation Loss:   7.259387 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:57:14,132 [Epoch: 003 Step: 00000465] Batch Translation Loss:   7.702924 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:57:36,862 [Epoch: 003 Step: 00000466] Batch Translation Loss:   7.355451 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:57:59,935 [Epoch: 003 Step: 00000467] Batch Translation Loss:   6.871124 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:58:23,142 [Epoch: 003 Step: 00000468] Batch Translation Loss:   7.943295 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 15:58:47,184 [Epoch: 003 Step: 00000469] Batch Translation Loss:   7.838039 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:59:10,696 [Epoch: 003 Step: 00000470] Batch Translation Loss:   7.705883 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 15:59:34,455 [Epoch: 003 Step: 00000471] Batch Translation Loss:   7.061256 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:00:00,285 [Epoch: 003 Step: 00000472] Batch Translation Loss:   8.536886 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:00:24,588 [Epoch: 003 Step: 00000473] Batch Translation Loss:   6.819571 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:00:49,087 [Epoch: 003 Step: 00000474] Batch Translation Loss:   7.519270 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:01:13,589 [Epoch: 003 Step: 00000475] Batch Translation Loss:   6.619373 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:01:38,455 [Epoch: 003 Step: 00000476] Batch Translation Loss:   7.347419 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:02:03,217 [Epoch: 003 Step: 00000477] Batch Translation Loss:   7.930474 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:02:28,429 [Epoch: 003 Step: 00000478] Batch Translation Loss:   8.367290 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:02:54,496 [Epoch: 003 Step: 00000479] Batch Translation Loss:   9.371589 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:03:40,855 [Epoch: 003 Step: 00000480] Batch Translation Loss:   8.536094 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:04:06,009 [Epoch: 003 Step: 00000481] Batch Translation Loss:   7.615580 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:04:30,885 [Epoch: 003 Step: 00000482] Batch Translation Loss:   8.047793 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:04:56,789 [Epoch: 003 Step: 00000483] Batch Translation Loss:   9.966484 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:05:23,200 [Epoch: 003 Step: 00000484] Batch Translation Loss:   8.576960 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:05:47,974 [Epoch: 003 Step: 00000485] Batch Translation Loss:   7.132456 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:06:13,522 [Epoch: 003 Step: 00000486] Batch Translation Loss:   6.612177 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:06:39,748 [Epoch: 003 Step: 00000487] Batch Translation Loss:   8.106463 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:07:06,219 [Epoch: 003 Step: 00000488] Batch Translation Loss:   9.134789 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:07:32,386 [Epoch: 003 Step: 00000489] Batch Translation Loss:   7.787939 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:08:01,022 [Epoch: 003 Step: 00000490] Batch Translation Loss:   7.924800 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:08:27,470 [Epoch: 003 Step: 00000491] Batch Translation Loss:   7.165027 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:08:54,288 [Epoch: 003 Step: 00000492] Batch Translation Loss:   8.172936 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:09:20,765 [Epoch: 003 Step: 00000493] Batch Translation Loss:   7.418740 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:09:47,731 [Epoch: 003 Step: 00000494] Batch Translation Loss:   7.606637 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:10:16,283 [Epoch: 003 Step: 00000495] Batch Translation Loss:   7.075603 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:10:43,026 [Epoch: 003 Step: 00000496] Batch Translation Loss:   7.039880 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:11:10,504 [Epoch: 003 Step: 00000497] Batch Translation Loss:   8.496046 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:11:38,520 [Epoch: 003 Step: 00000498] Batch Translation Loss:   7.766889 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:12:06,742 [Epoch: 003 Step: 00000499] Batch Translation Loss:   8.288337 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:12:34,122 [Epoch: 003 Step: 00000500] Batch Translation Loss:   7.697067 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:17:41,918 Validation result at epoch   3, step      500: duration: 307.7951s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 10579.13184	PPL: 4642.65576
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 3.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 6.60	ROUGE 3.53
2021-12-29 16:17:48,259 Logging Recognition and Translation Outputs
2021-12-29 16:17:48,260 ========================================================================================================================
2021-12-29 16:17:48,261 Logging Sequence: youtube_3-ben_bahan_4532
2021-12-29 16:17:48,261 	Text Reference  :	agents
2021-12-29 16:17:48,261 	Text Hypothesis :	deaf  
2021-12-29 16:17:48,262 	Text Alignment  :	S     
2021-12-29 16:17:48,262 ========================================================================================================================
2021-12-29 16:17:48,262 Logging Sequence: youtube_1-catherine_mackinnon_2827
2021-12-29 16:17:48,262 	Text Reference  :	om 
2021-12-29 16:17:48,262 	Text Hypothesis :	asl
2021-12-29 16:17:48,263 	Text Alignment  :	S  
2021-12-29 16:17:48,263 ========================================================================================================================
2021-12-29 16:17:48,263 Logging Sequence: youtube_3-ben_bahan_4523
2021-12-29 16:17:48,263 	Text Reference  :	paleo herew
2021-12-29 16:17:48,263 	Text Hypothesis :	***** deaf 
2021-12-29 16:17:48,264 	Text Alignment  :	D     S    
2021-12-29 16:17:48,264 ========================================================================================================================
2021-12-29 16:17:48,264 Logging Sequence: youtube_5-melissa_draganac-hawk_5842
2021-12-29 16:17:48,264 	Text Reference  :	ak ok
2021-12-29 16:17:48,264 	Text Hypothesis :	** or
2021-12-29 16:17:48,265 	Text Alignment  :	D  S 
2021-12-29 16:17:48,265 ========================================================================================================================
2021-12-29 16:17:48,265 Logging Sequence: deafvideo_3-titans_4696
2021-12-29 16:17:48,265 	Text Reference  :	wow
2021-12-29 16:17:48,265 	Text Hypothesis :	asl
2021-12-29 16:17:48,266 	Text Alignment  :	S  
2021-12-29 16:17:48,266 ========================================================================================================================
2021-12-29 16:18:15,337 [Epoch: 003 Step: 00000501] Batch Translation Loss:   8.692631 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:18:43,686 [Epoch: 003 Step: 00000502] Batch Translation Loss:   7.195990 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:19:10,967 [Epoch: 003 Step: 00000503] Batch Translation Loss:   6.878870 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:19:38,546 [Epoch: 003 Step: 00000504] Batch Translation Loss:   7.247435 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:20:06,985 [Epoch: 003 Step: 00000505] Batch Translation Loss:   8.603110 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:20:35,589 [Epoch: 003 Step: 00000506] Batch Translation Loss:   8.199168 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:21:04,334 [Epoch: 003 Step: 00000507] Batch Translation Loss:   7.979294 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:21:33,755 [Epoch: 003 Step: 00000508] Batch Translation Loss:   9.755152 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:22:26,800 [Epoch: 003 Step: 00000509] Batch Translation Loss:  12.303653 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-29 16:22:27,062 Epoch   3: Total Training Recognition Loss -1.00  Total Training Translation Loss 1381.45 
2021-12-29 16:22:27,062 EPOCH 4
2021-12-29 16:22:32,331 [Epoch: 004 Step: 00000510] Batch Translation Loss:   7.207735 => Txt Tokens per Sec:        6 || Lr: 0.001000
2021-12-29 16:22:38,707 [Epoch: 004 Step: 00000511] Batch Translation Loss:   8.834638 => Txt Tokens per Sec:        6 || Lr: 0.001000
2021-12-29 16:22:45,135 [Epoch: 004 Step: 00000512] Batch Translation Loss:   9.384014 => Txt Tokens per Sec:        7 || Lr: 0.001000
2021-12-29 16:22:52,533 [Epoch: 004 Step: 00000513] Batch Translation Loss:   9.280540 => Txt Tokens per Sec:        6 || Lr: 0.001000
2021-12-29 16:23:03,255 [Epoch: 004 Step: 00000514] Batch Translation Loss:  11.442060 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 16:23:12,788 [Epoch: 004 Step: 00000515] Batch Translation Loss:   9.772095 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 16:23:21,121 [Epoch: 004 Step: 00000516] Batch Translation Loss:   9.665192 => Txt Tokens per Sec:        6 || Lr: 0.001000
2021-12-29 16:23:29,087 [Epoch: 004 Step: 00000517] Batch Translation Loss:   8.863629 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 16:23:40,145 [Epoch: 004 Step: 00000518] Batch Translation Loss:   9.593397 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 16:23:50,224 [Epoch: 004 Step: 00000519] Batch Translation Loss:  11.472664 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 16:23:59,712 [Epoch: 004 Step: 00000520] Batch Translation Loss:   9.296287 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 16:24:11,305 [Epoch: 004 Step: 00000521] Batch Translation Loss:  10.293861 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 16:24:21,331 [Epoch: 004 Step: 00000522] Batch Translation Loss:   9.321052 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 16:24:28,492 [Epoch: 004 Step: 00000523] Batch Translation Loss:   7.332489 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 16:24:43,916 [Epoch: 004 Step: 00000524] Batch Translation Loss:   7.670793 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:24:56,105 [Epoch: 004 Step: 00000525] Batch Translation Loss:   8.587955 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:25:08,888 [Epoch: 004 Step: 00000526] Batch Translation Loss:   8.867756 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:25:22,311 [Epoch: 004 Step: 00000527] Batch Translation Loss:   9.341716 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:25:37,532 [Epoch: 004 Step: 00000528] Batch Translation Loss:   8.957627 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:25:52,370 [Epoch: 004 Step: 00000529] Batch Translation Loss:   9.745379 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:26:01,099 [Epoch: 004 Step: 00000530] Batch Translation Loss:   8.213898 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 16:26:17,727 [Epoch: 004 Step: 00000531] Batch Translation Loss:  10.904518 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:26:26,296 [Epoch: 004 Step: 00000532] Batch Translation Loss:   8.366508 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 16:26:36,919 [Epoch: 004 Step: 00000533] Batch Translation Loss:  10.021627 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 16:26:54,281 [Epoch: 004 Step: 00000534] Batch Translation Loss:  10.467199 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:27:08,830 [Epoch: 004 Step: 00000535] Batch Translation Loss:   7.670738 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:27:19,811 [Epoch: 004 Step: 00000536] Batch Translation Loss:   7.910048 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:27:29,783 [Epoch: 004 Step: 00000537] Batch Translation Loss:   7.658774 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 16:27:40,269 [Epoch: 004 Step: 00000538] Batch Translation Loss:   8.198182 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 16:27:58,153 [Epoch: 004 Step: 00000539] Batch Translation Loss:   8.565600 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:28:09,750 [Epoch: 004 Step: 00000540] Batch Translation Loss:   8.961839 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 16:28:19,681 [Epoch: 004 Step: 00000541] Batch Translation Loss:   7.373764 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 16:28:32,427 [Epoch: 004 Step: 00000542] Batch Translation Loss:   9.859999 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 16:28:43,083 [Epoch: 004 Step: 00000543] Batch Translation Loss:   7.390753 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 16:28:53,586 [Epoch: 004 Step: 00000544] Batch Translation Loss:   7.103941 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:29:06,551 [Epoch: 004 Step: 00000545] Batch Translation Loss:   7.660779 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:29:24,645 [Epoch: 004 Step: 00000546] Batch Translation Loss:   7.776165 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:29:35,350 [Epoch: 004 Step: 00000547] Batch Translation Loss:   6.214509 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:29:45,985 [Epoch: 004 Step: 00000548] Batch Translation Loss:   6.604572 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:29:57,542 [Epoch: 004 Step: 00000549] Batch Translation Loss:   8.967316 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 16:30:09,318 [Epoch: 004 Step: 00000550] Batch Translation Loss:   7.240241 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:30:20,483 [Epoch: 004 Step: 00000551] Batch Translation Loss:   6.956133 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:30:42,688 [Epoch: 004 Step: 00000552] Batch Translation Loss:   8.486235 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:30:56,018 [Epoch: 004 Step: 00000553] Batch Translation Loss:   7.160833 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:31:08,942 [Epoch: 004 Step: 00000554] Batch Translation Loss:   7.816022 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:31:20,961 [Epoch: 004 Step: 00000555] Batch Translation Loss:   7.739321 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:31:34,425 [Epoch: 004 Step: 00000556] Batch Translation Loss:   9.437051 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:31:50,670 [Epoch: 004 Step: 00000557] Batch Translation Loss:  10.000207 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:32:05,266 [Epoch: 004 Step: 00000558] Batch Translation Loss:   7.291787 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:32:21,656 [Epoch: 004 Step: 00000559] Batch Translation Loss:   9.542248 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:32:36,656 [Epoch: 004 Step: 00000560] Batch Translation Loss:   8.703445 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:32:52,327 [Epoch: 004 Step: 00000561] Batch Translation Loss:   6.673807 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:33:04,977 [Epoch: 004 Step: 00000562] Batch Translation Loss:   7.092469 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:33:17,940 [Epoch: 004 Step: 00000563] Batch Translation Loss:   8.608624 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:33:43,031 [Epoch: 004 Step: 00000564] Batch Translation Loss:   8.079243 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:34:10,500 [Epoch: 004 Step: 00000565] Batch Translation Loss:   9.391263 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:34:24,348 [Epoch: 004 Step: 00000566] Batch Translation Loss:   7.349285 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:34:38,328 [Epoch: 004 Step: 00000567] Batch Translation Loss:   7.290499 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:34:53,494 [Epoch: 004 Step: 00000568] Batch Translation Loss:   7.563590 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:35:08,015 [Epoch: 004 Step: 00000569] Batch Translation Loss:   8.064219 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:35:22,231 [Epoch: 004 Step: 00000570] Batch Translation Loss:   6.942817 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:35:36,645 [Epoch: 004 Step: 00000571] Batch Translation Loss:   7.772478 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:35:51,537 [Epoch: 004 Step: 00000572] Batch Translation Loss:   7.881911 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:36:08,104 [Epoch: 004 Step: 00000573] Batch Translation Loss:   7.058911 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:36:34,208 [Epoch: 004 Step: 00000574] Batch Translation Loss:   8.954070 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:36:49,545 [Epoch: 004 Step: 00000575] Batch Translation Loss:   7.872426 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:37:05,821 [Epoch: 004 Step: 00000576] Batch Translation Loss:   8.658128 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:37:20,963 [Epoch: 004 Step: 00000577] Batch Translation Loss:   6.842133 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:37:36,824 [Epoch: 004 Step: 00000578] Batch Translation Loss:   8.304845 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:37:52,523 [Epoch: 004 Step: 00000579] Batch Translation Loss:   7.288776 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:38:07,558 [Epoch: 004 Step: 00000580] Batch Translation Loss:   7.329730 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:38:23,047 [Epoch: 004 Step: 00000581] Batch Translation Loss:   7.258984 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:38:39,110 [Epoch: 004 Step: 00000582] Batch Translation Loss:   8.619188 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:38:56,629 [Epoch: 004 Step: 00000583] Batch Translation Loss:   7.944002 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:39:12,444 [Epoch: 004 Step: 00000584] Batch Translation Loss:   8.284081 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:39:29,177 [Epoch: 004 Step: 00000585] Batch Translation Loss:   7.727138 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:39:45,374 [Epoch: 004 Step: 00000586] Batch Translation Loss:   6.434373 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:40:01,256 [Epoch: 004 Step: 00000587] Batch Translation Loss:   7.436340 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:40:17,648 [Epoch: 004 Step: 00000588] Batch Translation Loss:   6.853428 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:40:34,065 [Epoch: 004 Step: 00000589] Batch Translation Loss:   7.376079 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:40:50,265 [Epoch: 004 Step: 00000590] Batch Translation Loss:   7.103071 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:41:06,960 [Epoch: 004 Step: 00000591] Batch Translation Loss:   6.577851 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:41:39,152 [Epoch: 004 Step: 00000592] Batch Translation Loss:   9.605562 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:41:57,113 [Epoch: 004 Step: 00000593] Batch Translation Loss:   7.281015 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:42:16,134 [Epoch: 004 Step: 00000594] Batch Translation Loss:   7.008327 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:42:34,348 [Epoch: 004 Step: 00000595] Batch Translation Loss:   7.045786 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:42:52,750 [Epoch: 004 Step: 00000596] Batch Translation Loss:   7.881128 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:43:12,466 [Epoch: 004 Step: 00000597] Batch Translation Loss:   7.603612 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:43:44,981 [Epoch: 004 Step: 00000598] Batch Translation Loss:   7.103472 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:44:04,889 [Epoch: 004 Step: 00000599] Batch Translation Loss:   7.434506 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:44:23,302 [Epoch: 004 Step: 00000600] Batch Translation Loss:   7.735753 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:49:30,010 Validation result at epoch   4, step      600: duration: 306.7072s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11247.84473	PPL: 7321.80420
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 2.28,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 8.08	ROUGE 2.77
2021-12-29 16:49:35,104 Logging Recognition and Translation Outputs
2021-12-29 16:49:35,105 ========================================================================================================================
2021-12-29 16:49:35,105 Logging Sequence: youtube_1-don_grushkin_2759
2021-12-29 16:49:35,105 	Text Reference  :	open source
2021-12-29 16:49:35,105 	Text Hypothesis :	**** of    
2021-12-29 16:49:35,105 	Text Alignment  :	D    S     
2021-12-29 16:49:35,105 ========================================================================================================================
2021-12-29 16:49:35,106 Logging Sequence: deafvideo_2-fairytales9_2285
2021-12-29 16:49:35,106 	Text Reference  :	dirctory
2021-12-29 16:49:35,106 	Text Hypothesis :	asl     
2021-12-29 16:49:35,106 	Text Alignment  :	S       
2021-12-29 16:49:35,106 ========================================================================================================================
2021-12-29 16:49:35,106 Logging Sequence: youtube_1-shoshannah_stern_2397
2021-12-29 16:49:35,106 	Text Reference  :	emmett
2021-12-29 16:49:35,106 	Text Hypothesis :	asl   
2021-12-29 16:49:35,106 	Text Alignment  :	S     
2021-12-29 16:49:35,106 ========================================================================================================================
2021-12-29 16:49:35,106 Logging Sequence: youtube_1-catherine_mackinnon_2820
2021-12-29 16:49:35,107 	Text Reference  :	up to 
2021-12-29 16:49:35,107 	Text Hypothesis :	** asl
2021-12-29 16:49:35,107 	Text Alignment  :	D  S  
2021-12-29 16:49:35,107 ========================================================================================================================
2021-12-29 16:49:35,107 Logging Sequence: youtube_1-catherine_mackinnon_2844
2021-12-29 16:49:35,107 	Text Reference  :	tump
2021-12-29 16:49:35,107 	Text Hypothesis :	asl 
2021-12-29 16:49:35,107 	Text Alignment  :	S   
2021-12-29 16:49:35,107 ========================================================================================================================
2021-12-29 16:49:54,512 [Epoch: 004 Step: 00000601] Batch Translation Loss:   7.681728 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:50:12,963 [Epoch: 004 Step: 00000602] Batch Translation Loss:   7.000405 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:50:31,872 [Epoch: 004 Step: 00000603] Batch Translation Loss:   9.820558 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 16:50:50,425 [Epoch: 004 Step: 00000604] Batch Translation Loss:   6.784366 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:51:09,747 [Epoch: 004 Step: 00000605] Batch Translation Loss:   7.484414 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:51:29,564 [Epoch: 004 Step: 00000606] Batch Translation Loss:   6.645308 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:51:48,354 [Epoch: 004 Step: 00000607] Batch Translation Loss:   6.972148 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:52:07,119 [Epoch: 004 Step: 00000608] Batch Translation Loss:   6.895144 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:52:26,356 [Epoch: 004 Step: 00000609] Batch Translation Loss:   7.372425 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:52:45,740 [Epoch: 004 Step: 00000610] Batch Translation Loss:   8.352847 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:53:05,162 [Epoch: 004 Step: 00000611] Batch Translation Loss:   6.736822 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:53:25,786 [Epoch: 004 Step: 00000612] Batch Translation Loss:   6.292574 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:53:46,377 [Epoch: 004 Step: 00000613] Batch Translation Loss:   7.058371 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:54:06,114 [Epoch: 004 Step: 00000614] Batch Translation Loss:   6.941541 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:54:26,098 [Epoch: 004 Step: 00000615] Batch Translation Loss:   7.228833 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:54:46,438 [Epoch: 004 Step: 00000616] Batch Translation Loss:   6.665134 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:55:07,192 [Epoch: 004 Step: 00000617] Batch Translation Loss:   7.195296 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:55:27,704 [Epoch: 004 Step: 00000618] Batch Translation Loss:   6.250963 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:55:48,268 [Epoch: 004 Step: 00000619] Batch Translation Loss:   6.979256 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:56:10,338 [Epoch: 004 Step: 00000620] Batch Translation Loss:   7.676829 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:56:36,130 [Epoch: 004 Step: 00000621] Batch Translation Loss:   8.119656 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 16:57:03,892 [Epoch: 004 Step: 00000622] Batch Translation Loss:   7.113138 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:57:41,765 [Epoch: 004 Step: 00000623] Batch Translation Loss:   8.308619 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:58:15,051 [Epoch: 004 Step: 00000624] Batch Translation Loss:   7.101502 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:59:16,675 [Epoch: 004 Step: 00000625] Batch Translation Loss:   7.645158 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 16:59:53,042 [Epoch: 004 Step: 00000626] Batch Translation Loss:   7.191876 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:00:55,710 [Epoch: 004 Step: 00000627] Batch Translation Loss:   7.255633 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:01:32,085 [Epoch: 004 Step: 00000628] Batch Translation Loss:   8.864061 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:02:10,564 [Epoch: 004 Step: 00000629] Batch Translation Loss:   6.988058 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:02:45,654 [Epoch: 004 Step: 00000630] Batch Translation Loss:   7.931714 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:03:19,962 [Epoch: 004 Step: 00000631] Batch Translation Loss:   7.221292 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:04:29,112 [Epoch: 004 Step: 00000632] Batch Translation Loss:   7.398265 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:05:06,360 [Epoch: 004 Step: 00000633] Batch Translation Loss:   8.077919 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:05:43,920 [Epoch: 004 Step: 00000634] Batch Translation Loss:   7.336793 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:06:53,919 [Epoch: 004 Step: 00000635] Batch Translation Loss:   7.078483 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:07:32,007 [Epoch: 004 Step: 00000636] Batch Translation Loss:   6.846667 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:08:07,433 [Epoch: 004 Step: 00000637] Batch Translation Loss:   8.377327 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:08:42,903 [Epoch: 004 Step: 00000638] Batch Translation Loss:   7.846385 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:09:48,812 [Epoch: 004 Step: 00000639] Batch Translation Loss:   7.109761 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:10:24,946 [Epoch: 004 Step: 00000640] Batch Translation Loss:   7.538757 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:10:58,786 [Epoch: 004 Step: 00000641] Batch Translation Loss:   8.279251 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:11:33,996 [Epoch: 004 Step: 00000642] Batch Translation Loss:   7.307954 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:12:12,974 [Epoch: 004 Step: 00000643] Batch Translation Loss:   6.460382 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:12:56,817 [Epoch: 004 Step: 00000644] Batch Translation Loss:   8.588158 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:13:35,590 [Epoch: 004 Step: 00000645] Batch Translation Loss:   8.775337 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:14:14,584 [Epoch: 004 Step: 00000646] Batch Translation Loss:   7.159618 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:14:54,028 [Epoch: 004 Step: 00000647] Batch Translation Loss:   7.524608 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:15:28,977 [Epoch: 004 Step: 00000648] Batch Translation Loss:   6.807343 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:15:56,122 [Epoch: 004 Step: 00000649] Batch Translation Loss:   8.175504 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:16:23,291 [Epoch: 004 Step: 00000650] Batch Translation Loss:   7.947524 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:17:12,744 [Epoch: 004 Step: 00000651] Batch Translation Loss:   9.178547 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:17:39,018 [Epoch: 004 Step: 00000652] Batch Translation Loss:   6.511623 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:18:05,333 [Epoch: 004 Step: 00000653] Batch Translation Loss:   6.935798 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:18:32,061 [Epoch: 004 Step: 00000654] Batch Translation Loss:   8.053881 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:19:20,208 [Epoch: 004 Step: 00000655] Batch Translation Loss:   7.077934 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:19:48,137 [Epoch: 004 Step: 00000656] Batch Translation Loss:   7.348114 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:20:14,735 [Epoch: 004 Step: 00000657] Batch Translation Loss:   6.270438 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:20:42,798 [Epoch: 004 Step: 00000658] Batch Translation Loss:   8.494111 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:21:09,862 [Epoch: 004 Step: 00000659] Batch Translation Loss:   8.277788 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:21:36,895 [Epoch: 004 Step: 00000660] Batch Translation Loss:   8.403090 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:22:03,869 [Epoch: 004 Step: 00000661] Batch Translation Loss:   8.537875 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:22:30,721 [Epoch: 004 Step: 00000662] Batch Translation Loss:   7.343175 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:22:59,218 [Epoch: 004 Step: 00000663] Batch Translation Loss:   8.316560 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:23:26,521 [Epoch: 004 Step: 00000664] Batch Translation Loss:   7.585441 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:23:53,211 [Epoch: 004 Step: 00000665] Batch Translation Loss:   6.847175 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:24:21,022 [Epoch: 004 Step: 00000666] Batch Translation Loss:   7.667542 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:24:47,955 [Epoch: 004 Step: 00000667] Batch Translation Loss:   7.396596 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:25:14,651 [Epoch: 004 Step: 00000668] Batch Translation Loss:   6.409044 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:25:41,845 [Epoch: 004 Step: 00000669] Batch Translation Loss:   7.532759 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:26:09,181 [Epoch: 004 Step: 00000670] Batch Translation Loss:   7.115438 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:26:37,618 [Epoch: 004 Step: 00000671] Batch Translation Loss:   7.540434 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:27:05,224 [Epoch: 004 Step: 00000672] Batch Translation Loss:   7.289670 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:27:34,068 [Epoch: 004 Step: 00000673] Batch Translation Loss:   7.859215 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:28:01,614 [Epoch: 004 Step: 00000674] Batch Translation Loss:   6.273279 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:28:29,195 [Epoch: 004 Step: 00000675] Batch Translation Loss:   6.909317 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:28:57,161 [Epoch: 004 Step: 00000676] Batch Translation Loss:   6.716462 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:29:25,134 [Epoch: 004 Step: 00000677] Batch Translation Loss:   7.379601 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:30:21,160 [Epoch: 004 Step: 00000678] Batch Translation Loss:  10.344015 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:31:10,941 [Epoch: 004 Step: 00000679] Batch Translation Loss:  11.675277 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-29 17:31:11,044 Epoch   4: Total Training Recognition Loss -1.00  Total Training Translation Loss 1342.23 
2021-12-29 17:31:11,044 EPOCH 5
2021-12-29 17:31:16,979 [Epoch: 005 Step: 00000680] Batch Translation Loss:   7.204272 => Txt Tokens per Sec:        6 || Lr: 0.001000
2021-12-29 17:31:23,973 [Epoch: 005 Step: 00000681] Batch Translation Loss:   7.716166 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 17:31:31,594 [Epoch: 005 Step: 00000682] Batch Translation Loss:   8.433578 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 17:31:39,642 [Epoch: 005 Step: 00000683] Batch Translation Loss:   8.654020 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 17:31:47,406 [Epoch: 005 Step: 00000684] Batch Translation Loss:   8.725082 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 17:31:56,244 [Epoch: 005 Step: 00000685] Batch Translation Loss:   9.168712 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 17:32:05,262 [Epoch: 005 Step: 00000686] Batch Translation Loss:  10.246798 => Txt Tokens per Sec:        6 || Lr: 0.001000
2021-12-29 17:32:18,731 [Epoch: 005 Step: 00000687] Batch Translation Loss:   9.817824 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 17:32:29,718 [Epoch: 005 Step: 00000688] Batch Translation Loss:   9.404355 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 17:32:38,922 [Epoch: 005 Step: 00000689] Batch Translation Loss:   8.760021 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 17:32:51,505 [Epoch: 005 Step: 00000690] Batch Translation Loss:   8.570796 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:33:00,056 [Epoch: 005 Step: 00000691] Batch Translation Loss:   8.005283 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 17:33:09,304 [Epoch: 005 Step: 00000692] Batch Translation Loss:   8.448087 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 17:33:22,224 [Epoch: 005 Step: 00000693] Batch Translation Loss:  10.355779 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 17:33:30,848 [Epoch: 005 Step: 00000694] Batch Translation Loss:   9.079896 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 17:33:40,588 [Epoch: 005 Step: 00000695] Batch Translation Loss:   9.178759 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 17:33:48,789 [Epoch: 005 Step: 00000696] Batch Translation Loss:   6.575728 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 17:34:04,663 [Epoch: 005 Step: 00000697] Batch Translation Loss:   9.366594 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:34:13,041 [Epoch: 005 Step: 00000698] Batch Translation Loss:   7.277683 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 17:34:22,753 [Epoch: 005 Step: 00000699] Batch Translation Loss:   9.148814 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 17:34:32,674 [Epoch: 005 Step: 00000700] Batch Translation Loss:   7.866641 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 17:39:31,916 Validation result at epoch   5, step      700: duration: 299.2411s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 10979.75195	PPL: 6527.64209
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 2.40,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.84	ROUGE 2.96
2021-12-29 17:39:37,113 Logging Recognition and Translation Outputs
2021-12-29 17:39:37,113 ========================================================================================================================
2021-12-29 17:39:37,113 Logging Sequence: youtube_5-sean_berdy_6098
2021-12-29 17:39:37,114 	Text Reference  :	dhf
2021-12-29 17:39:37,114 	Text Hypothesis :	or 
2021-12-29 17:39:37,115 	Text Alignment  :	S  
2021-12-29 17:39:37,115 ========================================================================================================================
2021-12-29 17:39:37,115 Logging Sequence: deafvideo_3-yellowbirdie84_4671
2021-12-29 17:39:37,115 	Text Reference  :	cheif  
2021-12-29 17:39:37,115 	Text Hypothesis :	duality
2021-12-29 17:39:37,115 	Text Alignment  :	S      
2021-12-29 17:39:37,115 ========================================================================================================================
2021-12-29 17:39:37,116 Logging Sequence: youtube_4-sean_berdy_5750
2021-12-29 17:39:37,116 	Text Reference  :	aclu
2021-12-29 17:39:37,116 	Text Hypothesis :	asl 
2021-12-29 17:39:37,116 	Text Alignment  :	S   
2021-12-29 17:39:37,116 ========================================================================================================================
2021-12-29 17:39:37,116 Logging Sequence: youtube_5-roberta_cordano_6152
2021-12-29 17:39:37,116 	Text Reference  :	her
2021-12-29 17:39:37,117 	Text Hypothesis :	if 
2021-12-29 17:39:37,117 	Text Alignment  :	S  
2021-12-29 17:39:37,117 ========================================================================================================================
2021-12-29 17:39:37,117 Logging Sequence: youtube_1-catherine_mackinnon_2835
2021-12-29 17:39:37,117 	Text Reference  :	gadi
2021-12-29 17:39:37,117 	Text Hypothesis :	asl 
2021-12-29 17:39:37,117 	Text Alignment  :	S   
2021-12-29 17:39:37,118 ========================================================================================================================
2021-12-29 17:39:53,231 [Epoch: 005 Step: 00000701] Batch Translation Loss:  11.701284 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:40:02,974 [Epoch: 005 Step: 00000702] Batch Translation Loss:   7.505173 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 17:40:19,962 [Epoch: 005 Step: 00000703] Batch Translation Loss:  11.916610 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:40:35,733 [Epoch: 005 Step: 00000704] Batch Translation Loss:   8.796475 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:40:45,652 [Epoch: 005 Step: 00000705] Batch Translation Loss:   7.848688 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 17:40:56,585 [Epoch: 005 Step: 00000706] Batch Translation Loss:   6.895669 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:41:07,323 [Epoch: 005 Step: 00000707] Batch Translation Loss:   7.687191 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:41:17,039 [Epoch: 005 Step: 00000708] Batch Translation Loss:   7.085578 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 17:41:27,541 [Epoch: 005 Step: 00000709] Batch Translation Loss:   7.056817 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:41:39,416 [Epoch: 005 Step: 00000710] Batch Translation Loss:   9.018990 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 17:41:49,680 [Epoch: 005 Step: 00000711] Batch Translation Loss:   7.590685 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 17:42:00,212 [Epoch: 005 Step: 00000712] Batch Translation Loss:   6.794082 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:42:11,109 [Epoch: 005 Step: 00000713] Batch Translation Loss:   7.475074 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:42:28,119 [Epoch: 005 Step: 00000714] Batch Translation Loss:   7.070147 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:42:49,379 [Epoch: 005 Step: 00000715] Batch Translation Loss:   8.037976 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:43:01,150 [Epoch: 005 Step: 00000716] Batch Translation Loss:   6.819714 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:43:12,333 [Epoch: 005 Step: 00000717] Batch Translation Loss:   7.404410 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:43:25,959 [Epoch: 005 Step: 00000718] Batch Translation Loss:   9.413201 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 17:43:46,840 [Epoch: 005 Step: 00000719] Batch Translation Loss:   8.120629 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:43:58,398 [Epoch: 005 Step: 00000720] Batch Translation Loss:   7.372401 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:44:11,278 [Epoch: 005 Step: 00000721] Batch Translation Loss:   8.697820 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:44:23,480 [Epoch: 005 Step: 00000722] Batch Translation Loss:   7.664420 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:44:36,957 [Epoch: 005 Step: 00000723] Batch Translation Loss:   8.064080 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:44:50,803 [Epoch: 005 Step: 00000724] Batch Translation Loss:   8.283566 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:45:12,604 [Epoch: 005 Step: 00000725] Batch Translation Loss:   7.648908 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:45:24,533 [Epoch: 005 Step: 00000726] Batch Translation Loss:   6.827836 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:45:37,784 [Epoch: 005 Step: 00000727] Batch Translation Loss:   9.241220 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 17:45:51,678 [Epoch: 005 Step: 00000728] Batch Translation Loss:   7.129193 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:46:05,030 [Epoch: 005 Step: 00000729] Batch Translation Loss:   8.022211 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:46:17,316 [Epoch: 005 Step: 00000730] Batch Translation Loss:   7.943027 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:46:42,955 [Epoch: 005 Step: 00000731] Batch Translation Loss:   8.259367 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:46:57,192 [Epoch: 005 Step: 00000732] Batch Translation Loss:   6.975083 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:47:11,815 [Epoch: 005 Step: 00000733] Batch Translation Loss:   7.429983 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:47:26,031 [Epoch: 005 Step: 00000734] Batch Translation Loss:   7.033732 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:47:39,214 [Epoch: 005 Step: 00000735] Batch Translation Loss:   6.855163 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:48:04,577 [Epoch: 005 Step: 00000736] Batch Translation Loss:   9.050460 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:48:19,064 [Epoch: 005 Step: 00000737] Batch Translation Loss:   7.478570 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:48:45,780 [Epoch: 005 Step: 00000738] Batch Translation Loss:   8.577118 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:49:00,877 [Epoch: 005 Step: 00000739] Batch Translation Loss:   7.812900 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:49:16,138 [Epoch: 005 Step: 00000740] Batch Translation Loss:   8.132800 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:49:30,432 [Epoch: 005 Step: 00000741] Batch Translation Loss:   6.824818 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:49:44,693 [Epoch: 005 Step: 00000742] Batch Translation Loss:   7.204578 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:50:09,423 [Epoch: 005 Step: 00000743] Batch Translation Loss:   6.779268 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:50:34,198 [Epoch: 005 Step: 00000744] Batch Translation Loss:   6.897958 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:50:49,638 [Epoch: 005 Step: 00000745] Batch Translation Loss:   8.535672 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:51:06,053 [Epoch: 005 Step: 00000746] Batch Translation Loss:   8.810677 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:51:20,995 [Epoch: 005 Step: 00000747] Batch Translation Loss:   6.802332 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:51:48,347 [Epoch: 005 Step: 00000748] Batch Translation Loss:   7.526752 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:52:03,496 [Epoch: 005 Step: 00000749] Batch Translation Loss:   8.129417 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:52:19,798 [Epoch: 005 Step: 00000750] Batch Translation Loss:   7.285698 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:52:35,386 [Epoch: 005 Step: 00000751] Batch Translation Loss:   6.701478 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:52:51,364 [Epoch: 005 Step: 00000752] Batch Translation Loss:   8.272348 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:53:07,460 [Epoch: 005 Step: 00000753] Batch Translation Loss:   7.500420 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 17:53:23,418 [Epoch: 005 Step: 00000754] Batch Translation Loss:   7.153202 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:53:39,505 [Epoch: 005 Step: 00000755] Batch Translation Loss:   6.518836 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:53:56,781 [Epoch: 005 Step: 00000756] Batch Translation Loss:   6.274816 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:54:14,386 [Epoch: 005 Step: 00000757] Batch Translation Loss:   6.795572 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:54:31,878 [Epoch: 005 Step: 00000758] Batch Translation Loss:   6.705418 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:54:49,446 [Epoch: 005 Step: 00000759] Batch Translation Loss:   6.792548 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:55:08,808 [Epoch: 005 Step: 00000760] Batch Translation Loss:   7.212061 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:55:27,389 [Epoch: 005 Step: 00000761] Batch Translation Loss:   6.371483 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:55:46,491 [Epoch: 005 Step: 00000762] Batch Translation Loss:   7.076631 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:56:04,472 [Epoch: 005 Step: 00000763] Batch Translation Loss:   7.224745 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:56:21,829 [Epoch: 005 Step: 00000764] Batch Translation Loss:   7.947810 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:56:40,753 [Epoch: 005 Step: 00000765] Batch Translation Loss:   7.872940 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:57:12,168 [Epoch: 005 Step: 00000766] Batch Translation Loss:   7.950087 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:57:29,473 [Epoch: 005 Step: 00000767] Batch Translation Loss:   7.506092 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:58:02,826 [Epoch: 005 Step: 00000768] Batch Translation Loss:   7.321990 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 17:58:24,341 [Epoch: 005 Step: 00000769] Batch Translation Loss:   6.390697 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:58:43,765 [Epoch: 005 Step: 00000770] Batch Translation Loss:   8.176273 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:59:02,215 [Epoch: 005 Step: 00000771] Batch Translation Loss:   6.176932 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:59:22,226 [Epoch: 005 Step: 00000772] Batch Translation Loss:   7.691518 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 17:59:42,271 [Epoch: 005 Step: 00000773] Batch Translation Loss:   8.249795 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:00:01,298 [Epoch: 005 Step: 00000774] Batch Translation Loss:   8.028553 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:00:19,861 [Epoch: 005 Step: 00000775] Batch Translation Loss:   7.512812 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:00:40,822 [Epoch: 005 Step: 00000776] Batch Translation Loss:   7.826044 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:00:59,996 [Epoch: 005 Step: 00000777] Batch Translation Loss:   8.226619 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:01:19,194 [Epoch: 005 Step: 00000778] Batch Translation Loss:   7.225301 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:01:40,586 [Epoch: 005 Step: 00000779] Batch Translation Loss:   7.430790 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:02:01,977 [Epoch: 005 Step: 00000780] Batch Translation Loss:   6.715929 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:02:21,812 [Epoch: 005 Step: 00000781] Batch Translation Loss:   7.760025 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:02:42,102 [Epoch: 005 Step: 00000782] Batch Translation Loss:   6.363674 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:03:02,124 [Epoch: 005 Step: 00000783] Batch Translation Loss:   7.406870 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:03:22,331 [Epoch: 005 Step: 00000784] Batch Translation Loss:   7.179209 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:03:43,179 [Epoch: 005 Step: 00000785] Batch Translation Loss:   7.430903 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:04:03,688 [Epoch: 005 Step: 00000786] Batch Translation Loss:   7.004261 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:04:24,727 [Epoch: 005 Step: 00000787] Batch Translation Loss:   7.310431 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:04:45,359 [Epoch: 005 Step: 00000788] Batch Translation Loss:   7.041992 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:05:05,899 [Epoch: 005 Step: 00000789] Batch Translation Loss:   7.273438 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:05:28,062 [Epoch: 005 Step: 00000790] Batch Translation Loss:   8.224178 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:05:50,804 [Epoch: 005 Step: 00000791] Batch Translation Loss:   7.188889 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:06:14,000 [Epoch: 005 Step: 00000792] Batch Translation Loss:   6.982215 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:06:35,899 [Epoch: 005 Step: 00000793] Batch Translation Loss:   7.473594 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:06:57,110 [Epoch: 005 Step: 00000794] Batch Translation Loss:   6.538824 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:07:18,755 [Epoch: 005 Step: 00000795] Batch Translation Loss:   7.767901 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:07:41,628 [Epoch: 005 Step: 00000796] Batch Translation Loss:   8.375656 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:08:03,983 [Epoch: 005 Step: 00000797] Batch Translation Loss:   7.689709 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:08:27,672 [Epoch: 005 Step: 00000798] Batch Translation Loss:   7.334362 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:08:51,558 [Epoch: 005 Step: 00000799] Batch Translation Loss:   6.358896 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:09:14,208 [Epoch: 005 Step: 00000800] Batch Translation Loss:   7.568283 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:14:22,687 Validation result at epoch   5, step      800: duration: 308.4778s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 10756.53711	PPL: 5574.35400
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 1.93,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 4.73	ROUGE 2.47
2021-12-29 18:14:27,960 Logging Recognition and Translation Outputs
2021-12-29 18:14:27,961 ========================================================================================================================
2021-12-29 18:14:27,961 Logging Sequence: aslized-joy_maisel_6445
2021-12-29 18:14:27,961 	Text Reference  :	upates
2021-12-29 18:14:27,961 	Text Hypothesis :	or    
2021-12-29 18:14:27,961 	Text Alignment  :	S     
2021-12-29 18:14:27,961 ========================================================================================================================
2021-12-29 18:14:27,961 Logging Sequence: youtube_1-don_grushkin_2314
2021-12-29 18:14:27,962 	Text Reference  :	advocates nbda 
2021-12-29 18:14:27,962 	Text Hypothesis :	********* anita
2021-12-29 18:14:27,962 	Text Alignment  :	D         S    
2021-12-29 18:14:27,962 ========================================================================================================================
2021-12-29 18:14:27,962 Logging Sequence: deafvideo_3-otismhill82_4604
2021-12-29 18:14:27,962 	Text Reference  :	gaddafi
2021-12-29 18:14:27,962 	Text Hypothesis :	anita  
2021-12-29 18:14:27,962 	Text Alignment  :	S      
2021-12-29 18:14:27,962 ========================================================================================================================
2021-12-29 18:14:27,962 Logging Sequence: youtube_1-shoshannah_stern_2393
2021-12-29 18:14:27,962 	Text Reference  :	irs
2021-12-29 18:14:27,962 	Text Hypothesis :	asl
2021-12-29 18:14:27,963 	Text Alignment  :	S  
2021-12-29 18:14:27,963 ========================================================================================================================
2021-12-29 18:14:27,963 Logging Sequence: aslized-joy_maisel_6434
2021-12-29 18:14:27,963 	Text Reference  :	melvin paterson
2021-12-29 18:14:27,963 	Text Hypothesis :	****** asl     
2021-12-29 18:14:27,963 	Text Alignment  :	D      S       
2021-12-29 18:14:27,963 ========================================================================================================================
2021-12-29 18:14:50,515 [Epoch: 005 Step: 00000801] Batch Translation Loss:   7.231357 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:15:13,808 [Epoch: 005 Step: 00000802] Batch Translation Loss:   7.789633 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:15:37,413 [Epoch: 005 Step: 00000803] Batch Translation Loss:   7.855982 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:16:00,452 [Epoch: 005 Step: 00000804] Batch Translation Loss:   7.182723 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:16:24,776 [Epoch: 005 Step: 00000805] Batch Translation Loss:   7.393239 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:16:49,082 [Epoch: 005 Step: 00000806] Batch Translation Loss:   7.720885 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:17:12,575 [Epoch: 005 Step: 00000807] Batch Translation Loss:   7.578497 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:17:35,548 [Epoch: 005 Step: 00000808] Batch Translation Loss:   6.284182 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:17:58,553 [Epoch: 005 Step: 00000809] Batch Translation Loss:   7.287500 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:18:49,452 [Epoch: 005 Step: 00000810] Batch Translation Loss:   7.875911 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:19:13,403 [Epoch: 005 Step: 00000811] Batch Translation Loss:   7.643266 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:19:37,585 [Epoch: 005 Step: 00000812] Batch Translation Loss:   7.749506 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:20:01,485 [Epoch: 005 Step: 00000813] Batch Translation Loss:   6.723956 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:20:25,984 [Epoch: 005 Step: 00000814] Batch Translation Loss:   7.787368 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:20:50,813 [Epoch: 005 Step: 00000815] Batch Translation Loss:   8.312689 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:21:15,590 [Epoch: 005 Step: 00000816] Batch Translation Loss:   7.076671 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:21:40,144 [Epoch: 005 Step: 00000817] Batch Translation Loss:   7.202793 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:22:05,052 [Epoch: 005 Step: 00000818] Batch Translation Loss:   7.094702 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:22:51,183 [Epoch: 005 Step: 00000819] Batch Translation Loss:   6.392787 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:23:17,932 [Epoch: 005 Step: 00000820] Batch Translation Loss:   6.857808 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:24:03,583 [Epoch: 005 Step: 00000821] Batch Translation Loss:   7.873981 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:24:30,811 [Epoch: 005 Step: 00000822] Batch Translation Loss:   8.456978 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:24:56,364 [Epoch: 005 Step: 00000823] Batch Translation Loss:   7.207633 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:25:22,448 [Epoch: 005 Step: 00000824] Batch Translation Loss:   7.938917 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:25:48,304 [Epoch: 005 Step: 00000825] Batch Translation Loss:   7.699299 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:26:14,989 [Epoch: 005 Step: 00000826] Batch Translation Loss:   7.417964 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:26:40,990 [Epoch: 005 Step: 00000827] Batch Translation Loss:   7.512538 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:27:07,003 [Epoch: 005 Step: 00000828] Batch Translation Loss:   7.826350 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:27:32,892 [Epoch: 005 Step: 00000829] Batch Translation Loss:   7.287652 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:27:58,873 [Epoch: 005 Step: 00000830] Batch Translation Loss:   6.983378 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:28:24,822 [Epoch: 005 Step: 00000831] Batch Translation Loss:   7.407259 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:28:51,391 [Epoch: 005 Step: 00000832] Batch Translation Loss:   7.846058 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:29:17,893 [Epoch: 005 Step: 00000833] Batch Translation Loss:   7.115236 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:29:45,180 [Epoch: 005 Step: 00000834] Batch Translation Loss:   7.005700 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:30:30,742 [Epoch: 005 Step: 00000835] Batch Translation Loss:   8.183942 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:30:56,974 [Epoch: 005 Step: 00000836] Batch Translation Loss:   7.780200 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:31:45,804 [Epoch: 005 Step: 00000837] Batch Translation Loss:   6.975666 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:32:12,010 [Epoch: 005 Step: 00000838] Batch Translation Loss:   7.582469 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:32:39,158 [Epoch: 005 Step: 00000839] Batch Translation Loss:   8.772801 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:33:05,815 [Epoch: 005 Step: 00000840] Batch Translation Loss:   8.325437 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:33:57,324 [Epoch: 005 Step: 00000841] Batch Translation Loss:   7.807444 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:34:24,697 [Epoch: 005 Step: 00000842] Batch Translation Loss:   6.697910 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:34:53,475 [Epoch: 005 Step: 00000843] Batch Translation Loss:   7.386412 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:35:53,564 [Epoch: 005 Step: 00000844] Batch Translation Loss:   7.694416 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:36:20,932 [Epoch: 005 Step: 00000845] Batch Translation Loss:   6.656640 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:36:49,391 [Epoch: 005 Step: 00000846] Batch Translation Loss:   7.429815 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:37:42,368 [Epoch: 005 Step: 00000847] Batch Translation Loss:   6.699531 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 18:38:11,432 [Epoch: 005 Step: 00000848] Batch Translation Loss:  10.053789 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:39:02,466 [Epoch: 005 Step: 00000849] Batch Translation Loss:  14.406796 => Txt Tokens per Sec:        0 || Lr: 0.001000
2021-12-29 18:39:02,535 Epoch   5: Total Training Recognition Loss -1.00  Total Training Translation Loss 1315.74 
2021-12-29 18:39:02,535 EPOCH 6
2021-12-29 18:39:08,111 [Epoch: 006 Step: 00000850] Batch Translation Loss:   7.189777 => Txt Tokens per Sec:        6 || Lr: 0.001000
2021-12-29 18:39:15,042 [Epoch: 006 Step: 00000851] Batch Translation Loss:   8.168211 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 18:39:22,201 [Epoch: 006 Step: 00000852] Batch Translation Loss:   8.484488 => Txt Tokens per Sec:        6 || Lr: 0.001000
2021-12-29 18:39:29,596 [Epoch: 006 Step: 00000853] Batch Translation Loss:   8.175529 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 18:39:36,762 [Epoch: 006 Step: 00000854] Batch Translation Loss:   8.768333 => Txt Tokens per Sec:        6 || Lr: 0.001000
2021-12-29 18:39:45,973 [Epoch: 006 Step: 00000855] Batch Translation Loss:   8.964478 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 18:39:54,828 [Epoch: 006 Step: 00000856] Batch Translation Loss:   9.521648 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 18:40:04,096 [Epoch: 006 Step: 00000857] Batch Translation Loss:   9.572987 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 18:40:15,387 [Epoch: 006 Step: 00000858] Batch Translation Loss:   9.541209 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 18:40:25,760 [Epoch: 006 Step: 00000859] Batch Translation Loss:   7.444689 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 18:40:32,508 [Epoch: 006 Step: 00000860] Batch Translation Loss:   9.078625 => Txt Tokens per Sec:        7 || Lr: 0.001000
2021-12-29 18:40:44,259 [Epoch: 006 Step: 00000861] Batch Translation Loss:   9.342991 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 18:40:51,973 [Epoch: 006 Step: 00000862] Batch Translation Loss:   6.773988 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 18:41:04,615 [Epoch: 006 Step: 00000863] Batch Translation Loss:   8.726427 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:41:12,614 [Epoch: 006 Step: 00000864] Batch Translation Loss:   7.889891 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 18:41:27,255 [Epoch: 006 Step: 00000865] Batch Translation Loss:   8.512188 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:41:35,432 [Epoch: 006 Step: 00000866] Batch Translation Loss:   7.019636 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 18:41:50,498 [Epoch: 006 Step: 00000867] Batch Translation Loss:   8.927155 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:41:58,151 [Epoch: 006 Step: 00000868] Batch Translation Loss:   7.559944 => Txt Tokens per Sec:        5 || Lr: 0.001000
2021-12-29 18:42:14,893 [Epoch: 006 Step: 00000869] Batch Translation Loss:   8.954939 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:42:24,961 [Epoch: 006 Step: 00000870] Batch Translation Loss:   7.150688 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 18:42:33,725 [Epoch: 006 Step: 00000871] Batch Translation Loss:   6.089766 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 18:42:49,743 [Epoch: 006 Step: 00000872] Batch Translation Loss:   9.758857 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:42:59,887 [Epoch: 006 Step: 00000873] Batch Translation Loss:   6.298546 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:43:09,263 [Epoch: 006 Step: 00000874] Batch Translation Loss:   7.801517 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 18:43:20,603 [Epoch: 006 Step: 00000875] Batch Translation Loss:   9.414488 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 18:43:37,200 [Epoch: 006 Step: 00000876] Batch Translation Loss:   8.958780 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:43:49,222 [Epoch: 006 Step: 00000877] Batch Translation Loss:   9.127295 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 18:44:07,789 [Epoch: 006 Step: 00000878] Batch Translation Loss:  10.915895 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:44:26,789 [Epoch: 006 Step: 00000879] Batch Translation Loss:   8.422843 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:44:45,842 [Epoch: 006 Step: 00000880] Batch Translation Loss:   8.974138 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:45:03,057 [Epoch: 006 Step: 00000881] Batch Translation Loss:   8.878093 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:45:13,027 [Epoch: 006 Step: 00000882] Batch Translation Loss:   6.814677 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 18:45:23,742 [Epoch: 006 Step: 00000883] Batch Translation Loss:   6.402557 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:45:34,552 [Epoch: 006 Step: 00000884] Batch Translation Loss:   6.789324 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:45:53,835 [Epoch: 006 Step: 00000885] Batch Translation Loss:   9.431260 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:46:04,501 [Epoch: 006 Step: 00000886] Batch Translation Loss:   6.145076 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:46:16,211 [Epoch: 006 Step: 00000887] Batch Translation Loss:   7.601593 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:46:35,074 [Epoch: 006 Step: 00000888] Batch Translation Loss:   6.568164 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:46:46,614 [Epoch: 006 Step: 00000889] Batch Translation Loss:   7.114324 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:46:59,399 [Epoch: 006 Step: 00000890] Batch Translation Loss:   7.362092 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:47:11,113 [Epoch: 006 Step: 00000891] Batch Translation Loss:   8.044560 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:47:23,047 [Epoch: 006 Step: 00000892] Batch Translation Loss:   6.810431 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:47:35,068 [Epoch: 006 Step: 00000893] Batch Translation Loss:   6.594970 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:47:47,174 [Epoch: 006 Step: 00000894] Batch Translation Loss:   7.676681 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:47:59,101 [Epoch: 006 Step: 00000895] Batch Translation Loss:   6.575477 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:48:23,592 [Epoch: 006 Step: 00000896] Batch Translation Loss:   9.554655 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:48:37,393 [Epoch: 006 Step: 00000897] Batch Translation Loss:  10.086034 => Txt Tokens per Sec:        4 || Lr: 0.001000
2021-12-29 18:48:49,914 [Epoch: 006 Step: 00000898] Batch Translation Loss:   7.191726 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:49:12,140 [Epoch: 006 Step: 00000899] Batch Translation Loss:   7.981072 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:49:25,215 [Epoch: 006 Step: 00000900] Batch Translation Loss:   6.752249 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:54:25,287 Validation result at epoch   6, step      900: duration: 300.0709s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 10915.77637	PPL: 5405.10645
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 1.43,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.05	ROUGE 1.65
2021-12-29 18:54:30,350 Logging Recognition and Translation Outputs
2021-12-29 18:54:30,350 ========================================================================================================================
2021-12-29 18:54:30,350 Logging Sequence: youtube_1-don_grushkin_2758
2021-12-29 18:54:30,350 	Text Reference  :	brain
2021-12-29 18:54:30,350 	Text Hypothesis :	of   
2021-12-29 18:54:30,350 	Text Alignment  :	S    
2021-12-29 18:54:30,350 ========================================================================================================================
2021-12-29 18:54:30,350 Logging Sequence: deafvideo_3-crossover_3864
2021-12-29 18:54:30,351 	Text Reference  :	f 
2021-12-29 18:54:30,351 	Text Hypothesis :	if
2021-12-29 18:54:30,351 	Text Alignment  :	S 
2021-12-29 18:54:30,351 ========================================================================================================================
2021-12-29 18:54:30,351 Logging Sequence: deafvideo_2-sddsimple_1582
2021-12-29 18:54:30,351 	Text Reference  :	taylerade
2021-12-29 18:54:30,351 	Text Hypothesis :	of       
2021-12-29 18:54:30,351 	Text Alignment  :	S        
2021-12-29 18:54:30,351 ========================================================================================================================
2021-12-29 18:54:30,351 Logging Sequence: youtube_5-roberta_cordano_6145
2021-12-29 18:54:30,351 	Text Reference  :	cheif
2021-12-29 18:54:30,351 	Text Hypothesis :	of   
2021-12-29 18:54:30,352 	Text Alignment  :	S    
2021-12-29 18:54:30,352 ========================================================================================================================
2021-12-29 18:54:30,352 Logging Sequence: youtube_5-caroline_jackson_5864
2021-12-29 18:54:30,352 	Text Reference  :	was
2021-12-29 18:54:30,352 	Text Hypothesis :	ok 
2021-12-29 18:54:30,352 	Text Alignment  :	S  
2021-12-29 18:54:30,352 ========================================================================================================================
2021-12-29 18:54:43,200 [Epoch: 006 Step: 00000901] Batch Translation Loss:   6.802489 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:54:56,986 [Epoch: 006 Step: 00000902] Batch Translation Loss:   8.541496 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:55:10,358 [Epoch: 006 Step: 00000903] Batch Translation Loss:   7.987662 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:55:24,126 [Epoch: 006 Step: 00000904] Batch Translation Loss:   7.858824 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:55:37,811 [Epoch: 006 Step: 00000905] Batch Translation Loss:   7.269019 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:55:51,504 [Epoch: 006 Step: 00000906] Batch Translation Loss:   7.579432 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:56:17,348 [Epoch: 006 Step: 00000907] Batch Translation Loss:   8.850810 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:56:31,760 [Epoch: 006 Step: 00000908] Batch Translation Loss:   7.070086 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:56:47,437 [Epoch: 006 Step: 00000909] Batch Translation Loss:   6.891259 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:57:01,793 [Epoch: 006 Step: 00000910] Batch Translation Loss:   6.749658 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:57:15,883 [Epoch: 006 Step: 00000911] Batch Translation Loss:   7.729531 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:57:31,121 [Epoch: 006 Step: 00000912] Batch Translation Loss:   7.816040 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:57:58,307 [Epoch: 006 Step: 00000913] Batch Translation Loss:   7.775138 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:58:12,566 [Epoch: 006 Step: 00000914] Batch Translation Loss:   7.357776 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:58:28,023 [Epoch: 006 Step: 00000915] Batch Translation Loss:   7.925518 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:58:42,962 [Epoch: 006 Step: 00000916] Batch Translation Loss:   7.001428 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 18:58:59,039 [Epoch: 006 Step: 00000917] Batch Translation Loss:   7.789352 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:59:28,567 [Epoch: 006 Step: 00000918] Batch Translation Loss:  10.118143 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 18:59:43,780 [Epoch: 006 Step: 00000919] Batch Translation Loss:   7.771891 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 19:00:12,461 [Epoch: 006 Step: 00000920] Batch Translation Loss:   7.996568 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 19:00:32,462 [Epoch: 006 Step: 00000921] Batch Translation Loss:   7.222876 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 19:00:51,092 [Epoch: 006 Step: 00000922] Batch Translation Loss:   8.224911 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 19:01:07,437 [Epoch: 006 Step: 00000923] Batch Translation Loss:   7.432379 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 19:01:25,042 [Epoch: 006 Step: 00000924] Batch Translation Loss:   7.472481 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 19:01:41,976 [Epoch: 006 Step: 00000925] Batch Translation Loss:   6.665375 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 19:01:59,376 [Epoch: 006 Step: 00000926] Batch Translation Loss:   7.281264 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 19:02:15,584 [Epoch: 006 Step: 00000927] Batch Translation Loss:   6.611525 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 19:02:32,282 [Epoch: 006 Step: 00000928] Batch Translation Loss:   6.491337 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 19:02:49,703 [Epoch: 006 Step: 00000929] Batch Translation Loss:   8.500265 => Txt Tokens per Sec:        3 || Lr: 0.001000
2021-12-29 19:03:19,764 [Epoch: 006 Step: 00000930] Batch Translation Loss:   7.483171 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:03:36,707 [Epoch: 006 Step: 00000931] Batch Translation Loss:   6.673211 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 19:03:54,200 [Epoch: 006 Step: 00000932] Batch Translation Loss:   7.302692 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 19:04:24,975 [Epoch: 006 Step: 00000933] Batch Translation Loss:   7.436667 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:04:42,700 [Epoch: 006 Step: 00000934] Batch Translation Loss:   7.375063 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 19:05:00,249 [Epoch: 006 Step: 00000935] Batch Translation Loss:   6.762226 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 19:05:23,777 [Epoch: 006 Step: 00000936] Batch Translation Loss:   7.181987 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 19:05:50,030 [Epoch: 006 Step: 00000937] Batch Translation Loss:   6.743621 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:06:18,120 [Epoch: 006 Step: 00000938] Batch Translation Loss:   6.414769 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:06:41,914 [Epoch: 006 Step: 00000939] Batch Translation Loss:   6.215084 => Txt Tokens per Sec:        2 || Lr: 0.001000
2021-12-29 19:07:11,247 [Epoch: 006 Step: 00000940] Batch Translation Loss:   7.890618 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:07:41,834 [Epoch: 006 Step: 00000941] Batch Translation Loss:   6.573589 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:08:10,531 [Epoch: 006 Step: 00000942] Batch Translation Loss:   7.349277 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:08:39,770 [Epoch: 006 Step: 00000943] Batch Translation Loss:   7.149430 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:09:08,827 [Epoch: 006 Step: 00000944] Batch Translation Loss:   7.931860 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:09:38,413 [Epoch: 006 Step: 00000945] Batch Translation Loss:   6.953799 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:10:09,244 [Epoch: 006 Step: 00000946] Batch Translation Loss:   7.149335 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:10:39,824 [Epoch: 006 Step: 00000947] Batch Translation Loss:   7.068998 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:11:12,563 [Epoch: 006 Step: 00000948] Batch Translation Loss:   6.151193 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:11:45,042 [Epoch: 006 Step: 00000949] Batch Translation Loss:   6.667566 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:12:17,115 [Epoch: 006 Step: 00000950] Batch Translation Loss:   6.771018 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:12:48,317 [Epoch: 006 Step: 00000951] Batch Translation Loss:   7.084645 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:13:20,059 [Epoch: 006 Step: 00000952] Batch Translation Loss:   6.517217 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:13:53,043 [Epoch: 006 Step: 00000953] Batch Translation Loss:   7.541629 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:14:25,968 [Epoch: 006 Step: 00000954] Batch Translation Loss:   7.565829 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:15:00,384 [Epoch: 006 Step: 00000955] Batch Translation Loss:   7.720571 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:15:32,451 [Epoch: 006 Step: 00000956] Batch Translation Loss:   7.092217 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:16:28,365 [Epoch: 006 Step: 00000957] Batch Translation Loss:   6.797896 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:16:59,309 [Epoch: 006 Step: 00000958] Batch Translation Loss:   6.634542 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:17:32,536 [Epoch: 006 Step: 00000959] Batch Translation Loss:   8.067822 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:18:20,099 [Epoch: 006 Step: 00000960] Batch Translation Loss:   7.346821 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:18:57,702 [Epoch: 006 Step: 00000961] Batch Translation Loss:   7.803504 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:19:32,091 [Epoch: 006 Step: 00000962] Batch Translation Loss:   7.380842 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:20:06,258 [Epoch: 006 Step: 00000963] Batch Translation Loss:   7.021942 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:20:41,065 [Epoch: 006 Step: 00000964] Batch Translation Loss:   6.072742 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:21:15,893 [Epoch: 006 Step: 00000965] Batch Translation Loss:   6.872126 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:21:55,265 [Epoch: 006 Step: 00000966] Batch Translation Loss:   7.824980 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:22:32,969 [Epoch: 006 Step: 00000967] Batch Translation Loss:   7.500665 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:23:10,288 [Epoch: 006 Step: 00000968] Batch Translation Loss:   8.044912 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:23:46,752 [Epoch: 006 Step: 00000969] Batch Translation Loss:   7.689681 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:24:33,322 [Epoch: 006 Step: 00000970] Batch Translation Loss:   6.971731 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:25:09,371 [Epoch: 006 Step: 00000971] Batch Translation Loss:   7.282318 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:25:47,764 [Epoch: 006 Step: 00000972] Batch Translation Loss:   7.499866 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:26:18,376 [Epoch: 006 Step: 00000973] Batch Translation Loss:   6.216300 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:26:56,642 [Epoch: 006 Step: 00000974] Batch Translation Loss:   6.587189 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:27:29,962 [Epoch: 006 Step: 00000975] Batch Translation Loss:   7.215219 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:27:58,516 [Epoch: 006 Step: 00000976] Batch Translation Loss:   6.839341 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:28:26,127 [Epoch: 006 Step: 00000977] Batch Translation Loss:   7.354484 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:28:55,970 [Epoch: 006 Step: 00000978] Batch Translation Loss:   7.036155 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:29:37,264 [Epoch: 006 Step: 00000979] Batch Translation Loss:   7.165478 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:30:30,150 [Epoch: 006 Step: 00000980] Batch Translation Loss:   7.116816 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:31:01,792 [Epoch: 006 Step: 00000981] Batch Translation Loss:   7.799975 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:31:31,971 [Epoch: 006 Step: 00000982] Batch Translation Loss:   7.298454 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:31:59,620 [Epoch: 006 Step: 00000983] Batch Translation Loss:   7.825251 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:32:27,417 [Epoch: 006 Step: 00000984] Batch Translation Loss:   7.450276 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:33:22,777 [Epoch: 006 Step: 00000985] Batch Translation Loss:   7.022318 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:33:50,194 [Epoch: 006 Step: 00000986] Batch Translation Loss:   7.044576 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:34:21,466 [Epoch: 006 Step: 00000987] Batch Translation Loss:   7.198112 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:34:51,326 [Epoch: 006 Step: 00000988] Batch Translation Loss:   7.570797 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:35:19,661 [Epoch: 006 Step: 00000989] Batch Translation Loss:   6.691218 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:36:07,532 [Epoch: 006 Step: 00000990] Batch Translation Loss:   7.358447 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:36:38,432 [Epoch: 006 Step: 00000991] Batch Translation Loss:   8.611191 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:37:14,989 [Epoch: 006 Step: 00000992] Batch Translation Loss:   6.888580 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:37:41,391 [Epoch: 006 Step: 00000993] Batch Translation Loss:   7.722321 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:38:09,046 [Epoch: 006 Step: 00000994] Batch Translation Loss:   6.352314 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:38:42,485 [Epoch: 006 Step: 00000995] Batch Translation Loss:   6.400498 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:39:10,124 [Epoch: 006 Step: 00000996] Batch Translation Loss:   7.165916 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:39:43,756 [Epoch: 006 Step: 00000997] Batch Translation Loss:   7.984077 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:40:15,883 [Epoch: 006 Step: 00000998] Batch Translation Loss:   6.817189 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:40:49,159 [Epoch: 006 Step: 00000999] Batch Translation Loss:   7.022161 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:41:21,474 [Epoch: 006 Step: 00001000] Batch Translation Loss:   7.977704 => Txt Tokens per Sec:        1 || Lr: 0.001000
2021-12-29 19:48:04,658 Validation result at epoch   6, step     1000: duration: 403.1631s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11114.22168	PPL: 5554.48096
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 1.48,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.98	ROUGE 1.86
2021-12-29 19:48:11,456 Logging Recognition and Translation Outputs
2021-12-29 19:48:11,461 ========================================================================================================================
2021-12-29 19:48:11,461 Logging Sequence: deafvideo_2-sddsimple_1591
2021-12-29 19:48:11,462 	Text Reference  :	sean berdy entertainment
2021-12-29 19:48:11,463 	Text Hypothesis :	**** ***** fillet       
2021-12-29 19:48:11,463 	Text Alignment  :	D    D     S            
2021-12-29 19:48:11,463 ========================================================================================================================
2021-12-29 19:48:11,463 Logging Sequence: youtube_1-don_grushkin_2303
2021-12-29 19:48:11,463 	Text Reference  :	met
2021-12-29 19:48:11,463 	Text Hypothesis :	or 
2021-12-29 19:48:11,464 	Text Alignment  :	S  
2021-12-29 19:48:11,464 ========================================================================================================================
2021-12-29 19:48:11,464 Logging Sequence: deafvideo_2-sddsimple_1548
2021-12-29 19:48:11,464 	Text Reference  :	trash
2021-12-29 19:48:11,464 	Text Hypothesis :	asl  
2021-12-29 19:48:11,464 	Text Alignment  :	S    
2021-12-29 19:48:11,464 ========================================================================================================================
2021-12-29 19:48:11,465 Logging Sequence: deafvideo_2-sddsimple_1554
2021-12-29 19:48:11,465 	Text Reference  :	electronics
2021-12-29 19:48:11,465 	Text Hypothesis :	fillet     
2021-12-29 19:48:11,465 	Text Alignment  :	S          
2021-12-29 19:48:11,465 ========================================================================================================================
2021-12-29 19:48:11,465 Logging Sequence: youtube_1-don_grushkin_2764
2021-12-29 19:48:11,466 	Text Reference  :	speak asl   
2021-12-29 19:48:11,466 	Text Hypothesis :	***** fillet
2021-12-29 19:48:11,466 	Text Alignment  :	D     S     
2021-12-29 19:48:11,466 ========================================================================================================================
2021-12-29 19:50:24,280 [Epoch: 006 Step: 00001001] Batch Translation Loss:   7.273520 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-29 19:51:45,290 [Epoch: 006 Step: 00001002] Batch Translation Loss:   7.494117 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 19:52:20,294 [Epoch: 006 Step: 00001003] Batch Translation Loss:   6.761425 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 19:52:51,355 [Epoch: 006 Step: 00001004] Batch Translation Loss:   5.828836 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 19:53:25,342 [Epoch: 006 Step: 00001005] Batch Translation Loss:   6.759371 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 19:54:01,031 [Epoch: 006 Step: 00001006] Batch Translation Loss:   6.626752 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 19:55:03,727 [Epoch: 006 Step: 00001007] Batch Translation Loss:   7.027290 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 19:55:40,240 [Epoch: 006 Step: 00001008] Batch Translation Loss:   6.964141 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 19:56:16,855 [Epoch: 006 Step: 00001009] Batch Translation Loss:   6.746181 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 19:56:47,510 [Epoch: 006 Step: 00001010] Batch Translation Loss:   6.673532 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 19:57:20,955 [Epoch: 006 Step: 00001011] Batch Translation Loss:   7.384038 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 19:57:59,145 [Epoch: 006 Step: 00001012] Batch Translation Loss:   7.524384 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 19:58:29,778 [Epoch: 006 Step: 00001013] Batch Translation Loss:   7.329358 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 19:59:02,068 [Epoch: 006 Step: 00001014] Batch Translation Loss:   7.501490 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 19:59:38,765 [Epoch: 006 Step: 00001015] Batch Translation Loss:   6.670897 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:00:12,953 [Epoch: 006 Step: 00001016] Batch Translation Loss:   8.353200 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:00:47,048 [Epoch: 006 Step: 00001017] Batch Translation Loss:   6.961073 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:01:25,500 [Epoch: 006 Step: 00001018] Batch Translation Loss:   7.516088 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:01:57,299 [Epoch: 006 Step: 00001019] Batch Translation Loss:  10.366025 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:01:57,452 Epoch   6: Total Training Recognition Loss -1.00  Total Training Translation Loss 1279.76 
2021-12-29 20:01:57,452 EPOCH 7
2021-12-29 20:02:04,240 [Epoch: 007 Step: 00001020] Batch Translation Loss:   6.592140 => Txt Tokens per Sec:        5 || Lr: 0.000700
2021-12-29 20:02:11,625 [Epoch: 007 Step: 00001021] Batch Translation Loss:   8.181487 => Txt Tokens per Sec:        5 || Lr: 0.000700
2021-12-29 20:02:19,935 [Epoch: 007 Step: 00001022] Batch Translation Loss:   7.979265 => Txt Tokens per Sec:        5 || Lr: 0.000700
2021-12-29 20:02:28,138 [Epoch: 007 Step: 00001023] Batch Translation Loss:   8.801648 => Txt Tokens per Sec:        5 || Lr: 0.000700
2021-12-29 20:02:39,120 [Epoch: 007 Step: 00001024] Batch Translation Loss:   8.010022 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-29 20:02:50,716 [Epoch: 007 Step: 00001025] Batch Translation Loss:   8.530563 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-29 20:03:00,176 [Epoch: 007 Step: 00001026] Batch Translation Loss:   7.976446 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-29 20:03:17,644 [Epoch: 007 Step: 00001027] Batch Translation Loss:   9.239642 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 20:03:27,000 [Epoch: 007 Step: 00001028] Batch Translation Loss:  10.241495 => Txt Tokens per Sec:        6 || Lr: 0.000700
2021-12-29 20:03:39,484 [Epoch: 007 Step: 00001029] Batch Translation Loss:   8.238816 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-29 20:03:53,554 [Epoch: 007 Step: 00001030] Batch Translation Loss:   9.737967 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-29 20:04:04,078 [Epoch: 007 Step: 00001031] Batch Translation Loss:   6.882894 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-29 20:04:14,233 [Epoch: 007 Step: 00001032] Batch Translation Loss:   8.415188 => Txt Tokens per Sec:        5 || Lr: 0.000700
2021-12-29 20:04:30,658 [Epoch: 007 Step: 00001033] Batch Translation Loss:   7.749347 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 20:04:42,822 [Epoch: 007 Step: 00001034] Batch Translation Loss:   7.523597 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 20:04:54,076 [Epoch: 007 Step: 00001035] Batch Translation Loss:   7.642530 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-29 20:05:03,613 [Epoch: 007 Step: 00001036] Batch Translation Loss:   7.289062 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-29 20:05:22,863 [Epoch: 007 Step: 00001037] Batch Translation Loss:   9.737294 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 20:05:33,959 [Epoch: 007 Step: 00001038] Batch Translation Loss:   6.209287 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 20:05:47,505 [Epoch: 007 Step: 00001039] Batch Translation Loss:   7.184462 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 20:06:01,931 [Epoch: 007 Step: 00001040] Batch Translation Loss:   7.296586 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 20:06:11,771 [Epoch: 007 Step: 00001041] Batch Translation Loss:   7.186492 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-29 20:06:21,467 [Epoch: 007 Step: 00001042] Batch Translation Loss:   7.301311 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-29 20:06:35,960 [Epoch: 007 Step: 00001043] Batch Translation Loss:   8.260472 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 20:06:46,599 [Epoch: 007 Step: 00001044] Batch Translation Loss:   6.658893 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 20:07:07,714 [Epoch: 007 Step: 00001045] Batch Translation Loss:   8.322787 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:07:21,853 [Epoch: 007 Step: 00001046] Batch Translation Loss:   8.162994 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 20:07:39,091 [Epoch: 007 Step: 00001047] Batch Translation Loss:   8.099037 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 20:08:02,826 [Epoch: 007 Step: 00001048] Batch Translation Loss:   8.006856 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:08:17,699 [Epoch: 007 Step: 00001049] Batch Translation Loss:   7.257327 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:08:29,908 [Epoch: 007 Step: 00001050] Batch Translation Loss:   7.691560 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-29 20:08:43,239 [Epoch: 007 Step: 00001051] Batch Translation Loss:   6.348105 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:09:00,412 [Epoch: 007 Step: 00001052] Batch Translation Loss:   8.305530 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 20:09:13,958 [Epoch: 007 Step: 00001053] Batch Translation Loss:   6.753761 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 20:09:31,948 [Epoch: 007 Step: 00001054] Batch Translation Loss:   7.921865 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:09:46,611 [Epoch: 007 Step: 00001055] Batch Translation Loss:   7.718683 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 20:10:01,227 [Epoch: 007 Step: 00001056] Batch Translation Loss:   6.416782 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:10:14,873 [Epoch: 007 Step: 00001057] Batch Translation Loss:   7.118022 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 20:10:39,857 [Epoch: 007 Step: 00001058] Batch Translation Loss:   7.959945 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:10:56,090 [Epoch: 007 Step: 00001059] Batch Translation Loss:   7.359302 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:11:09,161 [Epoch: 007 Step: 00001060] Batch Translation Loss:   6.851989 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 20:11:39,457 [Epoch: 007 Step: 00001061] Batch Translation Loss:   8.431180 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:11:53,400 [Epoch: 007 Step: 00001062] Batch Translation Loss:   7.330057 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 20:12:15,131 [Epoch: 007 Step: 00001063] Batch Translation Loss:   7.766330 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:12:29,881 [Epoch: 007 Step: 00001064] Batch Translation Loss:   6.798914 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:12:45,127 [Epoch: 007 Step: 00001065] Batch Translation Loss:   7.714605 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 20:12:59,278 [Epoch: 007 Step: 00001066] Batch Translation Loss:   7.542578 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 20:13:19,161 [Epoch: 007 Step: 00001067] Batch Translation Loss:   7.562628 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:13:35,861 [Epoch: 007 Step: 00001068] Batch Translation Loss:   6.294927 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:13:53,870 [Epoch: 007 Step: 00001069] Batch Translation Loss:   7.222568 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:14:08,670 [Epoch: 007 Step: 00001070] Batch Translation Loss:   7.245263 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 20:14:24,138 [Epoch: 007 Step: 00001071] Batch Translation Loss:   7.241579 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:14:43,290 [Epoch: 007 Step: 00001072] Batch Translation Loss:   7.997316 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 20:15:00,186 [Epoch: 007 Step: 00001073] Batch Translation Loss:   7.120214 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:15:22,563 [Epoch: 007 Step: 00001074] Batch Translation Loss:   6.367450 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:15:38,261 [Epoch: 007 Step: 00001075] Batch Translation Loss:   6.319215 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:15:52,541 [Epoch: 007 Step: 00001076] Batch Translation Loss:   6.627724 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 20:16:21,205 [Epoch: 007 Step: 00001077] Batch Translation Loss:   7.090447 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:16:37,878 [Epoch: 007 Step: 00001078] Batch Translation Loss:   6.453316 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:16:54,569 [Epoch: 007 Step: 00001079] Batch Translation Loss:   7.055151 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:17:12,727 [Epoch: 007 Step: 00001080] Batch Translation Loss:   7.601148 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:17:32,107 [Epoch: 007 Step: 00001081] Batch Translation Loss:   6.613309 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:17:54,156 [Epoch: 007 Step: 00001082] Batch Translation Loss:   6.810695 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:18:33,313 [Epoch: 007 Step: 00001083] Batch Translation Loss:   7.868869 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:18:50,213 [Epoch: 007 Step: 00001084] Batch Translation Loss:   7.413054 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:19:07,897 [Epoch: 007 Step: 00001085] Batch Translation Loss:   7.501296 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:19:40,419 [Epoch: 007 Step: 00001086] Batch Translation Loss:   7.987999 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:20:19,988 [Epoch: 007 Step: 00001087] Batch Translation Loss:   6.747124 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:20:36,865 [Epoch: 007 Step: 00001088] Batch Translation Loss:   7.076128 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:20:54,866 [Epoch: 007 Step: 00001089] Batch Translation Loss:   6.980079 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:21:12,437 [Epoch: 007 Step: 00001090] Batch Translation Loss:   7.219361 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:21:33,103 [Epoch: 007 Step: 00001091] Batch Translation Loss:   7.281215 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:22:10,200 [Epoch: 007 Step: 00001092] Batch Translation Loss:   7.066112 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:22:37,736 [Epoch: 007 Step: 00001093] Batch Translation Loss:   6.323129 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:22:55,769 [Epoch: 007 Step: 00001094] Batch Translation Loss:   6.160035 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:23:15,265 [Epoch: 007 Step: 00001095] Batch Translation Loss:   7.023468 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:23:33,474 [Epoch: 007 Step: 00001096] Batch Translation Loss:   6.657605 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:24:09,007 [Epoch: 007 Step: 00001097] Batch Translation Loss:   7.162577 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:24:54,645 [Epoch: 007 Step: 00001098] Batch Translation Loss:   6.716101 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:25:12,527 [Epoch: 007 Step: 00001099] Batch Translation Loss:   6.846416 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:25:34,135 [Epoch: 007 Step: 00001100] Batch Translation Loss:   6.618455 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:32:31,624 Validation result at epoch   7, step     1100: duration: 417.4885s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 10736.31348	PPL: 5086.93408
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 2.67,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 4.98	ROUGE 3.47
2021-12-29 20:32:37,887 Logging Recognition and Translation Outputs
2021-12-29 20:32:37,915 ========================================================================================================================
2021-12-29 20:32:37,915 Logging Sequence: youtube_1-catherine_mackinnon_2814
2021-12-29 20:32:37,915 	Text Reference  :	love
2021-12-29 20:32:37,916 	Text Hypothesis :	so  
2021-12-29 20:32:37,916 	Text Alignment  :	S   
2021-12-29 20:32:37,916 ========================================================================================================================
2021-12-29 20:32:37,916 Logging Sequence: deafvideo_3-damien23_3607
2021-12-29 20:32:37,916 	Text Reference  :	defhood yoga
2021-12-29 20:32:37,916 	Text Hypothesis :	******* asl 
2021-12-29 20:32:37,916 	Text Alignment  :	D       S   
2021-12-29 20:32:37,917 ========================================================================================================================
2021-12-29 20:32:37,917 Logging Sequence: youtube_1-don_grushkin_2761
2021-12-29 20:32:37,917 	Text Reference  :	tylor
2021-12-29 20:32:37,917 	Text Hypothesis :	ok   
2021-12-29 20:32:37,918 	Text Alignment  :	S    
2021-12-29 20:32:37,918 ========================================================================================================================
2021-12-29 20:32:37,918 Logging Sequence: deafvideo_2-fairytales9_2294
2021-12-29 20:32:37,918 	Text Reference  :	vp 
2021-12-29 20:32:37,919 	Text Hypothesis :	asl
2021-12-29 20:32:37,919 	Text Alignment  :	S  
2021-12-29 20:32:37,919 ========================================================================================================================
2021-12-29 20:32:37,919 Logging Sequence: aslized-suzanne_stecker_0278
2021-12-29 20:32:37,920 	Text Reference  :	so 
2021-12-29 20:32:37,920 	Text Hypothesis :	asl
2021-12-29 20:32:37,920 	Text Alignment  :	S  
2021-12-29 20:32:37,920 ========================================================================================================================
2021-12-29 20:34:41,600 [Epoch: 007 Step: 00001101] Batch Translation Loss:   7.679668 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-29 20:35:19,556 [Epoch: 007 Step: 00001102] Batch Translation Loss:   6.826716 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:35:52,622 [Epoch: 007 Step: 00001103] Batch Translation Loss:   6.435523 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:36:13,847 [Epoch: 007 Step: 00001104] Batch Translation Loss:   7.162131 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:36:34,062 [Epoch: 007 Step: 00001105] Batch Translation Loss:   6.918245 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:36:56,077 [Epoch: 007 Step: 00001106] Batch Translation Loss:   6.848757 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:37:21,689 [Epoch: 007 Step: 00001107] Batch Translation Loss:   7.279821 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:37:46,958 [Epoch: 007 Step: 00001108] Batch Translation Loss:   6.899037 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:38:05,795 [Epoch: 007 Step: 00001109] Batch Translation Loss:   6.975271 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:38:25,393 [Epoch: 007 Step: 00001110] Batch Translation Loss:   6.676495 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:38:45,558 [Epoch: 007 Step: 00001111] Batch Translation Loss:   6.284173 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:39:26,019 [Epoch: 007 Step: 00001112] Batch Translation Loss:   5.920835 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:39:57,348 [Epoch: 007 Step: 00001113] Batch Translation Loss:   7.077597 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:40:19,471 [Epoch: 007 Step: 00001114] Batch Translation Loss:   6.136587 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:40:51,331 [Epoch: 007 Step: 00001115] Batch Translation Loss:   6.828257 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:41:13,847 [Epoch: 007 Step: 00001116] Batch Translation Loss:   7.272224 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:41:38,318 [Epoch: 007 Step: 00001117] Batch Translation Loss:   7.160131 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:42:08,108 [Epoch: 007 Step: 00001118] Batch Translation Loss:   7.636020 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:42:36,115 [Epoch: 007 Step: 00001119] Batch Translation Loss:   6.487998 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:42:59,652 [Epoch: 007 Step: 00001120] Batch Translation Loss:   7.816964 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:43:21,105 [Epoch: 007 Step: 00001121] Batch Translation Loss:   6.336253 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:43:46,195 [Epoch: 007 Step: 00001122] Batch Translation Loss:   7.032268 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:44:11,584 [Epoch: 007 Step: 00001123] Batch Translation Loss:   6.937352 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:44:48,240 [Epoch: 007 Step: 00001124] Batch Translation Loss:   6.539792 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:45:09,847 [Epoch: 007 Step: 00001125] Batch Translation Loss:   7.037243 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:45:34,384 [Epoch: 007 Step: 00001126] Batch Translation Loss:   7.626750 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:45:57,468 [Epoch: 007 Step: 00001127] Batch Translation Loss:   7.050305 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:46:23,564 [Epoch: 007 Step: 00001128] Batch Translation Loss:   6.579332 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:46:55,829 [Epoch: 007 Step: 00001129] Batch Translation Loss:   7.165741 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:47:28,196 [Epoch: 007 Step: 00001130] Batch Translation Loss:   7.093921 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:47:55,569 [Epoch: 007 Step: 00001131] Batch Translation Loss:   6.612415 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:48:20,805 [Epoch: 007 Step: 00001132] Batch Translation Loss:   6.416222 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:48:46,978 [Epoch: 007 Step: 00001133] Batch Translation Loss:   7.180612 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:49:15,811 [Epoch: 007 Step: 00001134] Batch Translation Loss:   7.094777 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:50:21,572 [Epoch: 007 Step: 00001135] Batch Translation Loss:   6.761826 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:51:09,271 [Epoch: 007 Step: 00001136] Batch Translation Loss:   7.057496 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:51:35,164 [Epoch: 007 Step: 00001137] Batch Translation Loss:   6.393695 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:52:39,347 [Epoch: 007 Step: 00001138] Batch Translation Loss:   7.567789 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:53:04,583 [Epoch: 007 Step: 00001139] Batch Translation Loss:   7.349959 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 20:53:31,074 [Epoch: 007 Step: 00001140] Batch Translation Loss:   6.373275 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:53:59,588 [Epoch: 007 Step: 00001141] Batch Translation Loss:   7.075167 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:54:46,677 [Epoch: 007 Step: 00001142] Batch Translation Loss:   6.368172 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:55:18,081 [Epoch: 007 Step: 00001143] Batch Translation Loss:   6.883547 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:55:44,997 [Epoch: 007 Step: 00001144] Batch Translation Loss:   6.999702 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:56:13,806 [Epoch: 007 Step: 00001145] Batch Translation Loss:   6.480527 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:56:48,599 [Epoch: 007 Step: 00001146] Batch Translation Loss:   6.439817 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:57:18,869 [Epoch: 007 Step: 00001147] Batch Translation Loss:   6.277796 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:58:08,081 [Epoch: 007 Step: 00001148] Batch Translation Loss:   6.270631 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:59:04,204 [Epoch: 007 Step: 00001149] Batch Translation Loss:   6.653924 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 20:59:37,402 [Epoch: 007 Step: 00001150] Batch Translation Loss:   6.731756 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:00:08,472 [Epoch: 007 Step: 00001151] Batch Translation Loss:   6.527042 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:00:35,928 [Epoch: 007 Step: 00001152] Batch Translation Loss:   6.529815 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:01:03,228 [Epoch: 007 Step: 00001153] Batch Translation Loss:   5.886578 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:01:35,573 [Epoch: 007 Step: 00001154] Batch Translation Loss:   6.985805 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:02:17,469 [Epoch: 007 Step: 00001155] Batch Translation Loss:   6.669343 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:02:47,787 [Epoch: 007 Step: 00001156] Batch Translation Loss:   6.649554 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:03:39,311 [Epoch: 007 Step: 00001157] Batch Translation Loss:   6.194354 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:04:48,136 [Epoch: 007 Step: 00001158] Batch Translation Loss:   7.287792 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:05:21,661 [Epoch: 007 Step: 00001159] Batch Translation Loss:   6.519683 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:05:49,934 [Epoch: 007 Step: 00001160] Batch Translation Loss:   6.714669 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:06:21,287 [Epoch: 007 Step: 00001161] Batch Translation Loss:   6.231599 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:06:59,103 [Epoch: 007 Step: 00001162] Batch Translation Loss:   6.230731 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:07:34,871 [Epoch: 007 Step: 00001163] Batch Translation Loss:   6.843858 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:08:05,003 [Epoch: 007 Step: 00001164] Batch Translation Loss:   6.734190 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:08:34,136 [Epoch: 007 Step: 00001165] Batch Translation Loss:   6.850782 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:09:07,417 [Epoch: 007 Step: 00001166] Batch Translation Loss:   6.302834 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:10:21,339 [Epoch: 007 Step: 00001167] Batch Translation Loss:   7.635696 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:10:51,791 [Epoch: 007 Step: 00001168] Batch Translation Loss:   7.420997 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:11:24,584 [Epoch: 007 Step: 00001169] Batch Translation Loss:   8.223369 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:12:07,408 [Epoch: 007 Step: 00001170] Batch Translation Loss:   7.140163 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:12:40,841 [Epoch: 007 Step: 00001171] Batch Translation Loss:   7.127112 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:13:10,735 [Epoch: 007 Step: 00001172] Batch Translation Loss:   6.414416 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:13:40,810 [Epoch: 007 Step: 00001173] Batch Translation Loss:   6.648285 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:14:14,274 [Epoch: 007 Step: 00001174] Batch Translation Loss:   6.030844 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:15:00,028 [Epoch: 007 Step: 00001175] Batch Translation Loss:   6.097255 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:15:38,499 [Epoch: 007 Step: 00001176] Batch Translation Loss:   6.269058 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:16:08,266 [Epoch: 007 Step: 00001177] Batch Translation Loss:   5.900417 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:16:42,950 [Epoch: 007 Step: 00001178] Batch Translation Loss:   6.272983 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:17:26,733 [Epoch: 007 Step: 00001179] Batch Translation Loss:   7.182265 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:18:01,092 [Epoch: 007 Step: 00001180] Batch Translation Loss:   7.003793 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:18:31,227 [Epoch: 007 Step: 00001181] Batch Translation Loss:   6.949451 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:19:18,098 [Epoch: 007 Step: 00001182] Batch Translation Loss:   5.733526 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:19:59,454 [Epoch: 007 Step: 00001183] Batch Translation Loss:   6.410388 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:20:35,743 [Epoch: 007 Step: 00001184] Batch Translation Loss:   7.187084 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:21:21,503 [Epoch: 007 Step: 00001185] Batch Translation Loss:   6.769572 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:22:03,679 [Epoch: 007 Step: 00001186] Batch Translation Loss:   6.061790 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:22:40,618 [Epoch: 007 Step: 00001187] Batch Translation Loss:   6.629017 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:24:07,848 [Epoch: 007 Step: 00001188] Batch Translation Loss:   7.403439 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-29 21:25:22,724 [Epoch: 007 Step: 00001189] Batch Translation Loss:   8.480069 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-29 21:25:22,843 Epoch   7: Total Training Recognition Loss -1.00  Total Training Translation Loss 1207.88 
2021-12-29 21:25:22,843 EPOCH 8
2021-12-29 21:25:30,321 [Epoch: 008 Step: 00001190] Batch Translation Loss:   6.666994 => Txt Tokens per Sec:        5 || Lr: 0.000700
2021-12-29 21:25:39,866 [Epoch: 008 Step: 00001191] Batch Translation Loss:   7.301136 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-29 21:25:48,862 [Epoch: 008 Step: 00001192] Batch Translation Loss:   7.508839 => Txt Tokens per Sec:        5 || Lr: 0.000700
2021-12-29 21:25:57,347 [Epoch: 008 Step: 00001193] Batch Translation Loss:   7.526133 => Txt Tokens per Sec:        5 || Lr: 0.000700
2021-12-29 21:26:08,717 [Epoch: 008 Step: 00001194] Batch Translation Loss:   7.978852 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-29 21:26:21,676 [Epoch: 008 Step: 00001195] Batch Translation Loss:   8.074386 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-29 21:26:37,187 [Epoch: 008 Step: 00001196] Batch Translation Loss:   8.685828 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-29 21:26:47,331 [Epoch: 008 Step: 00001197] Batch Translation Loss:   7.052761 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-29 21:27:01,641 [Epoch: 008 Step: 00001198] Batch Translation Loss:   8.661685 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-29 21:27:15,566 [Epoch: 008 Step: 00001199] Batch Translation Loss:   7.288562 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-29 21:27:29,931 [Epoch: 008 Step: 00001200] Batch Translation Loss:   8.035388 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 21:34:33,637 Validation result at epoch   8, step     1200: duration: 423.6895s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 10840.36523	PPL: 4992.06543
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 3.84,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 5.31	ROUGE 4.71
2021-12-29 21:34:41,360 Logging Recognition and Translation Outputs
2021-12-29 21:34:41,376 ========================================================================================================================
2021-12-29 21:34:41,376 Logging Sequence: youtube_4-sean_berdy_5735
2021-12-29 21:34:41,376 	Text Reference  :	all senses 
2021-12-29 21:34:41,376 	Text Hypothesis :	*** aslized
2021-12-29 21:34:41,377 	Text Alignment  :	D   S      
2021-12-29 21:34:41,377 ========================================================================================================================
2021-12-29 21:34:41,377 Logging Sequence: youtube_1-catherine_mackinnon_2816
2021-12-29 21:34:41,377 	Text Reference  :	debra patkin
2021-12-29 21:34:41,377 	Text Hypothesis :	***** dr    
2021-12-29 21:34:41,377 	Text Alignment  :	D     S     
2021-12-29 21:34:41,377 ========================================================================================================================
2021-12-29 21:34:41,377 Logging Sequence: youtube_4-howard_rosenblum_5560
2021-12-29 21:34:41,377 	Text Reference  :	use
2021-12-29 21:34:41,377 	Text Hypothesis :	asl
2021-12-29 21:34:41,378 	Text Alignment  :	S  
2021-12-29 21:34:41,378 ========================================================================================================================
2021-12-29 21:34:41,378 Logging Sequence: aslized-suzanne_stecker_0265
2021-12-29 21:34:41,378 	Text Reference  :	hackers
2021-12-29 21:34:41,378 	Text Hypothesis :	asl    
2021-12-29 21:34:41,378 	Text Alignment  :	S      
2021-12-29 21:34:41,378 ========================================================================================================================
2021-12-29 21:34:41,378 Logging Sequence: deafvideo_5-silentoneye_7325
2021-12-29 21:34:41,378 	Text Reference  :	sc 
2021-12-29 21:34:41,378 	Text Hypothesis :	asl
2021-12-29 21:34:41,378 	Text Alignment  :	S  
2021-12-29 21:34:41,378 ========================================================================================================================
2021-12-29 21:35:18,069 [Epoch: 008 Step: 00001201] Batch Translation Loss:   6.536721 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:35:47,218 [Epoch: 008 Step: 00001202] Batch Translation Loss:   6.885952 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:36:16,580 [Epoch: 008 Step: 00001203] Batch Translation Loss:   7.335423 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:36:41,052 [Epoch: 008 Step: 00001204] Batch Translation Loss:   6.497589 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:37:04,337 [Epoch: 008 Step: 00001205] Batch Translation Loss:   7.185284 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:37:17,618 [Epoch: 008 Step: 00001206] Batch Translation Loss:   6.931229 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 21:37:35,272 [Epoch: 008 Step: 00001207] Batch Translation Loss:   6.937562 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:37:51,882 [Epoch: 008 Step: 00001208] Batch Translation Loss:   6.488925 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:38:07,278 [Epoch: 008 Step: 00001209] Batch Translation Loss:   7.172512 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 21:38:33,546 [Epoch: 008 Step: 00001210] Batch Translation Loss:   6.934135 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:38:53,607 [Epoch: 008 Step: 00001211] Batch Translation Loss:   6.861410 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:39:11,872 [Epoch: 008 Step: 00001212] Batch Translation Loss:   7.018774 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 21:39:24,988 [Epoch: 008 Step: 00001213] Batch Translation Loss:   7.574022 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-29 21:39:37,774 [Epoch: 008 Step: 00001214] Batch Translation Loss:   6.911678 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 21:39:49,681 [Epoch: 008 Step: 00001215] Batch Translation Loss:   6.418814 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 21:40:02,216 [Epoch: 008 Step: 00001216] Batch Translation Loss:   6.485801 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 21:40:15,452 [Epoch: 008 Step: 00001217] Batch Translation Loss:   7.590590 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-29 21:40:35,233 [Epoch: 008 Step: 00001218] Batch Translation Loss:   6.879347 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:40:48,874 [Epoch: 008 Step: 00001219] Batch Translation Loss:   7.712986 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 21:41:00,493 [Epoch: 008 Step: 00001220] Batch Translation Loss:   6.965350 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 21:41:12,511 [Epoch: 008 Step: 00001221] Batch Translation Loss:   6.673814 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 21:41:26,761 [Epoch: 008 Step: 00001222] Batch Translation Loss:   6.621304 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 21:41:43,372 [Epoch: 008 Step: 00001223] Batch Translation Loss:   6.784011 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:42:13,375 [Epoch: 008 Step: 00001224] Batch Translation Loss:   6.598258 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:42:37,334 [Epoch: 008 Step: 00001225] Batch Translation Loss:   6.593550 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:42:53,716 [Epoch: 008 Step: 00001226] Batch Translation Loss:   8.703645 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 21:43:07,359 [Epoch: 008 Step: 00001227] Batch Translation Loss:   6.546662 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:43:24,528 [Epoch: 008 Step: 00001228] Batch Translation Loss:   7.124816 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 21:43:41,005 [Epoch: 008 Step: 00001229] Batch Translation Loss:   6.367379 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:43:59,298 [Epoch: 008 Step: 00001230] Batch Translation Loss:   6.523934 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:44:19,663 [Epoch: 008 Step: 00001231] Batch Translation Loss:   7.601397 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:44:38,662 [Epoch: 008 Step: 00001232] Batch Translation Loss:   6.663278 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:44:54,616 [Epoch: 008 Step: 00001233] Batch Translation Loss:   6.657976 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:45:09,331 [Epoch: 008 Step: 00001234] Batch Translation Loss:   6.913836 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 21:45:25,757 [Epoch: 008 Step: 00001235] Batch Translation Loss:   6.145795 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:45:39,917 [Epoch: 008 Step: 00001236] Batch Translation Loss:   6.846118 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 21:45:56,790 [Epoch: 008 Step: 00001237] Batch Translation Loss:   7.057164 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:46:15,017 [Epoch: 008 Step: 00001238] Batch Translation Loss:   6.399116 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:46:31,677 [Epoch: 008 Step: 00001239] Batch Translation Loss:   7.189106 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:46:54,135 [Epoch: 008 Step: 00001240] Batch Translation Loss:   7.120679 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:47:23,682 [Epoch: 008 Step: 00001241] Batch Translation Loss:   6.572667 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:47:42,923 [Epoch: 008 Step: 00001242] Batch Translation Loss:   7.249399 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:48:08,681 [Epoch: 008 Step: 00001243] Batch Translation Loss:   6.381303 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:48:25,444 [Epoch: 008 Step: 00001244] Batch Translation Loss:   6.304170 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:48:40,977 [Epoch: 008 Step: 00001245] Batch Translation Loss:   7.001869 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 21:48:58,666 [Epoch: 008 Step: 00001246] Batch Translation Loss:   7.154355 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:49:16,323 [Epoch: 008 Step: 00001247] Batch Translation Loss:   6.740439 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:49:50,621 [Epoch: 008 Step: 00001248] Batch Translation Loss:   6.778273 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:50:15,399 [Epoch: 008 Step: 00001249] Batch Translation Loss:   7.571075 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:50:53,356 [Epoch: 008 Step: 00001250] Batch Translation Loss:   7.066166 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:51:22,519 [Epoch: 008 Step: 00001251] Batch Translation Loss:   6.804270 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:51:39,189 [Epoch: 008 Step: 00001252] Batch Translation Loss:   6.955405 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 21:51:58,387 [Epoch: 008 Step: 00001253] Batch Translation Loss:   7.013466 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:52:16,749 [Epoch: 008 Step: 00001254] Batch Translation Loss:   6.438199 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:52:35,355 [Epoch: 008 Step: 00001255] Batch Translation Loss:   6.161736 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:53:06,497 [Epoch: 008 Step: 00001256] Batch Translation Loss:   6.903401 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:53:29,128 [Epoch: 008 Step: 00001257] Batch Translation Loss:   6.275488 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:53:49,507 [Epoch: 008 Step: 00001258] Batch Translation Loss:   6.963112 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:54:08,617 [Epoch: 008 Step: 00001259] Batch Translation Loss:   6.794106 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:54:26,283 [Epoch: 008 Step: 00001260] Batch Translation Loss:   7.230221 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:54:45,639 [Epoch: 008 Step: 00001261] Batch Translation Loss:   6.858470 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:55:05,585 [Epoch: 008 Step: 00001262] Batch Translation Loss:   7.183276 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:55:31,523 [Epoch: 008 Step: 00001263] Batch Translation Loss:   6.181700 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:55:54,866 [Epoch: 008 Step: 00001264] Batch Translation Loss:   6.383188 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:56:36,758 [Epoch: 008 Step: 00001265] Batch Translation Loss:   6.541001 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:56:54,620 [Epoch: 008 Step: 00001266] Batch Translation Loss:   6.732067 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:57:14,063 [Epoch: 008 Step: 00001267] Batch Translation Loss:   6.843492 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:57:32,865 [Epoch: 008 Step: 00001268] Batch Translation Loss:   6.741612 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:57:54,127 [Epoch: 008 Step: 00001269] Batch Translation Loss:   6.845854 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:58:16,020 [Epoch: 008 Step: 00001270] Batch Translation Loss:   6.414840 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:58:38,380 [Epoch: 008 Step: 00001271] Batch Translation Loss:   6.996401 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 21:59:11,168 [Epoch: 008 Step: 00001272] Batch Translation Loss:   6.892490 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 21:59:54,921 [Epoch: 008 Step: 00001273] Batch Translation Loss:   6.604306 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:00:15,322 [Epoch: 008 Step: 00001274] Batch Translation Loss:   6.476195 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 22:00:35,751 [Epoch: 008 Step: 00001275] Batch Translation Loss:   6.185513 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 22:00:58,262 [Epoch: 008 Step: 00001276] Batch Translation Loss:   7.167646 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 22:01:20,989 [Epoch: 008 Step: 00001277] Batch Translation Loss:   6.787411 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 22:02:13,652 [Epoch: 008 Step: 00001278] Batch Translation Loss:   6.606341 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:02:40,704 [Epoch: 008 Step: 00001279] Batch Translation Loss:   6.019416 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:03:05,272 [Epoch: 008 Step: 00001280] Batch Translation Loss:   6.738181 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 22:03:43,549 [Epoch: 008 Step: 00001281] Batch Translation Loss:   7.600320 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:04:06,024 [Epoch: 008 Step: 00001282] Batch Translation Loss:   6.330798 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 22:04:28,962 [Epoch: 008 Step: 00001283] Batch Translation Loss:   6.473777 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 22:04:59,432 [Epoch: 008 Step: 00001284] Batch Translation Loss:   7.177401 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:05:27,102 [Epoch: 008 Step: 00001285] Batch Translation Loss:   7.262810 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:06:38,885 [Epoch: 008 Step: 00001286] Batch Translation Loss:   7.215650 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:07:03,650 [Epoch: 008 Step: 00001287] Batch Translation Loss:   6.491545 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 22:07:28,113 [Epoch: 008 Step: 00001288] Batch Translation Loss:   6.438272 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 22:08:16,657 [Epoch: 008 Step: 00001289] Batch Translation Loss:   7.115322 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:08:48,194 [Epoch: 008 Step: 00001290] Batch Translation Loss:   6.987210 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:09:15,611 [Epoch: 008 Step: 00001291] Batch Translation Loss:   5.967778 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:09:39,355 [Epoch: 008 Step: 00001292] Batch Translation Loss:   6.736908 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 22:10:01,638 [Epoch: 008 Step: 00001293] Batch Translation Loss:   6.474968 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 22:10:26,254 [Epoch: 008 Step: 00001294] Batch Translation Loss:   6.089140 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:10:52,028 [Epoch: 008 Step: 00001295] Batch Translation Loss:   6.256738 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 22:11:49,943 [Epoch: 008 Step: 00001296] Batch Translation Loss:   7.627563 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:12:20,036 [Epoch: 008 Step: 00001297] Batch Translation Loss:   7.005466 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:12:44,809 [Epoch: 008 Step: 00001298] Batch Translation Loss:   7.158877 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 22:13:11,613 [Epoch: 008 Step: 00001299] Batch Translation Loss:   6.874864 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:13:34,122 [Epoch: 008 Step: 00001300] Batch Translation Loss:   5.782752 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 22:20:50,576 Validation result at epoch   8, step     1300: duration: 436.4279s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 10819.27344	PPL: 6156.23486
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 2.02,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 4.68	ROUGE 2.40
2021-12-29 22:20:59,474 Logging Recognition and Translation Outputs
2021-12-29 22:20:59,509 ========================================================================================================================
2021-12-29 22:20:59,510 Logging Sequence: deafvideo_4-tax_tips_by_irs_4963
2021-12-29 22:20:59,511 	Text Reference  :	him    
2021-12-29 22:20:59,511 	Text Hypothesis :	theresa
2021-12-29 22:20:59,516 	Text Alignment  :	S      
2021-12-29 22:20:59,516 ========================================================================================================================
2021-12-29 22:20:59,516 Logging Sequence: deafvideo_3-geoalpha_4550
2021-12-29 22:20:59,516 	Text Reference  :	facbk
2021-12-29 22:20:59,516 	Text Hypothesis :	asl  
2021-12-29 22:20:59,517 	Text Alignment  :	S    
2021-12-29 22:20:59,517 ========================================================================================================================
2021-12-29 22:20:59,517 Logging Sequence: aslized-suzanne_stecker_0196
2021-12-29 22:20:59,517 	Text Reference  :	savoir
2021-12-29 22:20:59,517 	Text Hypothesis :	asl   
2021-12-29 22:20:59,517 	Text Alignment  :	S     
2021-12-29 22:20:59,517 ========================================================================================================================
2021-12-29 22:20:59,517 Logging Sequence: deafvideo_5-deafpoweronethumbtwo_7293
2021-12-29 22:20:59,517 	Text Reference  :	fr
2021-12-29 22:20:59,517 	Text Hypothesis :	or
2021-12-29 22:20:59,518 	Text Alignment  :	S 
2021-12-29 22:20:59,518 ========================================================================================================================
2021-12-29 22:20:59,518 Logging Sequence: deafvideo_3-otismhill82_4616
2021-12-29 22:20:59,518 	Text Reference  :	mat hamll
2021-12-29 22:20:59,518 	Text Hypothesis :	*** asl  
2021-12-29 22:20:59,518 	Text Alignment  :	D   S    
2021-12-29 22:20:59,518 ========================================================================================================================
2021-12-29 22:22:50,838 [Epoch: 008 Step: 00001301] Batch Translation Loss:   6.410055 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-29 22:23:56,131 [Epoch: 008 Step: 00001302] Batch Translation Loss:   6.932886 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:24:25,761 [Epoch: 008 Step: 00001303] Batch Translation Loss:   7.239166 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:24:59,010 [Epoch: 008 Step: 00001304] Batch Translation Loss:   6.787841 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:25:30,795 [Epoch: 008 Step: 00001305] Batch Translation Loss:   6.125614 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:26:01,220 [Epoch: 008 Step: 00001306] Batch Translation Loss:   5.896691 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:26:29,474 [Epoch: 008 Step: 00001307] Batch Translation Loss:   6.702247 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:26:54,719 [Epoch: 008 Step: 00001308] Batch Translation Loss:   5.639013 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:27:25,206 [Epoch: 008 Step: 00001309] Batch Translation Loss:   6.406513 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:28:01,793 [Epoch: 008 Step: 00001310] Batch Translation Loss:   6.569604 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:28:35,812 [Epoch: 008 Step: 00001311] Batch Translation Loss:   6.641953 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:29:07,630 [Epoch: 008 Step: 00001312] Batch Translation Loss:   6.847741 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:29:35,644 [Epoch: 008 Step: 00001313] Batch Translation Loss:   6.318799 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:30:03,488 [Epoch: 008 Step: 00001314] Batch Translation Loss:   6.419761 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:30:45,997 [Epoch: 008 Step: 00001315] Batch Translation Loss:   7.535400 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:31:17,566 [Epoch: 008 Step: 00001316] Batch Translation Loss:   7.109477 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:31:55,493 [Epoch: 008 Step: 00001317] Batch Translation Loss:   6.954453 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:32:24,958 [Epoch: 008 Step: 00001318] Batch Translation Loss:   7.426008 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:32:52,854 [Epoch: 008 Step: 00001319] Batch Translation Loss:   6.449358 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:33:21,295 [Epoch: 008 Step: 00001320] Batch Translation Loss:   6.357951 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:33:51,803 [Epoch: 008 Step: 00001321] Batch Translation Loss:   6.798550 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:34:32,768 [Epoch: 008 Step: 00001322] Batch Translation Loss:   6.992352 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:35:37,817 [Epoch: 008 Step: 00001323] Batch Translation Loss:   7.333330 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:36:30,031 [Epoch: 008 Step: 00001324] Batch Translation Loss:   7.409604 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:36:57,705 [Epoch: 008 Step: 00001325] Batch Translation Loss:   6.755972 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:37:26,779 [Epoch: 008 Step: 00001326] Batch Translation Loss:   6.425821 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:38:10,119 [Epoch: 008 Step: 00001327] Batch Translation Loss:   6.991297 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:38:46,895 [Epoch: 008 Step: 00001328] Batch Translation Loss:   6.456324 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:39:21,136 [Epoch: 008 Step: 00001329] Batch Translation Loss:   7.276831 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:39:51,261 [Epoch: 008 Step: 00001330] Batch Translation Loss:   6.430106 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:40:22,073 [Epoch: 008 Step: 00001331] Batch Translation Loss:   6.029869 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:40:55,146 [Epoch: 008 Step: 00001332] Batch Translation Loss:   6.579495 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:41:41,701 [Epoch: 008 Step: 00001333] Batch Translation Loss:   6.852437 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:42:19,544 [Epoch: 008 Step: 00001334] Batch Translation Loss:   6.071147 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:43:21,746 [Epoch: 008 Step: 00001335] Batch Translation Loss:   6.132239 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:43:52,015 [Epoch: 008 Step: 00001336] Batch Translation Loss:   6.499528 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:44:39,286 [Epoch: 008 Step: 00001337] Batch Translation Loss:   5.571690 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:45:14,379 [Epoch: 008 Step: 00001338] Batch Translation Loss:   6.650235 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:45:56,392 [Epoch: 008 Step: 00001339] Batch Translation Loss:   6.876281 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:46:27,091 [Epoch: 008 Step: 00001340] Batch Translation Loss:   5.580061 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:46:57,272 [Epoch: 008 Step: 00001341] Batch Translation Loss:   6.895864 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:47:42,357 [Epoch: 008 Step: 00001342] Batch Translation Loss:   6.242227 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:48:20,999 [Epoch: 008 Step: 00001343] Batch Translation Loss:   6.258890 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:48:58,079 [Epoch: 008 Step: 00001344] Batch Translation Loss:   6.091565 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:49:34,216 [Epoch: 008 Step: 00001345] Batch Translation Loss:   6.382534 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:50:06,425 [Epoch: 008 Step: 00001346] Batch Translation Loss:   6.300173 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:50:39,220 [Epoch: 008 Step: 00001347] Batch Translation Loss:   7.087451 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:51:20,560 [Epoch: 008 Step: 00001348] Batch Translation Loss:   6.377003 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:51:57,787 [Epoch: 008 Step: 00001349] Batch Translation Loss:   7.111484 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:52:39,942 [Epoch: 008 Step: 00001350] Batch Translation Loss:   7.012583 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:53:21,184 [Epoch: 008 Step: 00001351] Batch Translation Loss:   5.932975 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:53:52,642 [Epoch: 008 Step: 00001352] Batch Translation Loss:   6.679291 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:54:26,425 [Epoch: 008 Step: 00001353] Batch Translation Loss:   7.496573 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:55:10,182 [Epoch: 008 Step: 00001354] Batch Translation Loss:   6.430985 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:55:48,243 [Epoch: 008 Step: 00001355] Batch Translation Loss:   6.724417 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:56:28,519 [Epoch: 008 Step: 00001356] Batch Translation Loss:   6.755811 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:57:00,386 [Epoch: 008 Step: 00001357] Batch Translation Loss:   6.147414 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:57:32,622 [Epoch: 008 Step: 00001358] Batch Translation Loss:   7.049916 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 22:58:45,712 [Epoch: 008 Step: 00001359] Batch Translation Loss:   6.742370 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-29 22:58:46,060 Epoch   8: Total Training Recognition Loss -1.00  Total Training Translation Loss 1156.07 
2021-12-29 22:58:46,060 EPOCH 9
2021-12-29 22:58:53,826 [Epoch: 009 Step: 00001360] Batch Translation Loss:   6.142471 => Txt Tokens per Sec:        5 || Lr: 0.000700
2021-12-29 22:59:01,414 [Epoch: 009 Step: 00001361] Batch Translation Loss:   7.220427 => Txt Tokens per Sec:        5 || Lr: 0.000700
2021-12-29 22:59:12,033 [Epoch: 009 Step: 00001362] Batch Translation Loss:   7.284266 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-29 22:59:22,849 [Epoch: 009 Step: 00001363] Batch Translation Loss:   6.851413 => Txt Tokens per Sec:        5 || Lr: 0.000700
2021-12-29 22:59:33,386 [Epoch: 009 Step: 00001364] Batch Translation Loss:   7.594978 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-29 22:59:46,725 [Epoch: 009 Step: 00001365] Batch Translation Loss:   6.900696 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 22:59:58,553 [Epoch: 009 Step: 00001366] Batch Translation Loss:   7.542703 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-29 23:00:13,024 [Epoch: 009 Step: 00001367] Batch Translation Loss:   7.557813 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 23:00:26,386 [Epoch: 009 Step: 00001368] Batch Translation Loss:   7.318521 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 23:00:35,106 [Epoch: 009 Step: 00001369] Batch Translation Loss:   7.002287 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-29 23:00:53,809 [Epoch: 009 Step: 00001370] Batch Translation Loss:   6.909836 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:01:04,853 [Epoch: 009 Step: 00001371] Batch Translation Loss:   6.678629 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-29 23:01:15,394 [Epoch: 009 Step: 00001372] Batch Translation Loss:   6.612077 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-29 23:01:34,842 [Epoch: 009 Step: 00001373] Batch Translation Loss:   6.215247 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:01:53,191 [Epoch: 009 Step: 00001374] Batch Translation Loss:   6.561481 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 23:02:04,167 [Epoch: 009 Step: 00001375] Batch Translation Loss:   5.956333 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 23:02:19,282 [Epoch: 009 Step: 00001376] Batch Translation Loss:   5.853267 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 23:02:31,969 [Epoch: 009 Step: 00001377] Batch Translation Loss:   7.295145 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 23:02:53,674 [Epoch: 009 Step: 00001378] Batch Translation Loss:   7.313868 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:03:13,163 [Epoch: 009 Step: 00001379] Batch Translation Loss:   6.517872 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:03:26,142 [Epoch: 009 Step: 00001380] Batch Translation Loss:   6.751052 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 23:03:36,905 [Epoch: 009 Step: 00001381] Batch Translation Loss:   6.628264 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 23:03:47,658 [Epoch: 009 Step: 00001382] Batch Translation Loss:   6.248636 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 23:04:03,938 [Epoch: 009 Step: 00001383] Batch Translation Loss:   7.208573 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:04:14,202 [Epoch: 009 Step: 00001384] Batch Translation Loss:   6.141094 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-29 23:04:26,400 [Epoch: 009 Step: 00001385] Batch Translation Loss:   6.316981 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 23:04:38,375 [Epoch: 009 Step: 00001386] Batch Translation Loss:   5.643257 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 23:04:52,002 [Epoch: 009 Step: 00001387] Batch Translation Loss:   7.075484 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 23:05:05,202 [Epoch: 009 Step: 00001388] Batch Translation Loss:   6.088141 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 23:05:34,972 [Epoch: 009 Step: 00001389] Batch Translation Loss:   8.135972 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:05:48,796 [Epoch: 009 Step: 00001390] Batch Translation Loss:   6.886196 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 23:06:04,268 [Epoch: 009 Step: 00001391] Batch Translation Loss:   6.368789 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:06:21,347 [Epoch: 009 Step: 00001392] Batch Translation Loss:   6.599526 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:06:35,378 [Epoch: 009 Step: 00001393] Batch Translation Loss:   6.421383 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 23:07:02,575 [Epoch: 009 Step: 00001394] Batch Translation Loss:   6.942420 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:07:25,911 [Epoch: 009 Step: 00001395] Batch Translation Loss:   7.214475 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:07:39,331 [Epoch: 009 Step: 00001396] Batch Translation Loss:   6.848564 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-29 23:08:03,505 [Epoch: 009 Step: 00001397] Batch Translation Loss:   7.005309 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:08:19,181 [Epoch: 009 Step: 00001398] Batch Translation Loss:   6.812276 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:08:47,722 [Epoch: 009 Step: 00001399] Batch Translation Loss:   7.378469 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:09:12,620 [Epoch: 009 Step: 00001400] Batch Translation Loss:   7.422977 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:16:51,204 Validation result at epoch   9, step     1400: duration: 458.5803s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 10766.17578	PPL: 6654.75732
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 2.54,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.99	ROUGE 3.06
2021-12-29 23:16:57,901 Logging Recognition and Translation Outputs
2021-12-29 23:16:57,901 ========================================================================================================================
2021-12-29 23:16:57,902 Logging Sequence: youtube_4-howard_rosenblum_5564
2021-12-29 23:16:57,903 	Text Reference  :	cdo 
2021-12-29 23:16:57,903 	Text Hypothesis :	july
2021-12-29 23:16:57,904 	Text Alignment  :	S   
2021-12-29 23:16:57,904 ========================================================================================================================
2021-12-29 23:16:57,904 Logging Sequence: aslized-suzanne_stecker_0259
2021-12-29 23:16:57,905 	Text Reference  :	moritz  
2021-12-29 23:16:57,905 	Text Hypothesis :	handling
2021-12-29 23:16:57,905 	Text Alignment  :	S       
2021-12-29 23:16:57,906 ========================================================================================================================
2021-12-29 23:16:57,906 Logging Sequence: deafvideo_3-crossover_3866
2021-12-29 23:16:57,906 	Text Reference  :	facess
2021-12-29 23:16:57,907 	Text Hypothesis :	fla   
2021-12-29 23:16:57,907 	Text Alignment  :	S     
2021-12-29 23:16:57,907 ========================================================================================================================
2021-12-29 23:16:57,907 Logging Sequence: youtube_4-howard_rosenblum_5559
2021-12-29 23:16:57,908 	Text Reference  :	com
2021-12-29 23:16:57,908 	Text Hypothesis :	asl
2021-12-29 23:16:57,909 	Text Alignment  :	S  
2021-12-29 23:16:57,909 ========================================================================================================================
2021-12-29 23:16:57,909 Logging Sequence: aslized-suzanne_stecker_0195
2021-12-29 23:16:57,910 	Text Reference  :	raja rajeshwari
2021-12-29 23:16:57,910 	Text Hypothesis :	**** fla       
2021-12-29 23:16:57,910 	Text Alignment  :	D    S         
2021-12-29 23:16:57,910 ========================================================================================================================
2021-12-29 23:17:54,678 [Epoch: 009 Step: 00001401] Batch Translation Loss:   6.691866 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:18:19,288 [Epoch: 009 Step: 00001402] Batch Translation Loss:   6.300649 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:18:46,941 [Epoch: 009 Step: 00001403] Batch Translation Loss:   6.808345 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:19:11,234 [Epoch: 009 Step: 00001404] Batch Translation Loss:   6.813900 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:19:32,358 [Epoch: 009 Step: 00001405] Batch Translation Loss:   6.552521 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:20:06,589 [Epoch: 009 Step: 00001406] Batch Translation Loss:   6.561858 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:20:40,420 [Epoch: 009 Step: 00001407] Batch Translation Loss:   8.114356 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:21:06,102 [Epoch: 009 Step: 00001408] Batch Translation Loss:   6.536581 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:21:22,515 [Epoch: 009 Step: 00001409] Batch Translation Loss:   6.295096 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:21:38,731 [Epoch: 009 Step: 00001410] Batch Translation Loss:   6.700068 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:21:54,458 [Epoch: 009 Step: 00001411] Batch Translation Loss:   6.611062 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:22:23,597 [Epoch: 009 Step: 00001412] Batch Translation Loss:   6.312206 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:22:58,275 [Epoch: 009 Step: 00001413] Batch Translation Loss:   6.843742 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:23:34,520 [Epoch: 009 Step: 00001414] Batch Translation Loss:   7.068141 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:23:55,528 [Epoch: 009 Step: 00001415] Batch Translation Loss:   7.102751 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:24:15,508 [Epoch: 009 Step: 00001416] Batch Translation Loss:   6.326057 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:24:34,750 [Epoch: 009 Step: 00001417] Batch Translation Loss:   6.438335 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:24:51,847 [Epoch: 009 Step: 00001418] Batch Translation Loss:   6.373212 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:25:08,122 [Epoch: 009 Step: 00001419] Batch Translation Loss:   6.323470 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:25:24,421 [Epoch: 009 Step: 00001420] Batch Translation Loss:   6.342164 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:25:44,372 [Epoch: 009 Step: 00001421] Batch Translation Loss:   6.761595 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:26:04,043 [Epoch: 009 Step: 00001422] Batch Translation Loss:   6.227248 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:26:29,074 [Epoch: 009 Step: 00001423] Batch Translation Loss:   6.804567 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:26:49,523 [Epoch: 009 Step: 00001424] Batch Translation Loss:   6.605462 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:27:29,111 [Epoch: 009 Step: 00001425] Batch Translation Loss:   6.607585 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:27:48,344 [Epoch: 009 Step: 00001426] Batch Translation Loss:   5.995911 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:28:10,254 [Epoch: 009 Step: 00001427] Batch Translation Loss:   6.903693 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:28:28,225 [Epoch: 009 Step: 00001428] Batch Translation Loss:   6.437353 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:28:47,806 [Epoch: 009 Step: 00001429] Batch Translation Loss:   7.282161 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:29:04,685 [Epoch: 009 Step: 00001430] Batch Translation Loss:   6.330028 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:29:27,249 [Epoch: 009 Step: 00001431] Batch Translation Loss:   5.898446 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:29:47,967 [Epoch: 009 Step: 00001432] Batch Translation Loss:   6.353894 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:30:22,478 [Epoch: 009 Step: 00001433] Batch Translation Loss:   6.660038 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:31:03,854 [Epoch: 009 Step: 00001434] Batch Translation Loss:   6.335991 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:31:26,943 [Epoch: 009 Step: 00001435] Batch Translation Loss:   6.191154 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:31:54,552 [Epoch: 009 Step: 00001436] Batch Translation Loss:   6.557439 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:32:15,776 [Epoch: 009 Step: 00001437] Batch Translation Loss:   6.596055 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:32:35,041 [Epoch: 009 Step: 00001438] Batch Translation Loss:   7.868412 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:33:01,501 [Epoch: 009 Step: 00001439] Batch Translation Loss:   6.494104 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:33:22,118 [Epoch: 009 Step: 00001440] Batch Translation Loss:   7.346045 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:34:08,242 [Epoch: 009 Step: 00001441] Batch Translation Loss:   6.436148 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:34:31,615 [Epoch: 009 Step: 00001442] Batch Translation Loss:   5.990575 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:34:58,210 [Epoch: 009 Step: 00001443] Batch Translation Loss:   7.066376 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:35:22,099 [Epoch: 009 Step: 00001444] Batch Translation Loss:   7.286336 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:35:46,752 [Epoch: 009 Step: 00001445] Batch Translation Loss:   6.325401 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:36:08,047 [Epoch: 009 Step: 00001446] Batch Translation Loss:   6.980422 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:36:26,268 [Epoch: 009 Step: 00001447] Batch Translation Loss:   6.487059 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:36:49,687 [Epoch: 009 Step: 00001448] Batch Translation Loss:   6.518404 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:37:20,028 [Epoch: 009 Step: 00001449] Batch Translation Loss:   6.766739 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:37:47,641 [Epoch: 009 Step: 00001450] Batch Translation Loss:   6.239779 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:38:16,941 [Epoch: 009 Step: 00001451] Batch Translation Loss:   6.197959 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:38:44,815 [Epoch: 009 Step: 00001452] Batch Translation Loss:   6.486656 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:39:08,166 [Epoch: 009 Step: 00001453] Batch Translation Loss:   6.354977 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:39:31,196 [Epoch: 009 Step: 00001454] Batch Translation Loss:   6.360027 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:39:55,834 [Epoch: 009 Step: 00001455] Batch Translation Loss:   6.988811 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:40:25,698 [Epoch: 009 Step: 00001456] Batch Translation Loss:   6.950915 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:40:54,599 [Epoch: 009 Step: 00001457] Batch Translation Loss:   6.452753 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:41:24,382 [Epoch: 009 Step: 00001458] Batch Translation Loss:   6.112264 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:41:50,601 [Epoch: 009 Step: 00001459] Batch Translation Loss:   6.042654 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:42:18,266 [Epoch: 009 Step: 00001460] Batch Translation Loss:   6.612012 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:42:46,278 [Epoch: 009 Step: 00001461] Batch Translation Loss:   5.496327 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:43:09,483 [Epoch: 009 Step: 00001462] Batch Translation Loss:   6.618030 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:43:32,066 [Epoch: 009 Step: 00001463] Batch Translation Loss:   6.563246 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:44:24,001 [Epoch: 009 Step: 00001464] Batch Translation Loss:   6.627260 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:44:55,092 [Epoch: 009 Step: 00001465] Batch Translation Loss:   6.046991 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:45:26,109 [Epoch: 009 Step: 00001466] Batch Translation Loss:   6.082513 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:45:56,010 [Epoch: 009 Step: 00001467] Batch Translation Loss:   6.857729 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:46:27,922 [Epoch: 009 Step: 00001468] Batch Translation Loss:   6.671124 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:47:12,463 [Epoch: 009 Step: 00001469] Batch Translation Loss:   6.559482 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:47:38,492 [Epoch: 009 Step: 00001470] Batch Translation Loss:   6.465364 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-29 23:48:04,973 [Epoch: 009 Step: 00001471] Batch Translation Loss:   7.101155 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:48:43,662 [Epoch: 009 Step: 00001472] Batch Translation Loss:   6.630274 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:49:17,766 [Epoch: 009 Step: 00001473] Batch Translation Loss:   7.093963 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:49:48,435 [Epoch: 009 Step: 00001474] Batch Translation Loss:   6.208919 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:50:34,610 [Epoch: 009 Step: 00001475] Batch Translation Loss:   6.209121 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:51:05,176 [Epoch: 009 Step: 00001476] Batch Translation Loss:   6.177253 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:51:32,942 [Epoch: 009 Step: 00001477] Batch Translation Loss:   6.769423 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:52:10,506 [Epoch: 009 Step: 00001478] Batch Translation Loss:   6.114811 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:53:20,187 [Epoch: 009 Step: 00001479] Batch Translation Loss:   6.846337 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:53:53,286 [Epoch: 009 Step: 00001480] Batch Translation Loss:   6.578303 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:54:42,047 [Epoch: 009 Step: 00001481] Batch Translation Loss:   6.934628 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:55:12,322 [Epoch: 009 Step: 00001482] Batch Translation Loss:   6.307789 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:55:51,135 [Epoch: 009 Step: 00001483] Batch Translation Loss:   5.925373 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:56:26,613 [Epoch: 009 Step: 00001484] Batch Translation Loss:   6.518074 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:57:00,009 [Epoch: 009 Step: 00001485] Batch Translation Loss:   6.541095 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:57:35,905 [Epoch: 009 Step: 00001486] Batch Translation Loss:   6.504956 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:58:07,707 [Epoch: 009 Step: 00001487] Batch Translation Loss:   6.660461 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:58:37,717 [Epoch: 009 Step: 00001488] Batch Translation Loss:   6.044036 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:59:06,874 [Epoch: 009 Step: 00001489] Batch Translation Loss:   6.316356 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-29 23:59:45,153 [Epoch: 009 Step: 00001490] Batch Translation Loss:   5.872757 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:00:22,443 [Epoch: 009 Step: 00001491] Batch Translation Loss:   6.971171 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:00:57,591 [Epoch: 009 Step: 00001492] Batch Translation Loss:   6.592039 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:01:34,087 [Epoch: 009 Step: 00001493] Batch Translation Loss:   6.556849 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:02:07,113 [Epoch: 009 Step: 00001494] Batch Translation Loss:   6.227523 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:02:38,298 [Epoch: 009 Step: 00001495] Batch Translation Loss:   6.113348 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:03:08,347 [Epoch: 009 Step: 00001496] Batch Translation Loss:   6.828306 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:03:46,829 [Epoch: 009 Step: 00001497] Batch Translation Loss:   6.528415 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:04:22,486 [Epoch: 009 Step: 00001498] Batch Translation Loss:   6.891725 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:05:02,349 [Epoch: 009 Step: 00001499] Batch Translation Loss:   6.439199 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:05:44,124 [Epoch: 009 Step: 00001500] Batch Translation Loss:   6.301715 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:13:02,565 Validation result at epoch   9, step     1500: duration: 438.4264s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11291.09668	PPL: 5722.61768
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 1.82,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 4.40	ROUGE 2.39
2021-12-30 00:13:09,070 Logging Recognition and Translation Outputs
2021-12-30 00:13:09,153 ========================================================================================================================
2021-12-30 00:13:09,153 Logging Sequence: deafvideo_2-goatman_1544
2021-12-30 00:13:09,154 	Text Reference  :	are
2021-12-30 00:13:09,154 	Text Hypothesis :	or 
2021-12-30 00:13:09,154 	Text Alignment  :	S  
2021-12-30 00:13:09,155 ========================================================================================================================
2021-12-30 00:13:09,155 Logging Sequence: deafvideo_2-deafpoweronethumbtwo_1795
2021-12-30 00:13:09,155 	Text Reference  :	ok 
2021-12-30 00:13:09,155 	Text Hypothesis :	asl
2021-12-30 00:13:09,156 	Text Alignment  :	S  
2021-12-30 00:13:09,156 ========================================================================================================================
2021-12-30 00:13:09,156 Logging Sequence: deafvideo_3-yesyes_3103
2021-12-30 00:13:09,156 	Text Reference  :	there
2021-12-30 00:13:09,157 	Text Hypothesis :	or   
2021-12-30 00:13:09,157 	Text Alignment  :	S    
2021-12-30 00:13:09,157 ========================================================================================================================
2021-12-30 00:13:09,157 Logging Sequence: youtube_5-daniel_durant_5893
2021-12-30 00:13:09,158 	Text Reference  :	scan
2021-12-30 00:13:09,158 	Text Hypothesis :	asl 
2021-12-30 00:13:09,158 	Text Alignment  :	S   
2021-12-30 00:13:09,158 ========================================================================================================================
2021-12-30 00:13:09,158 Logging Sequence: deafvideo_5-silentoneye_7322
2021-12-30 00:13:09,159 	Text Reference  :	wow
2021-12-30 00:13:09,159 	Text Hypothesis :	asl
2021-12-30 00:13:09,159 	Text Alignment  :	S  
2021-12-30 00:13:09,159 ========================================================================================================================
2021-12-30 00:16:19,795 [Epoch: 009 Step: 00001501] Batch Translation Loss:   6.644471 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-30 00:17:06,797 [Epoch: 009 Step: 00001502] Batch Translation Loss:   6.634250 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:17:37,945 [Epoch: 009 Step: 00001503] Batch Translation Loss:   6.756243 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:18:06,071 [Epoch: 009 Step: 00001504] Batch Translation Loss:   6.111627 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:18:37,471 [Epoch: 009 Step: 00001505] Batch Translation Loss:   6.318181 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:19:21,457 [Epoch: 009 Step: 00001506] Batch Translation Loss:   5.878788 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:20:01,767 [Epoch: 009 Step: 00001507] Batch Translation Loss:   6.937029 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:21:10,389 [Epoch: 009 Step: 00001508] Batch Translation Loss:   6.478712 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:22:08,547 [Epoch: 009 Step: 00001509] Batch Translation Loss:   7.010803 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:22:50,217 [Epoch: 009 Step: 00001510] Batch Translation Loss:   6.488265 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:23:29,058 [Epoch: 009 Step: 00001511] Batch Translation Loss:   6.748514 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:24:07,377 [Epoch: 009 Step: 00001512] Batch Translation Loss:   6.583969 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:24:46,993 [Epoch: 009 Step: 00001513] Batch Translation Loss:   6.631546 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:25:17,037 [Epoch: 009 Step: 00001514] Batch Translation Loss:   6.703236 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:25:47,364 [Epoch: 009 Step: 00001515] Batch Translation Loss:   6.283318 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:26:37,743 [Epoch: 009 Step: 00001516] Batch Translation Loss:   6.286857 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:27:17,092 [Epoch: 009 Step: 00001517] Batch Translation Loss:   5.994243 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:28:01,795 [Epoch: 009 Step: 00001518] Batch Translation Loss:   6.606977 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:28:42,001 [Epoch: 009 Step: 00001519] Batch Translation Loss:   6.260370 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:29:27,043 [Epoch: 009 Step: 00001520] Batch Translation Loss:   6.902863 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:30:03,265 [Epoch: 009 Step: 00001521] Batch Translation Loss:   6.492265 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:30:47,788 [Epoch: 009 Step: 00001522] Batch Translation Loss:   5.993230 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:32:03,037 [Epoch: 009 Step: 00001523] Batch Translation Loss:   6.947348 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-30 00:32:43,090 [Epoch: 009 Step: 00001524] Batch Translation Loss:   6.863178 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:33:23,203 [Epoch: 009 Step: 00001525] Batch Translation Loss:   6.030608 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:33:58,278 [Epoch: 009 Step: 00001526] Batch Translation Loss:   6.479314 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:34:46,790 [Epoch: 009 Step: 00001527] Batch Translation Loss:   7.114000 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:36:11,230 [Epoch: 009 Step: 00001528] Batch Translation Loss:   7.853143 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:36:43,143 [Epoch: 009 Step: 00001529] Batch Translation Loss:   7.258018 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:36:43,285 Epoch   9: Total Training Recognition Loss -1.00  Total Training Translation Loss 1125.58 
2021-12-30 00:36:43,286 EPOCH 10
2021-12-30 00:36:50,608 [Epoch: 010 Step: 00001530] Batch Translation Loss:   6.444184 => Txt Tokens per Sec:        5 || Lr: 0.000700
2021-12-30 00:37:01,786 [Epoch: 010 Step: 00001531] Batch Translation Loss:   7.171003 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-30 00:37:10,808 [Epoch: 010 Step: 00001532] Batch Translation Loss:   7.308636 => Txt Tokens per Sec:        5 || Lr: 0.000700
2021-12-30 00:37:21,452 [Epoch: 010 Step: 00001533] Batch Translation Loss:   7.059694 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-30 00:37:33,876 [Epoch: 010 Step: 00001534] Batch Translation Loss:   6.407107 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-30 00:37:44,157 [Epoch: 010 Step: 00001535] Batch Translation Loss:   7.012369 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-30 00:37:56,618 [Epoch: 010 Step: 00001536] Batch Translation Loss:   7.050994 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-30 00:38:12,964 [Epoch: 010 Step: 00001537] Batch Translation Loss:   6.747263 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 00:38:24,962 [Epoch: 010 Step: 00001538] Batch Translation Loss:   6.985173 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-30 00:38:39,931 [Epoch: 010 Step: 00001539] Batch Translation Loss:   7.148174 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 00:38:55,069 [Epoch: 010 Step: 00001540] Batch Translation Loss:   6.728195 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 00:39:09,260 [Epoch: 010 Step: 00001541] Batch Translation Loss:   6.765337 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-30 00:39:22,867 [Epoch: 010 Step: 00001542] Batch Translation Loss:   6.779874 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 00:39:38,778 [Epoch: 010 Step: 00001543] Batch Translation Loss:   6.841702 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 00:39:52,548 [Epoch: 010 Step: 00001544] Batch Translation Loss:   6.654418 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 00:40:02,934 [Epoch: 010 Step: 00001545] Batch Translation Loss:   5.882903 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-30 00:40:15,532 [Epoch: 010 Step: 00001546] Batch Translation Loss:   6.913888 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 00:40:33,450 [Epoch: 010 Step: 00001547] Batch Translation Loss:   6.088997 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 00:40:50,684 [Epoch: 010 Step: 00001548] Batch Translation Loss:   6.243083 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:41:06,459 [Epoch: 010 Step: 00001549] Batch Translation Loss:   7.880271 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 00:41:19,758 [Epoch: 010 Step: 00001550] Batch Translation Loss:   5.858527 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 00:41:32,877 [Epoch: 010 Step: 00001551] Batch Translation Loss:   6.597219 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 00:41:45,494 [Epoch: 010 Step: 00001552] Batch Translation Loss:   5.707059 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 00:41:59,386 [Epoch: 010 Step: 00001553] Batch Translation Loss:   7.650311 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 00:42:14,701 [Epoch: 010 Step: 00001554] Batch Translation Loss:   7.039035 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 00:42:29,206 [Epoch: 010 Step: 00001555] Batch Translation Loss:   6.376802 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 00:42:44,422 [Epoch: 010 Step: 00001556] Batch Translation Loss:   6.875105 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 00:43:02,994 [Epoch: 010 Step: 00001557] Batch Translation Loss:   6.852166 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:43:14,558 [Epoch: 010 Step: 00001558] Batch Translation Loss:   5.755928 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 00:43:25,947 [Epoch: 010 Step: 00001559] Batch Translation Loss:   6.054579 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 00:43:38,368 [Epoch: 010 Step: 00001560] Batch Translation Loss:   6.531159 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 00:43:49,590 [Epoch: 010 Step: 00001561] Batch Translation Loss:   6.285773 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 00:44:14,518 [Epoch: 010 Step: 00001562] Batch Translation Loss:   6.268110 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:44:33,487 [Epoch: 010 Step: 00001563] Batch Translation Loss:   6.238184 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:44:49,961 [Epoch: 010 Step: 00001564] Batch Translation Loss:   7.174049 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:45:15,753 [Epoch: 010 Step: 00001565] Batch Translation Loss:   7.365490 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:45:35,091 [Epoch: 010 Step: 00001566] Batch Translation Loss:   7.159305 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 00:45:50,811 [Epoch: 010 Step: 00001567] Batch Translation Loss:   5.689830 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:46:17,452 [Epoch: 010 Step: 00001568] Batch Translation Loss:   6.804327 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:46:34,746 [Epoch: 010 Step: 00001569] Batch Translation Loss:   6.224696 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:46:48,587 [Epoch: 010 Step: 00001570] Batch Translation Loss:   6.271122 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:47:02,400 [Epoch: 010 Step: 00001571] Batch Translation Loss:   6.932173 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 00:47:17,249 [Epoch: 010 Step: 00001572] Batch Translation Loss:   6.846654 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 00:47:31,612 [Epoch: 010 Step: 00001573] Batch Translation Loss:   7.170469 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 00:47:46,615 [Epoch: 010 Step: 00001574] Batch Translation Loss:   6.068222 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 00:48:02,541 [Epoch: 010 Step: 00001575] Batch Translation Loss:   6.732723 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 00:48:37,423 [Epoch: 010 Step: 00001576] Batch Translation Loss:   6.369955 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:48:56,365 [Epoch: 010 Step: 00001577] Batch Translation Loss:   6.332466 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:49:16,438 [Epoch: 010 Step: 00001578] Batch Translation Loss:   6.080761 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:49:36,658 [Epoch: 010 Step: 00001579] Batch Translation Loss:   6.364234 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:49:55,437 [Epoch: 010 Step: 00001580] Batch Translation Loss:   7.007576 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:50:14,298 [Epoch: 010 Step: 00001581] Batch Translation Loss:   6.014677 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:50:29,866 [Epoch: 010 Step: 00001582] Batch Translation Loss:   7.117582 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:51:00,651 [Epoch: 010 Step: 00001583] Batch Translation Loss:   6.790283 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:51:18,353 [Epoch: 010 Step: 00001584] Batch Translation Loss:   6.895765 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:51:42,805 [Epoch: 010 Step: 00001585] Batch Translation Loss:   6.588560 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:52:04,141 [Epoch: 010 Step: 00001586] Batch Translation Loss:   6.167139 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:52:25,393 [Epoch: 010 Step: 00001587] Batch Translation Loss:   6.427052 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:52:46,001 [Epoch: 010 Step: 00001588] Batch Translation Loss:   6.000621 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:53:07,359 [Epoch: 010 Step: 00001589] Batch Translation Loss:   6.605643 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:53:29,644 [Epoch: 010 Step: 00001590] Batch Translation Loss:   7.103084 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:53:51,937 [Epoch: 010 Step: 00001591] Batch Translation Loss:   6.736107 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:54:09,040 [Epoch: 010 Step: 00001592] Batch Translation Loss:   6.557720 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:54:28,691 [Epoch: 010 Step: 00001593] Batch Translation Loss:   6.277512 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:54:46,347 [Epoch: 010 Step: 00001594] Batch Translation Loss:   5.861250 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:55:06,690 [Epoch: 010 Step: 00001595] Batch Translation Loss:   6.682269 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:55:32,713 [Epoch: 010 Step: 00001596] Batch Translation Loss:   6.163931 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 00:55:56,330 [Epoch: 010 Step: 00001597] Batch Translation Loss:   6.585329 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:56:18,964 [Epoch: 010 Step: 00001598] Batch Translation Loss:   6.018303 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:56:42,866 [Epoch: 010 Step: 00001599] Batch Translation Loss:   6.502960 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 00:57:05,492 [Epoch: 010 Step: 00001600] Batch Translation Loss:   6.161484 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 01:04:55,985 Validation result at epoch  10, step     1600: duration: 470.4702s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11414.36719	PPL: 6205.90967
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 2.40,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.93	ROUGE 3.28
2021-12-30 01:05:02,042 Logging Recognition and Translation Outputs
2021-12-30 01:05:02,053 ========================================================================================================================
2021-12-30 01:05:02,053 Logging Sequence: youtube_5-sean_berdy_6121
2021-12-30 01:05:02,054 	Text Reference  :	all
2021-12-30 01:05:02,054 	Text Hypothesis :	asl
2021-12-30 01:05:02,054 	Text Alignment  :	S  
2021-12-30 01:05:02,054 ========================================================================================================================
2021-12-30 01:05:02,054 Logging Sequence: deafvideo_2-sddsimple_1590
2021-12-30 01:05:02,054 	Text Reference  :	hammer
2021-12-30 01:05:02,054 	Text Hypothesis :	hs    
2021-12-30 01:05:02,054 	Text Alignment  :	S     
2021-12-30 01:05:02,055 ========================================================================================================================
2021-12-30 01:05:02,055 Logging Sequence: youtube_5-jeffrey_spinale_6046
2021-12-30 01:05:02,055 	Text Reference  :	cheif
2021-12-30 01:05:02,055 	Text Hypothesis :	hs   
2021-12-30 01:05:02,055 	Text Alignment  :	S    
2021-12-30 01:05:02,055 ========================================================================================================================
2021-12-30 01:05:02,055 Logging Sequence: deafvideo_5-scottnorby_6465
2021-12-30 01:05:02,055 	Text Reference  :	babel tower
2021-12-30 01:05:02,055 	Text Hypothesis :	***** dr   
2021-12-30 01:05:02,056 	Text Alignment  :	D     S    
2021-12-30 01:05:02,056 ========================================================================================================================
2021-12-30 01:05:02,056 Logging Sequence: youtube_3-ben_bahan_4523
2021-12-30 01:05:02,056 	Text Reference  :	chris catell     
2021-12-30 01:05:02,056 	Text Hypothesis :	***** revelations
2021-12-30 01:05:02,056 	Text Alignment  :	D     S          
2021-12-30 01:05:02,056 ========================================================================================================================
2021-12-30 01:06:23,514 [Epoch: 010 Step: 00001601] Batch Translation Loss:   7.104512 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-30 01:06:55,265 [Epoch: 010 Step: 00001602] Batch Translation Loss:   6.123550 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:07:17,136 [Epoch: 010 Step: 00001603] Batch Translation Loss:   6.583941 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 01:07:43,561 [Epoch: 010 Step: 00001604] Batch Translation Loss:   7.507106 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 01:08:32,273 [Epoch: 010 Step: 00001605] Batch Translation Loss:   6.452343 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:09:20,765 [Epoch: 010 Step: 00001606] Batch Translation Loss:   6.443838 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:10:13,908 [Epoch: 010 Step: 00001607] Batch Translation Loss:   5.744280 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:12:02,737 [Epoch: 010 Step: 00001608] Batch Translation Loss:   6.637330 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-30 01:12:57,593 [Epoch: 010 Step: 00001609] Batch Translation Loss:   6.057713 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:14:08,481 [Epoch: 010 Step: 00001610] Batch Translation Loss:   6.733730 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:15:28,954 [Epoch: 010 Step: 00001611] Batch Translation Loss:   5.838170 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-30 01:16:35,401 [Epoch: 010 Step: 00001612] Batch Translation Loss:   6.464660 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:17:37,017 [Epoch: 010 Step: 00001613] Batch Translation Loss:   6.131019 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:18:23,745 [Epoch: 010 Step: 00001614] Batch Translation Loss:   6.972935 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:18:49,445 [Epoch: 010 Step: 00001615] Batch Translation Loss:   6.201607 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:19:36,699 [Epoch: 010 Step: 00001616] Batch Translation Loss:   6.293843 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:20:04,550 [Epoch: 010 Step: 00001617] Batch Translation Loss:   6.344514 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:20:50,965 [Epoch: 010 Step: 00001618] Batch Translation Loss:   6.250525 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:21:13,137 [Epoch: 010 Step: 00001619] Batch Translation Loss:   6.428411 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 01:21:34,047 [Epoch: 010 Step: 00001620] Batch Translation Loss:   7.164380 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 01:21:55,477 [Epoch: 010 Step: 00001621] Batch Translation Loss:   5.758007 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 01:22:44,652 [Epoch: 010 Step: 00001622] Batch Translation Loss:   6.254614 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:23:15,417 [Epoch: 010 Step: 00001623] Batch Translation Loss:   6.117874 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:23:45,255 [Epoch: 010 Step: 00001624] Batch Translation Loss:   6.682240 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:24:15,152 [Epoch: 010 Step: 00001625] Batch Translation Loss:   7.023792 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:24:41,685 [Epoch: 010 Step: 00001626] Batch Translation Loss:   5.851087 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:25:03,591 [Epoch: 010 Step: 00001627] Batch Translation Loss:   6.752686 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 01:25:29,721 [Epoch: 010 Step: 00001628] Batch Translation Loss:   7.155785 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:25:52,995 [Epoch: 010 Step: 00001629] Batch Translation Loss:   6.787111 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 01:26:23,878 [Epoch: 010 Step: 00001630] Batch Translation Loss:   6.623693 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:26:57,138 [Epoch: 010 Step: 00001631] Batch Translation Loss:   6.599025 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:27:27,709 [Epoch: 010 Step: 00001632] Batch Translation Loss:   5.551637 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:27:56,668 [Epoch: 010 Step: 00001633] Batch Translation Loss:   6.487137 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:28:27,197 [Epoch: 010 Step: 00001634] Batch Translation Loss:   6.521283 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:28:53,578 [Epoch: 010 Step: 00001635] Batch Translation Loss:   6.803148 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:29:23,485 [Epoch: 010 Step: 00001636] Batch Translation Loss:   6.331645 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:29:49,974 [Epoch: 010 Step: 00001637] Batch Translation Loss:   6.306846 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:30:28,851 [Epoch: 010 Step: 00001638] Batch Translation Loss:   7.079066 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:31:15,972 [Epoch: 010 Step: 00001639] Batch Translation Loss:   6.034163 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:31:48,614 [Epoch: 010 Step: 00001640] Batch Translation Loss:   6.719106 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:32:20,228 [Epoch: 010 Step: 00001641] Batch Translation Loss:   6.379379 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:32:44,937 [Epoch: 010 Step: 00001642] Batch Translation Loss:   6.435710 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 01:33:13,293 [Epoch: 010 Step: 00001643] Batch Translation Loss:   6.557973 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:33:50,565 [Epoch: 010 Step: 00001644] Batch Translation Loss:   6.178601 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:34:45,010 [Epoch: 010 Step: 00001645] Batch Translation Loss:   6.053636 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:35:19,077 [Epoch: 010 Step: 00001646] Batch Translation Loss:   5.782758 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:36:32,750 [Epoch: 010 Step: 00001647] Batch Translation Loss:   6.935570 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-30 01:39:14,377 [Epoch: 010 Step: 00001648] Batch Translation Loss:   5.957386 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-30 01:40:44,821 [Epoch: 010 Step: 00001649] Batch Translation Loss:   5.638333 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-30 01:42:11,229 [Epoch: 010 Step: 00001650] Batch Translation Loss:   6.287351 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-30 01:43:51,260 [Epoch: 010 Step: 00001651] Batch Translation Loss:   6.181734 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-30 01:45:38,707 [Epoch: 010 Step: 00001652] Batch Translation Loss:   6.217753 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-30 01:47:02,753 [Epoch: 010 Step: 00001653] Batch Translation Loss:   5.934608 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-30 01:47:36,037 [Epoch: 010 Step: 00001654] Batch Translation Loss:   6.509407 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:48:09,153 [Epoch: 010 Step: 00001655] Batch Translation Loss:   6.198961 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:48:46,412 [Epoch: 010 Step: 00001656] Batch Translation Loss:   6.888307 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:49:22,400 [Epoch: 010 Step: 00001657] Batch Translation Loss:   6.192860 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:49:51,762 [Epoch: 010 Step: 00001658] Batch Translation Loss:   5.950902 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:50:45,418 [Epoch: 010 Step: 00001659] Batch Translation Loss:   6.253808 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:51:19,880 [Epoch: 010 Step: 00001660] Batch Translation Loss:   5.955957 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:51:58,191 [Epoch: 010 Step: 00001661] Batch Translation Loss:   6.645782 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:52:37,118 [Epoch: 010 Step: 00001662] Batch Translation Loss:   6.089647 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:53:18,829 [Epoch: 010 Step: 00001663] Batch Translation Loss:   6.770575 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:53:56,857 [Epoch: 010 Step: 00001664] Batch Translation Loss:   5.949706 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:54:27,150 [Epoch: 010 Step: 00001665] Batch Translation Loss:   6.452328 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:54:55,790 [Epoch: 010 Step: 00001666] Batch Translation Loss:   5.600379 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:55:41,074 [Epoch: 010 Step: 00001667] Batch Translation Loss:   7.249974 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:56:17,226 [Epoch: 010 Step: 00001668] Batch Translation Loss:   5.773808 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:56:54,888 [Epoch: 010 Step: 00001669] Batch Translation Loss:   6.184747 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:57:34,198 [Epoch: 010 Step: 00001670] Batch Translation Loss:   6.350615 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:58:06,219 [Epoch: 010 Step: 00001671] Batch Translation Loss:   6.395894 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:58:41,063 [Epoch: 010 Step: 00001672] Batch Translation Loss:   6.143620 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 01:59:14,041 [Epoch: 010 Step: 00001673] Batch Translation Loss:   6.012711 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:00:01,340 [Epoch: 010 Step: 00001674] Batch Translation Loss:   6.360176 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:00:43,148 [Epoch: 010 Step: 00001675] Batch Translation Loss:   6.011554 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:01:23,470 [Epoch: 010 Step: 00001676] Batch Translation Loss:   6.156163 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:02:01,180 [Epoch: 010 Step: 00001677] Batch Translation Loss:   6.548997 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:02:35,788 [Epoch: 010 Step: 00001678] Batch Translation Loss:   6.694052 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:03:23,062 [Epoch: 010 Step: 00001679] Batch Translation Loss:   6.185655 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:04:40,061 [Epoch: 010 Step: 00001680] Batch Translation Loss:   6.570415 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:05:22,759 [Epoch: 010 Step: 00001681] Batch Translation Loss:   6.542735 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:06:00,243 [Epoch: 010 Step: 00001682] Batch Translation Loss:   6.538104 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:06:32,439 [Epoch: 010 Step: 00001683] Batch Translation Loss:   6.883629 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:07:08,676 [Epoch: 010 Step: 00001684] Batch Translation Loss:   6.935242 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:08:14,010 [Epoch: 010 Step: 00001685] Batch Translation Loss:   6.338600 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:08:56,574 [Epoch: 010 Step: 00001686] Batch Translation Loss:   7.643003 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:10:10,332 [Epoch: 010 Step: 00001687] Batch Translation Loss:   6.365363 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-30 02:11:53,557 [Epoch: 010 Step: 00001688] Batch Translation Loss:   6.507803 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-30 02:13:34,146 [Epoch: 010 Step: 00001689] Batch Translation Loss:   6.518759 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-30 02:15:34,428 [Epoch: 010 Step: 00001690] Batch Translation Loss:   6.736729 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-30 02:17:34,399 [Epoch: 010 Step: 00001691] Batch Translation Loss:   6.736931 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-30 02:19:29,308 [Epoch: 010 Step: 00001692] Batch Translation Loss:   6.231391 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-30 02:20:29,824 [Epoch: 010 Step: 00001693] Batch Translation Loss:   6.969964 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:21:14,804 [Epoch: 010 Step: 00001694] Batch Translation Loss:   6.590655 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:21:54,512 [Epoch: 010 Step: 00001695] Batch Translation Loss:   6.449975 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:22:36,213 [Epoch: 010 Step: 00001696] Batch Translation Loss:   6.718291 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:23:15,229 [Epoch: 010 Step: 00001697] Batch Translation Loss:   6.356275 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:23:47,310 [Epoch: 010 Step: 00001698] Batch Translation Loss:   5.999630 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:24:23,005 [Epoch: 010 Step: 00001699] Batch Translation Loss:   6.320822 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:24:23,141 Epoch  10: Total Training Recognition Loss -1.00  Total Training Translation Loss 1102.99 
2021-12-30 02:24:23,141 EPOCH 11
2021-12-30 02:24:30,513 [Epoch: 011 Step: 00001700] Batch Translation Loss:   6.107241 => Txt Tokens per Sec:        5 || Lr: 0.000700
2021-12-30 02:32:00,756 Validation result at epoch  11, step     1700: duration: 450.2147s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 10430.07227	PPL: 5347.69678
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 3.12,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 4.36	ROUGE 3.84
2021-12-30 02:32:07,872 Logging Recognition and Translation Outputs
2021-12-30 02:32:07,896 ========================================================================================================================
2021-12-30 02:32:07,896 Logging Sequence: deafvideo_3-otismhill82_4623
2021-12-30 02:32:07,896 	Text Reference  :	us 
2021-12-30 02:32:07,897 	Text Hypothesis :	asl
2021-12-30 02:32:07,897 	Text Alignment  :	S  
2021-12-30 02:32:07,897 ========================================================================================================================
2021-12-30 02:32:07,897 Logging Sequence: deafvideo_3-deafgoldenhair_3075
2021-12-30 02:32:07,897 	Text Reference  :	faceles
2021-12-30 02:32:07,898 	Text Hypothesis :	mass   
2021-12-30 02:32:07,898 	Text Alignment  :	S      
2021-12-30 02:32:07,898 ========================================================================================================================
2021-12-30 02:32:07,898 Logging Sequence: youtube_5-daniel_durant_5876
2021-12-30 02:32:07,898 	Text Reference  :	ma
2021-12-30 02:32:07,898 	Text Hypothesis :	or
2021-12-30 02:32:07,898 	Text Alignment  :	S 
2021-12-30 02:32:07,899 ========================================================================================================================
2021-12-30 02:32:07,899 Logging Sequence: youtube_4-sean_berdy_5757
2021-12-30 02:32:07,899 	Text Reference  :	fetre
2021-12-30 02:32:07,899 	Text Hypothesis :	asl  
2021-12-30 02:32:07,899 	Text Alignment  :	S    
2021-12-30 02:32:07,899 ========================================================================================================================
2021-12-30 02:32:07,899 Logging Sequence: deafvideo_5-scottnorby_6463
2021-12-30 02:32:07,899 	Text Reference  :	the
2021-12-30 02:32:07,900 	Text Hypothesis :	asl
2021-12-30 02:32:07,900 	Text Alignment  :	S  
2021-12-30 02:32:07,900 ========================================================================================================================
2021-12-30 02:32:35,805 [Epoch: 011 Step: 00001701] Batch Translation Loss:   6.435975 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:33:03,458 [Epoch: 011 Step: 00001702] Batch Translation Loss:   6.276775 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:33:30,673 [Epoch: 011 Step: 00001703] Batch Translation Loss:   7.135504 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:33:52,266 [Epoch: 011 Step: 00001704] Batch Translation Loss:   6.971768 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:34:13,332 [Epoch: 011 Step: 00001705] Batch Translation Loss:   6.102542 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:34:43,204 [Epoch: 011 Step: 00001706] Batch Translation Loss:   6.937274 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:34:56,911 [Epoch: 011 Step: 00001707] Batch Translation Loss:   6.549887 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 02:35:25,107 [Epoch: 011 Step: 00001708] Batch Translation Loss:   7.076628 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:35:56,211 [Epoch: 011 Step: 00001709] Batch Translation Loss:   6.910169 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:36:17,128 [Epoch: 011 Step: 00001710] Batch Translation Loss:   6.855804 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:36:26,514 [Epoch: 011 Step: 00001711] Batch Translation Loss:   6.385908 => Txt Tokens per Sec:        5 || Lr: 0.000700
2021-12-30 02:36:41,747 [Epoch: 011 Step: 00001712] Batch Translation Loss:   6.311287 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 02:36:55,551 [Epoch: 011 Step: 00001713] Batch Translation Loss:   6.190569 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 02:37:04,157 [Epoch: 011 Step: 00001714] Batch Translation Loss:   6.893558 => Txt Tokens per Sec:        5 || Lr: 0.000700
2021-12-30 02:37:22,780 [Epoch: 011 Step: 00001715] Batch Translation Loss:   6.776669 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 02:37:37,848 [Epoch: 011 Step: 00001716] Batch Translation Loss:   5.975811 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 02:37:59,852 [Epoch: 011 Step: 00001717] Batch Translation Loss:   7.357145 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:38:23,789 [Epoch: 011 Step: 00001718] Batch Translation Loss:   6.558450 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:38:35,182 [Epoch: 011 Step: 00001719] Batch Translation Loss:   6.220906 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-30 02:38:51,750 [Epoch: 011 Step: 00001720] Batch Translation Loss:   6.525470 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:39:05,430 [Epoch: 011 Step: 00001721] Batch Translation Loss:   6.608875 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 02:39:22,941 [Epoch: 011 Step: 00001722] Batch Translation Loss:   6.982558 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 02:39:41,605 [Epoch: 011 Step: 00001723] Batch Translation Loss:   6.495486 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 02:39:53,941 [Epoch: 011 Step: 00001724] Batch Translation Loss:   5.813015 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 02:40:08,332 [Epoch: 011 Step: 00001725] Batch Translation Loss:   5.906315 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:40:21,117 [Epoch: 011 Step: 00001726] Batch Translation Loss:   6.867737 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 02:40:42,124 [Epoch: 011 Step: 00001727] Batch Translation Loss:   6.897496 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:40:54,939 [Epoch: 011 Step: 00001728] Batch Translation Loss:   6.291530 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 02:41:11,315 [Epoch: 011 Step: 00001729] Batch Translation Loss:   6.873876 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 02:41:35,816 [Epoch: 011 Step: 00001730] Batch Translation Loss:   7.344640 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:41:50,426 [Epoch: 011 Step: 00001731] Batch Translation Loss:   6.475945 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 02:42:03,361 [Epoch: 011 Step: 00001732] Batch Translation Loss:   6.783565 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 02:42:26,975 [Epoch: 011 Step: 00001733] Batch Translation Loss:   6.658646 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:42:41,876 [Epoch: 011 Step: 00001734] Batch Translation Loss:   6.036732 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 02:43:00,743 [Epoch: 011 Step: 00001735] Batch Translation Loss:   6.687446 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:43:19,485 [Epoch: 011 Step: 00001736] Batch Translation Loss:   6.253548 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:43:38,074 [Epoch: 011 Step: 00001737] Batch Translation Loss:   6.182273 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 02:43:53,652 [Epoch: 011 Step: 00001738] Batch Translation Loss:   5.669750 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 02:44:11,619 [Epoch: 011 Step: 00001739] Batch Translation Loss:   5.888412 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:44:27,921 [Epoch: 011 Step: 00001740] Batch Translation Loss:   6.465265 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 02:44:43,908 [Epoch: 011 Step: 00001741] Batch Translation Loss:   6.025873 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:45:01,021 [Epoch: 011 Step: 00001742] Batch Translation Loss:   6.412432 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:45:18,867 [Epoch: 011 Step: 00001743] Batch Translation Loss:   6.464269 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:45:36,675 [Epoch: 011 Step: 00001744] Batch Translation Loss:   6.080355 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:45:50,812 [Epoch: 011 Step: 00001745] Batch Translation Loss:   6.589718 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:46:06,152 [Epoch: 011 Step: 00001746] Batch Translation Loss:   6.313119 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:46:31,887 [Epoch: 011 Step: 00001747] Batch Translation Loss:   6.888082 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:46:50,095 [Epoch: 011 Step: 00001748] Batch Translation Loss:   6.184150 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:47:06,341 [Epoch: 011 Step: 00001749] Batch Translation Loss:   7.080725 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:47:30,549 [Epoch: 011 Step: 00001750] Batch Translation Loss:   5.878811 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:47:48,174 [Epoch: 011 Step: 00001751] Batch Translation Loss:   6.792500 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:48:09,104 [Epoch: 011 Step: 00001752] Batch Translation Loss:   6.432056 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:48:29,647 [Epoch: 011 Step: 00001753] Batch Translation Loss:   5.735437 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:48:47,676 [Epoch: 011 Step: 00001754] Batch Translation Loss:   6.773357 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:49:07,502 [Epoch: 011 Step: 00001755] Batch Translation Loss:   6.391055 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:49:39,779 [Epoch: 011 Step: 00001756] Batch Translation Loss:   6.305346 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:50:00,485 [Epoch: 011 Step: 00001757] Batch Translation Loss:   7.112407 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:50:21,020 [Epoch: 011 Step: 00001758] Batch Translation Loss:   6.586390 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:50:37,026 [Epoch: 011 Step: 00001759] Batch Translation Loss:   6.415399 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:50:55,517 [Epoch: 011 Step: 00001760] Batch Translation Loss:   5.577740 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:51:25,563 [Epoch: 011 Step: 00001761] Batch Translation Loss:   6.478503 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:51:45,104 [Epoch: 011 Step: 00001762] Batch Translation Loss:   6.604271 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:52:35,241 [Epoch: 011 Step: 00001763] Batch Translation Loss:   6.496577 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:52:58,865 [Epoch: 011 Step: 00001764] Batch Translation Loss:   6.619565 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:53:21,636 [Epoch: 011 Step: 00001765] Batch Translation Loss:   6.198600 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:53:43,049 [Epoch: 011 Step: 00001766] Batch Translation Loss:   6.583542 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:54:05,285 [Epoch: 011 Step: 00001767] Batch Translation Loss:   6.259194 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:54:26,760 [Epoch: 011 Step: 00001768] Batch Translation Loss:   6.214097 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:54:48,371 [Epoch: 011 Step: 00001769] Batch Translation Loss:   6.118929 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:55:27,067 [Epoch: 011 Step: 00001770] Batch Translation Loss:   7.117576 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:55:43,497 [Epoch: 011 Step: 00001771] Batch Translation Loss:   6.360734 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:56:03,376 [Epoch: 011 Step: 00001772] Batch Translation Loss:   6.368513 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:56:21,908 [Epoch: 011 Step: 00001773] Batch Translation Loss:   6.324986 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:56:42,764 [Epoch: 011 Step: 00001774] Batch Translation Loss:   6.861311 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:57:10,452 [Epoch: 011 Step: 00001775] Batch Translation Loss:   7.071411 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:57:35,402 [Epoch: 011 Step: 00001776] Batch Translation Loss:   7.054578 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:58:00,041 [Epoch: 011 Step: 00001777] Batch Translation Loss:   5.832899 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:58:42,711 [Epoch: 011 Step: 00001778] Batch Translation Loss:   6.134829 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:59:10,981 [Epoch: 011 Step: 00001779] Batch Translation Loss:   6.553606 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 02:59:35,535 [Epoch: 011 Step: 00001780] Batch Translation Loss:   6.807758 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 02:59:56,116 [Epoch: 011 Step: 00001781] Batch Translation Loss:   7.162675 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 03:00:15,811 [Epoch: 011 Step: 00001782] Batch Translation Loss:   6.289543 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 03:00:35,528 [Epoch: 011 Step: 00001783] Batch Translation Loss:   6.052944 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 03:00:57,624 [Epoch: 011 Step: 00001784] Batch Translation Loss:   6.424720 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 03:01:27,930 [Epoch: 011 Step: 00001785] Batch Translation Loss:   6.172112 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:01:52,678 [Epoch: 011 Step: 00001786] Batch Translation Loss:   6.332447 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 03:02:20,522 [Epoch: 011 Step: 00001787] Batch Translation Loss:   5.872277 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:02:46,138 [Epoch: 011 Step: 00001788] Batch Translation Loss:   6.546927 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:03:31,931 [Epoch: 011 Step: 00001789] Batch Translation Loss:   6.684506 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:04:00,865 [Epoch: 011 Step: 00001790] Batch Translation Loss:   6.276061 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:04:25,990 [Epoch: 011 Step: 00001791] Batch Translation Loss:   6.203087 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:04:47,839 [Epoch: 011 Step: 00001792] Batch Translation Loss:   6.976166 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 03:05:09,558 [Epoch: 011 Step: 00001793] Batch Translation Loss:   6.034380 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:05:30,918 [Epoch: 011 Step: 00001794] Batch Translation Loss:   5.930294 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 03:05:53,525 [Epoch: 011 Step: 00001795] Batch Translation Loss:   6.453694 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 03:06:39,447 [Epoch: 011 Step: 00001796] Batch Translation Loss:   5.501961 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:07:27,018 [Epoch: 011 Step: 00001797] Batch Translation Loss:   7.111424 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:07:53,247 [Epoch: 011 Step: 00001798] Batch Translation Loss:   6.118739 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:08:22,742 [Epoch: 011 Step: 00001799] Batch Translation Loss:   5.988120 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:08:50,891 [Epoch: 011 Step: 00001800] Batch Translation Loss:   6.262665 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:16:04,556 Validation result at epoch  11, step     1800: duration: 433.6463s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11311.54883	PPL: 6837.98828
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 2.24,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 4.74	ROUGE 2.96
2021-12-30 03:16:12,500 Logging Recognition and Translation Outputs
2021-12-30 03:16:12,572 ========================================================================================================================
2021-12-30 03:16:12,572 Logging Sequence: youtube_3-ben_bahan_4529
2021-12-30 03:16:12,573 	Text Reference  :	oscar
2021-12-30 03:16:12,573 	Text Hypothesis :	asl  
2021-12-30 03:16:12,574 	Text Alignment  :	S    
2021-12-30 03:16:12,574 ========================================================================================================================
2021-12-30 03:16:12,574 Logging Sequence: deafvideo_2-goatman_1525
2021-12-30 03:16:12,574 	Text Reference  :	dr pady ladd
2021-12-30 03:16:12,575 	Text Hypothesis :	** **** asl 
2021-12-30 03:16:12,575 	Text Alignment  :	D  D    S   
2021-12-30 03:16:12,575 ========================================================================================================================
2021-12-30 03:16:12,575 Logging Sequence: deafvideo_3-yesyes_4476
2021-12-30 03:16:12,576 	Text Reference  :	neb
2021-12-30 03:16:12,576 	Text Hypothesis :	asl
2021-12-30 03:16:12,576 	Text Alignment  :	S  
2021-12-30 03:16:12,576 ========================================================================================================================
2021-12-30 03:16:12,576 Logging Sequence: youtube_4-tim_albert_5274
2021-12-30 03:16:12,577 	Text Reference  :	or
2021-12-30 03:16:12,577 	Text Hypothesis :	or
2021-12-30 03:16:12,577 	Text Alignment  :	  
2021-12-30 03:16:12,577 ========================================================================================================================
2021-12-30 03:16:12,577 Logging Sequence: youtube_1-shoshannah_stern_2376
2021-12-30 03:16:12,578 	Text Reference  :	nlr
2021-12-30 03:16:12,578 	Text Hypothesis :	asl
2021-12-30 03:16:12,578 	Text Alignment  :	S  
2021-12-30 03:16:12,578 ========================================================================================================================
2021-12-30 03:18:15,100 [Epoch: 011 Step: 00001801] Batch Translation Loss:   6.055017 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-30 03:20:08,516 [Epoch: 011 Step: 00001802] Batch Translation Loss:   6.729670 => Txt Tokens per Sec:        0 || Lr: 0.000700
2021-12-30 03:20:39,386 [Epoch: 011 Step: 00001803] Batch Translation Loss:   5.519241 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:21:07,738 [Epoch: 011 Step: 00001804] Batch Translation Loss:   5.987078 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:21:54,446 [Epoch: 011 Step: 00001805] Batch Translation Loss:   6.474821 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:22:22,857 [Epoch: 011 Step: 00001806] Batch Translation Loss:   6.731271 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:22:48,532 [Epoch: 011 Step: 00001807] Batch Translation Loss:   5.844488 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:23:41,557 [Epoch: 011 Step: 00001808] Batch Translation Loss:   6.136691 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:24:09,240 [Epoch: 011 Step: 00001809] Batch Translation Loss:   6.191068 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:24:59,106 [Epoch: 011 Step: 00001810] Batch Translation Loss:   6.354765 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:25:22,862 [Epoch: 011 Step: 00001811] Batch Translation Loss:   6.661787 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 03:25:48,681 [Epoch: 011 Step: 00001812] Batch Translation Loss:   6.005190 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:26:25,577 [Epoch: 011 Step: 00001813] Batch Translation Loss:   6.345070 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:27:13,124 [Epoch: 011 Step: 00001814] Batch Translation Loss:   6.692337 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:27:43,719 [Epoch: 011 Step: 00001815] Batch Translation Loss:   6.221563 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:28:12,119 [Epoch: 011 Step: 00001816] Batch Translation Loss:   6.619308 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:28:45,223 [Epoch: 011 Step: 00001817] Batch Translation Loss:   6.073731 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:29:12,548 [Epoch: 011 Step: 00001818] Batch Translation Loss:   6.203519 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:29:41,034 [Epoch: 011 Step: 00001819] Batch Translation Loss:   5.426918 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:30:06,950 [Epoch: 011 Step: 00001820] Batch Translation Loss:   6.381556 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:30:36,202 [Epoch: 011 Step: 00001821] Batch Translation Loss:   6.534993 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:31:38,840 [Epoch: 011 Step: 00001822] Batch Translation Loss:   6.289923 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:32:08,702 [Epoch: 011 Step: 00001823] Batch Translation Loss:   6.354050 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:32:40,052 [Epoch: 011 Step: 00001824] Batch Translation Loss:   6.433402 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:33:14,041 [Epoch: 011 Step: 00001825] Batch Translation Loss:   6.061781 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:33:47,421 [Epoch: 011 Step: 00001826] Batch Translation Loss:   5.326600 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:34:16,329 [Epoch: 011 Step: 00001827] Batch Translation Loss:   6.027660 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:34:47,412 [Epoch: 011 Step: 00001828] Batch Translation Loss:   6.063447 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:35:16,334 [Epoch: 011 Step: 00001829] Batch Translation Loss:   6.730836 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:35:48,604 [Epoch: 011 Step: 00001830] Batch Translation Loss:   6.326295 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:36:26,194 [Epoch: 011 Step: 00001831] Batch Translation Loss:   6.885712 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:37:03,024 [Epoch: 011 Step: 00001832] Batch Translation Loss:   6.202264 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:37:35,396 [Epoch: 011 Step: 00001833] Batch Translation Loss:   5.590051 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:38:37,975 [Epoch: 011 Step: 00001834] Batch Translation Loss:   6.180162 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:39:12,716 [Epoch: 011 Step: 00001835] Batch Translation Loss:   6.114591 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:39:39,841 [Epoch: 011 Step: 00001836] Batch Translation Loss:   6.426323 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:40:04,995 [Epoch: 011 Step: 00001837] Batch Translation Loss:   6.746542 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 03:40:37,833 [Epoch: 011 Step: 00001838] Batch Translation Loss:   6.166072 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:41:19,668 [Epoch: 011 Step: 00001839] Batch Translation Loss:   6.203078 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:41:54,334 [Epoch: 011 Step: 00001840] Batch Translation Loss:   6.814176 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:42:59,421 [Epoch: 011 Step: 00001841] Batch Translation Loss:   6.204153 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:44:10,548 [Epoch: 011 Step: 00001842] Batch Translation Loss:   6.231606 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:45:04,520 [Epoch: 011 Step: 00001843] Batch Translation Loss:   5.778084 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:45:41,397 [Epoch: 011 Step: 00001844] Batch Translation Loss:   6.791105 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:46:21,958 [Epoch: 011 Step: 00001845] Batch Translation Loss:   6.117139 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:47:00,279 [Epoch: 011 Step: 00001846] Batch Translation Loss:   6.613827 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:47:37,385 [Epoch: 011 Step: 00001847] Batch Translation Loss:   6.118105 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:48:13,100 [Epoch: 011 Step: 00001848] Batch Translation Loss:   6.136226 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:48:49,285 [Epoch: 011 Step: 00001849] Batch Translation Loss:   6.343876 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:49:24,163 [Epoch: 011 Step: 00001850] Batch Translation Loss:   6.456549 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:49:55,639 [Epoch: 011 Step: 00001851] Batch Translation Loss:   6.569570 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:50:22,181 [Epoch: 011 Step: 00001852] Batch Translation Loss:   6.337358 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:50:54,243 [Epoch: 011 Step: 00001853] Batch Translation Loss:   6.071407 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:51:36,973 [Epoch: 011 Step: 00001854] Batch Translation Loss:   6.048410 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:52:14,020 [Epoch: 011 Step: 00001855] Batch Translation Loss:   6.159046 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:52:52,267 [Epoch: 011 Step: 00001856] Batch Translation Loss:   6.796994 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:53:34,067 [Epoch: 011 Step: 00001857] Batch Translation Loss:   5.978047 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:54:12,648 [Epoch: 011 Step: 00001858] Batch Translation Loss:   6.163777 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:54:50,828 [Epoch: 011 Step: 00001859] Batch Translation Loss:   6.284762 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:55:20,670 [Epoch: 011 Step: 00001860] Batch Translation Loss:   6.631546 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:55:50,964 [Epoch: 011 Step: 00001861] Batch Translation Loss:   6.460505 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:56:23,255 [Epoch: 011 Step: 00001862] Batch Translation Loss:   5.583441 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:57:09,670 [Epoch: 011 Step: 00001863] Batch Translation Loss:   6.103812 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:58:17,694 [Epoch: 011 Step: 00001864] Batch Translation Loss:   6.505232 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:58:55,628 [Epoch: 011 Step: 00001865] Batch Translation Loss:   6.108950 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 03:59:33,820 [Epoch: 011 Step: 00001866] Batch Translation Loss:   6.120926 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 04:00:12,306 [Epoch: 011 Step: 00001867] Batch Translation Loss:   6.427469 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 04:00:45,970 [Epoch: 011 Step: 00001868] Batch Translation Loss:   6.291787 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 04:01:13,980 [Epoch: 011 Step: 00001869] Batch Translation Loss:   7.279019 => Txt Tokens per Sec:        1 || Lr: 0.000700
2021-12-30 04:01:14,063 Epoch  11: Total Training Recognition Loss -1.00  Total Training Translation Loss 1085.08 
2021-12-30 04:01:14,063 EPOCH 12
2021-12-30 04:01:19,817 [Epoch: 012 Step: 00001870] Batch Translation Loss:   6.330589 => Txt Tokens per Sec:        6 || Lr: 0.000700
2021-12-30 04:01:28,202 [Epoch: 012 Step: 00001871] Batch Translation Loss:   6.590418 => Txt Tokens per Sec:        5 || Lr: 0.000700
2021-12-30 04:01:36,422 [Epoch: 012 Step: 00001872] Batch Translation Loss:   6.337692 => Txt Tokens per Sec:        6 || Lr: 0.000700
2021-12-30 04:01:45,973 [Epoch: 012 Step: 00001873] Batch Translation Loss:   6.401168 => Txt Tokens per Sec:        5 || Lr: 0.000700
2021-12-30 04:01:53,991 [Epoch: 012 Step: 00001874] Batch Translation Loss:   6.673558 => Txt Tokens per Sec:        5 || Lr: 0.000700
2021-12-30 04:02:06,187 [Epoch: 012 Step: 00001875] Batch Translation Loss:   6.651046 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-30 04:02:17,629 [Epoch: 012 Step: 00001876] Batch Translation Loss:   6.369550 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 04:02:26,339 [Epoch: 012 Step: 00001877] Batch Translation Loss:   6.323858 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-30 04:02:40,808 [Epoch: 012 Step: 00001878] Batch Translation Loss:   6.456954 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 04:02:50,466 [Epoch: 012 Step: 00001879] Batch Translation Loss:   6.060945 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-30 04:02:59,453 [Epoch: 012 Step: 00001880] Batch Translation Loss:   6.734142 => Txt Tokens per Sec:        5 || Lr: 0.000700
2021-12-30 04:03:11,690 [Epoch: 012 Step: 00001881] Batch Translation Loss:   6.277407 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 04:03:24,996 [Epoch: 012 Step: 00001882] Batch Translation Loss:   6.128978 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 04:03:39,033 [Epoch: 012 Step: 00001883] Batch Translation Loss:   7.071520 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 04:03:48,838 [Epoch: 012 Step: 00001884] Batch Translation Loss:   6.512274 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-30 04:04:05,752 [Epoch: 012 Step: 00001885] Batch Translation Loss:   6.395254 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 04:04:16,797 [Epoch: 012 Step: 00001886] Batch Translation Loss:   6.403595 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-30 04:04:36,558 [Epoch: 012 Step: 00001887] Batch Translation Loss:   6.191682 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 04:04:55,535 [Epoch: 012 Step: 00001888] Batch Translation Loss:   7.218259 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 04:05:13,865 [Epoch: 012 Step: 00001889] Batch Translation Loss:   6.305753 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 04:05:25,960 [Epoch: 012 Step: 00001890] Batch Translation Loss:   5.453424 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 04:05:37,610 [Epoch: 012 Step: 00001891] Batch Translation Loss:   6.594875 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 04:05:47,834 [Epoch: 012 Step: 00001892] Batch Translation Loss:   6.634027 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-30 04:05:58,251 [Epoch: 012 Step: 00001893] Batch Translation Loss:   6.290767 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-30 04:06:11,458 [Epoch: 012 Step: 00001894] Batch Translation Loss:   7.251704 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-30 04:06:33,383 [Epoch: 012 Step: 00001895] Batch Translation Loss:   5.993812 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 04:06:43,258 [Epoch: 012 Step: 00001896] Batch Translation Loss:   7.184052 => Txt Tokens per Sec:        4 || Lr: 0.000700
2021-12-30 04:06:56,389 [Epoch: 012 Step: 00001897] Batch Translation Loss:   5.895852 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 04:07:14,755 [Epoch: 012 Step: 00001898] Batch Translation Loss:   6.088933 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 04:07:25,785 [Epoch: 012 Step: 00001899] Batch Translation Loss:   5.445606 => Txt Tokens per Sec:        3 || Lr: 0.000700
2021-12-30 04:07:46,003 [Epoch: 012 Step: 00001900] Batch Translation Loss:   6.013338 => Txt Tokens per Sec:        2 || Lr: 0.000700
2021-12-30 04:14:51,305 Validation result at epoch  12, step     1900: duration: 425.2955s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11435.02930	PPL: 7908.47998
	Eval Metric: BLEU
	WER -1.00	(DEL: -1.00,	INS: -1.00,	SUB: -1.00)
	BLEU-4 0.00	(BLEU-1: 1.43,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 4.25	ROUGE 1.53
2021-12-30 04:14:58,320 Logging Recognition and Translation Outputs
2021-12-30 04:14:58,349 ========================================================================================================================
2021-12-30 04:14:58,349 Logging Sequence: youtube_5-caroline_jackson_5865
2021-12-30 04:14:58,350 	Text Reference  :	so
2021-12-30 04:14:58,350 	Text Hypothesis :	so
2021-12-30 04:14:58,350 	Text Alignment  :	  
2021-12-30 04:14:58,350 ========================================================================================================================
2021-12-30 04:14:58,351 Logging Sequence: youtube_1-catherine_mackinnon_2820
2021-12-30 04:14:58,351 	Text Reference  :	dnv deaf nfl vlogs      
2021-12-30 04:14:58,352 	Text Hypothesis :	*** **** *** revelations
2021-12-30 04:14:58,352 	Text Alignment  :	D   D    D   S          
2021-12-30 04:14:58,352 ========================================================================================================================
2021-12-30 04:14:58,352 Logging Sequence: youtube_1-don_grushkin_2311
2021-12-30 04:14:58,353 	Text Reference  :	asl corpus     
2021-12-30 04:14:58,353 	Text Hypothesis :	*** revelations
2021-12-30 04:14:58,353 	Text Alignment  :	D   S          
2021-12-30 04:14:58,353 ========================================================================================================================
2021-12-30 04:14:58,353 Logging Sequence: youtube_5-roberta_cordano_6126
2021-12-30 04:14:58,354 	Text Reference  :	baa
2021-12-30 04:14:58,354 	Text Hypothesis :	asl
2021-12-30 04:14:58,354 	Text Alignment  :	S  
2021-12-30 04:14:58,354 ========================================================================================================================
2021-12-30 04:14:58,355 Logging Sequence: deafvideo_2-sddsimple_1556
2021-12-30 04:14:58,355 	Text Reference  :	ussr
2021-12-30 04:14:58,355 	Text Hypothesis :	asl 
2021-12-30 04:14:58,355 	Text Alignment  :	S   
2021-12-30 04:14:58,356 ========================================================================================================================
2021-12-30 04:14:59,052 Training ended since there were no improvements inthe last learning rate step: 0.000700
2021-12-30 04:14:59,052 Best validation result at step      100:   0.00 eval_metric.
