2022-01-02 03:06:04,407 Hello! This is Joey-NMT.
2022-01-02 03:06:08,015 Total params: 27946760
2022-01-02 03:06:08,022 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.output_layer.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'image_encoder.classifier.0.bias', 'image_encoder.classifier.0.weight', 'image_encoder.classifier.3.bias', 'image_encoder.classifier.3.weight', 'image_encoder.features.0.0.weight', 'image_encoder.features.0.1.bias', 'image_encoder.features.0.1.weight', 'image_encoder.features.1.block.0.0.weight', 'image_encoder.features.1.block.0.1.bias', 'image_encoder.features.1.block.0.1.weight', 'image_encoder.features.1.block.1.fc1.bias', 'image_encoder.features.1.block.1.fc1.weight', 'image_encoder.features.1.block.1.fc2.bias', 'image_encoder.features.1.block.1.fc2.weight', 'image_encoder.features.1.block.2.0.weight', 'image_encoder.features.1.block.2.1.bias', 'image_encoder.features.1.block.2.1.weight', 'image_encoder.features.10.block.0.0.weight', 'image_encoder.features.10.block.0.1.bias', 'image_encoder.features.10.block.0.1.weight', 'image_encoder.features.10.block.1.0.weight', 'image_encoder.features.10.block.1.1.bias', 'image_encoder.features.10.block.1.1.weight', 'image_encoder.features.10.block.2.fc1.bias', 'image_encoder.features.10.block.2.fc1.weight', 'image_encoder.features.10.block.2.fc2.bias', 'image_encoder.features.10.block.2.fc2.weight', 'image_encoder.features.10.block.3.0.weight', 'image_encoder.features.10.block.3.1.bias', 'image_encoder.features.10.block.3.1.weight', 'image_encoder.features.11.block.0.0.weight', 'image_encoder.features.11.block.0.1.bias', 'image_encoder.features.11.block.0.1.weight', 'image_encoder.features.11.block.1.0.weight', 'image_encoder.features.11.block.1.1.bias', 'image_encoder.features.11.block.1.1.weight', 'image_encoder.features.11.block.2.fc1.bias', 'image_encoder.features.11.block.2.fc1.weight', 'image_encoder.features.11.block.2.fc2.bias', 'image_encoder.features.11.block.2.fc2.weight', 'image_encoder.features.11.block.3.0.weight', 'image_encoder.features.11.block.3.1.bias', 'image_encoder.features.11.block.3.1.weight', 'image_encoder.features.12.0.weight', 'image_encoder.features.12.1.bias', 'image_encoder.features.12.1.weight', 'image_encoder.features.2.block.0.0.weight', 'image_encoder.features.2.block.0.1.bias', 'image_encoder.features.2.block.0.1.weight', 'image_encoder.features.2.block.1.0.weight', 'image_encoder.features.2.block.1.1.bias', 'image_encoder.features.2.block.1.1.weight', 'image_encoder.features.2.block.2.0.weight', 'image_encoder.features.2.block.2.1.bias', 'image_encoder.features.2.block.2.1.weight', 'image_encoder.features.3.block.0.0.weight', 'image_encoder.features.3.block.0.1.bias', 'image_encoder.features.3.block.0.1.weight', 'image_encoder.features.3.block.1.0.weight', 'image_encoder.features.3.block.1.1.bias', 'image_encoder.features.3.block.1.1.weight', 'image_encoder.features.3.block.2.0.weight', 'image_encoder.features.3.block.2.1.bias', 'image_encoder.features.3.block.2.1.weight', 'image_encoder.features.4.block.0.0.weight', 'image_encoder.features.4.block.0.1.bias', 'image_encoder.features.4.block.0.1.weight', 'image_encoder.features.4.block.1.0.weight', 'image_encoder.features.4.block.1.1.bias', 'image_encoder.features.4.block.1.1.weight', 'image_encoder.features.4.block.2.fc1.bias', 'image_encoder.features.4.block.2.fc1.weight', 'image_encoder.features.4.block.2.fc2.bias', 'image_encoder.features.4.block.2.fc2.weight', 'image_encoder.features.4.block.3.0.weight', 'image_encoder.features.4.block.3.1.bias', 'image_encoder.features.4.block.3.1.weight', 'image_encoder.features.5.block.0.0.weight', 'image_encoder.features.5.block.0.1.bias', 'image_encoder.features.5.block.0.1.weight', 'image_encoder.features.5.block.1.0.weight', 'image_encoder.features.5.block.1.1.bias', 'image_encoder.features.5.block.1.1.weight', 'image_encoder.features.5.block.2.fc1.bias', 'image_encoder.features.5.block.2.fc1.weight', 'image_encoder.features.5.block.2.fc2.bias', 'image_encoder.features.5.block.2.fc2.weight', 'image_encoder.features.5.block.3.0.weight', 'image_encoder.features.5.block.3.1.bias', 'image_encoder.features.5.block.3.1.weight', 'image_encoder.features.6.block.0.0.weight', 'image_encoder.features.6.block.0.1.bias', 'image_encoder.features.6.block.0.1.weight', 'image_encoder.features.6.block.1.0.weight', 'image_encoder.features.6.block.1.1.bias', 'image_encoder.features.6.block.1.1.weight', 'image_encoder.features.6.block.2.fc1.bias', 'image_encoder.features.6.block.2.fc1.weight', 'image_encoder.features.6.block.2.fc2.bias', 'image_encoder.features.6.block.2.fc2.weight', 'image_encoder.features.6.block.3.0.weight', 'image_encoder.features.6.block.3.1.bias', 'image_encoder.features.6.block.3.1.weight', 'image_encoder.features.7.block.0.0.weight', 'image_encoder.features.7.block.0.1.bias', 'image_encoder.features.7.block.0.1.weight', 'image_encoder.features.7.block.1.0.weight', 'image_encoder.features.7.block.1.1.bias', 'image_encoder.features.7.block.1.1.weight', 'image_encoder.features.7.block.2.fc1.bias', 'image_encoder.features.7.block.2.fc1.weight', 'image_encoder.features.7.block.2.fc2.bias', 'image_encoder.features.7.block.2.fc2.weight', 'image_encoder.features.7.block.3.0.weight', 'image_encoder.features.7.block.3.1.bias', 'image_encoder.features.7.block.3.1.weight', 'image_encoder.features.8.block.0.0.weight', 'image_encoder.features.8.block.0.1.bias', 'image_encoder.features.8.block.0.1.weight', 'image_encoder.features.8.block.1.0.weight', 'image_encoder.features.8.block.1.1.bias', 'image_encoder.features.8.block.1.1.weight', 'image_encoder.features.8.block.2.fc1.bias', 'image_encoder.features.8.block.2.fc1.weight', 'image_encoder.features.8.block.2.fc2.bias', 'image_encoder.features.8.block.2.fc2.weight', 'image_encoder.features.8.block.3.0.weight', 'image_encoder.features.8.block.3.1.bias', 'image_encoder.features.8.block.3.1.weight', 'image_encoder.features.9.block.0.0.weight', 'image_encoder.features.9.block.0.1.bias', 'image_encoder.features.9.block.0.1.weight', 'image_encoder.features.9.block.1.0.weight', 'image_encoder.features.9.block.1.1.bias', 'image_encoder.features.9.block.1.1.weight', 'image_encoder.features.9.block.2.fc1.bias', 'image_encoder.features.9.block.2.fc1.weight', 'image_encoder.features.9.block.2.fc2.bias', 'image_encoder.features.9.block.2.fc2.weight', 'image_encoder.features.9.block.3.0.weight', 'image_encoder.features.9.block.3.1.bias', 'image_encoder.features.9.block.3.1.weight', 'sgn_embed.ln.bias', 'sgn_embed.ln.weight', 'sgn_embed.norm.norm.bias', 'sgn_embed.norm.norm.weight', 'txt_embed.lut.weight', 'txt_embed.norm.norm.bias', 'txt_embed.norm.norm.weight']
2022-01-02 03:06:42,899 cfg.name                           : ChicagoFSWild Experiment
2022-01-02 03:06:42,999 cfg.data.data_path                 : ./data/
2022-01-02 03:06:42,999 cfg.data.version                   : ChicagoFSWild
2022-01-02 03:06:42,999 cfg.data.sgn                       : sign
2022-01-02 03:06:42,999 cfg.data.gls                       : gloss
2022-01-02 03:06:42,999 cfg.data.feature_size              : 1000
2022-01-02 03:06:42,999 cfg.data.level                     : word
2022-01-02 03:06:42,999 cfg.data.max_sent_length           : 400
2022-01-02 03:06:42,999 cfg.data.random_train_subset       : -1
2022-01-02 03:06:42,999 cfg.data.random_dev_subset         : -1
2022-01-02 03:06:42,999 cfg.testing.recognition_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2022-01-02 03:06:43,000 cfg.testing.translation_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2022-01-02 03:06:43,000 cfg.testing.translation_beam_alphas : [-1, 0, 1, 2, 3, 4, 5]
2022-01-02 03:06:43,000 cfg.training.reset_best_ckpt       : False
2022-01-02 03:06:43,000 cfg.training.reset_scheduler       : False
2022-01-02 03:06:43,000 cfg.training.reset_optimizer       : False
2022-01-02 03:06:43,000 cfg.training.random_seed           : 42
2022-01-02 03:06:43,000 cfg.training.model_dir             : ./ChicagoFSWild Experiments/ChicagoFSWild_experiment_19
2022-01-02 03:06:43,000 cfg.training.recognition_loss_weight : 0.0
2022-01-02 03:06:43,000 cfg.training.translation_loss_weight : 1.0
2022-01-02 03:06:43,000 cfg.training.eval_metric           : wacc
2022-01-02 03:06:43,000 cfg.training.optimizer             : adam
2022-01-02 03:06:43,000 cfg.training.learning_rate         : 0.001
2022-01-02 03:06:43,000 cfg.training.batch_size            : 32
2022-01-02 03:06:43,001 cfg.training.num_valid_log         : 5
2022-01-02 03:06:43,001 cfg.training.epochs                : 5000000
2022-01-02 03:06:43,001 cfg.training.early_stopping_metric : eval_metric
2022-01-02 03:06:43,001 cfg.training.batch_type            : token
2022-01-02 03:06:43,001 cfg.training.translation_normalization : batch
2022-01-02 03:06:43,001 cfg.training.eval_recognition_beam_size : 9
2022-01-02 03:06:43,001 cfg.training.eval_translation_beam_size : 9
2022-01-02 03:06:43,001 cfg.training.eval_translation_beam_alpha : 1
2022-01-02 03:06:43,001 cfg.training.overwrite             : True
2022-01-02 03:06:43,001 cfg.training.shuffle               : True
2022-01-02 03:06:43,001 cfg.training.use_cuda              : True
2022-01-02 03:06:43,001 cfg.training.translation_max_output_length : 1
2022-01-02 03:06:43,001 cfg.training.keep_last_ckpts       : 1
2022-01-02 03:06:43,002 cfg.training.batch_multiplier      : 1
2022-01-02 03:06:43,002 cfg.training.logging_freq          : 1
2022-01-02 03:06:43,002 cfg.training.validation_freq       : 100
2022-01-02 03:06:43,002 cfg.training.betas                 : [0.9, 0.998]
2022-01-02 03:06:43,002 cfg.training.scheduling            : plateau
2022-01-02 03:06:43,002 cfg.training.learning_rate_min     : 1e-06
2022-01-02 03:06:43,002 cfg.training.weight_decay          : 0.001
2022-01-02 03:06:43,002 cfg.training.patience              : 8
2022-01-02 03:06:43,002 cfg.training.decrease_factor       : 0.7
2022-01-02 03:06:43,002 cfg.training.label_smoothing       : 0.0
2022-01-02 03:06:43,002 cfg.model.initializer              : xavier
2022-01-02 03:06:43,002 cfg.model.bias_initializer         : zeros
2022-01-02 03:06:43,002 cfg.model.init_gain                : 1.0
2022-01-02 03:06:43,002 cfg.model.embed_initializer        : xavier
2022-01-02 03:06:43,003 cfg.model.embed_init_gain          : 1.0
2022-01-02 03:06:43,003 cfg.model.tied_softmax             : False
2022-01-02 03:06:43,003 cfg.model.encoder.type             : transformer
2022-01-02 03:06:43,003 cfg.model.encoder.num_layers       : 3
2022-01-02 03:06:43,003 cfg.model.encoder.num_heads        : 8
2022-01-02 03:06:43,003 cfg.model.encoder.embeddings.embedding_dim : 512
2022-01-02 03:06:43,003 cfg.model.encoder.embeddings.scale : False
2022-01-02 03:06:43,003 cfg.model.encoder.embeddings.dropout : 0.1
2022-01-02 03:06:43,003 cfg.model.encoder.embeddings.norm_type : batch
2022-01-02 03:06:43,003 cfg.model.encoder.embeddings.activation_type : softsign
2022-01-02 03:06:43,003 cfg.model.encoder.hidden_size      : 512
2022-01-02 03:06:43,003 cfg.model.encoder.ff_size          : 2048
2022-01-02 03:06:43,003 cfg.model.encoder.dropout          : 0.1
2022-01-02 03:06:43,003 cfg.model.decoder.type             : transformer
2022-01-02 03:06:43,004 cfg.model.decoder.num_layers       : 3
2022-01-02 03:06:43,004 cfg.model.decoder.num_heads        : 8
2022-01-02 03:06:43,004 cfg.model.decoder.embeddings.embedding_dim : 512
2022-01-02 03:06:43,004 cfg.model.decoder.embeddings.scale : False
2022-01-02 03:06:43,004 cfg.model.decoder.embeddings.dropout : 0.1
2022-01-02 03:06:43,004 cfg.model.decoder.embeddings.norm_type : batch
2022-01-02 03:06:43,004 cfg.model.decoder.embeddings.activation_type : softsign
2022-01-02 03:06:43,004 cfg.model.decoder.hidden_size      : 512
2022-01-02 03:06:43,004 cfg.model.decoder.ff_size          : 2048
2022-01-02 03:06:43,004 cfg.model.decoder.dropout          : 0.1
2022-01-02 03:06:43,004 SignModel(
	encoder=TransformerEncoder(num_layers=3, num_heads=8),
	decoder=TransformerDecoder(num_layers=3, num_heads=8),
	sgn_embed=SpatialEmbeddings(embedding_dim=512, input_size=1000),
	txt_embed=Embeddings(embedding_dim=512, vocab_size=2752))
2022-01-02 03:06:43,536 EPOCH 1
2022-01-02 03:07:20,581 [Epoch: 001 Step: 00000001] Batch Translation Loss:   8.652844 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:08:11,667 [Epoch: 001 Step: 00000002] Batch Translation Loss:   9.717216 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:08:40,575 [Epoch: 001 Step: 00000003] Batch Translation Loss:   9.705888 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:09:12,930 [Epoch: 001 Step: 00000004] Batch Translation Loss:   8.619120 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:09:42,996 [Epoch: 001 Step: 00000005] Batch Translation Loss:   8.234411 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:10:09,860 [Epoch: 001 Step: 00000006] Batch Translation Loss:   9.770602 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:11:03,200 [Epoch: 001 Step: 00000007] Batch Translation Loss:   9.437288 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:11:35,575 [Epoch: 001 Step: 00000008] Batch Translation Loss:  10.695519 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:12:08,158 [Epoch: 001 Step: 00000009] Batch Translation Loss:   9.113930 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:13:05,909 [Epoch: 001 Step: 00000010] Batch Translation Loss:   9.728973 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:13:48,661 [Epoch: 001 Step: 00000011] Batch Translation Loss:   9.704565 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:14:49,362 [Epoch: 001 Step: 00000012] Batch Translation Loss:   9.027560 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:15:40,251 [Epoch: 001 Step: 00000013] Batch Translation Loss:   8.866664 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:16:35,368 [Epoch: 001 Step: 00000014] Batch Translation Loss:   8.492994 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:18:17,521 [Epoch: 001 Step: 00000015] Batch Translation Loss:  10.105733 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 03:19:48,897 [Epoch: 001 Step: 00000016] Batch Translation Loss:   9.314757 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 03:20:18,300 [Epoch: 001 Step: 00000017] Batch Translation Loss:   9.624949 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:21:09,814 [Epoch: 001 Step: 00000018] Batch Translation Loss:   9.054884 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:22:08,489 [Epoch: 001 Step: 00000019] Batch Translation Loss:   9.420218 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:23:06,487 [Epoch: 001 Step: 00000020] Batch Translation Loss:   7.899823 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:24:00,753 [Epoch: 001 Step: 00000021] Batch Translation Loss:   8.493554 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:24:54,820 [Epoch: 001 Step: 00000022] Batch Translation Loss:   9.507616 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:25:50,523 [Epoch: 001 Step: 00000023] Batch Translation Loss:   8.888057 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:27:08,125 [Epoch: 001 Step: 00000024] Batch Translation Loss:   8.935248 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 03:27:48,595 [Epoch: 001 Step: 00000025] Batch Translation Loss:  11.973447 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:28:24,158 [Epoch: 001 Step: 00000026] Batch Translation Loss:   9.910177 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:29:09,099 [Epoch: 001 Step: 00000027] Batch Translation Loss:  12.609355 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:30:37,250 [Epoch: 001 Step: 00000028] Batch Translation Loss:   8.532742 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 03:31:30,546 [Epoch: 001 Step: 00000029] Batch Translation Loss:   9.296816 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:32:23,616 [Epoch: 001 Step: 00000030] Batch Translation Loss:   8.882023 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:33:23,533 [Epoch: 001 Step: 00000031] Batch Translation Loss:  10.290965 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:34:09,643 [Epoch: 001 Step: 00000032] Batch Translation Loss:   8.132942 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:35:39,827 [Epoch: 001 Step: 00000033] Batch Translation Loss:   8.886327 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 03:36:32,945 [Epoch: 001 Step: 00000034] Batch Translation Loss:   8.989180 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:37:12,336 [Epoch: 001 Step: 00000035] Batch Translation Loss:  11.013369 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:38:35,522 [Epoch: 001 Step: 00000036] Batch Translation Loss:  10.519357 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 03:39:26,232 [Epoch: 001 Step: 00000037] Batch Translation Loss:  10.548805 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:39:54,963 [Epoch: 001 Step: 00000038] Batch Translation Loss:  10.584111 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:40:12,725 [Epoch: 001 Step: 00000039] Batch Translation Loss:   9.699674 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 03:40:36,272 [Epoch: 001 Step: 00000040] Batch Translation Loss:  10.083617 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 03:40:59,948 [Epoch: 001 Step: 00000041] Batch Translation Loss:   8.395703 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:41:23,219 [Epoch: 001 Step: 00000042] Batch Translation Loss:   8.442019 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 03:41:43,932 [Epoch: 001 Step: 00000043] Batch Translation Loss:   8.441318 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 03:42:13,405 [Epoch: 001 Step: 00000044] Batch Translation Loss:   8.957796 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:42:37,381 [Epoch: 001 Step: 00000045] Batch Translation Loss:   9.882275 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 03:42:58,773 [Epoch: 001 Step: 00000046] Batch Translation Loss:   8.009290 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 03:43:18,461 [Epoch: 001 Step: 00000047] Batch Translation Loss:   8.504841 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 03:43:38,989 [Epoch: 001 Step: 00000048] Batch Translation Loss:   9.403002 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 03:43:59,418 [Epoch: 001 Step: 00000049] Batch Translation Loss:  10.882308 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 03:44:25,311 [Epoch: 001 Step: 00000050] Batch Translation Loss:   8.528143 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:44:52,119 [Epoch: 001 Step: 00000051] Batch Translation Loss:   8.893411 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:45:19,832 [Epoch: 001 Step: 00000052] Batch Translation Loss:   8.113012 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:45:49,174 [Epoch: 001 Step: 00000053] Batch Translation Loss:   8.534566 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:46:16,936 [Epoch: 001 Step: 00000054] Batch Translation Loss:   9.287107 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:46:43,354 [Epoch: 001 Step: 00000055] Batch Translation Loss:   8.850191 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:47:09,767 [Epoch: 001 Step: 00000056] Batch Translation Loss:  10.206520 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 03:47:44,361 [Epoch: 001 Step: 00000057] Batch Translation Loss:   8.665897 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:48:07,840 [Epoch: 001 Step: 00000058] Batch Translation Loss:   8.908756 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 03:48:37,343 [Epoch: 001 Step: 00000059] Batch Translation Loss:   8.140009 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:49:07,657 [Epoch: 001 Step: 00000060] Batch Translation Loss:   8.644917 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:49:37,559 [Epoch: 001 Step: 00000061] Batch Translation Loss:   7.742403 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:50:27,259 [Epoch: 001 Step: 00000062] Batch Translation Loss:   9.014485 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:50:52,534 [Epoch: 001 Step: 00000063] Batch Translation Loss:   8.126372 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 03:51:20,834 [Epoch: 001 Step: 00000064] Batch Translation Loss:   8.171956 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:52:24,256 [Epoch: 001 Step: 00000065] Batch Translation Loss:  12.767076 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:52:52,374 [Epoch: 001 Step: 00000066] Batch Translation Loss:   9.814110 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:53:22,334 [Epoch: 001 Step: 00000067] Batch Translation Loss:  10.309031 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:54:00,998 [Epoch: 001 Step: 00000068] Batch Translation Loss:  10.425423 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:54:31,892 [Epoch: 001 Step: 00000069] Batch Translation Loss:   7.689768 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:55:06,420 [Epoch: 001 Step: 00000070] Batch Translation Loss:  10.275414 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:55:37,919 [Epoch: 001 Step: 00000071] Batch Translation Loss:   9.662707 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:56:06,515 [Epoch: 001 Step: 00000072] Batch Translation Loss:   7.342889 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:56:32,051 [Epoch: 001 Step: 00000073] Batch Translation Loss:   9.073938 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:57:05,118 [Epoch: 001 Step: 00000074] Batch Translation Loss:   8.160797 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:57:33,030 [Epoch: 001 Step: 00000075] Batch Translation Loss:   7.951965 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:58:04,285 [Epoch: 001 Step: 00000076] Batch Translation Loss:   9.027861 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:58:39,815 [Epoch: 001 Step: 00000077] Batch Translation Loss:   7.613180 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:59:18,087 [Epoch: 001 Step: 00000078] Batch Translation Loss:   8.298067 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 03:59:52,774 [Epoch: 001 Step: 00000079] Batch Translation Loss:   9.174748 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:00:25,382 [Epoch: 001 Step: 00000080] Batch Translation Loss:  10.178362 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:01:04,520 [Epoch: 001 Step: 00000081] Batch Translation Loss:   9.429385 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:01:41,636 [Epoch: 001 Step: 00000082] Batch Translation Loss:   9.709961 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:02:12,387 [Epoch: 001 Step: 00000083] Batch Translation Loss:   8.976140 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:02:46,452 [Epoch: 001 Step: 00000084] Batch Translation Loss:   9.785895 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:03:28,894 [Epoch: 001 Step: 00000085] Batch Translation Loss:   9.299124 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:04:06,323 [Epoch: 001 Step: 00000086] Batch Translation Loss:   7.337909 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:05:09,933 [Epoch: 001 Step: 00000087] Batch Translation Loss:   9.474871 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:06:06,337 [Epoch: 001 Step: 00000088] Batch Translation Loss:   9.166105 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:07:02,267 [Epoch: 001 Step: 00000089] Batch Translation Loss:   9.125916 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:07:40,642 [Epoch: 001 Step: 00000090] Batch Translation Loss:   8.351399 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:08:21,477 [Epoch: 001 Step: 00000091] Batch Translation Loss:   9.965345 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:09:01,363 [Epoch: 001 Step: 00000092] Batch Translation Loss:   9.376817 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:09:56,794 [Epoch: 001 Step: 00000093] Batch Translation Loss:   9.274631 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:10:39,452 [Epoch: 001 Step: 00000094] Batch Translation Loss:   8.607845 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:11:32,479 [Epoch: 001 Step: 00000095] Batch Translation Loss:   8.579098 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:12:11,978 [Epoch: 001 Step: 00000096] Batch Translation Loss:   8.465240 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:13:22,205 [Epoch: 001 Step: 00000097] Batch Translation Loss:   9.391184 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 04:13:51,218 [Epoch: 001 Step: 00000098] Batch Translation Loss:   9.712483 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:14:45,809 [Epoch: 001 Step: 00000099] Batch Translation Loss:   7.996007 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:15:57,492 [Epoch: 001 Step: 00000100] Batch Translation Loss:   8.500839 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:25:50,531 Hooray! New best validation result [eval_metric]!
2022-01-02 04:25:50,580 Saving new checkpoint.
2022-01-02 04:25:52,943 Validation result at epoch   1, step      100: duration: 595.3949s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 12272.50195	PPL: 13948.93555
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 0.93	(DEL: 25.51,	INS: 0.00,	SUB: 73.56)
	Sequence Accuracy 0.73
2022-01-02 04:26:03,181 Logging Recognition and Translation Outputs
2022-01-02 04:26:03,222 ========================================================================================================================
2022-01-02 04:26:03,222 Logging Sequence: youtube_5-sean_berdy_6117
2022-01-02 04:26:03,223 	Text Reference  :	past patrick
2022-01-02 04:26:03,223 	Text Hypothesis :	**** ok     
2022-01-02 04:26:03,223 	Text Alignment  :	D    S      
2022-01-02 04:26:03,223 ========================================================================================================================
2022-01-02 04:26:03,223 Logging Sequence: youtube_5-sean_berdy_6086
2022-01-02 04:26:03,224 	Text Reference  :	deafhooyd yoga
2022-01-02 04:26:03,224 	Text Hypothesis :	********* ok  
2022-01-02 04:26:03,224 	Text Alignment  :	D         S   
2022-01-02 04:26:03,224 ========================================================================================================================
2022-01-02 04:26:03,224 Logging Sequence: youtube_5-daniel_durant_5890
2022-01-02 04:26:03,225 	Text Reference  :	date
2022-01-02 04:26:03,225 	Text Hypothesis :	ok  
2022-01-02 04:26:03,225 	Text Alignment  :	S   
2022-01-02 04:26:03,225 ========================================================================================================================
2022-01-02 04:26:03,225 Logging Sequence: aslized-suzanne_stecker_0256
2022-01-02 04:26:03,225 	Text Reference  :	vermont
2022-01-02 04:26:03,225 	Text Hypothesis :	ok     
2022-01-02 04:26:03,226 	Text Alignment  :	S      
2022-01-02 04:26:03,226 ========================================================================================================================
2022-01-02 04:26:03,226 Logging Sequence: aslized-suzanne_stecker_0258
2022-01-02 04:26:03,226 	Text Reference  :	fans
2022-01-02 04:26:03,226 	Text Hypothesis :	ok  
2022-01-02 04:26:03,226 	Text Alignment  :	S   
2022-01-02 04:26:03,226 ========================================================================================================================
2022-01-02 04:27:06,918 [Epoch: 001 Step: 00000101] Batch Translation Loss:   9.166830 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:28:23,407 [Epoch: 001 Step: 00000102] Batch Translation Loss:   7.956511 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 04:29:37,762 [Epoch: 001 Step: 00000103] Batch Translation Loss:   9.146532 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:30:50,652 [Epoch: 001 Step: 00000104] Batch Translation Loss:   8.364147 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:31:36,024 [Epoch: 001 Step: 00000105] Batch Translation Loss:   7.970424 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:32:34,354 [Epoch: 001 Step: 00000106] Batch Translation Loss:   9.781520 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:33:41,833 [Epoch: 001 Step: 00000107] Batch Translation Loss:   9.521235 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:35:26,731 [Epoch: 001 Step: 00000108] Batch Translation Loss:   8.326360 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 04:36:13,219 [Epoch: 001 Step: 00000109] Batch Translation Loss:   9.049941 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:37:00,762 [Epoch: 001 Step: 00000110] Batch Translation Loss:   9.803144 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:37:45,078 [Epoch: 001 Step: 00000111] Batch Translation Loss:   8.823713 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:38:56,192 [Epoch: 001 Step: 00000112] Batch Translation Loss:   8.264287 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 04:39:35,356 [Epoch: 001 Step: 00000113] Batch Translation Loss:   9.356489 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:40:19,020 [Epoch: 001 Step: 00000114] Batch Translation Loss:   8.700411 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:41:17,993 [Epoch: 001 Step: 00000115] Batch Translation Loss:  10.156289 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:42:04,523 [Epoch: 001 Step: 00000116] Batch Translation Loss:  10.123020 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:42:45,883 [Epoch: 001 Step: 00000117] Batch Translation Loss:   8.596007 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:43:25,542 [Epoch: 001 Step: 00000118] Batch Translation Loss:   8.625571 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:44:13,039 [Epoch: 001 Step: 00000119] Batch Translation Loss:   8.439933 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:45:11,838 [Epoch: 001 Step: 00000120] Batch Translation Loss:   7.754981 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:46:02,689 [Epoch: 001 Step: 00000121] Batch Translation Loss:   8.312160 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:46:57,679 [Epoch: 001 Step: 00000122] Batch Translation Loss:   7.381157 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:48:30,463 [Epoch: 001 Step: 00000123] Batch Translation Loss:   9.592977 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 04:49:22,380 [Epoch: 001 Step: 00000124] Batch Translation Loss:   7.121406 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:51:38,640 [Epoch: 001 Step: 00000125] Batch Translation Loss:   9.784995 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 04:52:42,428 [Epoch: 001 Step: 00000126] Batch Translation Loss:   9.269506 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:53:38,092 [Epoch: 001 Step: 00000127] Batch Translation Loss:   8.596888 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:54:30,543 [Epoch: 001 Step: 00000128] Batch Translation Loss:   9.603098 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:55:26,130 [Epoch: 001 Step: 00000129] Batch Translation Loss:   9.486604 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:56:19,424 [Epoch: 001 Step: 00000130] Batch Translation Loss:   7.920984 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:57:16,170 [Epoch: 001 Step: 00000131] Batch Translation Loss:   9.572732 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:58:14,469 [Epoch: 001 Step: 00000132] Batch Translation Loss:  10.289781 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 04:59:08,704 [Epoch: 001 Step: 00000133] Batch Translation Loss:   8.895044 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 05:00:03,594 [Epoch: 001 Step: 00000134] Batch Translation Loss:  10.429896 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 05:02:29,821 [Epoch: 001 Step: 00000135] Batch Translation Loss:   9.850163 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 05:03:20,928 [Epoch: 001 Step: 00000136] Batch Translation Loss:   8.434164 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 05:04:11,501 [Epoch: 001 Step: 00000137] Batch Translation Loss:   7.969772 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 05:04:58,133 [Epoch: 001 Step: 00000138] Batch Translation Loss:   7.842150 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 05:05:46,942 [Epoch: 001 Step: 00000139] Batch Translation Loss:   9.587950 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 05:06:49,938 [Epoch: 001 Step: 00000140] Batch Translation Loss:   9.715881 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 05:07:50,128 [Epoch: 001 Step: 00000141] Batch Translation Loss:   8.110055 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 05:08:52,028 [Epoch: 001 Step: 00000142] Batch Translation Loss:   8.108624 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 05:09:48,645 [Epoch: 001 Step: 00000143] Batch Translation Loss:   8.693604 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 05:11:29,989 [Epoch: 001 Step: 00000144] Batch Translation Loss:   8.645222 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 05:12:32,846 [Epoch: 001 Step: 00000145] Batch Translation Loss:   8.725024 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 05:13:16,488 [Epoch: 001 Step: 00000146] Batch Translation Loss:   9.147992 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 05:14:06,751 [Epoch: 001 Step: 00000147] Batch Translation Loss:   9.359393 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 05:16:23,770 [Epoch: 001 Step: 00000148] Batch Translation Loss:  10.447654 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 05:17:26,304 [Epoch: 001 Step: 00000149] Batch Translation Loss:   8.833728 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 05:19:10,121 [Epoch: 001 Step: 00000150] Batch Translation Loss:   7.728510 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 05:20:04,194 [Epoch: 001 Step: 00000151] Batch Translation Loss:   8.932964 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 05:21:35,275 [Epoch: 001 Step: 00000152] Batch Translation Loss:   7.556849 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 05:22:41,733 [Epoch: 001 Step: 00000153] Batch Translation Loss:   8.955958 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 05:23:41,457 [Epoch: 001 Step: 00000154] Batch Translation Loss:   8.930069 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 05:24:42,875 [Epoch: 001 Step: 00000155] Batch Translation Loss:   9.430140 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 05:25:42,442 [Epoch: 001 Step: 00000156] Batch Translation Loss:   8.648125 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 05:26:38,093 [Epoch: 001 Step: 00000157] Batch Translation Loss:   8.089104 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 05:27:35,934 [Epoch: 001 Step: 00000158] Batch Translation Loss:   8.300261 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 05:28:34,499 [Epoch: 001 Step: 00000159] Batch Translation Loss:   7.642022 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 05:29:23,178 [Epoch: 001 Step: 00000160] Batch Translation Loss:   9.164418 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 05:31:28,294 [Epoch: 001 Step: 00000161] Batch Translation Loss:   8.795309 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 05:33:46,099 [Epoch: 001 Step: 00000162] Batch Translation Loss:   8.105311 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 05:34:53,312 [Epoch: 001 Step: 00000163] Batch Translation Loss:   8.464546 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 05:36:14,994 [Epoch: 001 Step: 00000164] Batch Translation Loss:   8.346321 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 05:37:43,784 [Epoch: 001 Step: 00000165] Batch Translation Loss:   8.416757 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 05:39:16,077 [Epoch: 001 Step: 00000166] Batch Translation Loss:   9.162045 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 05:40:21,440 [Epoch: 001 Step: 00000167] Batch Translation Loss:   9.206226 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 05:43:30,499 [Epoch: 001 Step: 00000168] Batch Translation Loss:   8.415758 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 05:44:32,633 [Epoch: 001 Step: 00000169] Batch Translation Loss:   8.882350 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 05:45:36,020 [Epoch: 001 Step: 00000170] Batch Translation Loss:  12.745008 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 05:45:36,339 Epoch   1: Total Training Recognition Loss -1.00  Total Training Translation Loss 1541.58 
2022-01-02 05:45:36,340 EPOCH 2
2022-01-02 05:45:47,222 [Epoch: 002 Step: 00000171] Batch Translation Loss:   8.150972 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 05:46:03,467 [Epoch: 002 Step: 00000172] Batch Translation Loss:   8.836768 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 05:46:24,849 [Epoch: 002 Step: 00000173] Batch Translation Loss:   9.149441 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 05:46:40,552 [Epoch: 002 Step: 00000174] Batch Translation Loss:  10.178648 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 05:47:08,649 [Epoch: 002 Step: 00000175] Batch Translation Loss:  10.621862 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 05:47:29,438 [Epoch: 002 Step: 00000176] Batch Translation Loss:   8.747363 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 05:47:51,354 [Epoch: 002 Step: 00000177] Batch Translation Loss:  10.930106 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 05:48:24,213 [Epoch: 002 Step: 00000178] Batch Translation Loss:  11.672813 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 05:48:40,294 [Epoch: 002 Step: 00000179] Batch Translation Loss:  11.005129 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 05:49:00,532 [Epoch: 002 Step: 00000180] Batch Translation Loss:  11.196065 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 05:49:12,539 [Epoch: 002 Step: 00000181] Batch Translation Loss:  11.371722 => Txt Tokens per Sec:        4 || Lr: 0.001000
2022-01-02 05:49:34,970 [Epoch: 002 Step: 00000182] Batch Translation Loss:  10.578452 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 05:49:46,914 [Epoch: 002 Step: 00000183] Batch Translation Loss:   8.740697 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 05:50:09,551 [Epoch: 002 Step: 00000184] Batch Translation Loss:  13.615886 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 05:50:23,514 [Epoch: 002 Step: 00000185] Batch Translation Loss:   9.683745 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 05:50:45,318 [Epoch: 002 Step: 00000186] Batch Translation Loss:  10.069044 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 05:51:04,437 [Epoch: 002 Step: 00000187] Batch Translation Loss:  10.823890 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 05:51:28,276 [Epoch: 002 Step: 00000188] Batch Translation Loss:  12.420102 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 05:51:46,671 [Epoch: 002 Step: 00000189] Batch Translation Loss:   8.808968 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 05:52:08,699 [Epoch: 002 Step: 00000190] Batch Translation Loss:   8.568389 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 05:52:27,575 [Epoch: 002 Step: 00000191] Batch Translation Loss:   8.450084 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 05:52:42,299 [Epoch: 002 Step: 00000192] Batch Translation Loss:   7.154384 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 05:52:59,025 [Epoch: 002 Step: 00000193] Batch Translation Loss:   9.691766 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 05:53:14,836 [Epoch: 002 Step: 00000194] Batch Translation Loss:   7.196599 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 05:53:35,034 [Epoch: 002 Step: 00000195] Batch Translation Loss:   8.669344 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 05:53:53,606 [Epoch: 002 Step: 00000196] Batch Translation Loss:  10.388305 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 05:54:13,898 [Epoch: 002 Step: 00000197] Batch Translation Loss:   8.833238 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 05:54:29,261 [Epoch: 002 Step: 00000198] Batch Translation Loss:  10.529593 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 05:54:50,548 [Epoch: 002 Step: 00000199] Batch Translation Loss:   7.137394 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 05:55:13,352 [Epoch: 002 Step: 00000200] Batch Translation Loss:   9.036183 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 06:04:41,917 Hooray! New best validation result [eval_metric]!
2022-01-02 06:04:42,052 Saving new checkpoint.
2022-01-02 06:04:44,516 Validation result at epoch   2, step      200: duration: 571.1280s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 10590.62109	PPL: 5336.63574
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.70	(DEL: 22.69,	INS: 0.00,	SUB: 75.61)
	Sequence Accuracy 1.36
2022-01-02 06:04:53,521 Logging Recognition and Translation Outputs
2022-01-02 06:04:53,525 ========================================================================================================================
2022-01-02 06:04:53,526 Logging Sequence: deafvideo_5-silentoneye_7315
2022-01-02 06:04:53,527 	Text Reference  :	gis
2022-01-02 06:04:53,528 	Text Hypothesis :	so 
2022-01-02 06:04:53,528 	Text Alignment  :	S  
2022-01-02 06:04:53,529 ========================================================================================================================
2022-01-02 06:04:53,529 Logging Sequence: deafvideo_3-yesyes_4475
2022-01-02 06:04:53,529 	Text Reference  :	aslized
2022-01-02 06:04:53,530 	Text Hypothesis :	so     
2022-01-02 06:04:53,530 	Text Alignment  :	S      
2022-01-02 06:04:53,530 ========================================================================================================================
2022-01-02 06:04:53,530 Logging Sequence: aslized-suzanne_stecker_0281
2022-01-02 06:04:53,531 	Text Reference  :	past patrick
2022-01-02 06:04:53,531 	Text Hypothesis :	**** so     
2022-01-02 06:04:53,531 	Text Alignment  :	D    S      
2022-01-02 06:04:53,531 ========================================================================================================================
2022-01-02 06:04:53,531 Logging Sequence: youtube_3-ben_bahan_4529
2022-01-02 06:04:53,532 	Text Reference  :	open source
2022-01-02 06:04:53,532 	Text Hypothesis :	**** dr    
2022-01-02 06:04:53,532 	Text Alignment  :	D    S     
2022-01-02 06:04:53,532 ========================================================================================================================
2022-01-02 06:04:53,533 Logging Sequence: deafvideo_3-yesyes_3104
2022-01-02 06:04:53,533 	Text Reference  :	textfields
2022-01-02 06:04:53,533 	Text Hypothesis :	dr        
2022-01-02 06:04:53,533 	Text Alignment  :	S         
2022-01-02 06:04:53,534 ========================================================================================================================
2022-01-02 06:05:52,255 [Epoch: 002 Step: 00000201] Batch Translation Loss:   9.590949 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:06:26,338 [Epoch: 002 Step: 00000202] Batch Translation Loss:   8.172447 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:07:12,092 [Epoch: 002 Step: 00000203] Batch Translation Loss:   8.952405 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:07:47,779 [Epoch: 002 Step: 00000204] Batch Translation Loss:  10.271036 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:08:07,459 [Epoch: 002 Step: 00000205] Batch Translation Loss:   8.513080 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 06:08:45,010 [Epoch: 002 Step: 00000206] Batch Translation Loss:  10.065777 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:09:07,033 [Epoch: 002 Step: 00000207] Batch Translation Loss:   7.932085 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 06:09:40,385 [Epoch: 002 Step: 00000208] Batch Translation Loss:  11.502651 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:09:58,249 [Epoch: 002 Step: 00000209] Batch Translation Loss:   8.579763 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 06:10:44,822 [Epoch: 002 Step: 00000210] Batch Translation Loss:  10.250582 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:11:07,874 [Epoch: 002 Step: 00000211] Batch Translation Loss:   8.356131 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 06:11:31,273 [Epoch: 002 Step: 00000212] Batch Translation Loss:   7.785280 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 06:11:55,182 [Epoch: 002 Step: 00000213] Batch Translation Loss:  10.419745 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 06:12:16,562 [Epoch: 002 Step: 00000214] Batch Translation Loss:   8.461121 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 06:12:48,514 [Epoch: 002 Step: 00000215] Batch Translation Loss:   8.202847 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:13:11,713 [Epoch: 002 Step: 00000216] Batch Translation Loss:   7.937449 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:13:44,087 [Epoch: 002 Step: 00000217] Batch Translation Loss:   8.226779 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:14:31,388 [Epoch: 002 Step: 00000218] Batch Translation Loss:   8.714680 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:15:16,919 [Epoch: 002 Step: 00000219] Batch Translation Loss:   9.577292 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:15:58,247 [Epoch: 002 Step: 00000220] Batch Translation Loss:   9.348038 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:16:19,962 [Epoch: 002 Step: 00000221] Batch Translation Loss:   9.034094 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 06:16:46,240 [Epoch: 002 Step: 00000222] Batch Translation Loss:   8.533206 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:17:15,799 [Epoch: 002 Step: 00000223] Batch Translation Loss:   9.306706 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:17:46,619 [Epoch: 002 Step: 00000224] Batch Translation Loss:   7.986603 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:18:18,336 [Epoch: 002 Step: 00000225] Batch Translation Loss:   7.922347 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:18:38,059 [Epoch: 002 Step: 00000226] Batch Translation Loss:   8.477049 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 06:19:09,011 [Epoch: 002 Step: 00000227] Batch Translation Loss:   8.865106 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:19:33,695 [Epoch: 002 Step: 00000228] Batch Translation Loss:   8.458275 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 06:20:07,039 [Epoch: 002 Step: 00000229] Batch Translation Loss:   8.519842 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:20:55,727 [Epoch: 002 Step: 00000230] Batch Translation Loss:   8.123096 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:21:53,678 [Epoch: 002 Step: 00000231] Batch Translation Loss:  11.105532 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:22:18,044 [Epoch: 002 Step: 00000232] Batch Translation Loss:   8.131523 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:23:06,798 [Epoch: 002 Step: 00000233] Batch Translation Loss:   8.033236 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:24:01,573 [Epoch: 002 Step: 00000234] Batch Translation Loss:   8.466230 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:24:47,979 [Epoch: 002 Step: 00000235] Batch Translation Loss:  12.716880 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:25:23,370 [Epoch: 002 Step: 00000236] Batch Translation Loss:  11.433414 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:25:56,175 [Epoch: 002 Step: 00000237] Batch Translation Loss:   8.161710 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:26:25,601 [Epoch: 002 Step: 00000238] Batch Translation Loss:   8.031200 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:27:00,173 [Epoch: 002 Step: 00000239] Batch Translation Loss:  10.042391 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:27:33,644 [Epoch: 002 Step: 00000240] Batch Translation Loss:   8.572803 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:28:07,341 [Epoch: 002 Step: 00000241] Batch Translation Loss:   9.903870 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:28:34,372 [Epoch: 002 Step: 00000242] Batch Translation Loss:   8.350860 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:29:27,940 [Epoch: 002 Step: 00000243] Batch Translation Loss:   9.514034 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:30:32,131 [Epoch: 002 Step: 00000244] Batch Translation Loss:   8.050861 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:31:31,927 [Epoch: 002 Step: 00000245] Batch Translation Loss:   7.628779 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:32:10,128 [Epoch: 002 Step: 00000246] Batch Translation Loss:   9.167706 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:32:44,854 [Epoch: 002 Step: 00000247] Batch Translation Loss:   8.404963 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:33:20,075 [Epoch: 002 Step: 00000248] Batch Translation Loss:   8.972297 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:33:53,841 [Epoch: 002 Step: 00000249] Batch Translation Loss:   6.810425 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:34:25,307 [Epoch: 002 Step: 00000250] Batch Translation Loss:   9.362967 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:35:06,086 [Epoch: 002 Step: 00000251] Batch Translation Loss:   6.990960 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:35:45,066 [Epoch: 002 Step: 00000252] Batch Translation Loss:   7.818498 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:36:40,383 [Epoch: 002 Step: 00000253] Batch Translation Loss:   8.088141 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:37:20,973 [Epoch: 002 Step: 00000254] Batch Translation Loss:   8.693237 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:37:58,629 [Epoch: 002 Step: 00000255] Batch Translation Loss:   8.716970 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:38:32,681 [Epoch: 002 Step: 00000256] Batch Translation Loss:   7.493756 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:39:20,106 [Epoch: 002 Step: 00000257] Batch Translation Loss:   7.913144 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:40:02,564 [Epoch: 002 Step: 00000258] Batch Translation Loss:   7.318566 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:40:44,843 [Epoch: 002 Step: 00000259] Batch Translation Loss:   8.222687 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:41:28,241 [Epoch: 002 Step: 00000260] Batch Translation Loss:   7.324865 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:42:04,829 [Epoch: 002 Step: 00000261] Batch Translation Loss:   7.912941 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:42:43,899 [Epoch: 002 Step: 00000262] Batch Translation Loss:   8.260923 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:43:25,513 [Epoch: 002 Step: 00000263] Batch Translation Loss:   8.723421 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:44:13,097 [Epoch: 002 Step: 00000264] Batch Translation Loss:   7.135448 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:44:46,803 [Epoch: 002 Step: 00000265] Batch Translation Loss:   7.845903 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:45:18,483 [Epoch: 002 Step: 00000266] Batch Translation Loss:   7.612112 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:46:01,836 [Epoch: 002 Step: 00000267] Batch Translation Loss:   9.367949 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:46:52,503 [Epoch: 002 Step: 00000268] Batch Translation Loss:   7.797740 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:48:10,684 [Epoch: 002 Step: 00000269] Batch Translation Loss:   9.287707 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:48:58,131 [Epoch: 002 Step: 00000270] Batch Translation Loss:   7.337118 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:49:43,236 [Epoch: 002 Step: 00000271] Batch Translation Loss:   8.792036 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:50:29,991 [Epoch: 002 Step: 00000272] Batch Translation Loss:   9.145465 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:51:12,719 [Epoch: 002 Step: 00000273] Batch Translation Loss:   7.886714 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:51:48,378 [Epoch: 002 Step: 00000274] Batch Translation Loss:   7.387775 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:52:39,357 [Epoch: 002 Step: 00000275] Batch Translation Loss:   8.114781 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:54:02,841 [Epoch: 002 Step: 00000276] Batch Translation Loss:   9.518676 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:54:46,153 [Epoch: 002 Step: 00000277] Batch Translation Loss:   8.222069 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:55:34,652 [Epoch: 002 Step: 00000278] Batch Translation Loss:   8.114108 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:56:20,732 [Epoch: 002 Step: 00000279] Batch Translation Loss:   8.789283 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:57:06,068 [Epoch: 002 Step: 00000280] Batch Translation Loss:   7.367511 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:58:25,149 [Epoch: 002 Step: 00000281] Batch Translation Loss:   7.772635 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 06:59:12,388 [Epoch: 002 Step: 00000282] Batch Translation Loss:   9.716071 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 06:59:56,716 [Epoch: 002 Step: 00000283] Batch Translation Loss:   7.347006 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:00:47,299 [Epoch: 002 Step: 00000284] Batch Translation Loss:   8.514778 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:01:36,454 [Epoch: 002 Step: 00000285] Batch Translation Loss:   8.061663 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:02:13,403 [Epoch: 002 Step: 00000286] Batch Translation Loss:   8.861266 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:03:03,056 [Epoch: 002 Step: 00000287] Batch Translation Loss:   7.043191 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:03:41,742 [Epoch: 002 Step: 00000288] Batch Translation Loss:   8.153356 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:04:20,107 [Epoch: 002 Step: 00000289] Batch Translation Loss:  10.215527 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:05:11,755 [Epoch: 002 Step: 00000290] Batch Translation Loss:   7.845364 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:06:05,731 [Epoch: 002 Step: 00000291] Batch Translation Loss:   9.463552 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:06:48,684 [Epoch: 002 Step: 00000292] Batch Translation Loss:   6.984159 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:07:43,559 [Epoch: 002 Step: 00000293] Batch Translation Loss:   8.172083 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:08:29,746 [Epoch: 002 Step: 00000294] Batch Translation Loss:   7.946864 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:09:14,002 [Epoch: 002 Step: 00000295] Batch Translation Loss:   9.332690 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:10:06,374 [Epoch: 002 Step: 00000296] Batch Translation Loss:   8.411976 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:11:27,762 [Epoch: 002 Step: 00000297] Batch Translation Loss:   9.681313 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:12:23,460 [Epoch: 002 Step: 00000298] Batch Translation Loss:   6.520185 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:13:50,438 [Epoch: 002 Step: 00000299] Batch Translation Loss:   8.904435 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 07:14:57,193 [Epoch: 002 Step: 00000300] Batch Translation Loss:   8.503018 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:24:29,511 Hooray! New best validation result [eval_metric]!
2022-01-02 07:24:29,563 Saving new checkpoint.
2022-01-02 07:24:33,875 Validation result at epoch   2, step      300: duration: 576.6606s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11325.06543	PPL: 6366.15479
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 2.32	(DEL: 26.14,	INS: 0.00,	SUB: 71.54)
	Sequence Accuracy 1.36
2022-01-02 07:24:42,641 Logging Recognition and Translation Outputs
2022-01-02 07:24:42,689 ========================================================================================================================
2022-01-02 07:24:42,689 Logging Sequence: youtube_4-sean_berdy_5742
2022-01-02 07:24:42,690 	Text Reference  :	n 
2022-01-02 07:24:42,691 	Text Hypothesis :	if
2022-01-02 07:24:42,691 	Text Alignment  :	S 
2022-01-02 07:24:42,691 ========================================================================================================================
2022-01-02 07:24:42,691 Logging Sequence: youtube_5-sean_berdy_6089
2022-01-02 07:24:42,692 	Text Reference  :	moritz
2022-01-02 07:24:42,692 	Text Hypothesis :	dr    
2022-01-02 07:24:42,692 	Text Alignment  :	S     
2022-01-02 07:24:42,692 ========================================================================================================================
2022-01-02 07:24:42,692 Logging Sequence: youtube_5-tanea_brown_6036
2022-01-02 07:24:42,693 	Text Reference  :	mainsteam
2022-01-02 07:24:42,693 	Text Hypothesis :	dr       
2022-01-02 07:24:42,693 	Text Alignment  :	S        
2022-01-02 07:24:42,693 ========================================================================================================================
2022-01-02 07:24:42,693 Logging Sequence: youtube_1-catherine_mackinnon_2814
2022-01-02 07:24:42,694 	Text Reference  :	cancer
2022-01-02 07:24:42,694 	Text Hypothesis :	dr    
2022-01-02 07:24:42,694 	Text Alignment  :	S     
2022-01-02 07:24:42,694 ========================================================================================================================
2022-01-02 07:24:42,694 Logging Sequence: deafvideo_3-titans_4702
2022-01-02 07:24:42,695 	Text Reference  :	dr pady ladd
2022-01-02 07:24:42,695 	Text Hypothesis :	dr **** ****
2022-01-02 07:24:42,695 	Text Alignment  :	   D    D   
2022-01-02 07:24:42,695 ========================================================================================================================
2022-01-02 07:26:14,739 [Epoch: 002 Step: 00000301] Batch Translation Loss:   8.149371 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 07:27:31,500 [Epoch: 002 Step: 00000302] Batch Translation Loss:   8.493082 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 07:28:24,570 [Epoch: 002 Step: 00000303] Batch Translation Loss:   8.155712 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:29:25,665 [Epoch: 002 Step: 00000304] Batch Translation Loss:   7.706436 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:30:19,830 [Epoch: 002 Step: 00000305] Batch Translation Loss:   9.061122 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:31:13,537 [Epoch: 002 Step: 00000306] Batch Translation Loss:   6.816225 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:32:04,043 [Epoch: 002 Step: 00000307] Batch Translation Loss:   6.349973 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:33:10,116 [Epoch: 002 Step: 00000308] Batch Translation Loss:   8.427485 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:34:11,620 [Epoch: 002 Step: 00000309] Batch Translation Loss:   8.343369 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:35:45,863 [Epoch: 002 Step: 00000310] Batch Translation Loss:   7.926076 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 07:36:45,157 [Epoch: 002 Step: 00000311] Batch Translation Loss:   7.860769 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:37:35,416 [Epoch: 002 Step: 00000312] Batch Translation Loss:   8.189735 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:38:34,668 [Epoch: 002 Step: 00000313] Batch Translation Loss:   8.025299 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:39:52,104 [Epoch: 002 Step: 00000314] Batch Translation Loss:   9.040298 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:40:45,221 [Epoch: 002 Step: 00000315] Batch Translation Loss:  10.999533 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:42:21,983 [Epoch: 002 Step: 00000316] Batch Translation Loss:   7.792639 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 07:43:54,516 [Epoch: 002 Step: 00000317] Batch Translation Loss:   8.504436 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 07:45:26,581 [Epoch: 002 Step: 00000318] Batch Translation Loss:   8.043113 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 07:46:22,512 [Epoch: 002 Step: 00000319] Batch Translation Loss:   7.869066 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:47:24,523 [Epoch: 002 Step: 00000320] Batch Translation Loss:   8.192432 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:48:26,296 [Epoch: 002 Step: 00000321] Batch Translation Loss:   8.753009 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:49:21,852 [Epoch: 002 Step: 00000322] Batch Translation Loss:   7.455745 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:50:27,525 [Epoch: 002 Step: 00000323] Batch Translation Loss:   8.331876 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:51:59,889 [Epoch: 002 Step: 00000324] Batch Translation Loss:   8.460452 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 07:54:36,067 [Epoch: 002 Step: 00000325] Batch Translation Loss:   7.641069 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 07:55:24,184 [Epoch: 002 Step: 00000326] Batch Translation Loss:   8.370685 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:56:28,577 [Epoch: 002 Step: 00000327] Batch Translation Loss:   9.100446 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:57:30,672 [Epoch: 002 Step: 00000328] Batch Translation Loss:   8.243697 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:58:30,978 [Epoch: 002 Step: 00000329] Batch Translation Loss:   7.766073 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 07:59:35,107 [Epoch: 002 Step: 00000330] Batch Translation Loss:   9.336810 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:00:31,142 [Epoch: 002 Step: 00000331] Batch Translation Loss:   7.892873 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:01:31,723 [Epoch: 002 Step: 00000332] Batch Translation Loss:   7.537507 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:02:30,666 [Epoch: 002 Step: 00000333] Batch Translation Loss:   9.603107 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:03:21,685 [Epoch: 002 Step: 00000334] Batch Translation Loss:   7.984032 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:04:11,816 [Epoch: 002 Step: 00000335] Batch Translation Loss:   8.428018 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:06:01,403 [Epoch: 002 Step: 00000336] Batch Translation Loss:   8.281301 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 08:07:02,697 [Epoch: 002 Step: 00000337] Batch Translation Loss:   8.467647 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:08:08,364 [Epoch: 002 Step: 00000338] Batch Translation Loss:   7.506635 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:08:47,642 [Epoch: 002 Step: 00000339] Batch Translation Loss:   7.978581 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:10:35,766 [Epoch: 002 Step: 00000340] Batch Translation Loss:  16.212982 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 08:10:35,968 Epoch   2: Total Training Recognition Loss -1.00  Total Training Translation Loss 1487.16 
2022-01-02 08:10:35,968 EPOCH 3
2022-01-02 08:10:47,886 [Epoch: 003 Step: 00000341] Batch Translation Loss:   8.180134 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 08:11:00,141 [Epoch: 003 Step: 00000342] Batch Translation Loss:   7.835043 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 08:11:17,464 [Epoch: 003 Step: 00000343] Batch Translation Loss:   8.456226 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:11:34,889 [Epoch: 003 Step: 00000344] Batch Translation Loss:   8.702112 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:11:54,167 [Epoch: 003 Step: 00000345] Batch Translation Loss:  10.443333 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 08:12:18,376 [Epoch: 003 Step: 00000346] Batch Translation Loss:  10.385326 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:12:32,482 [Epoch: 003 Step: 00000347] Batch Translation Loss:  10.780260 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 08:12:46,258 [Epoch: 003 Step: 00000348] Batch Translation Loss:  10.743075 => Txt Tokens per Sec:        4 || Lr: 0.001000
2022-01-02 08:13:04,913 [Epoch: 003 Step: 00000349] Batch Translation Loss:   9.511008 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 08:13:18,667 [Epoch: 003 Step: 00000350] Batch Translation Loss:  11.081035 => Txt Tokens per Sec:        4 || Lr: 0.001000
2022-01-02 08:13:45,721 [Epoch: 003 Step: 00000351] Batch Translation Loss:   9.922385 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:14:01,496 [Epoch: 003 Step: 00000352] Batch Translation Loss:  12.095137 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 08:14:18,346 [Epoch: 003 Step: 00000353] Batch Translation Loss:   8.517005 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:14:39,183 [Epoch: 003 Step: 00000354] Batch Translation Loss:   9.330512 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:15:01,452 [Epoch: 003 Step: 00000355] Batch Translation Loss:   9.019332 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:15:16,029 [Epoch: 003 Step: 00000356] Batch Translation Loss:   7.783170 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:15:43,325 [Epoch: 003 Step: 00000357] Batch Translation Loss:  11.116892 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:16:18,414 [Epoch: 003 Step: 00000358] Batch Translation Loss:   8.359869 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:16:40,383 [Epoch: 003 Step: 00000359] Batch Translation Loss:   9.817572 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:16:59,157 [Epoch: 003 Step: 00000360] Batch Translation Loss:   8.648056 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:17:15,389 [Epoch: 003 Step: 00000361] Batch Translation Loss:   7.697594 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:17:30,285 [Epoch: 003 Step: 00000362] Batch Translation Loss:   7.465007 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:17:56,057 [Epoch: 003 Step: 00000363] Batch Translation Loss:   9.386140 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:18:30,777 [Epoch: 003 Step: 00000364] Batch Translation Loss:   8.911677 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:18:48,977 [Epoch: 003 Step: 00000365] Batch Translation Loss:   8.713139 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:19:05,759 [Epoch: 003 Step: 00000366] Batch Translation Loss:   8.376822 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:19:24,278 [Epoch: 003 Step: 00000367] Batch Translation Loss:   6.339288 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:19:46,003 [Epoch: 003 Step: 00000368] Batch Translation Loss:   8.552818 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:20:17,740 [Epoch: 003 Step: 00000369] Batch Translation Loss:   8.214505 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:20:34,891 [Epoch: 003 Step: 00000370] Batch Translation Loss:   7.848297 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:20:54,177 [Epoch: 003 Step: 00000371] Batch Translation Loss:   7.452803 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:21:11,815 [Epoch: 003 Step: 00000372] Batch Translation Loss:   7.531003 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:21:32,247 [Epoch: 003 Step: 00000373] Batch Translation Loss:   8.678545 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:21:57,843 [Epoch: 003 Step: 00000374] Batch Translation Loss:   6.718984 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:22:16,985 [Epoch: 003 Step: 00000375] Batch Translation Loss:   8.646731 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:22:37,418 [Epoch: 003 Step: 00000376] Batch Translation Loss:   6.944024 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:23:05,357 [Epoch: 003 Step: 00000377] Batch Translation Loss:   9.196870 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:23:34,600 [Epoch: 003 Step: 00000378] Batch Translation Loss:   8.796589 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:24:13,827 [Epoch: 003 Step: 00000379] Batch Translation Loss:  10.108781 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:24:36,616 [Epoch: 003 Step: 00000380] Batch Translation Loss:   8.954974 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:25:01,085 [Epoch: 003 Step: 00000381] Batch Translation Loss:   8.567502 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:25:22,261 [Epoch: 003 Step: 00000382] Batch Translation Loss:   7.522152 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:25:37,317 [Epoch: 003 Step: 00000383] Batch Translation Loss:   6.992233 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:26:34,253 [Epoch: 003 Step: 00000384] Batch Translation Loss:  10.300961 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:26:55,256 [Epoch: 003 Step: 00000385] Batch Translation Loss:   7.684370 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:27:26,540 [Epoch: 003 Step: 00000386] Batch Translation Loss:   9.327627 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:28:02,977 [Epoch: 003 Step: 00000387] Batch Translation Loss:   7.638564 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:28:28,141 [Epoch: 003 Step: 00000388] Batch Translation Loss:   8.116980 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:28:50,692 [Epoch: 003 Step: 00000389] Batch Translation Loss:   8.946892 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:29:13,884 [Epoch: 003 Step: 00000390] Batch Translation Loss:   7.798685 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:29:40,778 [Epoch: 003 Step: 00000391] Batch Translation Loss:   8.419255 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:30:06,570 [Epoch: 003 Step: 00000392] Batch Translation Loss:   7.827529 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:30:33,955 [Epoch: 003 Step: 00000393] Batch Translation Loss:   7.071172 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:31:20,375 [Epoch: 003 Step: 00000394] Batch Translation Loss:   8.443427 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:31:47,214 [Epoch: 003 Step: 00000395] Batch Translation Loss:   7.897566 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:32:32,786 [Epoch: 003 Step: 00000396] Batch Translation Loss:   7.469610 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:32:56,569 [Epoch: 003 Step: 00000397] Batch Translation Loss:   8.541990 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:33:21,558 [Epoch: 003 Step: 00000398] Batch Translation Loss:   9.108660 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:33:56,651 [Epoch: 003 Step: 00000399] Batch Translation Loss:   9.183332 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:35:14,848 [Epoch: 003 Step: 00000400] Batch Translation Loss:   8.341108 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 08:44:47,277 Hooray! New best validation result [eval_metric]!
2022-01-02 08:44:47,382 Saving new checkpoint.
2022-01-02 08:44:51,377 Validation result at epoch   3, step      400: duration: 576.3544s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11050.75293	PPL: 6264.68994
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 2.61	(DEL: 23.73,	INS: 0.00,	SUB: 73.66)
	Sequence Accuracy 2.18
2022-01-02 08:44:59,909 Logging Recognition and Translation Outputs
2022-01-02 08:44:59,967 ========================================================================================================================
2022-01-02 08:44:59,967 Logging Sequence: youtube_4-howard_rosenblum_5572
2022-01-02 08:44:59,968 	Text Reference  :	matseatle
2022-01-02 08:44:59,968 	Text Hypothesis :	asl      
2022-01-02 08:44:59,968 	Text Alignment  :	S        
2022-01-02 08:44:59,969 ========================================================================================================================
2022-01-02 08:44:59,969 Logging Sequence: deafvideo_3-deafgoldenhair_3062
2022-01-02 08:44:59,969 	Text Reference  :	savior
2022-01-02 08:44:59,970 	Text Hypothesis :	asl   
2022-01-02 08:44:59,970 	Text Alignment  :	S     
2022-01-02 08:44:59,970 ========================================================================================================================
2022-01-02 08:44:59,970 Logging Sequence: youtube_5-daniel_durant_5885
2022-01-02 08:44:59,970 	Text Reference  :	dvtv
2022-01-02 08:44:59,971 	Text Hypothesis :	asl 
2022-01-02 08:44:59,971 	Text Alignment  :	S   
2022-01-02 08:44:59,971 ========================================================================================================================
2022-01-02 08:44:59,971 Logging Sequence: youtube_5-caroline_jackson_5854
2022-01-02 08:44:59,972 	Text Reference  :	cill
2022-01-02 08:44:59,972 	Text Hypothesis :	asl 
2022-01-02 08:44:59,972 	Text Alignment  :	S   
2022-01-02 08:44:59,972 ========================================================================================================================
2022-01-02 08:44:59,973 Logging Sequence: deafvideo_3-titans_4699
2022-01-02 08:44:59,973 	Text Reference  :	date
2022-01-02 08:44:59,973 	Text Hypothesis :	asl 
2022-01-02 08:44:59,973 	Text Alignment  :	S   
2022-01-02 08:44:59,974 ========================================================================================================================
2022-01-02 08:45:41,525 [Epoch: 003 Step: 00000401] Batch Translation Loss:   8.115963 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:46:41,974 [Epoch: 003 Step: 00000402] Batch Translation Loss:   9.487377 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:47:34,645 [Epoch: 003 Step: 00000403] Batch Translation Loss:   7.241362 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:47:58,081 [Epoch: 003 Step: 00000404] Batch Translation Loss:   7.137245 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:48:30,645 [Epoch: 003 Step: 00000405] Batch Translation Loss:   8.087177 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:49:04,738 [Epoch: 003 Step: 00000406] Batch Translation Loss:   8.438761 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:49:44,595 [Epoch: 003 Step: 00000407] Batch Translation Loss:   7.564784 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:50:15,448 [Epoch: 003 Step: 00000408] Batch Translation Loss:   7.963588 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:50:47,161 [Epoch: 003 Step: 00000409] Batch Translation Loss:   7.157216 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:51:16,162 [Epoch: 003 Step: 00000410] Batch Translation Loss:   8.046101 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:51:43,157 [Epoch: 003 Step: 00000411] Batch Translation Loss:   7.801292 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:52:16,267 [Epoch: 003 Step: 00000412] Batch Translation Loss:   8.003302 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:52:49,751 [Epoch: 003 Step: 00000413] Batch Translation Loss:   8.050545 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:53:35,702 [Epoch: 003 Step: 00000414] Batch Translation Loss:   6.988378 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:54:03,810 [Epoch: 003 Step: 00000415] Batch Translation Loss:   8.548750 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 08:54:37,624 [Epoch: 003 Step: 00000416] Batch Translation Loss:   6.393684 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:55:03,072 [Epoch: 003 Step: 00000417] Batch Translation Loss:   8.327367 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:55:57,998 [Epoch: 003 Step: 00000418] Batch Translation Loss:   7.250961 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:56:35,041 [Epoch: 003 Step: 00000419] Batch Translation Loss:   6.958876 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:57:16,641 [Epoch: 003 Step: 00000420] Batch Translation Loss:   8.329966 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:57:54,128 [Epoch: 003 Step: 00000421] Batch Translation Loss:   8.563834 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:58:50,327 [Epoch: 003 Step: 00000422] Batch Translation Loss:   7.089876 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 08:59:26,732 [Epoch: 003 Step: 00000423] Batch Translation Loss:   8.000456 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:00:05,256 [Epoch: 003 Step: 00000424] Batch Translation Loss:   6.889578 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:00:51,437 [Epoch: 003 Step: 00000425] Batch Translation Loss:   7.039194 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:01:24,396 [Epoch: 003 Step: 00000426] Batch Translation Loss:   8.397949 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:02:04,672 [Epoch: 003 Step: 00000427] Batch Translation Loss:   7.087580 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:02:41,784 [Epoch: 003 Step: 00000428] Batch Translation Loss:   8.101958 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:03:24,702 [Epoch: 003 Step: 00000429] Batch Translation Loss:  10.136005 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:04:09,327 [Epoch: 003 Step: 00000430] Batch Translation Loss:  10.538100 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:04:46,460 [Epoch: 003 Step: 00000431] Batch Translation Loss:   6.780416 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:05:28,012 [Epoch: 003 Step: 00000432] Batch Translation Loss:   8.538237 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:06:24,549 [Epoch: 003 Step: 00000433] Batch Translation Loss:   7.515882 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:07:04,103 [Epoch: 003 Step: 00000434] Batch Translation Loss:   8.345252 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:07:50,580 [Epoch: 003 Step: 00000435] Batch Translation Loss:   7.539555 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:08:23,791 [Epoch: 003 Step: 00000436] Batch Translation Loss:   7.701285 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:09:04,996 [Epoch: 003 Step: 00000437] Batch Translation Loss:   7.271871 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:09:51,531 [Epoch: 003 Step: 00000438] Batch Translation Loss:   7.409008 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:10:32,672 [Epoch: 003 Step: 00000439] Batch Translation Loss:   8.517568 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:11:09,610 [Epoch: 003 Step: 00000440] Batch Translation Loss:   7.454905 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:11:59,436 [Epoch: 003 Step: 00000441] Batch Translation Loss:   9.917196 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:12:40,579 [Epoch: 003 Step: 00000442] Batch Translation Loss:   7.984160 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:13:30,326 [Epoch: 003 Step: 00000443] Batch Translation Loss:   7.699185 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:14:19,037 [Epoch: 003 Step: 00000444] Batch Translation Loss:   7.458523 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:14:54,134 [Epoch: 003 Step: 00000445] Batch Translation Loss:   8.024896 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:15:40,441 [Epoch: 003 Step: 00000446] Batch Translation Loss:   8.929678 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:16:28,102 [Epoch: 003 Step: 00000447] Batch Translation Loss:   7.615686 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:17:14,897 [Epoch: 003 Step: 00000448] Batch Translation Loss:   7.908494 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:17:59,926 [Epoch: 003 Step: 00000449] Batch Translation Loss:   7.000228 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:18:43,757 [Epoch: 003 Step: 00000450] Batch Translation Loss:   7.171674 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:20:12,189 [Epoch: 003 Step: 00000451] Batch Translation Loss:   7.547791 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 09:20:58,775 [Epoch: 003 Step: 00000452] Batch Translation Loss:   9.125965 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:21:48,826 [Epoch: 003 Step: 00000453] Batch Translation Loss:   8.354500 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:22:38,666 [Epoch: 003 Step: 00000454] Batch Translation Loss:   7.967566 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:23:35,975 [Epoch: 003 Step: 00000455] Batch Translation Loss:   8.912753 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:24:21,948 [Epoch: 003 Step: 00000456] Batch Translation Loss:   7.710895 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:25:15,295 [Epoch: 003 Step: 00000457] Batch Translation Loss:   7.165846 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:26:43,506 [Epoch: 003 Step: 00000458] Batch Translation Loss:   8.139375 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 09:27:29,486 [Epoch: 003 Step: 00000459] Batch Translation Loss:   7.812121 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:28:20,205 [Epoch: 003 Step: 00000460] Batch Translation Loss:   8.537102 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:29:20,787 [Epoch: 003 Step: 00000461] Batch Translation Loss:   7.355392 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:30:23,752 [Epoch: 003 Step: 00000462] Batch Translation Loss:   8.208190 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:31:03,265 [Epoch: 003 Step: 00000463] Batch Translation Loss:   7.831758 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:32:08,163 [Epoch: 003 Step: 00000464] Batch Translation Loss:   8.102387 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:32:59,495 [Epoch: 003 Step: 00000465] Batch Translation Loss:   7.566230 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:33:52,567 [Epoch: 003 Step: 00000466] Batch Translation Loss:   7.882536 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:34:42,652 [Epoch: 003 Step: 00000467] Batch Translation Loss:   8.572300 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:35:22,007 [Epoch: 003 Step: 00000468] Batch Translation Loss:   7.862725 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:36:55,566 [Epoch: 003 Step: 00000469] Batch Translation Loss:   7.909176 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 09:37:54,037 [Epoch: 003 Step: 00000470] Batch Translation Loss:   8.457232 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:38:49,514 [Epoch: 003 Step: 00000471] Batch Translation Loss:   7.574361 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:39:37,416 [Epoch: 003 Step: 00000472] Batch Translation Loss:   7.733042 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:40:39,995 [Epoch: 003 Step: 00000473] Batch Translation Loss:  10.319741 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:42:19,101 [Epoch: 003 Step: 00000474] Batch Translation Loss:   9.957541 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:43:18,036 [Epoch: 003 Step: 00000475] Batch Translation Loss:   7.456031 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:44:08,845 [Epoch: 003 Step: 00000476] Batch Translation Loss:   8.631285 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:45:41,025 [Epoch: 003 Step: 00000477] Batch Translation Loss:   7.157796 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 09:46:32,874 [Epoch: 003 Step: 00000478] Batch Translation Loss:   7.779316 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:47:23,975 [Epoch: 003 Step: 00000479] Batch Translation Loss:   7.450574 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:48:09,799 [Epoch: 003 Step: 00000480] Batch Translation Loss:   7.053417 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:50:05,413 [Epoch: 003 Step: 00000481] Batch Translation Loss:   9.814031 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 09:50:56,347 [Epoch: 003 Step: 00000482] Batch Translation Loss:   8.008293 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:51:58,246 [Epoch: 003 Step: 00000483] Batch Translation Loss:   7.764431 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:52:48,700 [Epoch: 003 Step: 00000484] Batch Translation Loss:   7.806858 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:53:43,334 [Epoch: 003 Step: 00000485] Batch Translation Loss:   8.117773 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:54:38,083 [Epoch: 003 Step: 00000486] Batch Translation Loss:  10.255117 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:55:30,656 [Epoch: 003 Step: 00000487] Batch Translation Loss:   7.511283 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:56:32,274 [Epoch: 003 Step: 00000488] Batch Translation Loss:   8.266553 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:57:35,627 [Epoch: 003 Step: 00000489] Batch Translation Loss:   8.366345 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:58:44,575 [Epoch: 003 Step: 00000490] Batch Translation Loss:   6.983820 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 09:59:36,792 [Epoch: 003 Step: 00000491] Batch Translation Loss:   9.040669 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:00:31,897 [Epoch: 003 Step: 00000492] Batch Translation Loss:   8.090212 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:01:23,020 [Epoch: 003 Step: 00000493] Batch Translation Loss:   7.342224 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:03:01,269 [Epoch: 003 Step: 00000494] Batch Translation Loss:   7.823848 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 10:04:37,087 [Epoch: 003 Step: 00000495] Batch Translation Loss:   7.855217 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 10:06:32,406 [Epoch: 003 Step: 00000496] Batch Translation Loss:   9.203656 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 10:07:23,997 [Epoch: 003 Step: 00000497] Batch Translation Loss:   9.337732 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:08:23,167 [Epoch: 003 Step: 00000498] Batch Translation Loss:   8.261106 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:09:21,610 [Epoch: 003 Step: 00000499] Batch Translation Loss:   7.414951 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:10:16,892 [Epoch: 003 Step: 00000500] Batch Translation Loss:   8.720734 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:20:42,614 Validation result at epoch   3, step      500: duration: 625.6666s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 10636.22168	PPL: 5311.33057
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.13	(DEL: 22.26,	INS: 0.00,	SUB: 76.61)
	Sequence Accuracy 1.14
2022-01-02 10:20:52,113 Logging Recognition and Translation Outputs
2022-01-02 10:20:52,113 ========================================================================================================================
2022-01-02 10:20:52,113 Logging Sequence: youtube_1-catherine_mackinnon_2811
2022-01-02 10:20:52,114 	Text Reference  :	poc
2022-01-02 10:20:52,114 	Text Hypothesis :	ok 
2022-01-02 10:20:52,114 	Text Alignment  :	S  
2022-01-02 10:20:52,114 ========================================================================================================================
2022-01-02 10:20:52,114 Logging Sequence: youtube_1-don_grushkin_2767
2022-01-02 10:20:52,115 	Text Reference  :	or
2022-01-02 10:20:52,115 	Text Hypothesis :	ok
2022-01-02 10:20:52,115 	Text Alignment  :	S 
2022-01-02 10:20:52,115 ========================================================================================================================
2022-01-02 10:20:52,115 Logging Sequence: youtube_4-howard_rosenblum_5578
2022-01-02 10:20:52,115 	Text Reference  :	pearl
2022-01-02 10:20:52,116 	Text Hypothesis :	asl  
2022-01-02 10:20:52,116 	Text Alignment  :	S    
2022-01-02 10:20:52,116 ========================================================================================================================
2022-01-02 10:20:52,116 Logging Sequence: youtube_5-debra_patkin_5794
2022-01-02 10:20:52,116 	Text Reference  :	paste
2022-01-02 10:20:52,116 	Text Hypothesis :	asl  
2022-01-02 10:20:52,116 	Text Alignment  :	S    
2022-01-02 10:20:52,116 ========================================================================================================================
2022-01-02 10:20:52,117 Logging Sequence: deafvideo_2-sddsimple_1575
2022-01-02 10:20:52,117 	Text Reference  :	dec
2022-01-02 10:20:52,117 	Text Hypothesis :	ok 
2022-01-02 10:20:52,117 	Text Alignment  :	S  
2022-01-02 10:20:52,117 ========================================================================================================================
2022-01-02 10:22:41,674 [Epoch: 003 Step: 00000501] Batch Translation Loss:   7.774320 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 10:24:05,411 [Epoch: 003 Step: 00000502] Batch Translation Loss:   9.205907 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:25:43,899 [Epoch: 003 Step: 00000503] Batch Translation Loss:   7.469951 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 10:26:41,500 [Epoch: 003 Step: 00000504] Batch Translation Loss:   7.967270 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:27:22,560 [Epoch: 003 Step: 00000505] Batch Translation Loss:   8.482093 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:28:55,115 [Epoch: 003 Step: 00000506] Batch Translation Loss:   7.465742 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 10:31:38,684 [Epoch: 003 Step: 00000507] Batch Translation Loss:   8.297094 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 10:32:54,187 [Epoch: 003 Step: 00000508] Batch Translation Loss:   8.033856 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:34:28,373 [Epoch: 003 Step: 00000509] Batch Translation Loss:   6.539989 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 10:36:02,391 [Epoch: 003 Step: 00000510] Batch Translation Loss:   8.417992 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 10:36:02,499 Epoch   3: Total Training Recognition Loss -1.00  Total Training Translation Loss 1402.76 
2022-01-02 10:36:02,500 EPOCH 4
2022-01-02 10:36:23,874 [Epoch: 004 Step: 00000511] Batch Translation Loss:   7.501086 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 10:36:41,055 [Epoch: 004 Step: 00000512] Batch Translation Loss:   8.281420 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 10:37:10,387 [Epoch: 004 Step: 00000513] Batch Translation Loss:   9.657181 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 10:37:48,467 [Epoch: 004 Step: 00000514] Batch Translation Loss:   7.824955 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:38:18,296 [Epoch: 004 Step: 00000515] Batch Translation Loss:  10.139593 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 10:38:42,586 [Epoch: 004 Step: 00000516] Batch Translation Loss:   6.892293 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:39:08,818 [Epoch: 004 Step: 00000517] Batch Translation Loss:   8.120622 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:39:34,183 [Epoch: 004 Step: 00000518] Batch Translation Loss:   7.423461 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:39:51,626 [Epoch: 004 Step: 00000519] Batch Translation Loss:  10.392777 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 10:40:15,894 [Epoch: 004 Step: 00000520] Batch Translation Loss:   8.966397 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 10:40:42,308 [Epoch: 004 Step: 00000521] Batch Translation Loss:   8.958057 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 10:41:10,918 [Epoch: 004 Step: 00000522] Batch Translation Loss:   9.300426 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:41:38,551 [Epoch: 004 Step: 00000523] Batch Translation Loss:   9.243546 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 10:42:07,742 [Epoch: 004 Step: 00000524] Batch Translation Loss:   8.534225 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 10:42:41,661 [Epoch: 004 Step: 00000525] Batch Translation Loss:   9.681285 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:43:06,021 [Epoch: 004 Step: 00000526] Batch Translation Loss:   7.496920 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 10:43:33,224 [Epoch: 004 Step: 00000527] Batch Translation Loss:   9.479903 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 10:43:55,749 [Epoch: 004 Step: 00000528] Batch Translation Loss:   8.779800 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 10:44:43,868 [Epoch: 004 Step: 00000529] Batch Translation Loss:   8.140397 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:45:12,796 [Epoch: 004 Step: 00000530] Batch Translation Loss:   7.823878 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:45:43,763 [Epoch: 004 Step: 00000531] Batch Translation Loss:   8.582640 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:46:36,182 [Epoch: 004 Step: 00000532] Batch Translation Loss:   7.935266 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:47:05,292 [Epoch: 004 Step: 00000533] Batch Translation Loss:  10.630713 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 10:47:45,464 [Epoch: 004 Step: 00000534] Batch Translation Loss:  10.281755 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:48:14,163 [Epoch: 004 Step: 00000535] Batch Translation Loss:   8.159920 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:49:03,584 [Epoch: 004 Step: 00000536] Batch Translation Loss:   8.061881 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:50:01,623 [Epoch: 004 Step: 00000537] Batch Translation Loss:   7.598742 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:50:29,590 [Epoch: 004 Step: 00000538] Batch Translation Loss:   8.049770 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:51:27,789 [Epoch: 004 Step: 00000539] Batch Translation Loss:   8.733845 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:51:57,052 [Epoch: 004 Step: 00000540] Batch Translation Loss:   6.953997 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:52:33,101 [Epoch: 004 Step: 00000541] Batch Translation Loss:   7.999039 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:53:00,063 [Epoch: 004 Step: 00000542] Batch Translation Loss:   9.254808 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 10:53:31,974 [Epoch: 004 Step: 00000543] Batch Translation Loss:   8.925196 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:54:10,616 [Epoch: 004 Step: 00000544] Batch Translation Loss:   9.047027 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:54:43,305 [Epoch: 004 Step: 00000545] Batch Translation Loss:   9.553576 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:55:22,574 [Epoch: 004 Step: 00000546] Batch Translation Loss:   7.260105 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:55:59,175 [Epoch: 004 Step: 00000547] Batch Translation Loss:   8.491566 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:56:25,066 [Epoch: 004 Step: 00000548] Batch Translation Loss:   9.089643 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 10:57:04,405 [Epoch: 004 Step: 00000549] Batch Translation Loss:  10.373198 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:57:43,176 [Epoch: 004 Step: 00000550] Batch Translation Loss:   8.433611 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:58:25,087 [Epoch: 004 Step: 00000551] Batch Translation Loss:   8.362933 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 10:58:56,647 [Epoch: 004 Step: 00000552] Batch Translation Loss:   8.090723 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:00:03,411 [Epoch: 004 Step: 00000553] Batch Translation Loss:   8.537479 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:00:35,995 [Epoch: 004 Step: 00000554] Batch Translation Loss:   8.305573 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:01:31,637 [Epoch: 004 Step: 00000555] Batch Translation Loss:   8.119981 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:02:06,415 [Epoch: 004 Step: 00000556] Batch Translation Loss:   7.078680 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:02:49,617 [Epoch: 004 Step: 00000557] Batch Translation Loss:   6.680852 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:03:58,776 [Epoch: 004 Step: 00000558] Batch Translation Loss:   8.018447 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:04:42,504 [Epoch: 004 Step: 00000559] Batch Translation Loss:   7.204252 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:05:16,313 [Epoch: 004 Step: 00000560] Batch Translation Loss:   6.938397 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:05:52,471 [Epoch: 004 Step: 00000561] Batch Translation Loss:   7.908058 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:06:36,391 [Epoch: 004 Step: 00000562] Batch Translation Loss:   9.402716 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:07:19,747 [Epoch: 004 Step: 00000563] Batch Translation Loss:   8.793211 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:08:05,984 [Epoch: 004 Step: 00000564] Batch Translation Loss:   9.019944 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:08:51,643 [Epoch: 004 Step: 00000565] Batch Translation Loss:   6.451729 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:09:15,736 [Epoch: 004 Step: 00000566] Batch Translation Loss:   8.163611 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 11:09:48,364 [Epoch: 004 Step: 00000567] Batch Translation Loss:   6.450401 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:10:34,795 [Epoch: 004 Step: 00000568] Batch Translation Loss:   9.453397 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:12:01,835 [Epoch: 004 Step: 00000569] Batch Translation Loss:   7.818638 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 11:12:54,059 [Epoch: 004 Step: 00000570] Batch Translation Loss:   7.149850 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:13:31,634 [Epoch: 004 Step: 00000571] Batch Translation Loss:   7.461908 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:14:10,370 [Epoch: 004 Step: 00000572] Batch Translation Loss:   7.829849 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:14:59,528 [Epoch: 004 Step: 00000573] Batch Translation Loss:   9.592438 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:15:48,337 [Epoch: 004 Step: 00000574] Batch Translation Loss:   7.921640 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:16:38,898 [Epoch: 004 Step: 00000575] Batch Translation Loss:   8.837895 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:17:26,781 [Epoch: 004 Step: 00000576] Batch Translation Loss:   8.518430 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:17:58,460 [Epoch: 004 Step: 00000577] Batch Translation Loss:   6.755518 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:18:49,258 [Epoch: 004 Step: 00000578] Batch Translation Loss:   7.827743 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:19:40,391 [Epoch: 004 Step: 00000579] Batch Translation Loss:   6.520178 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:20:29,827 [Epoch: 004 Step: 00000580] Batch Translation Loss:   8.345281 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:21:27,494 [Epoch: 004 Step: 00000581] Batch Translation Loss:   8.017904 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:22:16,588 [Epoch: 004 Step: 00000582] Batch Translation Loss:   7.590590 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:23:05,597 [Epoch: 004 Step: 00000583] Batch Translation Loss:   8.490945 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:24:06,046 [Epoch: 004 Step: 00000584] Batch Translation Loss:   8.629188 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:25:02,930 [Epoch: 004 Step: 00000585] Batch Translation Loss:   8.853093 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:25:58,261 [Epoch: 004 Step: 00000586] Batch Translation Loss:   7.848477 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:26:45,293 [Epoch: 004 Step: 00000587] Batch Translation Loss:   7.960926 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:27:25,589 [Epoch: 004 Step: 00000588] Batch Translation Loss:   7.231166 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:28:17,910 [Epoch: 004 Step: 00000589] Batch Translation Loss:   7.839302 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:29:18,363 [Epoch: 004 Step: 00000590] Batch Translation Loss:   7.873577 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:30:26,298 [Epoch: 004 Step: 00000591] Batch Translation Loss:   6.409436 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 11:31:46,263 [Epoch: 004 Step: 00000592] Batch Translation Loss:   8.301218 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 11:32:40,824 [Epoch: 004 Step: 00000593] Batch Translation Loss:   7.971614 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:34:27,080 [Epoch: 004 Step: 00000594] Batch Translation Loss:   7.565112 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 11:36:03,875 [Epoch: 004 Step: 00000595] Batch Translation Loss:   9.389758 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 11:36:51,721 [Epoch: 004 Step: 00000596] Batch Translation Loss:   7.593481 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:37:46,126 [Epoch: 004 Step: 00000597] Batch Translation Loss:   7.233281 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:38:48,627 [Epoch: 004 Step: 00000598] Batch Translation Loss:   9.012571 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:39:51,206 [Epoch: 004 Step: 00000599] Batch Translation Loss:   8.596722 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:40:41,040 [Epoch: 004 Step: 00000600] Batch Translation Loss:   7.739408 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:49:21,147 Validation result at epoch   4, step      600: duration: 520.0823s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 10916.05176	PPL: 5227.08594
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 2.04	(DEL: 24.16,	INS: 0.00,	SUB: 73.80)
	Sequence Accuracy 2.17
2022-01-02 11:49:27,351 Logging Recognition and Translation Outputs
2022-01-02 11:49:27,352 ========================================================================================================================
2022-01-02 11:49:27,352 Logging Sequence: deafvideo_2-sddsimple_1573
2022-01-02 11:49:27,352 	Text Reference  :	tool
2022-01-02 11:49:27,352 	Text Hypothesis :	asl 
2022-01-02 11:49:27,353 	Text Alignment  :	S   
2022-01-02 11:49:27,353 ========================================================================================================================
2022-01-02 11:49:27,353 Logging Sequence: youtube_4-sean_berdy_5736
2022-01-02 11:49:27,353 	Text Reference  :	asl
2022-01-02 11:49:27,353 	Text Hypothesis :	ok 
2022-01-02 11:49:27,353 	Text Alignment  :	S  
2022-01-02 11:49:27,353 ========================================================================================================================
2022-01-02 11:49:27,353 Logging Sequence: youtube_5-caroline_jackson_5859
2022-01-02 11:49:27,353 	Text Reference  :	nad
2022-01-02 11:49:27,353 	Text Hypothesis :	so 
2022-01-02 11:49:27,354 	Text Alignment  :	S  
2022-01-02 11:49:27,354 ========================================================================================================================
2022-01-02 11:49:27,354 Logging Sequence: youtube_3-ben_bahan_4536
2022-01-02 11:49:27,354 	Text Reference  :	met
2022-01-02 11:49:27,354 	Text Hypothesis :	ok 
2022-01-02 11:49:27,354 	Text Alignment  :	S  
2022-01-02 11:49:27,354 ========================================================================================================================
2022-01-02 11:49:27,354 Logging Sequence: deafvideo_2-sddsimple_1588
2022-01-02 11:49:27,354 	Text Reference  :	sc 
2022-01-02 11:49:27,354 	Text Hypothesis :	asl
2022-01-02 11:49:27,354 	Text Alignment  :	S  
2022-01-02 11:49:27,355 ========================================================================================================================
2022-01-02 11:50:41,452 [Epoch: 004 Step: 00000601] Batch Translation Loss:   7.682974 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 11:51:35,890 [Epoch: 004 Step: 00000602] Batch Translation Loss:   7.619889 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:52:26,588 [Epoch: 004 Step: 00000603] Batch Translation Loss:   7.368932 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:53:09,182 [Epoch: 004 Step: 00000604] Batch Translation Loss:   7.585282 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:53:53,819 [Epoch: 004 Step: 00000605] Batch Translation Loss:   7.560593 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:54:45,639 [Epoch: 004 Step: 00000606] Batch Translation Loss:   7.758465 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:55:32,291 [Epoch: 004 Step: 00000607] Batch Translation Loss:   7.711691 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:56:24,766 [Epoch: 004 Step: 00000608] Batch Translation Loss:   7.733771 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:57:10,387 [Epoch: 004 Step: 00000609] Batch Translation Loss:   7.094527 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:57:53,960 [Epoch: 004 Step: 00000610] Batch Translation Loss:   6.804681 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:58:37,185 [Epoch: 004 Step: 00000611] Batch Translation Loss:   8.035543 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 11:59:26,158 [Epoch: 004 Step: 00000612] Batch Translation Loss:   7.773406 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 12:00:21,012 [Epoch: 004 Step: 00000613] Batch Translation Loss:   8.833837 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 12:01:15,449 [Epoch: 004 Step: 00000614] Batch Translation Loss:   7.703406 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 12:02:04,279 [Epoch: 004 Step: 00000615] Batch Translation Loss:   8.262317 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 12:02:54,725 [Epoch: 004 Step: 00000616] Batch Translation Loss:   7.167592 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 12:03:47,430 [Epoch: 004 Step: 00000617] Batch Translation Loss:   7.141390 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 12:04:46,391 [Epoch: 004 Step: 00000618] Batch Translation Loss:   7.381146 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 12:05:39,603 [Epoch: 004 Step: 00000619] Batch Translation Loss:   7.827941 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 12:06:31,257 [Epoch: 004 Step: 00000620] Batch Translation Loss:  10.114353 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 12:08:04,825 [Epoch: 004 Step: 00000621] Batch Translation Loss:   6.812442 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 12:08:53,654 [Epoch: 004 Step: 00000622] Batch Translation Loss:   7.044266 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 12:09:50,803 [Epoch: 004 Step: 00000623] Batch Translation Loss:   8.039318 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 12:11:41,639 [Epoch: 004 Step: 00000624] Batch Translation Loss:   8.717904 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 12:13:12,597 [Epoch: 004 Step: 00000625] Batch Translation Loss:   7.718549 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 12:14:13,768 [Epoch: 004 Step: 00000626] Batch Translation Loss:   8.510183 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 12:15:07,284 [Epoch: 004 Step: 00000627] Batch Translation Loss:   8.018448 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 12:16:10,124 [Epoch: 004 Step: 00000628] Batch Translation Loss:   7.564699 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 12:17:22,146 [Epoch: 004 Step: 00000629] Batch Translation Loss:   7.602838 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 12:18:16,522 [Epoch: 004 Step: 00000630] Batch Translation Loss:   6.267151 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 12:19:19,652 [Epoch: 004 Step: 00000631] Batch Translation Loss:   8.048751 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 12:21:15,553 [Epoch: 004 Step: 00000632] Batch Translation Loss:   6.817812 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 12:22:21,675 [Epoch: 004 Step: 00000633] Batch Translation Loss:   7.998727 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 12:23:50,566 [Epoch: 004 Step: 00000634] Batch Translation Loss:   8.934737 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 12:24:50,098 [Epoch: 004 Step: 00000635] Batch Translation Loss:   8.618744 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 12:25:59,361 [Epoch: 004 Step: 00000636] Batch Translation Loss:   8.380898 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 12:27:11,538 [Epoch: 004 Step: 00000637] Batch Translation Loss:   7.838678 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 12:28:25,958 [Epoch: 004 Step: 00000638] Batch Translation Loss:   7.804790 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 12:29:22,388 [Epoch: 004 Step: 00000639] Batch Translation Loss:   7.997771 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 12:30:43,938 [Epoch: 004 Step: 00000640] Batch Translation Loss:   6.291986 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 12:32:06,410 [Epoch: 004 Step: 00000641] Batch Translation Loss:   7.666976 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 12:33:19,951 [Epoch: 004 Step: 00000642] Batch Translation Loss:   6.581244 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 12:34:31,428 [Epoch: 004 Step: 00000643] Batch Translation Loss:   7.765808 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 12:36:01,625 [Epoch: 004 Step: 00000644] Batch Translation Loss:   7.998905 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 12:37:10,759 [Epoch: 004 Step: 00000645] Batch Translation Loss:   8.443775 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 12:40:07,666 [Epoch: 004 Step: 00000646] Batch Translation Loss:   9.536901 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 12:41:39,852 [Epoch: 004 Step: 00000647] Batch Translation Loss:   7.009462 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 12:42:46,861 [Epoch: 004 Step: 00000648] Batch Translation Loss:   7.224306 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 12:45:25,606 [Epoch: 004 Step: 00000649] Batch Translation Loss:   8.347658 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 12:46:24,643 [Epoch: 004 Step: 00000650] Batch Translation Loss:   7.669363 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 12:47:23,871 [Epoch: 004 Step: 00000651] Batch Translation Loss:   6.987565 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 12:49:36,329 [Epoch: 004 Step: 00000652] Batch Translation Loss:   5.919861 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 12:50:51,147 [Epoch: 004 Step: 00000653] Batch Translation Loss:   6.938354 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 12:52:18,232 [Epoch: 004 Step: 00000654] Batch Translation Loss:   7.773164 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 12:53:14,039 [Epoch: 004 Step: 00000655] Batch Translation Loss:   8.772706 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 12:54:40,226 [Epoch: 004 Step: 00000656] Batch Translation Loss:   6.584604 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 12:57:16,249 [Epoch: 004 Step: 00000657] Batch Translation Loss:   6.639554 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 12:59:56,337 [Epoch: 004 Step: 00000658] Batch Translation Loss:   6.330295 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 13:02:33,910 [Epoch: 004 Step: 00000659] Batch Translation Loss:   8.453417 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 13:03:58,705 [Epoch: 004 Step: 00000660] Batch Translation Loss:   8.094454 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 13:05:11,476 [Epoch: 004 Step: 00000661] Batch Translation Loss:   7.762864 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 13:07:38,921 [Epoch: 004 Step: 00000662] Batch Translation Loss:   7.842373 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 13:08:57,223 [Epoch: 004 Step: 00000663] Batch Translation Loss:   6.502060 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 13:10:17,757 [Epoch: 004 Step: 00000664] Batch Translation Loss:   8.592838 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 13:12:55,002 [Epoch: 004 Step: 00000665] Batch Translation Loss:   7.809410 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 13:14:02,556 [Epoch: 004 Step: 00000666] Batch Translation Loss:   7.188832 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 13:15:29,430 [Epoch: 004 Step: 00000667] Batch Translation Loss:   7.686184 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 13:16:32,149 [Epoch: 004 Step: 00000668] Batch Translation Loss:   7.828840 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 13:17:58,563 [Epoch: 004 Step: 00000669] Batch Translation Loss:   6.403408 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 13:21:10,316 [Epoch: 004 Step: 00000670] Batch Translation Loss:   7.772037 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 13:22:32,036 [Epoch: 004 Step: 00000671] Batch Translation Loss:   7.098720 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 13:24:00,852 [Epoch: 004 Step: 00000672] Batch Translation Loss:   6.957558 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 13:25:25,718 [Epoch: 004 Step: 00000673] Batch Translation Loss:   6.571655 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 13:26:51,166 [Epoch: 004 Step: 00000674] Batch Translation Loss:   8.328479 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 13:28:16,545 [Epoch: 004 Step: 00000675] Batch Translation Loss:   6.975183 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 13:29:36,136 [Epoch: 004 Step: 00000676] Batch Translation Loss:   7.619988 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 13:31:00,659 [Epoch: 004 Step: 00000677] Batch Translation Loss:   7.802842 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 13:32:21,282 [Epoch: 004 Step: 00000678] Batch Translation Loss:   7.149583 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 13:33:40,760 [Epoch: 004 Step: 00000679] Batch Translation Loss:   8.652857 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 13:35:10,732 [Epoch: 004 Step: 00000680] Batch Translation Loss:   7.020318 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 13:35:11,770 Epoch   4: Total Training Recognition Loss -1.00  Total Training Translation Loss 1354.26 
2022-01-02 13:35:11,784 EPOCH 5
2022-01-02 13:35:27,206 [Epoch: 005 Step: 00000681] Batch Translation Loss:   7.844175 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 13:35:50,075 [Epoch: 005 Step: 00000682] Batch Translation Loss:   8.826526 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 13:36:16,695 [Epoch: 005 Step: 00000683] Batch Translation Loss:  10.410056 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 13:36:43,440 [Epoch: 005 Step: 00000684] Batch Translation Loss:   8.158723 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 13:37:10,236 [Epoch: 005 Step: 00000685] Batch Translation Loss:   8.576285 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 13:37:26,948 [Epoch: 005 Step: 00000686] Batch Translation Loss:   6.788763 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 13:38:14,977 [Epoch: 005 Step: 00000687] Batch Translation Loss:  10.335308 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 13:39:05,944 [Epoch: 005 Step: 00000688] Batch Translation Loss:   8.452088 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 13:39:29,898 [Epoch: 005 Step: 00000689] Batch Translation Loss:   8.318830 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 13:39:59,042 [Epoch: 005 Step: 00000690] Batch Translation Loss:   9.546066 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 13:40:31,094 [Epoch: 005 Step: 00000691] Batch Translation Loss:   7.591476 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 13:41:12,848 [Epoch: 005 Step: 00000692] Batch Translation Loss:   7.380902 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 13:41:44,789 [Epoch: 005 Step: 00000693] Batch Translation Loss:   8.277427 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 13:42:11,920 [Epoch: 005 Step: 00000694] Batch Translation Loss:  10.253759 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 13:42:28,590 [Epoch: 005 Step: 00000695] Batch Translation Loss:   9.606989 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 13:43:15,208 [Epoch: 005 Step: 00000696] Batch Translation Loss:   7.758050 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 13:43:39,948 [Epoch: 005 Step: 00000697] Batch Translation Loss:   7.811145 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 13:44:31,286 [Epoch: 005 Step: 00000698] Batch Translation Loss:   7.897559 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 13:44:51,402 [Epoch: 005 Step: 00000699] Batch Translation Loss:   8.252566 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 13:45:16,822 [Epoch: 005 Step: 00000700] Batch Translation Loss:   9.067715 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 13:56:34,530 Validation result at epoch   5, step      700: duration: 677.6617s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 10702.94336	PPL: 5339.85303
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.60	(DEL: 23.18,	INS: 0.00,	SUB: 75.22)
	Sequence Accuracy 1.25
2022-01-02 13:56:43,491 Logging Recognition and Translation Outputs
2022-01-02 13:56:43,492 ========================================================================================================================
2022-01-02 13:56:43,492 Logging Sequence: aslized-suzanne_stecker_0198
2022-01-02 13:56:43,492 	Text Reference  :	go sem
2022-01-02 13:56:43,492 	Text Hypothesis :	** asl
2022-01-02 13:56:43,493 	Text Alignment  :	D  S  
2022-01-02 13:56:43,493 ========================================================================================================================
2022-01-02 13:56:43,493 Logging Sequence: youtube_1-catherine_mackinnon_2816
2022-01-02 13:56:43,493 	Text Reference  :	matt
2022-01-02 13:56:43,493 	Text Hypothesis :	if  
2022-01-02 13:56:43,493 	Text Alignment  :	S   
2022-01-02 13:56:43,493 ========================================================================================================================
2022-01-02 13:56:43,493 Logging Sequence: youtube_3-ben_bahan_4525
2022-01-02 13:56:43,493 	Text Reference  :	mentor
2022-01-02 13:56:43,493 	Text Hypothesis :	asl   
2022-01-02 13:56:43,494 	Text Alignment  :	S     
2022-01-02 13:56:43,494 ========================================================================================================================
2022-01-02 13:56:43,494 Logging Sequence: deafvideo_3-deafgoldenhair_3061
2022-01-02 13:56:43,494 	Text Reference  :	or
2022-01-02 13:56:43,494 	Text Hypothesis :	if
2022-01-02 13:56:43,494 	Text Alignment  :	S 
2022-01-02 13:56:43,494 ========================================================================================================================
2022-01-02 13:56:43,494 Logging Sequence: deafvideo_3-damien23_3606
2022-01-02 13:56:43,495 	Text Reference  :	tool
2022-01-02 13:56:43,495 	Text Hypothesis :	asl 
2022-01-02 13:56:43,495 	Text Alignment  :	S   
2022-01-02 13:56:43,495 ========================================================================================================================
2022-01-02 13:57:21,952 [Epoch: 005 Step: 00000701] Batch Translation Loss:   9.030310 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 13:57:55,585 [Epoch: 005 Step: 00000702] Batch Translation Loss:   6.954609 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 13:58:31,063 [Epoch: 005 Step: 00000703] Batch Translation Loss:   9.115582 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 13:59:33,879 [Epoch: 005 Step: 00000704] Batch Translation Loss:   9.134555 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:00:01,792 [Epoch: 005 Step: 00000705] Batch Translation Loss:   7.359558 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:00:26,488 [Epoch: 005 Step: 00000706] Batch Translation Loss:   8.451916 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 14:00:56,081 [Epoch: 005 Step: 00000707] Batch Translation Loss:   8.138288 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:01:25,353 [Epoch: 005 Step: 00000708] Batch Translation Loss:   8.932147 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:01:59,996 [Epoch: 005 Step: 00000709] Batch Translation Loss:   7.473743 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:02:25,263 [Epoch: 005 Step: 00000710] Batch Translation Loss:   8.103830 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 14:02:52,031 [Epoch: 005 Step: 00000711] Batch Translation Loss:   8.100807 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:03:25,110 [Epoch: 005 Step: 00000712] Batch Translation Loss:   7.484792 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:03:55,731 [Epoch: 005 Step: 00000713] Batch Translation Loss:   6.813903 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:04:32,103 [Epoch: 005 Step: 00000714] Batch Translation Loss:   8.647663 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:05:04,886 [Epoch: 005 Step: 00000715] Batch Translation Loss:   7.230755 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:05:23,149 [Epoch: 005 Step: 00000716] Batch Translation Loss:   6.893525 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 14:05:47,688 [Epoch: 005 Step: 00000717] Batch Translation Loss:   7.705075 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 14:06:20,506 [Epoch: 005 Step: 00000718] Batch Translation Loss:   7.612123 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:07:18,892 [Epoch: 005 Step: 00000719] Batch Translation Loss:   9.482823 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:07:51,277 [Epoch: 005 Step: 00000720] Batch Translation Loss:   7.626505 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:08:14,039 [Epoch: 005 Step: 00000721] Batch Translation Loss:   7.111160 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 14:09:06,553 [Epoch: 005 Step: 00000722] Batch Translation Loss:   6.802429 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:10:12,688 [Epoch: 005 Step: 00000723] Batch Translation Loss:   7.577053 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:11:05,187 [Epoch: 005 Step: 00000724] Batch Translation Loss:   7.148013 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:12:04,143 [Epoch: 005 Step: 00000725] Batch Translation Loss:   8.323960 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:13:50,315 [Epoch: 005 Step: 00000726] Batch Translation Loss:   7.247557 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 14:14:51,316 [Epoch: 005 Step: 00000727] Batch Translation Loss:   6.522306 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:15:42,570 [Epoch: 005 Step: 00000728] Batch Translation Loss:   7.025206 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:17:30,200 [Epoch: 005 Step: 00000729] Batch Translation Loss:   8.053061 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 14:18:21,721 [Epoch: 005 Step: 00000730] Batch Translation Loss:   7.923909 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:19:18,603 [Epoch: 005 Step: 00000731] Batch Translation Loss:   7.366082 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:20:20,391 [Epoch: 005 Step: 00000732] Batch Translation Loss:   8.567662 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:21:22,509 [Epoch: 005 Step: 00000733] Batch Translation Loss:   8.055944 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:23:24,992 [Epoch: 005 Step: 00000734] Batch Translation Loss:   8.602360 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 14:24:26,664 [Epoch: 005 Step: 00000735] Batch Translation Loss:   7.560273 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:25:41,350 [Epoch: 005 Step: 00000736] Batch Translation Loss:   8.026006 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:26:42,491 [Epoch: 005 Step: 00000737] Batch Translation Loss:   7.412641 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:27:42,927 [Epoch: 005 Step: 00000738] Batch Translation Loss:   7.303773 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:28:47,226 [Epoch: 005 Step: 00000739] Batch Translation Loss:   8.326081 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:29:51,018 [Epoch: 005 Step: 00000740] Batch Translation Loss:   8.133758 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:31:01,761 [Epoch: 005 Step: 00000741] Batch Translation Loss:   7.346640 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:32:15,248 [Epoch: 005 Step: 00000742] Batch Translation Loss:   8.147511 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:33:28,631 [Epoch: 005 Step: 00000743] Batch Translation Loss:   8.187411 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:35:00,360 [Epoch: 005 Step: 00000744] Batch Translation Loss:   9.160882 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 14:36:15,080 [Epoch: 005 Step: 00000745] Batch Translation Loss:   7.376401 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 14:37:33,532 [Epoch: 005 Step: 00000746] Batch Translation Loss:   8.511286 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:38:50,624 [Epoch: 005 Step: 00000747] Batch Translation Loss:   7.166765 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 14:40:04,082 [Epoch: 005 Step: 00000748] Batch Translation Loss:   6.839921 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 14:41:21,245 [Epoch: 005 Step: 00000749] Batch Translation Loss:   7.684541 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 14:44:11,308 [Epoch: 005 Step: 00000750] Batch Translation Loss:   7.480044 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 14:45:42,262 [Epoch: 005 Step: 00000751] Batch Translation Loss:   6.970706 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 14:47:10,023 [Epoch: 005 Step: 00000752] Batch Translation Loss:   7.040771 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 14:48:02,585 [Epoch: 005 Step: 00000753] Batch Translation Loss:   8.395617 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:48:54,760 [Epoch: 005 Step: 00000754] Batch Translation Loss:   8.677690 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:49:31,112 [Epoch: 005 Step: 00000755] Batch Translation Loss:   6.950020 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:50:10,017 [Epoch: 005 Step: 00000756] Batch Translation Loss:   9.245257 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:50:52,047 [Epoch: 005 Step: 00000757] Batch Translation Loss:   7.770731 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:51:38,732 [Epoch: 005 Step: 00000758] Batch Translation Loss:   8.920790 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:52:26,348 [Epoch: 005 Step: 00000759] Batch Translation Loss:   7.190998 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:52:59,599 [Epoch: 005 Step: 00000760] Batch Translation Loss:   7.369227 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:53:38,086 [Epoch: 005 Step: 00000761] Batch Translation Loss:   8.091724 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:54:31,947 [Epoch: 005 Step: 00000762] Batch Translation Loss:   8.309627 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:55:29,024 [Epoch: 005 Step: 00000763] Batch Translation Loss:   8.380008 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:56:12,138 [Epoch: 005 Step: 00000764] Batch Translation Loss:   6.975579 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:56:54,460 [Epoch: 005 Step: 00000765] Batch Translation Loss:   7.388452 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:57:40,284 [Epoch: 005 Step: 00000766] Batch Translation Loss:   7.192367 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:58:36,403 [Epoch: 005 Step: 00000767] Batch Translation Loss:   9.592750 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 14:59:16,685 [Epoch: 005 Step: 00000768] Batch Translation Loss:   8.184549 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 15:00:02,384 [Epoch: 005 Step: 00000769] Batch Translation Loss:   8.043623 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 15:00:52,227 [Epoch: 005 Step: 00000770] Batch Translation Loss:   7.266722 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 15:02:37,304 [Epoch: 005 Step: 00000771] Batch Translation Loss:   7.359212 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 15:03:23,476 [Epoch: 005 Step: 00000772] Batch Translation Loss:   8.510035 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 15:04:22,393 [Epoch: 005 Step: 00000773] Batch Translation Loss:   8.282581 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 15:06:08,830 [Epoch: 005 Step: 00000774] Batch Translation Loss:   8.268035 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 15:06:54,530 [Epoch: 005 Step: 00000775] Batch Translation Loss:   7.183944 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 15:08:28,617 [Epoch: 005 Step: 00000776] Batch Translation Loss:   7.751745 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 15:09:29,445 [Epoch: 005 Step: 00000777] Batch Translation Loss:   7.972213 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 15:10:38,218 [Epoch: 005 Step: 00000778] Batch Translation Loss:   8.133388 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 15:12:27,600 [Epoch: 005 Step: 00000779] Batch Translation Loss:   7.515095 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 15:13:24,885 [Epoch: 005 Step: 00000780] Batch Translation Loss:   7.079469 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 15:14:32,477 [Epoch: 005 Step: 00000781] Batch Translation Loss:   8.550432 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 15:15:39,037 [Epoch: 005 Step: 00000782] Batch Translation Loss:   7.628425 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 15:16:17,380 [Epoch: 005 Step: 00000783] Batch Translation Loss:   7.404097 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 15:17:33,291 [Epoch: 005 Step: 00000784] Batch Translation Loss:   6.274669 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 15:18:46,674 [Epoch: 005 Step: 00000785] Batch Translation Loss:   7.901139 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 15:20:19,453 [Epoch: 005 Step: 00000786] Batch Translation Loss:   8.075315 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 15:21:38,856 [Epoch: 005 Step: 00000787] Batch Translation Loss:   7.185835 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 15:23:05,992 [Epoch: 005 Step: 00000788] Batch Translation Loss:   7.636583 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 15:24:46,758 [Epoch: 005 Step: 00000789] Batch Translation Loss:   8.132540 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 15:26:54,246 [Epoch: 005 Step: 00000790] Batch Translation Loss:   8.795989 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 15:27:44,749 [Epoch: 005 Step: 00000791] Batch Translation Loss:   8.290066 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 15:28:49,124 [Epoch: 005 Step: 00000792] Batch Translation Loss:   9.021557 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 15:29:58,195 [Epoch: 005 Step: 00000793] Batch Translation Loss:   7.542280 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 15:31:13,583 [Epoch: 005 Step: 00000794] Batch Translation Loss:   8.746569 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 15:32:17,471 [Epoch: 005 Step: 00000795] Batch Translation Loss:   7.388274 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 15:34:50,050 [Epoch: 005 Step: 00000796] Batch Translation Loss:   6.680434 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 15:35:41,115 [Epoch: 005 Step: 00000797] Batch Translation Loss:   7.650609 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 15:37:01,121 [Epoch: 005 Step: 00000798] Batch Translation Loss:   7.998844 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 15:38:27,598 [Epoch: 005 Step: 00000799] Batch Translation Loss:   7.407354 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 15:39:21,864 [Epoch: 005 Step: 00000800] Batch Translation Loss:   9.281043 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 15:49:29,606 Validation result at epoch   5, step      800: duration: 607.6971s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11175.87891	PPL: 6192.87891
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.17	(DEL: 25.16,	INS: 0.00,	SUB: 73.67)
	Sequence Accuracy 1.36
2022-01-02 15:49:37,251 Logging Recognition and Translation Outputs
2022-01-02 15:49:37,273 ========================================================================================================================
2022-01-02 15:49:37,273 Logging Sequence: deafvideo_2-sddsimple_1575
2022-01-02 15:49:37,273 	Text Reference  :	flash manual on
2022-01-02 15:49:37,273 	Text Hypothesis :	***** ****** so
2022-01-02 15:49:37,274 	Text Alignment  :	D     D      S 
2022-01-02 15:49:37,274 ========================================================================================================================
2022-01-02 15:49:37,274 Logging Sequence: youtube_1-catherine_mackinnon_2843
2022-01-02 15:49:37,274 	Text Reference  :	jim
2022-01-02 15:49:37,275 	Text Hypothesis :	so 
2022-01-02 15:49:37,275 	Text Alignment  :	S  
2022-01-02 15:49:37,275 ========================================================================================================================
2022-01-02 15:49:37,275 Logging Sequence: youtube_5-sean_berdy_6122
2022-01-02 15:49:37,275 	Text Reference  :	aslized
2022-01-02 15:49:37,275 	Text Hypothesis :	so     
2022-01-02 15:49:37,275 	Text Alignment  :	S      
2022-01-02 15:49:37,275 ========================================================================================================================
2022-01-02 15:49:37,275 Logging Sequence: deafvideo_2-goatman_1532
2022-01-02 15:49:37,276 	Text Reference  :	ok
2022-01-02 15:49:37,276 	Text Hypothesis :	so
2022-01-02 15:49:37,276 	Text Alignment  :	S 
2022-01-02 15:49:37,276 ========================================================================================================================
2022-01-02 15:49:37,276 Logging Sequence: deafvideo_3-yellowbirdie84_4676
2022-01-02 15:49:37,277 	Text Reference  :	hoth
2022-01-02 15:49:37,277 	Text Hypothesis :	so  
2022-01-02 15:49:37,277 	Text Alignment  :	S   
2022-01-02 15:49:37,277 ========================================================================================================================
2022-01-02 15:51:44,975 [Epoch: 005 Step: 00000801] Batch Translation Loss:   7.864387 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 15:53:26,179 [Epoch: 005 Step: 00000802] Batch Translation Loss:   8.612344 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 15:54:57,044 [Epoch: 005 Step: 00000803] Batch Translation Loss:   8.601864 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 15:56:17,496 [Epoch: 005 Step: 00000804] Batch Translation Loss:   7.174409 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 15:57:29,441 [Epoch: 005 Step: 00000805] Batch Translation Loss:   7.755100 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 15:58:55,219 [Epoch: 005 Step: 00000806] Batch Translation Loss:   8.043066 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:00:19,540 [Epoch: 005 Step: 00000807] Batch Translation Loss:   8.309338 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:01:35,831 [Epoch: 005 Step: 00000808] Batch Translation Loss:   7.833122 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:03:09,655 [Epoch: 005 Step: 00000809] Batch Translation Loss:   7.641146 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:04:36,700 [Epoch: 005 Step: 00000810] Batch Translation Loss:   7.442959 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:05:48,342 [Epoch: 005 Step: 00000811] Batch Translation Loss:   7.348477 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 16:07:11,944 [Epoch: 005 Step: 00000812] Batch Translation Loss:   9.078451 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 16:08:46,919 [Epoch: 005 Step: 00000813] Batch Translation Loss:   7.781875 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:09:51,311 [Epoch: 005 Step: 00000814] Batch Translation Loss:   7.731053 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 16:11:09,571 [Epoch: 005 Step: 00000815] Batch Translation Loss:   7.074192 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:12:28,675 [Epoch: 005 Step: 00000816] Batch Translation Loss:   6.398971 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:13:29,882 [Epoch: 005 Step: 00000817] Batch Translation Loss:   7.771324 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 16:14:43,538 [Epoch: 005 Step: 00000818] Batch Translation Loss:   6.166546 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:17:19,031 [Epoch: 005 Step: 00000819] Batch Translation Loss:   7.094079 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:18:45,162 [Epoch: 005 Step: 00000820] Batch Translation Loss:   8.777879 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:20:12,489 [Epoch: 005 Step: 00000821] Batch Translation Loss:   8.416841 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:21:40,204 [Epoch: 005 Step: 00000822] Batch Translation Loss:   8.983733 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:23:08,627 [Epoch: 005 Step: 00000823] Batch Translation Loss:   8.566698 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:24:43,690 [Epoch: 005 Step: 00000824] Batch Translation Loss:   7.166184 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:26:15,137 [Epoch: 005 Step: 00000825] Batch Translation Loss:   7.896548 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:29:14,336 [Epoch: 005 Step: 00000826] Batch Translation Loss:   7.469273 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:30:55,371 [Epoch: 005 Step: 00000827] Batch Translation Loss:   8.177223 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:32:20,325 [Epoch: 005 Step: 00000828] Batch Translation Loss:   7.023838 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:34:05,105 [Epoch: 005 Step: 00000829] Batch Translation Loss:   6.961567 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:35:26,149 [Epoch: 005 Step: 00000830] Batch Translation Loss:   7.583266 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:37:00,890 [Epoch: 005 Step: 00000831] Batch Translation Loss:   8.076034 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:38:47,793 [Epoch: 005 Step: 00000832] Batch Translation Loss:   8.256678 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:39:58,309 [Epoch: 005 Step: 00000833] Batch Translation Loss:   7.530812 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:41:21,436 [Epoch: 005 Step: 00000834] Batch Translation Loss:   7.206665 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:42:47,232 [Epoch: 005 Step: 00000835] Batch Translation Loss:   7.406858 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:44:05,188 [Epoch: 005 Step: 00000836] Batch Translation Loss:   7.973564 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 16:45:29,180 [Epoch: 005 Step: 00000837] Batch Translation Loss:   7.972654 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:46:45,154 [Epoch: 005 Step: 00000838] Batch Translation Loss:   6.770899 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:48:01,070 [Epoch: 005 Step: 00000839] Batch Translation Loss:   7.875919 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 16:49:16,344 [Epoch: 005 Step: 00000840] Batch Translation Loss:   7.059219 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:50:42,649 [Epoch: 005 Step: 00000841] Batch Translation Loss:   8.002225 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:52:05,841 [Epoch: 005 Step: 00000842] Batch Translation Loss:   8.019591 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:53:07,260 [Epoch: 005 Step: 00000843] Batch Translation Loss:   6.835790 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 16:56:15,884 [Epoch: 005 Step: 00000844] Batch Translation Loss:   6.515409 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 16:57:26,888 [Epoch: 005 Step: 00000845] Batch Translation Loss:   7.227133 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 16:58:17,948 [Epoch: 005 Step: 00000846] Batch Translation Loss:   6.428802 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 16:59:12,300 [Epoch: 005 Step: 00000847] Batch Translation Loss:   6.974783 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:00:34,628 [Epoch: 005 Step: 00000848] Batch Translation Loss:   8.316562 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:02:01,158 [Epoch: 005 Step: 00000849] Batch Translation Loss:   7.596745 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 17:04:39,913 [Epoch: 005 Step: 00000850] Batch Translation Loss:   9.131690 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 17:04:40,137 Epoch   5: Total Training Recognition Loss -1.00  Total Training Translation Loss 1339.97 
2022-01-02 17:04:40,137 EPOCH 6
2022-01-02 17:04:56,844 [Epoch: 006 Step: 00000851] Batch Translation Loss:   8.127415 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 17:05:15,859 [Epoch: 006 Step: 00000852] Batch Translation Loss:   8.196860 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 17:06:01,407 [Epoch: 006 Step: 00000853] Batch Translation Loss:   7.438440 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:06:23,454 [Epoch: 006 Step: 00000854] Batch Translation Loss:   8.666100 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 17:06:44,273 [Epoch: 006 Step: 00000855] Batch Translation Loss:  10.002422 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 17:07:04,432 [Epoch: 006 Step: 00000856] Batch Translation Loss:   8.988510 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 17:07:40,220 [Epoch: 006 Step: 00000857] Batch Translation Loss:   9.966799 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:08:06,665 [Epoch: 006 Step: 00000858] Batch Translation Loss:   8.745948 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 17:08:30,194 [Epoch: 006 Step: 00000859] Batch Translation Loss:   9.029598 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 17:09:17,849 [Epoch: 006 Step: 00000860] Batch Translation Loss:   9.952600 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:09:45,361 [Epoch: 006 Step: 00000861] Batch Translation Loss:   7.220987 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:10:28,658 [Epoch: 006 Step: 00000862] Batch Translation Loss:   7.424942 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:10:51,000 [Epoch: 006 Step: 00000863] Batch Translation Loss:   9.154413 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 17:11:34,740 [Epoch: 006 Step: 00000864] Batch Translation Loss:   9.422036 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:12:00,421 [Epoch: 006 Step: 00000865] Batch Translation Loss:   7.575016 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:12:29,253 [Epoch: 006 Step: 00000866] Batch Translation Loss:   8.282709 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 17:13:01,059 [Epoch: 006 Step: 00000867] Batch Translation Loss:   7.223732 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:13:52,034 [Epoch: 006 Step: 00000868] Batch Translation Loss:   7.641686 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:14:43,260 [Epoch: 006 Step: 00000869] Batch Translation Loss:   9.086558 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:15:12,774 [Epoch: 006 Step: 00000870] Batch Translation Loss:   7.418896 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:15:37,603 [Epoch: 006 Step: 00000871] Batch Translation Loss:   8.678809 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 17:16:07,944 [Epoch: 006 Step: 00000872] Batch Translation Loss:   9.103354 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 17:16:55,192 [Epoch: 006 Step: 00000873] Batch Translation Loss:   7.758161 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:17:20,878 [Epoch: 006 Step: 00000874] Batch Translation Loss:   8.136020 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 17:17:50,132 [Epoch: 006 Step: 00000875] Batch Translation Loss:   8.119905 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:18:18,374 [Epoch: 006 Step: 00000876] Batch Translation Loss:   8.404405 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:18:46,451 [Epoch: 006 Step: 00000877] Batch Translation Loss:   7.221109 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:19:14,926 [Epoch: 006 Step: 00000878] Batch Translation Loss:   7.562478 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:19:46,429 [Epoch: 006 Step: 00000879] Batch Translation Loss:   8.095983 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:20:06,834 [Epoch: 006 Step: 00000880] Batch Translation Loss:   7.058081 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 17:20:33,953 [Epoch: 006 Step: 00000881] Batch Translation Loss:   7.336044 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:21:36,379 [Epoch: 006 Step: 00000882] Batch Translation Loss:   8.417942 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:22:13,397 [Epoch: 006 Step: 00000883] Batch Translation Loss:   8.214485 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:23:14,835 [Epoch: 006 Step: 00000884] Batch Translation Loss:   7.561314 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:23:50,287 [Epoch: 006 Step: 00000885] Batch Translation Loss:   8.624875 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:24:32,429 [Epoch: 006 Step: 00000886] Batch Translation Loss:   8.544249 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:25:23,794 [Epoch: 006 Step: 00000887] Batch Translation Loss:   8.856688 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:26:28,113 [Epoch: 006 Step: 00000888] Batch Translation Loss:   7.568213 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:27:26,658 [Epoch: 006 Step: 00000889] Batch Translation Loss:   7.728026 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:29:08,204 [Epoch: 006 Step: 00000890] Batch Translation Loss:   6.942555 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 17:30:13,300 [Epoch: 006 Step: 00000891] Batch Translation Loss:   7.632090 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:31:13,426 [Epoch: 006 Step: 00000892] Batch Translation Loss:   7.973582 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:32:09,502 [Epoch: 006 Step: 00000893] Batch Translation Loss:   7.309083 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:33:06,054 [Epoch: 006 Step: 00000894] Batch Translation Loss:   7.841044 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:33:59,786 [Epoch: 006 Step: 00000895] Batch Translation Loss:   7.747159 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:34:54,062 [Epoch: 006 Step: 00000896] Batch Translation Loss:   7.283757 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:35:54,479 [Epoch: 006 Step: 00000897] Batch Translation Loss:   6.992813 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:36:42,219 [Epoch: 006 Step: 00000898] Batch Translation Loss:   7.458835 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:37:37,273 [Epoch: 006 Step: 00000899] Batch Translation Loss:   6.868121 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:38:38,990 [Epoch: 006 Step: 00000900] Batch Translation Loss:   7.303919 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:48:35,798 Validation result at epoch   6, step      900: duration: 596.7353s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11213.87207	PPL: 5960.58838
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.63	(DEL: 25.66,	INS: 0.00,	SUB: 72.71)
	Sequence Accuracy 1.46
2022-01-02 17:48:46,241 Logging Recognition and Translation Outputs
2022-01-02 17:48:46,279 ========================================================================================================================
2022-01-02 17:48:46,279 Logging Sequence: youtube_1-catherine_mackinnon_2813
2022-01-02 17:48:46,279 	Text Reference  :	ussr
2022-01-02 17:48:46,279 	Text Hypothesis :	asl 
2022-01-02 17:48:46,279 	Text Alignment  :	S   
2022-01-02 17:48:46,280 ========================================================================================================================
2022-01-02 17:48:46,280 Logging Sequence: youtube_5-caroline_jackson_5860
2022-01-02 17:48:46,280 	Text Reference  :	violence
2022-01-02 17:48:46,280 	Text Hypothesis :	asl     
2022-01-02 17:48:46,280 	Text Alignment  :	S       
2022-01-02 17:48:46,280 ========================================================================================================================
2022-01-02 17:48:46,280 Logging Sequence: youtube_1-don_grushkin_2315
2022-01-02 17:48:46,280 	Text Reference  :	asl
2022-01-02 17:48:46,280 	Text Hypothesis :	so 
2022-01-02 17:48:46,280 	Text Alignment  :	S  
2022-01-02 17:48:46,280 ========================================================================================================================
2022-01-02 17:48:46,280 Logging Sequence: deafvideo_5-morningstar_6258
2022-01-02 17:48:46,281 	Text Reference  :	sb
2022-01-02 17:48:46,281 	Text Hypothesis :	so
2022-01-02 17:48:46,281 	Text Alignment  :	S 
2022-01-02 17:48:46,281 ========================================================================================================================
2022-01-02 17:48:46,281 Logging Sequence: youtube_1-melvin_patterson_2340
2022-01-02 17:48:46,281 	Text Reference  :	exalted
2022-01-02 17:48:46,281 	Text Hypothesis :	so     
2022-01-02 17:48:46,281 	Text Alignment  :	S      
2022-01-02 17:48:46,281 ========================================================================================================================
2022-01-02 17:50:25,088 [Epoch: 006 Step: 00000901] Batch Translation Loss:   7.575247 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 17:51:46,880 [Epoch: 006 Step: 00000902] Batch Translation Loss:   7.939567 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 17:52:51,512 [Epoch: 006 Step: 00000903] Batch Translation Loss:   6.969577 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:54:02,244 [Epoch: 006 Step: 00000904] Batch Translation Loss:   8.598446 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:55:08,055 [Epoch: 006 Step: 00000905] Batch Translation Loss:   6.954455 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:56:28,837 [Epoch: 006 Step: 00000906] Batch Translation Loss:   6.296869 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 17:57:42,989 [Epoch: 006 Step: 00000907] Batch Translation Loss:   7.650511 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 17:59:36,502 [Epoch: 006 Step: 00000908] Batch Translation Loss:   7.187742 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 18:00:27,709 [Epoch: 006 Step: 00000909] Batch Translation Loss:   8.424660 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:01:09,124 [Epoch: 006 Step: 00000910] Batch Translation Loss:   8.323104 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:01:45,719 [Epoch: 006 Step: 00000911] Batch Translation Loss:   7.259946 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:02:22,641 [Epoch: 006 Step: 00000912] Batch Translation Loss:   7.334016 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:03:06,754 [Epoch: 006 Step: 00000913] Batch Translation Loss:   6.816366 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:03:51,588 [Epoch: 006 Step: 00000914] Batch Translation Loss:   7.559199 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:04:38,296 [Epoch: 006 Step: 00000915] Batch Translation Loss:   7.953513 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:05:30,978 [Epoch: 006 Step: 00000916] Batch Translation Loss:   6.762134 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:06:12,384 [Epoch: 006 Step: 00000917] Batch Translation Loss:   7.524386 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:07:39,508 [Epoch: 006 Step: 00000918] Batch Translation Loss:   7.454939 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 18:08:26,467 [Epoch: 006 Step: 00000919] Batch Translation Loss:   6.791581 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:09:10,231 [Epoch: 006 Step: 00000920] Batch Translation Loss:   6.711390 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:09:48,761 [Epoch: 006 Step: 00000921] Batch Translation Loss:   6.636036 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:10:36,852 [Epoch: 006 Step: 00000922] Batch Translation Loss:   7.564804 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:11:12,492 [Epoch: 006 Step: 00000923] Batch Translation Loss:   7.606962 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:12:00,504 [Epoch: 006 Step: 00000924] Batch Translation Loss:   8.174340 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:12:48,748 [Epoch: 006 Step: 00000925] Batch Translation Loss:   8.195972 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:13:32,299 [Epoch: 006 Step: 00000926] Batch Translation Loss:   7.424723 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:14:12,867 [Epoch: 006 Step: 00000927] Batch Translation Loss:   7.138198 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:14:46,851 [Epoch: 006 Step: 00000928] Batch Translation Loss:   7.605390 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:15:23,463 [Epoch: 006 Step: 00000929] Batch Translation Loss:   6.167817 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:15:58,255 [Epoch: 006 Step: 00000930] Batch Translation Loss:   7.298289 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:17:18,411 [Epoch: 006 Step: 00000931] Batch Translation Loss:   7.964426 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:18:17,376 [Epoch: 006 Step: 00000932] Batch Translation Loss:   7.675404 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:20:00,263 [Epoch: 006 Step: 00000933] Batch Translation Loss:   7.595066 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 18:20:43,721 [Epoch: 006 Step: 00000934] Batch Translation Loss:   6.619534 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:21:27,178 [Epoch: 006 Step: 00000935] Batch Translation Loss:   8.174069 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:22:15,950 [Epoch: 006 Step: 00000936] Batch Translation Loss:   7.504548 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:23:13,442 [Epoch: 006 Step: 00000937] Batch Translation Loss:   8.603175 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:24:02,308 [Epoch: 006 Step: 00000938] Batch Translation Loss:   8.603361 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:24:55,255 [Epoch: 006 Step: 00000939] Batch Translation Loss:   6.788037 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:25:45,579 [Epoch: 006 Step: 00000940] Batch Translation Loss:   8.085700 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:26:44,542 [Epoch: 006 Step: 00000941] Batch Translation Loss:   7.644454 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:27:48,899 [Epoch: 006 Step: 00000942] Batch Translation Loss:   7.439321 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:28:39,996 [Epoch: 006 Step: 00000943] Batch Translation Loss:   7.227891 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:29:42,131 [Epoch: 006 Step: 00000944] Batch Translation Loss:   6.971652 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:30:20,411 [Epoch: 006 Step: 00000945] Batch Translation Loss:   7.446685 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:31:11,685 [Epoch: 006 Step: 00000946] Batch Translation Loss:   7.281333 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:32:12,477 [Epoch: 006 Step: 00000947] Batch Translation Loss:   6.853359 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:33:20,114 [Epoch: 006 Step: 00000948] Batch Translation Loss:   7.649301 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:34:23,973 [Epoch: 006 Step: 00000949] Batch Translation Loss:   7.323227 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:35:24,645 [Epoch: 006 Step: 00000950] Batch Translation Loss:   7.565716 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:36:30,243 [Epoch: 006 Step: 00000951] Batch Translation Loss:   7.709852 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:37:39,250 [Epoch: 006 Step: 00000952] Batch Translation Loss:   7.147721 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 18:38:48,733 [Epoch: 006 Step: 00000953] Batch Translation Loss:   8.656782 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:39:50,011 [Epoch: 006 Step: 00000954] Batch Translation Loss:   7.619107 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:40:59,492 [Epoch: 006 Step: 00000955] Batch Translation Loss:   8.106492 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:42:08,430 [Epoch: 006 Step: 00000956] Batch Translation Loss:   6.952786 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 18:43:10,360 [Epoch: 006 Step: 00000957] Batch Translation Loss:   6.102345 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:44:09,844 [Epoch: 006 Step: 00000958] Batch Translation Loss:   8.187047 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:44:37,215 [Epoch: 006 Step: 00000959] Batch Translation Loss:   7.560047 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:47:18,437 [Epoch: 006 Step: 00000960] Batch Translation Loss:   7.400272 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 18:49:35,735 [Epoch: 006 Step: 00000961] Batch Translation Loss:   8.246019 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 18:51:00,700 [Epoch: 006 Step: 00000962] Batch Translation Loss:   8.115532 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 18:51:58,473 [Epoch: 006 Step: 00000963] Batch Translation Loss:   8.239565 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:52:44,704 [Epoch: 006 Step: 00000964] Batch Translation Loss:   7.698653 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:53:34,285 [Epoch: 006 Step: 00000965] Batch Translation Loss:   7.886556 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:54:33,917 [Epoch: 006 Step: 00000966] Batch Translation Loss:   7.155653 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:55:27,253 [Epoch: 006 Step: 00000967] Batch Translation Loss:   7.065970 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:56:58,280 [Epoch: 006 Step: 00000968] Batch Translation Loss:   7.356676 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 18:57:51,930 [Epoch: 006 Step: 00000969] Batch Translation Loss:   7.775064 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 18:59:05,566 [Epoch: 006 Step: 00000970] Batch Translation Loss:   7.569865 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 19:00:08,962 [Epoch: 006 Step: 00000971] Batch Translation Loss:   6.852182 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 19:01:16,633 [Epoch: 006 Step: 00000972] Batch Translation Loss:   6.760273 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 19:03:15,449 [Epoch: 006 Step: 00000973] Batch Translation Loss:   6.472720 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 19:04:21,335 [Epoch: 006 Step: 00000974] Batch Translation Loss:   7.165895 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 19:05:25,827 [Epoch: 006 Step: 00000975] Batch Translation Loss:   7.539894 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 19:06:39,998 [Epoch: 006 Step: 00000976] Batch Translation Loss:   7.281080 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 19:07:46,781 [Epoch: 006 Step: 00000977] Batch Translation Loss:   7.888068 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 19:12:02,141 [Epoch: 006 Step: 00000978] Batch Translation Loss:   6.963589 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 19:13:50,590 [Epoch: 006 Step: 00000979] Batch Translation Loss:   7.457047 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 19:15:40,585 [Epoch: 006 Step: 00000980] Batch Translation Loss:   7.614927 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 19:17:29,231 [Epoch: 006 Step: 00000981] Batch Translation Loss:   7.903642 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 19:19:21,604 [Epoch: 006 Step: 00000982] Batch Translation Loss:   6.949327 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 19:21:21,292 [Epoch: 006 Step: 00000983] Batch Translation Loss:   7.545256 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 19:23:09,459 [Epoch: 006 Step: 00000984] Batch Translation Loss:   8.802858 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 19:25:08,685 [Epoch: 006 Step: 00000985] Batch Translation Loss:   6.915113 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 19:27:39,673 [Epoch: 006 Step: 00000986] Batch Translation Loss:   6.759236 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 19:30:08,152 [Epoch: 006 Step: 00000987] Batch Translation Loss:   6.880023 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 19:32:25,986 [Epoch: 006 Step: 00000988] Batch Translation Loss:   7.402853 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 19:34:24,505 [Epoch: 006 Step: 00000989] Batch Translation Loss:   6.523340 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 19:36:58,291 [Epoch: 006 Step: 00000990] Batch Translation Loss:   7.935925 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 19:39:13,995 [Epoch: 006 Step: 00000991] Batch Translation Loss:   6.843521 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 19:41:24,596 [Epoch: 006 Step: 00000992] Batch Translation Loss:   7.005798 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 19:43:32,442 [Epoch: 006 Step: 00000993] Batch Translation Loss:   7.574740 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 19:45:24,374 [Epoch: 006 Step: 00000994] Batch Translation Loss:   7.417814 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 19:47:37,220 [Epoch: 006 Step: 00000995] Batch Translation Loss:   7.423309 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 19:50:01,181 [Epoch: 006 Step: 00000996] Batch Translation Loss:   6.302841 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 19:52:32,841 [Epoch: 006 Step: 00000997] Batch Translation Loss:   7.697486 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 19:54:53,807 [Epoch: 006 Step: 00000998] Batch Translation Loss:   8.179885 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 19:59:13,920 [Epoch: 006 Step: 00000999] Batch Translation Loss:   7.635514 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 20:01:23,851 [Epoch: 006 Step: 00001000] Batch Translation Loss:   8.075199 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 20:12:14,540 Validation result at epoch   6, step     1000: duration: 650.6555s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 10735.29785	PPL: 5556.53125
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.37	(DEL: 22.09,	INS: 0.00,	SUB: 76.55)
	Sequence Accuracy 1.75
2022-01-02 20:12:25,047 Logging Recognition and Translation Outputs
2022-01-02 20:12:25,146 ========================================================================================================================
2022-01-02 20:12:25,146 Logging Sequence: youtube_1-catherine_mackinnon_2788
2022-01-02 20:12:25,146 	Text Reference  :	matseale
2022-01-02 20:12:25,146 	Text Hypothesis :	handling
2022-01-02 20:12:25,146 	Text Alignment  :	S       
2022-01-02 20:12:25,147 ========================================================================================================================
2022-01-02 20:12:25,147 Logging Sequence: youtube_1-don_grushkin_2312
2022-01-02 20:12:25,147 	Text Reference  :	be
2022-01-02 20:12:25,147 	Text Hypothesis :	if
2022-01-02 20:12:25,147 	Text Alignment  :	S 
2022-01-02 20:12:25,147 ========================================================================================================================
2022-01-02 20:12:25,147 Logging Sequence: youtube_1-catherine_mackinnon_2832
2022-01-02 20:12:25,147 	Text Reference  :	johnson cty tenn 
2022-01-02 20:12:25,148 	Text Hypothesis :	******* *** nerda
2022-01-02 20:12:25,148 	Text Alignment  :	D       D   S    
2022-01-02 20:12:25,148 ========================================================================================================================
2022-01-02 20:12:25,148 Logging Sequence: deafvideo_3-titans_4693
2022-01-02 20:12:25,148 	Text Reference  :	unin
2022-01-02 20:12:25,148 	Text Hypothesis :	if  
2022-01-02 20:12:25,148 	Text Alignment  :	S   
2022-01-02 20:12:25,148 ========================================================================================================================
2022-01-02 20:12:25,148 Logging Sequence: deafvideo_3-titans_4703
2022-01-02 20:12:25,148 	Text Reference  :	out
2022-01-02 20:12:25,148 	Text Hypothesis :	if 
2022-01-02 20:12:25,149 	Text Alignment  :	S  
2022-01-02 20:12:25,149 ========================================================================================================================
2022-01-02 20:14:34,212 [Epoch: 006 Step: 00001001] Batch Translation Loss:   7.930688 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 20:16:59,376 [Epoch: 006 Step: 00001002] Batch Translation Loss:   6.851024 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 20:19:32,140 [Epoch: 006 Step: 00001003] Batch Translation Loss:   6.607576 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 20:23:49,637 [Epoch: 006 Step: 00001004] Batch Translation Loss:   7.114240 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 20:25:48,682 [Epoch: 006 Step: 00001005] Batch Translation Loss:   6.473667 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 20:28:13,456 [Epoch: 006 Step: 00001006] Batch Translation Loss:   7.628026 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 20:30:06,804 [Epoch: 006 Step: 00001007] Batch Translation Loss:   6.584691 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 20:32:12,786 [Epoch: 006 Step: 00001008] Batch Translation Loss:   8.145493 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 20:37:11,814 [Epoch: 006 Step: 00001009] Batch Translation Loss:   7.293213 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 20:39:01,593 [Epoch: 006 Step: 00001010] Batch Translation Loss:   7.170002 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 20:41:00,176 [Epoch: 006 Step: 00001011] Batch Translation Loss:   6.297769 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 20:43:07,117 [Epoch: 006 Step: 00001012] Batch Translation Loss:   8.197700 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 20:45:25,976 [Epoch: 006 Step: 00001013] Batch Translation Loss:   6.792601 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 20:50:02,996 [Epoch: 006 Step: 00001014] Batch Translation Loss:   7.737192 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 20:52:31,431 [Epoch: 006 Step: 00001015] Batch Translation Loss:   6.852144 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 20:54:41,815 [Epoch: 006 Step: 00001016] Batch Translation Loss:   6.179166 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 20:56:41,187 [Epoch: 006 Step: 00001017] Batch Translation Loss:   6.778862 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 21:00:53,479 [Epoch: 006 Step: 00001018] Batch Translation Loss:   6.812453 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 21:03:33,659 [Epoch: 006 Step: 00001019] Batch Translation Loss:   8.329576 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 21:05:57,197 [Epoch: 006 Step: 00001020] Batch Translation Loss:   7.877168 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 21:05:57,481 Epoch   6: Total Training Recognition Loss -1.00  Total Training Translation Loss 1292.80 
2022-01-02 21:05:57,482 EPOCH 7
2022-01-02 21:06:23,417 [Epoch: 007 Step: 00001021] Batch Translation Loss:   6.931817 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:06:59,773 [Epoch: 007 Step: 00001022] Batch Translation Loss:   8.469879 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:07:50,845 [Epoch: 007 Step: 00001023] Batch Translation Loss:   7.914061 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:09:00,328 [Epoch: 007 Step: 00001024] Batch Translation Loss:   7.679707 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:09:42,273 [Epoch: 007 Step: 00001025] Batch Translation Loss:   6.872027 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:10:47,709 [Epoch: 007 Step: 00001026] Batch Translation Loss:   6.882185 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:11:59,301 [Epoch: 007 Step: 00001027] Batch Translation Loss:   9.136774 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:12:51,736 [Epoch: 007 Step: 00001028] Batch Translation Loss:   7.730834 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:13:37,322 [Epoch: 007 Step: 00001029] Batch Translation Loss:   8.397254 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:14:50,159 [Epoch: 007 Step: 00001030] Batch Translation Loss:   7.302320 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:15:53,329 [Epoch: 007 Step: 00001031] Batch Translation Loss:   6.567727 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:16:29,766 [Epoch: 007 Step: 00001032] Batch Translation Loss:   8.831846 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:17:21,984 [Epoch: 007 Step: 00001033] Batch Translation Loss:   8.480788 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:17:55,425 [Epoch: 007 Step: 00001034] Batch Translation Loss:   8.244282 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:18:39,665 [Epoch: 007 Step: 00001035] Batch Translation Loss:   6.791577 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:19:35,660 [Epoch: 007 Step: 00001036] Batch Translation Loss:   7.080045 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:20:40,916 [Epoch: 007 Step: 00001037] Batch Translation Loss:   7.073429 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:21:19,824 [Epoch: 007 Step: 00001038] Batch Translation Loss:   7.541070 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:22:17,914 [Epoch: 007 Step: 00001039] Batch Translation Loss:   6.536250 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:22:59,223 [Epoch: 007 Step: 00001040] Batch Translation Loss:   7.137517 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:23:38,975 [Epoch: 007 Step: 00001041] Batch Translation Loss:   7.786729 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:24:28,597 [Epoch: 007 Step: 00001042] Batch Translation Loss:   7.898956 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:25:24,541 [Epoch: 007 Step: 00001043] Batch Translation Loss:   8.305854 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:26:38,664 [Epoch: 007 Step: 00001044] Batch Translation Loss:   7.248475 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:27:26,803 [Epoch: 007 Step: 00001045] Batch Translation Loss:   7.122350 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:28:15,465 [Epoch: 007 Step: 00001046] Batch Translation Loss:   7.046436 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:29:12,568 [Epoch: 007 Step: 00001047] Batch Translation Loss:   7.631531 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:30:03,194 [Epoch: 007 Step: 00001048] Batch Translation Loss:   7.098655 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:30:51,527 [Epoch: 007 Step: 00001049] Batch Translation Loss:   7.128157 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:31:38,030 [Epoch: 007 Step: 00001050] Batch Translation Loss:   6.162469 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:32:20,111 [Epoch: 007 Step: 00001051] Batch Translation Loss:   7.347511 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:33:19,446 [Epoch: 007 Step: 00001052] Batch Translation Loss:   7.114351 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:34:16,551 [Epoch: 007 Step: 00001053] Batch Translation Loss:   7.327852 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:35:01,505 [Epoch: 007 Step: 00001054] Batch Translation Loss:   7.570617 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:35:33,205 [Epoch: 007 Step: 00001055] Batch Translation Loss:   7.390077 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:36:04,666 [Epoch: 007 Step: 00001056] Batch Translation Loss:   6.567018 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:36:42,942 [Epoch: 007 Step: 00001057] Batch Translation Loss:   7.299860 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:37:17,245 [Epoch: 007 Step: 00001058] Batch Translation Loss:   7.052448 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:38:08,550 [Epoch: 007 Step: 00001059] Batch Translation Loss:  10.065006 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:38:36,047 [Epoch: 007 Step: 00001060] Batch Translation Loss:   7.479038 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 21:39:07,515 [Epoch: 007 Step: 00001061] Batch Translation Loss:   7.381629 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:39:38,894 [Epoch: 007 Step: 00001062] Batch Translation Loss:   7.298676 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:40:05,915 [Epoch: 007 Step: 00001063] Batch Translation Loss:   7.303004 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:40:36,762 [Epoch: 007 Step: 00001064] Batch Translation Loss:   7.338899 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:41:04,983 [Epoch: 007 Step: 00001065] Batch Translation Loss:   7.347347 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 21:42:05,625 [Epoch: 007 Step: 00001066] Batch Translation Loss:   6.888801 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:42:40,984 [Epoch: 007 Step: 00001067] Batch Translation Loss:   7.762969 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:43:21,840 [Epoch: 007 Step: 00001068] Batch Translation Loss:   7.930871 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:44:08,612 [Epoch: 007 Step: 00001069] Batch Translation Loss:   8.212794 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:44:39,130 [Epoch: 007 Step: 00001070] Batch Translation Loss:   8.092078 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:45:12,272 [Epoch: 007 Step: 00001071] Batch Translation Loss:   7.314666 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:45:59,769 [Epoch: 007 Step: 00001072] Batch Translation Loss:   6.920515 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:46:35,092 [Epoch: 007 Step: 00001073] Batch Translation Loss:   7.925689 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:46:56,654 [Epoch: 007 Step: 00001074] Batch Translation Loss:   7.511085 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 21:47:25,211 [Epoch: 007 Step: 00001075] Batch Translation Loss:   8.714802 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 21:47:56,267 [Epoch: 007 Step: 00001076] Batch Translation Loss:   7.733860 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:48:37,663 [Epoch: 007 Step: 00001077] Batch Translation Loss:   6.940708 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:49:13,664 [Epoch: 007 Step: 00001078] Batch Translation Loss:   7.489346 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:50:19,619 [Epoch: 007 Step: 00001079] Batch Translation Loss:   8.899508 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:51:01,162 [Epoch: 007 Step: 00001080] Batch Translation Loss:   8.206345 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:51:50,093 [Epoch: 007 Step: 00001081] Batch Translation Loss:   6.171347 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:52:42,250 [Epoch: 007 Step: 00001082] Batch Translation Loss:   7.001343 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:53:30,942 [Epoch: 007 Step: 00001083] Batch Translation Loss:   7.374010 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:53:58,459 [Epoch: 007 Step: 00001084] Batch Translation Loss:   7.367389 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 21:55:03,688 [Epoch: 007 Step: 00001085] Batch Translation Loss:   7.852972 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:55:45,408 [Epoch: 007 Step: 00001086] Batch Translation Loss:   7.353689 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:56:29,852 [Epoch: 007 Step: 00001087] Batch Translation Loss:   7.415339 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:56:59,977 [Epoch: 007 Step: 00001088] Batch Translation Loss:   7.514598 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:57:31,253 [Epoch: 007 Step: 00001089] Batch Translation Loss:   5.916137 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:58:09,223 [Epoch: 007 Step: 00001090] Batch Translation Loss:   6.551519 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:58:49,307 [Epoch: 007 Step: 00001091] Batch Translation Loss:   7.016160 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 21:59:30,755 [Epoch: 007 Step: 00001092] Batch Translation Loss:   6.424709 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:00:04,375 [Epoch: 007 Step: 00001093] Batch Translation Loss:   6.778783 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:00:48,363 [Epoch: 007 Step: 00001094] Batch Translation Loss:   7.488549 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:01:38,856 [Epoch: 007 Step: 00001095] Batch Translation Loss:   7.316365 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:03:10,454 [Epoch: 007 Step: 00001096] Batch Translation Loss:   7.285714 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 22:04:17,565 [Epoch: 007 Step: 00001097] Batch Translation Loss:   6.688207 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:05:13,879 [Epoch: 007 Step: 00001098] Batch Translation Loss:   8.081363 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:06:05,046 [Epoch: 007 Step: 00001099] Batch Translation Loss:   6.708145 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:07:01,404 [Epoch: 007 Step: 00001100] Batch Translation Loss:   6.699976 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:17:23,568 Hooray! New best validation result [eval_metric]!
2022-01-02 22:17:24,018 Saving new checkpoint.
2022-01-02 22:17:28,026 Validation result at epoch   7, step     1100: duration: 626.5831s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 10709.25391	PPL: 6261.96045
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 2.61	(DEL: 21.96,	INS: 0.00,	SUB: 75.43)
	Sequence Accuracy 2.72
2022-01-02 22:17:36,414 Logging Recognition and Translation Outputs
2022-01-02 22:17:36,433 ========================================================================================================================
2022-01-02 22:17:36,434 Logging Sequence: deafvideo_4-tax_tips_by_irs_4958
2022-01-02 22:17:36,434 	Text Reference  :	it
2022-01-02 22:17:36,434 	Text Hypothesis :	ok
2022-01-02 22:17:36,434 	Text Alignment  :	S 
2022-01-02 22:17:36,434 ========================================================================================================================
2022-01-02 22:17:36,435 Logging Sequence: deafvideo_5-silentoneye_7323
2022-01-02 22:17:36,435 	Text Reference  :	season
2022-01-02 22:17:36,435 	Text Hypothesis :	ok    
2022-01-02 22:17:36,435 	Text Alignment  :	S     
2022-01-02 22:17:36,435 ========================================================================================================================
2022-01-02 22:17:36,435 Logging Sequence: youtube_1-melvin_patterson_2367
2022-01-02 22:17:36,435 	Text Reference  :	xray o 
2022-01-02 22:17:36,435 	Text Hypothesis :	**** ok
2022-01-02 22:17:36,435 	Text Alignment  :	D    S 
2022-01-02 22:17:36,436 ========================================================================================================================
2022-01-02 22:17:36,436 Logging Sequence: youtube_4-tim_albert_5284
2022-01-02 22:17:36,436 	Text Reference  :	dc 
2022-01-02 22:17:36,436 	Text Hypothesis :	asl
2022-01-02 22:17:36,436 	Text Alignment  :	S  
2022-01-02 22:17:36,436 ========================================================================================================================
2022-01-02 22:17:36,436 Logging Sequence: youtube_1-shoshannah_stern_2374
2022-01-02 22:17:36,436 	Text Reference  :	asl
2022-01-02 22:17:36,436 	Text Hypothesis :	ok 
2022-01-02 22:17:36,436 	Text Alignment  :	S  
2022-01-02 22:17:36,436 ========================================================================================================================
2022-01-02 22:19:02,648 [Epoch: 007 Step: 00001101] Batch Translation Loss:   7.004278 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 22:20:06,415 [Epoch: 007 Step: 00001102] Batch Translation Loss:   7.152880 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:21:36,564 [Epoch: 007 Step: 00001103] Batch Translation Loss:   6.964242 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 22:23:16,780 [Epoch: 007 Step: 00001104] Batch Translation Loss:   9.282044 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 22:24:13,100 [Epoch: 007 Step: 00001105] Batch Translation Loss:   7.341918 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:25:04,857 [Epoch: 007 Step: 00001106] Batch Translation Loss:   7.451525 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:25:44,282 [Epoch: 007 Step: 00001107] Batch Translation Loss:   7.517488 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:26:37,031 [Epoch: 007 Step: 00001108] Batch Translation Loss:   7.288649 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:27:34,478 [Epoch: 007 Step: 00001109] Batch Translation Loss:   7.925445 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:28:29,268 [Epoch: 007 Step: 00001110] Batch Translation Loss:   8.603848 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:29:11,980 [Epoch: 007 Step: 00001111] Batch Translation Loss:   7.765366 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:29:44,191 [Epoch: 007 Step: 00001112] Batch Translation Loss:   6.887169 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:30:23,626 [Epoch: 007 Step: 00001113] Batch Translation Loss:   6.819176 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:31:11,429 [Epoch: 007 Step: 00001114] Batch Translation Loss:   6.639884 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:32:38,943 [Epoch: 007 Step: 00001115] Batch Translation Loss:   6.913936 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 22:33:53,631 [Epoch: 007 Step: 00001116] Batch Translation Loss:   7.510032 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:35:25,547 [Epoch: 007 Step: 00001117] Batch Translation Loss:   7.757484 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 22:36:24,676 [Epoch: 007 Step: 00001118] Batch Translation Loss:   7.033453 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:37:13,799 [Epoch: 007 Step: 00001119] Batch Translation Loss:   6.794481 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:37:54,295 [Epoch: 007 Step: 00001120] Batch Translation Loss:   6.919638 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:38:44,891 [Epoch: 007 Step: 00001121] Batch Translation Loss:   7.636846 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:39:13,883 [Epoch: 007 Step: 00001122] Batch Translation Loss:   7.036268 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:39:41,704 [Epoch: 007 Step: 00001123] Batch Translation Loss:   7.082013 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:40:11,500 [Epoch: 007 Step: 00001124] Batch Translation Loss:   6.275538 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:40:41,859 [Epoch: 007 Step: 00001125] Batch Translation Loss:   6.513311 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:41:12,929 [Epoch: 007 Step: 00001126] Batch Translation Loss:   6.653766 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:41:44,328 [Epoch: 007 Step: 00001127] Batch Translation Loss:   7.209054 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:42:13,133 [Epoch: 007 Step: 00001128] Batch Translation Loss:   6.463196 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:42:42,183 [Epoch: 007 Step: 00001129] Batch Translation Loss:   7.566699 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:43:14,990 [Epoch: 007 Step: 00001130] Batch Translation Loss:   7.054164 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:43:48,061 [Epoch: 007 Step: 00001131] Batch Translation Loss:   6.591051 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:44:20,275 [Epoch: 007 Step: 00001132] Batch Translation Loss:   7.138984 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:44:51,639 [Epoch: 007 Step: 00001133] Batch Translation Loss:   6.807130 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:45:19,243 [Epoch: 007 Step: 00001134] Batch Translation Loss:   7.025474 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:45:57,091 [Epoch: 007 Step: 00001135] Batch Translation Loss:   6.860033 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:46:27,647 [Epoch: 007 Step: 00001136] Batch Translation Loss:   7.040675 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:47:14,341 [Epoch: 007 Step: 00001137] Batch Translation Loss:   7.788521 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:47:41,330 [Epoch: 007 Step: 00001138] Batch Translation Loss:   7.340105 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:48:17,976 [Epoch: 007 Step: 00001139] Batch Translation Loss:   7.429553 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:48:51,839 [Epoch: 007 Step: 00001140] Batch Translation Loss:   7.649935 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:49:26,118 [Epoch: 007 Step: 00001141] Batch Translation Loss:   6.554578 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:50:20,525 [Epoch: 007 Step: 00001142] Batch Translation Loss:   7.403505 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:50:58,436 [Epoch: 007 Step: 00001143] Batch Translation Loss:   6.924956 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:51:34,683 [Epoch: 007 Step: 00001144] Batch Translation Loss:   7.640282 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:52:13,160 [Epoch: 007 Step: 00001145] Batch Translation Loss:   6.437973 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:52:44,474 [Epoch: 007 Step: 00001146] Batch Translation Loss:   7.606935 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:53:09,833 [Epoch: 007 Step: 00001147] Batch Translation Loss:   7.053008 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 22:53:52,479 [Epoch: 007 Step: 00001148] Batch Translation Loss:   5.989906 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:54:58,294 [Epoch: 007 Step: 00001149] Batch Translation Loss:   6.713640 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:55:33,876 [Epoch: 007 Step: 00001150] Batch Translation Loss:   7.103133 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:56:08,918 [Epoch: 007 Step: 00001151] Batch Translation Loss:   7.038038 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:56:48,011 [Epoch: 007 Step: 00001152] Batch Translation Loss:   6.295943 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:57:27,634 [Epoch: 007 Step: 00001153] Batch Translation Loss:   6.945265 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:58:00,880 [Epoch: 007 Step: 00001154] Batch Translation Loss:   7.361199 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:58:30,834 [Epoch: 007 Step: 00001155] Batch Translation Loss:   7.663874 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:59:15,479 [Epoch: 007 Step: 00001156] Batch Translation Loss:   7.600697 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 22:59:58,328 [Epoch: 007 Step: 00001157] Batch Translation Loss:   7.288438 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:01:06,395 [Epoch: 007 Step: 00001158] Batch Translation Loss:   6.757129 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 23:01:42,415 [Epoch: 007 Step: 00001159] Batch Translation Loss:   7.333855 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:02:20,292 [Epoch: 007 Step: 00001160] Batch Translation Loss:   7.454513 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:03:05,295 [Epoch: 007 Step: 00001161] Batch Translation Loss:   7.613880 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:03:44,607 [Epoch: 007 Step: 00001162] Batch Translation Loss:   7.228080 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:04:13,749 [Epoch: 007 Step: 00001163] Batch Translation Loss:   7.402835 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:05:04,478 [Epoch: 007 Step: 00001164] Batch Translation Loss:   6.959165 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:05:44,048 [Epoch: 007 Step: 00001165] Batch Translation Loss:   6.396806 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:06:18,747 [Epoch: 007 Step: 00001166] Batch Translation Loss:   6.648623 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:06:50,523 [Epoch: 007 Step: 00001167] Batch Translation Loss:   7.379270 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:07:36,967 [Epoch: 007 Step: 00001168] Batch Translation Loss:   7.358805 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:08:19,238 [Epoch: 007 Step: 00001169] Batch Translation Loss:   6.422673 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:08:58,881 [Epoch: 007 Step: 00001170] Batch Translation Loss:   7.064952 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:09:36,897 [Epoch: 007 Step: 00001171] Batch Translation Loss:   5.942863 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:10:23,557 [Epoch: 007 Step: 00001172] Batch Translation Loss:   7.203779 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:11:06,609 [Epoch: 007 Step: 00001173] Batch Translation Loss:   6.206689 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:11:45,531 [Epoch: 007 Step: 00001174] Batch Translation Loss:   6.171595 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:12:21,127 [Epoch: 007 Step: 00001175] Batch Translation Loss:   7.277205 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:13:03,813 [Epoch: 007 Step: 00001176] Batch Translation Loss:   6.960065 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:14:23,747 [Epoch: 007 Step: 00001177] Batch Translation Loss:   6.802663 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 23:15:03,869 [Epoch: 007 Step: 00001178] Batch Translation Loss:   8.281300 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:15:31,702 [Epoch: 007 Step: 00001179] Batch Translation Loss:   6.339113 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:15:59,377 [Epoch: 007 Step: 00001180] Batch Translation Loss:   6.800132 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:17:19,849 [Epoch: 007 Step: 00001181] Batch Translation Loss:   6.776558 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 23:18:03,094 [Epoch: 007 Step: 00001182] Batch Translation Loss:   7.087786 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:18:40,907 [Epoch: 007 Step: 00001183] Batch Translation Loss:   6.596488 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:19:13,291 [Epoch: 007 Step: 00001184] Batch Translation Loss:   6.710427 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:19:59,424 [Epoch: 007 Step: 00001185] Batch Translation Loss:   7.023387 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:20:40,892 [Epoch: 007 Step: 00001186] Batch Translation Loss:   9.017129 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:21:22,964 [Epoch: 007 Step: 00001187] Batch Translation Loss:   6.597777 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:22:03,207 [Epoch: 007 Step: 00001188] Batch Translation Loss:   7.661128 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:22:34,266 [Epoch: 007 Step: 00001189] Batch Translation Loss:   6.983835 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:23:48,388 [Epoch: 007 Step: 00001190] Batch Translation Loss:   9.181205 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 23:23:48,594 Epoch   7: Total Training Recognition Loss -1.00  Total Training Translation Loss 1236.46 
2022-01-02 23:23:48,594 EPOCH 8
2022-01-02 23:23:58,554 [Epoch: 008 Step: 00001191] Batch Translation Loss:   6.994609 => Txt Tokens per Sec:        4 || Lr: 0.001000
2022-01-02 23:24:08,835 [Epoch: 008 Step: 00001192] Batch Translation Loss:   7.796028 => Txt Tokens per Sec:        4 || Lr: 0.001000
2022-01-02 23:24:25,988 [Epoch: 008 Step: 00001193] Batch Translation Loss:   8.112443 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 23:24:38,254 [Epoch: 008 Step: 00001194] Batch Translation Loss:   8.031846 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 23:24:51,551 [Epoch: 008 Step: 00001195] Batch Translation Loss:   7.866006 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 23:25:02,853 [Epoch: 008 Step: 00001196] Batch Translation Loss:   7.426590 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 23:25:15,345 [Epoch: 008 Step: 00001197] Batch Translation Loss:   8.289256 => Txt Tokens per Sec:        4 || Lr: 0.001000
2022-01-02 23:25:27,102 [Epoch: 008 Step: 00001198] Batch Translation Loss:   8.098207 => Txt Tokens per Sec:        4 || Lr: 0.001000
2022-01-02 23:25:40,202 [Epoch: 008 Step: 00001199] Batch Translation Loss:   8.641195 => Txt Tokens per Sec:        4 || Lr: 0.001000
2022-01-02 23:25:58,798 [Epoch: 008 Step: 00001200] Batch Translation Loss:   7.942580 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 23:34:52,117 Hooray! New best validation result [eval_metric]!
2022-01-02 23:34:52,441 Saving new checkpoint.
2022-01-02 23:34:55,449 Validation result at epoch   8, step     1200: duration: 536.6349s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11073.94824	PPL: 6206.77930
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 3.08	(DEL: 24.84,	INS: 0.00,	SUB: 72.08)
	Sequence Accuracy 2.20
2022-01-02 23:35:02,940 Logging Recognition and Translation Outputs
2022-01-02 23:35:02,970 ========================================================================================================================
2022-01-02 23:35:02,971 Logging Sequence: deafvideo_3-fieldstreamasl_4039
2022-01-02 23:35:02,971 	Text Reference  :	of
2022-01-02 23:35:02,971 	Text Hypothesis :	so
2022-01-02 23:35:02,971 	Text Alignment  :	S 
2022-01-02 23:35:02,971 ========================================================================================================================
2022-01-02 23:35:02,971 Logging Sequence: youtube_5-sean_berdy_6113
2022-01-02 23:35:02,971 	Text Reference  :	hurt
2022-01-02 23:35:02,971 	Text Hypothesis :	asl 
2022-01-02 23:35:02,972 	Text Alignment  :	S   
2022-01-02 23:35:02,972 ========================================================================================================================
2022-01-02 23:35:02,972 Logging Sequence: deafvideo_3-geoalpha_4550
2022-01-02 23:35:02,972 	Text Reference  :	sty lafnce
2022-01-02 23:35:02,972 	Text Hypothesis :	*** asl   
2022-01-02 23:35:02,972 	Text Alignment  :	D   S     
2022-01-02 23:35:02,972 ========================================================================================================================
2022-01-02 23:35:02,972 Logging Sequence: youtube_4-howard_rosenblum_5578
2022-01-02 23:35:02,972 	Text Reference  :	ada
2022-01-02 23:35:02,972 	Text Hypothesis :	asl
2022-01-02 23:35:02,972 	Text Alignment  :	S  
2022-01-02 23:35:02,973 ========================================================================================================================
2022-01-02 23:35:02,973 Logging Sequence: youtube_5-debra_patkin_5786
2022-01-02 23:35:02,973 	Text Reference  :	or
2022-01-02 23:35:02,973 	Text Hypothesis :	so
2022-01-02 23:35:02,973 	Text Alignment  :	S 
2022-01-02 23:35:02,973 ========================================================================================================================
2022-01-02 23:35:36,037 [Epoch: 008 Step: 00001201] Batch Translation Loss:   7.391189 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:36:24,474 [Epoch: 008 Step: 00001202] Batch Translation Loss:   6.519174 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:36:51,705 [Epoch: 008 Step: 00001203] Batch Translation Loss:   7.758529 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:37:20,480 [Epoch: 008 Step: 00001204] Batch Translation Loss:   8.253433 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:37:44,997 [Epoch: 008 Step: 00001205] Batch Translation Loss:   6.378736 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:38:13,922 [Epoch: 008 Step: 00001206] Batch Translation Loss:   7.394037 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:38:27,681 [Epoch: 008 Step: 00001207] Batch Translation Loss:   7.773001 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 23:38:49,612 [Epoch: 008 Step: 00001208] Batch Translation Loss:   7.587077 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:39:16,699 [Epoch: 008 Step: 00001209] Batch Translation Loss:   8.360720 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:39:29,282 [Epoch: 008 Step: 00001210] Batch Translation Loss:   6.952521 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 23:39:41,475 [Epoch: 008 Step: 00001211] Batch Translation Loss:   7.304823 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 23:39:54,846 [Epoch: 008 Step: 00001212] Batch Translation Loss:   7.079161 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 23:40:05,710 [Epoch: 008 Step: 00001213] Batch Translation Loss:   7.414805 => Txt Tokens per Sec:        4 || Lr: 0.001000
2022-01-02 23:40:22,774 [Epoch: 008 Step: 00001214] Batch Translation Loss:   7.384090 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:40:38,509 [Epoch: 008 Step: 00001215] Batch Translation Loss:   6.886319 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:41:03,127 [Epoch: 008 Step: 00001216] Batch Translation Loss:   8.012498 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:41:19,454 [Epoch: 008 Step: 00001217] Batch Translation Loss:   8.556913 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 23:41:33,002 [Epoch: 008 Step: 00001218] Batch Translation Loss:   7.274732 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 23:41:58,290 [Epoch: 008 Step: 00001219] Batch Translation Loss:   7.354027 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:42:10,771 [Epoch: 008 Step: 00001220] Batch Translation Loss:   6.787820 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 23:42:24,902 [Epoch: 008 Step: 00001221] Batch Translation Loss:   7.772765 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 23:42:39,295 [Epoch: 008 Step: 00001222] Batch Translation Loss:   7.688823 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:43:03,509 [Epoch: 008 Step: 00001223] Batch Translation Loss:   8.499305 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:43:22,771 [Epoch: 008 Step: 00001224] Batch Translation Loss:   6.713915 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:43:40,313 [Epoch: 008 Step: 00001225] Batch Translation Loss:   7.335910 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:43:59,016 [Epoch: 008 Step: 00001226] Batch Translation Loss:   6.887022 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:44:18,980 [Epoch: 008 Step: 00001227] Batch Translation Loss:   7.931918 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:44:52,283 [Epoch: 008 Step: 00001228] Batch Translation Loss:   7.399424 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:45:10,552 [Epoch: 008 Step: 00001229] Batch Translation Loss:   7.708429 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:45:26,664 [Epoch: 008 Step: 00001230] Batch Translation Loss:   6.269249 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:45:45,755 [Epoch: 008 Step: 00001231] Batch Translation Loss:   8.136886 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 23:45:58,462 [Epoch: 008 Step: 00001232] Batch Translation Loss:   6.588991 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-02 23:46:18,122 [Epoch: 008 Step: 00001233] Batch Translation Loss:   6.553015 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:46:37,789 [Epoch: 008 Step: 00001234] Batch Translation Loss:   6.943357 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:47:05,208 [Epoch: 008 Step: 00001235] Batch Translation Loss:   7.228572 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:47:22,781 [Epoch: 008 Step: 00001236] Batch Translation Loss:   6.237997 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:47:42,427 [Epoch: 008 Step: 00001237] Batch Translation Loss:   7.010380 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:47:58,809 [Epoch: 008 Step: 00001238] Batch Translation Loss:   7.268181 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:48:18,161 [Epoch: 008 Step: 00001239] Batch Translation Loss:   7.313927 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:48:44,753 [Epoch: 008 Step: 00001240] Batch Translation Loss:   6.594828 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:49:01,149 [Epoch: 008 Step: 00001241] Batch Translation Loss:   6.827681 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:49:24,503 [Epoch: 008 Step: 00001242] Batch Translation Loss:   7.629110 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:49:49,615 [Epoch: 008 Step: 00001243] Batch Translation Loss:   6.943563 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:50:10,980 [Epoch: 008 Step: 00001244] Batch Translation Loss:   6.128735 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:50:53,948 [Epoch: 008 Step: 00001245] Batch Translation Loss:   7.984529 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:51:12,815 [Epoch: 008 Step: 00001246] Batch Translation Loss:   7.637300 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:51:32,531 [Epoch: 008 Step: 00001247] Batch Translation Loss:   7.308669 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:51:47,915 [Epoch: 008 Step: 00001248] Batch Translation Loss:   6.549290 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:52:23,736 [Epoch: 008 Step: 00001249] Batch Translation Loss:   7.024706 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:52:49,160 [Epoch: 008 Step: 00001250] Batch Translation Loss:   7.327185 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:53:12,484 [Epoch: 008 Step: 00001251] Batch Translation Loss:   6.992936 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:53:36,281 [Epoch: 008 Step: 00001252] Batch Translation Loss:   7.141235 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:53:58,203 [Epoch: 008 Step: 00001253] Batch Translation Loss:   7.028770 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:54:20,582 [Epoch: 008 Step: 00001254] Batch Translation Loss:   6.668564 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:54:44,192 [Epoch: 008 Step: 00001255] Batch Translation Loss:   8.095301 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:55:09,378 [Epoch: 008 Step: 00001256] Batch Translation Loss:   6.621419 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:55:31,195 [Epoch: 008 Step: 00001257] Batch Translation Loss:   7.244796 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:55:56,112 [Epoch: 008 Step: 00001258] Batch Translation Loss:   7.179120 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:56:21,952 [Epoch: 008 Step: 00001259] Batch Translation Loss:   7.336100 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:56:47,326 [Epoch: 008 Step: 00001260] Batch Translation Loss:   7.171019 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:57:10,012 [Epoch: 008 Step: 00001261] Batch Translation Loss:   7.282282 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:57:32,149 [Epoch: 008 Step: 00001262] Batch Translation Loss:   7.249264 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:57:51,175 [Epoch: 008 Step: 00001263] Batch Translation Loss:   7.074453 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-02 23:58:18,999 [Epoch: 008 Step: 00001264] Batch Translation Loss:   6.944186 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:58:47,675 [Epoch: 008 Step: 00001265] Batch Translation Loss:   6.362099 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:59:14,172 [Epoch: 008 Step: 00001266] Batch Translation Loss:   7.070847 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-02 23:59:39,599 [Epoch: 008 Step: 00001267] Batch Translation Loss:   7.171985 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 00:00:07,084 [Epoch: 008 Step: 00001268] Batch Translation Loss:   7.616789 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:00:33,286 [Epoch: 008 Step: 00001269] Batch Translation Loss:   7.944011 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 00:00:55,826 [Epoch: 008 Step: 00001270] Batch Translation Loss:   6.646194 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 00:01:26,245 [Epoch: 008 Step: 00001271] Batch Translation Loss:   6.309192 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:01:53,711 [Epoch: 008 Step: 00001272] Batch Translation Loss:   6.648832 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 00:02:19,790 [Epoch: 008 Step: 00001273] Batch Translation Loss:   6.500530 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:02:45,026 [Epoch: 008 Step: 00001274] Batch Translation Loss:   6.145422 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:03:10,645 [Epoch: 008 Step: 00001275] Batch Translation Loss:   7.022227 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:03:36,588 [Epoch: 008 Step: 00001276] Batch Translation Loss:   6.201213 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:04:31,278 [Epoch: 008 Step: 00001277] Batch Translation Loss:   7.745481 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:04:59,388 [Epoch: 008 Step: 00001278] Batch Translation Loss:   7.262074 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:05:26,506 [Epoch: 008 Step: 00001279] Batch Translation Loss:   6.893905 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:05:51,548 [Epoch: 008 Step: 00001280] Batch Translation Loss:   7.353908 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 00:06:23,156 [Epoch: 008 Step: 00001281] Batch Translation Loss:   7.131543 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:06:44,753 [Epoch: 008 Step: 00001282] Batch Translation Loss:   6.893174 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 00:07:03,592 [Epoch: 008 Step: 00001283] Batch Translation Loss:   6.955705 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 00:07:25,663 [Epoch: 008 Step: 00001284] Batch Translation Loss:   7.766186 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 00:07:56,937 [Epoch: 008 Step: 00001285] Batch Translation Loss:   6.552656 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:08:24,961 [Epoch: 008 Step: 00001286] Batch Translation Loss:   6.817871 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:08:52,868 [Epoch: 008 Step: 00001287] Batch Translation Loss:   7.014207 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:09:22,841 [Epoch: 008 Step: 00001288] Batch Translation Loss:   6.826555 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:10:14,973 [Epoch: 008 Step: 00001289] Batch Translation Loss:   7.250653 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:10:48,414 [Epoch: 008 Step: 00001290] Batch Translation Loss:   6.805888 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:11:20,987 [Epoch: 008 Step: 00001291] Batch Translation Loss:   6.356045 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:11:56,522 [Epoch: 008 Step: 00001292] Batch Translation Loss:   6.755236 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:12:25,009 [Epoch: 008 Step: 00001293] Batch Translation Loss:   7.369854 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:12:54,980 [Epoch: 008 Step: 00001294] Batch Translation Loss:   6.996768 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:13:28,247 [Epoch: 008 Step: 00001295] Batch Translation Loss:   7.109680 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:14:03,513 [Epoch: 008 Step: 00001296] Batch Translation Loss:   6.648572 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:14:35,294 [Epoch: 008 Step: 00001297] Batch Translation Loss:   6.717668 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:15:06,052 [Epoch: 008 Step: 00001298] Batch Translation Loss:   7.121468 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:15:37,774 [Epoch: 008 Step: 00001299] Batch Translation Loss:   6.157565 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:16:10,932 [Epoch: 008 Step: 00001300] Batch Translation Loss:   6.690482 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:23:49,534 Validation result at epoch   8, step     1300: duration: 458.5792s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11361.66699	PPL: 5543.51611
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 2.43	(DEL: 27.47,	INS: 0.00,	SUB: 70.11)
	Sequence Accuracy 2.20
2022-01-03 00:23:57,166 Logging Recognition and Translation Outputs
2022-01-03 00:23:57,242 ========================================================================================================================
2022-01-03 00:23:57,242 Logging Sequence: deafvideo_4-tax_tips_by_irs_4953
2022-01-03 00:23:57,243 	Text Reference  :	asl
2022-01-03 00:23:57,244 	Text Hypothesis :	asl
2022-01-03 00:23:57,244 	Text Alignment  :	   
2022-01-03 00:23:57,244 ========================================================================================================================
2022-01-03 00:23:57,244 Logging Sequence: youtube_5-daniel_durant_5887
2022-01-03 00:23:57,244 	Text Reference  :	titus
2022-01-03 00:23:57,244 	Text Hypothesis :	asl  
2022-01-03 00:23:57,244 	Text Alignment  :	S    
2022-01-03 00:23:57,244 ========================================================================================================================
2022-01-03 00:23:57,245 Logging Sequence: youtube_5-roberta_cordano_6136
2022-01-03 00:23:57,245 	Text Reference  :	afc nfc
2022-01-03 00:23:57,245 	Text Hypothesis :	*** asl
2022-01-03 00:23:57,245 	Text Alignment  :	D   S  
2022-01-03 00:23:57,245 ========================================================================================================================
2022-01-03 00:23:57,246 Logging Sequence: youtube_5-melissa_draganac-hawk_5840
2022-01-03 00:23:57,246 	Text Reference  :	it
2022-01-03 00:23:57,246 	Text Hypothesis :	ok
2022-01-03 00:23:57,246 	Text Alignment  :	S 
2022-01-03 00:23:57,246 ========================================================================================================================
2022-01-03 00:23:57,246 Logging Sequence: deafvideo_4-tax_tips_by_irs_4962
2022-01-03 00:23:57,247 	Text Reference  :	hammer
2022-01-03 00:23:57,247 	Text Hypothesis :	dr    
2022-01-03 00:23:57,247 	Text Alignment  :	S     
2022-01-03 00:23:57,247 ========================================================================================================================
2022-01-03 00:25:12,015 [Epoch: 008 Step: 00001301] Batch Translation Loss:   7.327639 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 00:26:29,012 [Epoch: 008 Step: 00001302] Batch Translation Loss:   6.524050 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 00:26:56,389 [Epoch: 008 Step: 00001303] Batch Translation Loss:   7.061257 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 00:27:25,525 [Epoch: 008 Step: 00001304] Batch Translation Loss:   6.929293 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:27:57,965 [Epoch: 008 Step: 00001305] Batch Translation Loss:   7.011542 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:28:32,440 [Epoch: 008 Step: 00001306] Batch Translation Loss:   5.513231 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:29:10,983 [Epoch: 008 Step: 00001307] Batch Translation Loss:   7.756178 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:29:44,337 [Epoch: 008 Step: 00001308] Batch Translation Loss:   6.987624 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:30:42,948 [Epoch: 008 Step: 00001309] Batch Translation Loss:   7.781307 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:31:19,400 [Epoch: 008 Step: 00001310] Batch Translation Loss:   7.467803 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:31:50,091 [Epoch: 008 Step: 00001311] Batch Translation Loss:   7.426722 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:32:49,628 [Epoch: 008 Step: 00001312] Batch Translation Loss:   6.713857 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:33:47,466 [Epoch: 008 Step: 00001313] Batch Translation Loss:   6.718859 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:34:19,691 [Epoch: 008 Step: 00001314] Batch Translation Loss:   6.723191 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:34:49,664 [Epoch: 008 Step: 00001315] Batch Translation Loss:   6.694366 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:35:27,851 [Epoch: 008 Step: 00001316] Batch Translation Loss:   6.525701 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:36:06,809 [Epoch: 008 Step: 00001317] Batch Translation Loss:   6.905354 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:36:40,773 [Epoch: 008 Step: 00001318] Batch Translation Loss:   6.700121 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:37:14,898 [Epoch: 008 Step: 00001319] Batch Translation Loss:   6.517047 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:37:55,246 [Epoch: 008 Step: 00001320] Batch Translation Loss:   7.054963 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:38:27,566 [Epoch: 008 Step: 00001321] Batch Translation Loss:   6.409726 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:39:20,332 [Epoch: 008 Step: 00001322] Batch Translation Loss:   7.186079 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:40:07,774 [Epoch: 008 Step: 00001323] Batch Translation Loss:   6.126121 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:41:17,583 [Epoch: 008 Step: 00001324] Batch Translation Loss:   6.891468 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:42:06,465 [Epoch: 008 Step: 00001325] Batch Translation Loss:   6.965322 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:42:47,863 [Epoch: 008 Step: 00001326] Batch Translation Loss:   7.139065 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:43:32,182 [Epoch: 008 Step: 00001327] Batch Translation Loss:   6.297040 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:44:10,914 [Epoch: 008 Step: 00001328] Batch Translation Loss:   6.992069 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:44:51,784 [Epoch: 008 Step: 00001329] Batch Translation Loss:   7.110091 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:45:29,567 [Epoch: 008 Step: 00001330] Batch Translation Loss:   6.408207 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:46:40,848 [Epoch: 008 Step: 00001331] Batch Translation Loss:   7.324866 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:47:20,550 [Epoch: 008 Step: 00001332] Batch Translation Loss:   6.915503 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:48:07,643 [Epoch: 008 Step: 00001333] Batch Translation Loss:   7.084757 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:48:47,161 [Epoch: 008 Step: 00001334] Batch Translation Loss:   6.808708 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:49:28,667 [Epoch: 008 Step: 00001335] Batch Translation Loss:   6.973888 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:50:07,809 [Epoch: 008 Step: 00001336] Batch Translation Loss:   8.042737 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:50:45,407 [Epoch: 008 Step: 00001337] Batch Translation Loss:   7.247283 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:51:55,766 [Epoch: 008 Step: 00001338] Batch Translation Loss:   6.390758 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:52:32,276 [Epoch: 008 Step: 00001339] Batch Translation Loss:   6.698478 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:53:08,916 [Epoch: 008 Step: 00001340] Batch Translation Loss:   6.515203 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:53:49,182 [Epoch: 008 Step: 00001341] Batch Translation Loss:   6.612452 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:54:26,761 [Epoch: 008 Step: 00001342] Batch Translation Loss:   7.541191 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:55:10,447 [Epoch: 008 Step: 00001343] Batch Translation Loss:   6.372637 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:56:00,708 [Epoch: 008 Step: 00001344] Batch Translation Loss:   6.960884 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:56:38,406 [Epoch: 008 Step: 00001345] Batch Translation Loss:   7.399736 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:57:20,329 [Epoch: 008 Step: 00001346] Batch Translation Loss:   7.233986 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:58:00,332 [Epoch: 008 Step: 00001347] Batch Translation Loss:   6.418913 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:58:37,749 [Epoch: 008 Step: 00001348] Batch Translation Loss:   6.858644 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 00:59:20,111 [Epoch: 008 Step: 00001349] Batch Translation Loss:   6.650541 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:00:03,587 [Epoch: 008 Step: 00001350] Batch Translation Loss:   6.541929 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:01:26,768 [Epoch: 008 Step: 00001351] Batch Translation Loss:   7.286054 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 01:02:05,590 [Epoch: 008 Step: 00001352] Batch Translation Loss:   7.069116 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:02:45,140 [Epoch: 008 Step: 00001353] Batch Translation Loss:   6.086194 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:03:35,860 [Epoch: 008 Step: 00001354] Batch Translation Loss:   6.745425 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:04:15,336 [Epoch: 008 Step: 00001355] Batch Translation Loss:   7.365961 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:04:47,540 [Epoch: 008 Step: 00001356] Batch Translation Loss:   6.468413 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:05:42,282 [Epoch: 008 Step: 00001357] Batch Translation Loss:   6.648123 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:07:49,912 [Epoch: 008 Step: 00001358] Batch Translation Loss:   6.986586 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 01:09:36,824 [Epoch: 008 Step: 00001359] Batch Translation Loss:   7.512659 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 01:11:35,708 [Epoch: 008 Step: 00001360] Batch Translation Loss:   7.351322 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 01:11:35,819 Epoch   8: Total Training Recognition Loss -1.00  Total Training Translation Loss 1205.91 
2022-01-03 01:11:35,819 EPOCH 9
2022-01-03 01:12:05,966 [Epoch: 009 Step: 00001361] Batch Translation Loss:   6.574301 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:12:32,565 [Epoch: 009 Step: 00001362] Batch Translation Loss:   7.181576 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 01:12:55,953 [Epoch: 009 Step: 00001363] Batch Translation Loss:   7.082571 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 01:13:42,869 [Epoch: 009 Step: 00001364] Batch Translation Loss:   7.838038 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:14:10,568 [Epoch: 009 Step: 00001365] Batch Translation Loss:   7.292688 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:14:41,803 [Epoch: 009 Step: 00001366] Batch Translation Loss:   9.094846 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 01:15:07,618 [Epoch: 009 Step: 00001367] Batch Translation Loss:   6.445948 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:15:39,255 [Epoch: 009 Step: 00001368] Batch Translation Loss:   6.703799 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:16:05,396 [Epoch: 009 Step: 00001369] Batch Translation Loss:   7.720334 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:16:29,417 [Epoch: 009 Step: 00001370] Batch Translation Loss:   6.437331 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 01:16:56,031 [Epoch: 009 Step: 00001371] Batch Translation Loss:   6.767371 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:17:21,781 [Epoch: 009 Step: 00001372] Batch Translation Loss:   7.652569 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 01:18:06,521 [Epoch: 009 Step: 00001373] Batch Translation Loss:   6.258494 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:18:29,851 [Epoch: 009 Step: 00001374] Batch Translation Loss:   6.485483 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 01:18:57,678 [Epoch: 009 Step: 00001375] Batch Translation Loss:   6.393044 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:19:20,330 [Epoch: 009 Step: 00001376] Batch Translation Loss:   6.566382 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 01:19:45,797 [Epoch: 009 Step: 00001377] Batch Translation Loss:   7.051912 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 01:20:27,124 [Epoch: 009 Step: 00001378] Batch Translation Loss:   6.630335 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:21:17,399 [Epoch: 009 Step: 00001379] Batch Translation Loss:   6.598104 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:21:47,732 [Epoch: 009 Step: 00001380] Batch Translation Loss:   7.298141 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:22:34,215 [Epoch: 009 Step: 00001381] Batch Translation Loss:   6.494503 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:23:16,354 [Epoch: 009 Step: 00001382] Batch Translation Loss:   6.870328 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:23:54,068 [Epoch: 009 Step: 00001383] Batch Translation Loss:   7.043027 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:24:37,920 [Epoch: 009 Step: 00001384] Batch Translation Loss:   6.432495 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:25:01,565 [Epoch: 009 Step: 00001385] Batch Translation Loss:   7.062459 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 01:25:39,922 [Epoch: 009 Step: 00001386] Batch Translation Loss:   6.930949 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:26:11,276 [Epoch: 009 Step: 00001387] Batch Translation Loss:   7.766011 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 01:27:03,260 [Epoch: 009 Step: 00001388] Batch Translation Loss:   7.400407 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:27:39,707 [Epoch: 009 Step: 00001389] Batch Translation Loss:   6.544184 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:28:14,776 [Epoch: 009 Step: 00001390] Batch Translation Loss:   7.124518 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:29:11,937 [Epoch: 009 Step: 00001391] Batch Translation Loss:   6.480889 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:29:42,396 [Epoch: 009 Step: 00001392] Batch Translation Loss:   7.426343 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 01:30:32,793 [Epoch: 009 Step: 00001393] Batch Translation Loss:   7.133723 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:31:18,771 [Epoch: 009 Step: 00001394] Batch Translation Loss:   7.374480 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:31:59,642 [Epoch: 009 Step: 00001395] Batch Translation Loss:   7.135145 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:33:00,583 [Epoch: 009 Step: 00001396] Batch Translation Loss:   7.893156 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:33:36,654 [Epoch: 009 Step: 00001397] Batch Translation Loss:   6.683601 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:34:00,643 [Epoch: 009 Step: 00001398] Batch Translation Loss:   6.787995 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 01:34:34,089 [Epoch: 009 Step: 00001399] Batch Translation Loss:   7.109675 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:35:20,684 [Epoch: 009 Step: 00001400] Batch Translation Loss:   6.524553 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:42:57,936 Validation result at epoch   9, step     1400: duration: 457.2373s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11174.67969	PPL: 6187.08203
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 2.42	(DEL: 24.61,	INS: 0.00,	SUB: 72.97)
	Sequence Accuracy 2.49
2022-01-03 01:43:06,647 Logging Recognition and Translation Outputs
2022-01-03 01:43:06,716 ========================================================================================================================
2022-01-03 01:43:06,716 Logging Sequence: deafvideo_2-deafpoweronethumbtwo_1795
2022-01-03 01:43:06,717 	Text Reference  :	savior
2022-01-03 01:43:06,718 	Text Hypothesis :	asl   
2022-01-03 01:43:06,718 	Text Alignment  :	S     
2022-01-03 01:43:06,718 ========================================================================================================================
2022-01-03 01:43:06,718 Logging Sequence: youtube_4-lizzie_sorkin_5251
2022-01-03 01:43:06,719 	Text Reference  :	emmett he    
2022-01-03 01:43:06,719 	Text Hypothesis :	****** detail
2022-01-03 01:43:06,719 	Text Alignment  :	D      S     
2022-01-03 01:43:06,719 ========================================================================================================================
2022-01-03 01:43:06,719 Logging Sequence: youtube_6-roberta_cordano_6471
2022-01-03 01:43:06,720 	Text Reference  :	youtube link  
2022-01-03 01:43:06,720 	Text Hypothesis :	******* robert
2022-01-03 01:43:06,720 	Text Alignment  :	D       S     
2022-01-03 01:43:06,721 ========================================================================================================================
2022-01-03 01:43:06,721 Logging Sequence: youtube_1-catherine_mackinnon_2843
2022-01-03 01:43:06,721 	Text Reference  :	by
2022-01-03 01:43:06,721 	Text Hypothesis :	ok
2022-01-03 01:43:06,722 	Text Alignment  :	S 
2022-01-03 01:43:06,722 ========================================================================================================================
2022-01-03 01:43:06,722 Logging Sequence: deafvideo_2-fairytales9_2299
2022-01-03 01:43:06,722 	Text Reference  :	aslized
2022-01-03 01:43:06,722 	Text Hypothesis :	so     
2022-01-03 01:43:06,723 	Text Alignment  :	S      
2022-01-03 01:43:06,723 ========================================================================================================================
2022-01-03 01:44:14,417 [Epoch: 009 Step: 00001401] Batch Translation Loss:   6.637509 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 01:45:06,201 [Epoch: 009 Step: 00001402] Batch Translation Loss:   6.558640 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:46:42,451 [Epoch: 009 Step: 00001403] Batch Translation Loss:   6.021033 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 01:47:17,803 [Epoch: 009 Step: 00001404] Batch Translation Loss:   5.961705 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:47:55,446 [Epoch: 009 Step: 00001405] Batch Translation Loss:   6.762763 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:48:46,665 [Epoch: 009 Step: 00001406] Batch Translation Loss:   6.715495 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:49:34,450 [Epoch: 009 Step: 00001407] Batch Translation Loss:   7.124484 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:50:12,779 [Epoch: 009 Step: 00001408] Batch Translation Loss:   7.831484 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:50:53,737 [Epoch: 009 Step: 00001409] Batch Translation Loss:   6.476780 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:51:45,550 [Epoch: 009 Step: 00001410] Batch Translation Loss:   6.494034 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:52:25,742 [Epoch: 009 Step: 00001411] Batch Translation Loss:   7.032142 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:53:11,174 [Epoch: 009 Step: 00001412] Batch Translation Loss:   7.064032 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:54:09,360 [Epoch: 009 Step: 00001413] Batch Translation Loss:   6.823258 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:54:44,195 [Epoch: 009 Step: 00001414] Batch Translation Loss:   7.836862 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:55:20,611 [Epoch: 009 Step: 00001415] Batch Translation Loss:   5.891619 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:56:21,479 [Epoch: 009 Step: 00001416] Batch Translation Loss:   7.632274 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:57:31,893 [Epoch: 009 Step: 00001417] Batch Translation Loss:   6.092141 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:58:09,980 [Epoch: 009 Step: 00001418] Batch Translation Loss:   7.015997 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 01:59:14,983 [Epoch: 009 Step: 00001419] Batch Translation Loss:   6.497944 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:00:01,221 [Epoch: 009 Step: 00001420] Batch Translation Loss:   7.565744 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:01:58,837 [Epoch: 009 Step: 00001421] Batch Translation Loss:   5.817431 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 02:02:47,453 [Epoch: 009 Step: 00001422] Batch Translation Loss:   6.885859 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:04:31,870 [Epoch: 009 Step: 00001423] Batch Translation Loss:   6.218763 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 02:05:21,330 [Epoch: 009 Step: 00001424] Batch Translation Loss:   6.927761 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:06:09,620 [Epoch: 009 Step: 00001425] Batch Translation Loss:   6.676485 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:07:11,010 [Epoch: 009 Step: 00001426] Batch Translation Loss:   7.248701 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:08:11,829 [Epoch: 009 Step: 00001427] Batch Translation Loss:   5.694170 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:08:56,561 [Epoch: 009 Step: 00001428] Batch Translation Loss:   6.031901 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:10:07,152 [Epoch: 009 Step: 00001429] Batch Translation Loss:   7.234911 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:11:33,182 [Epoch: 009 Step: 00001430] Batch Translation Loss:   6.771174 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 02:12:40,834 [Epoch: 009 Step: 00001431] Batch Translation Loss:   6.995531 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:13:33,926 [Epoch: 009 Step: 00001432] Batch Translation Loss:   6.978658 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:14:28,868 [Epoch: 009 Step: 00001433] Batch Translation Loss:   7.129463 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:15:29,430 [Epoch: 009 Step: 00001434] Batch Translation Loss:   6.971769 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:16:31,523 [Epoch: 009 Step: 00001435] Batch Translation Loss:   6.384312 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:17:13,672 [Epoch: 009 Step: 00001436] Batch Translation Loss:   6.391607 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:17:51,185 [Epoch: 009 Step: 00001437] Batch Translation Loss:   7.122566 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:19:00,328 [Epoch: 009 Step: 00001438] Batch Translation Loss:   6.522604 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:19:52,568 [Epoch: 009 Step: 00001439] Batch Translation Loss:   6.820698 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:20:37,647 [Epoch: 009 Step: 00001440] Batch Translation Loss:   6.849091 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:22:31,877 [Epoch: 009 Step: 00001441] Batch Translation Loss:   5.730176 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 02:23:17,961 [Epoch: 009 Step: 00001442] Batch Translation Loss:   6.848882 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:24:46,260 [Epoch: 009 Step: 00001443] Batch Translation Loss:   6.820536 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 02:25:49,264 [Epoch: 009 Step: 00001444] Batch Translation Loss:   7.377681 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:27:05,553 [Epoch: 009 Step: 00001445] Batch Translation Loss:   6.745476 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:27:57,472 [Epoch: 009 Step: 00001446] Batch Translation Loss:   6.407904 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:28:39,707 [Epoch: 009 Step: 00001447] Batch Translation Loss:   7.022161 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:29:50,778 [Epoch: 009 Step: 00001448] Batch Translation Loss:   7.507415 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:30:42,005 [Epoch: 009 Step: 00001449] Batch Translation Loss:   6.222725 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:31:38,797 [Epoch: 009 Step: 00001450] Batch Translation Loss:   6.492604 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:33:02,209 [Epoch: 009 Step: 00001451] Batch Translation Loss:   7.077142 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 02:33:54,936 [Epoch: 009 Step: 00001452] Batch Translation Loss:   7.096125 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:34:50,699 [Epoch: 009 Step: 00001453] Batch Translation Loss:   6.753137 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:36:10,657 [Epoch: 009 Step: 00001454] Batch Translation Loss:   6.220781 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 02:36:51,599 [Epoch: 009 Step: 00001455] Batch Translation Loss:   7.332940 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:37:47,470 [Epoch: 009 Step: 00001456] Batch Translation Loss:   6.876325 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:39:18,756 [Epoch: 009 Step: 00001457] Batch Translation Loss:   7.251951 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 02:40:16,483 [Epoch: 009 Step: 00001458] Batch Translation Loss:   5.917142 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:41:35,887 [Epoch: 009 Step: 00001459] Batch Translation Loss:   5.827846 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:42:46,235 [Epoch: 009 Step: 00001460] Batch Translation Loss:   6.531943 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:43:57,844 [Epoch: 009 Step: 00001461] Batch Translation Loss:   6.344373 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:45:27,735 [Epoch: 009 Step: 00001462] Batch Translation Loss:   7.313571 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 02:46:55,641 [Epoch: 009 Step: 00001463] Batch Translation Loss:   6.533005 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 02:48:15,576 [Epoch: 009 Step: 00001464] Batch Translation Loss:   6.817912 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 02:49:26,611 [Epoch: 009 Step: 00001465] Batch Translation Loss:   6.131707 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:50:52,001 [Epoch: 009 Step: 00001466] Batch Translation Loss:   7.369174 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 02:51:55,857 [Epoch: 009 Step: 00001467] Batch Translation Loss:   6.836640 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:53:21,706 [Epoch: 009 Step: 00001468] Batch Translation Loss:   6.696740 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 02:54:21,524 [Epoch: 009 Step: 00001469] Batch Translation Loss:   6.615114 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:55:45,495 [Epoch: 009 Step: 00001470] Batch Translation Loss:   7.677279 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 02:56:52,936 [Epoch: 009 Step: 00001471] Batch Translation Loss:   6.667417 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 02:59:20,435 [Epoch: 009 Step: 00001472] Batch Translation Loss:   7.733814 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 03:00:30,700 [Epoch: 009 Step: 00001473] Batch Translation Loss:   6.451635 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 03:01:56,041 [Epoch: 009 Step: 00001474] Batch Translation Loss:   7.455588 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 03:04:17,603 [Epoch: 009 Step: 00001475] Batch Translation Loss:   7.086431 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 03:05:25,554 [Epoch: 009 Step: 00001476] Batch Translation Loss:   6.361988 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 03:06:45,542 [Epoch: 009 Step: 00001477] Batch Translation Loss:   7.194293 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 03:07:47,975 [Epoch: 009 Step: 00001478] Batch Translation Loss:   6.641078 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 03:08:36,926 [Epoch: 009 Step: 00001479] Batch Translation Loss:   6.155970 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 03:09:56,768 [Epoch: 009 Step: 00001480] Batch Translation Loss:   6.165672 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 03:10:59,176 [Epoch: 009 Step: 00001481] Batch Translation Loss:   6.529824 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 03:12:25,354 [Epoch: 009 Step: 00001482] Batch Translation Loss:   7.380863 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 03:13:28,525 [Epoch: 009 Step: 00001483] Batch Translation Loss:   6.748586 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 03:15:38,839 [Epoch: 009 Step: 00001484] Batch Translation Loss:   7.474756 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 03:16:48,817 [Epoch: 009 Step: 00001485] Batch Translation Loss:   7.646380 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 03:18:15,930 [Epoch: 009 Step: 00001486] Batch Translation Loss:   6.869171 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 03:19:36,097 [Epoch: 009 Step: 00001487] Batch Translation Loss:   6.227875 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 03:20:59,503 [Epoch: 009 Step: 00001488] Batch Translation Loss:   6.656003 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 03:22:27,756 [Epoch: 009 Step: 00001489] Batch Translation Loss:   6.643659 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 03:23:53,355 [Epoch: 009 Step: 00001490] Batch Translation Loss:   7.050859 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 03:25:29,644 [Epoch: 009 Step: 00001491] Batch Translation Loss:   7.349553 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 03:27:11,475 [Epoch: 009 Step: 00001492] Batch Translation Loss:   6.250735 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 03:28:40,022 [Epoch: 009 Step: 00001493] Batch Translation Loss:   6.694895 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 03:30:17,992 [Epoch: 009 Step: 00001494] Batch Translation Loss:   7.087126 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 03:31:50,490 [Epoch: 009 Step: 00001495] Batch Translation Loss:   7.503022 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 03:33:05,000 [Epoch: 009 Step: 00001496] Batch Translation Loss:   6.987031 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 03:34:39,082 [Epoch: 009 Step: 00001497] Batch Translation Loss:   6.452739 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 03:35:55,974 [Epoch: 009 Step: 00001498] Batch Translation Loss:   6.142640 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 03:37:42,574 [Epoch: 009 Step: 00001499] Batch Translation Loss:   6.190671 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 03:40:26,889 [Epoch: 009 Step: 00001500] Batch Translation Loss:   6.795135 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 03:48:12,423 Validation result at epoch   9, step     1500: duration: 465.4686s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11228.44531	PPL: 6364.79541
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 2.73	(DEL: 24.96,	INS: 0.00,	SUB: 72.31)
	Sequence Accuracy 3.53
2022-01-03 03:48:18,881 Logging Recognition and Translation Outputs
2022-01-03 03:48:18,928 ========================================================================================================================
2022-01-03 03:48:18,928 Logging Sequence: deafvideo_5-morningstar_6260
2022-01-03 03:48:18,928 	Text Reference  :	june
2022-01-03 03:48:18,929 	Text Hypothesis :	asl 
2022-01-03 03:48:18,929 	Text Alignment  :	S   
2022-01-03 03:48:18,929 ========================================================================================================================
2022-01-03 03:48:18,929 Logging Sequence: youtube_1-catherine_mackinnon_2817
2022-01-03 03:48:18,929 	Text Reference  :	isaiah
2022-01-03 03:48:18,929 	Text Hypothesis :	asl   
2022-01-03 03:48:18,929 	Text Alignment  :	S     
2022-01-03 03:48:18,929 ========================================================================================================================
2022-01-03 03:48:18,929 Logging Sequence: youtube_1-catherine_mackinnon_2833
2022-01-03 03:48:18,929 	Text Reference  :	co
2022-01-03 03:48:18,930 	Text Hypothesis :	or
2022-01-03 03:48:18,930 	Text Alignment  :	S 
2022-01-03 03:48:18,930 ========================================================================================================================
2022-01-03 03:48:18,930 Logging Sequence: youtube_1-melvin_patterson_2336
2022-01-03 03:48:18,930 	Text Reference  :	co
2022-01-03 03:48:18,930 	Text Hypothesis :	or
2022-01-03 03:48:18,930 	Text Alignment  :	S 
2022-01-03 03:48:18,930 ========================================================================================================================
2022-01-03 03:48:18,930 Logging Sequence: youtube_1-catherine_mackinnon_2838
2022-01-03 03:48:18,930 	Text Reference  :	he 
2022-01-03 03:48:18,930 	Text Hypothesis :	asl
2022-01-03 03:48:18,930 	Text Alignment  :	S  
2022-01-03 03:48:18,931 ========================================================================================================================
2022-01-03 03:51:13,950 [Epoch: 009 Step: 00001501] Batch Translation Loss:   6.441664 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 03:53:14,955 [Epoch: 009 Step: 00001502] Batch Translation Loss:   6.277395 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 03:55:24,915 [Epoch: 009 Step: 00001503] Batch Translation Loss:   7.006804 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 03:57:01,989 [Epoch: 009 Step: 00001504] Batch Translation Loss:   6.425716 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 03:58:44,749 [Epoch: 009 Step: 00001505] Batch Translation Loss:   7.770031 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 04:00:54,103 [Epoch: 009 Step: 00001506] Batch Translation Loss:   7.058140 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 04:02:25,057 [Epoch: 009 Step: 00001507] Batch Translation Loss:   6.618727 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 04:04:51,573 [Epoch: 009 Step: 00001508] Batch Translation Loss:   6.755872 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 04:06:22,456 [Epoch: 009 Step: 00001509] Batch Translation Loss:   7.743336 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 04:08:51,745 [Epoch: 009 Step: 00001510] Batch Translation Loss:   6.213727 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 04:11:03,521 [Epoch: 009 Step: 00001511] Batch Translation Loss:   6.699288 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 04:13:10,509 [Epoch: 009 Step: 00001512] Batch Translation Loss:   7.442315 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 04:15:39,364 [Epoch: 009 Step: 00001513] Batch Translation Loss:   6.775823 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 04:19:27,925 [Epoch: 009 Step: 00001514] Batch Translation Loss:   6.410896 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 04:23:24,153 [Epoch: 009 Step: 00001515] Batch Translation Loss:   6.638469 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 04:24:54,038 [Epoch: 009 Step: 00001516] Batch Translation Loss:   5.956457 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 04:27:15,593 [Epoch: 009 Step: 00001517] Batch Translation Loss:   6.774124 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 04:29:04,573 [Epoch: 009 Step: 00001518] Batch Translation Loss:   7.140745 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 04:31:13,122 [Epoch: 009 Step: 00001519] Batch Translation Loss:   6.102818 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 04:36:10,688 [Epoch: 009 Step: 00001520] Batch Translation Loss:   7.133964 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 04:38:06,897 [Epoch: 009 Step: 00001521] Batch Translation Loss:   7.345241 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 04:42:50,576 [Epoch: 009 Step: 00001522] Batch Translation Loss:   7.127432 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 04:45:02,558 [Epoch: 009 Step: 00001523] Batch Translation Loss:   7.320421 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 04:47:03,262 [Epoch: 009 Step: 00001524] Batch Translation Loss:   7.153139 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 04:48:54,837 [Epoch: 009 Step: 00001525] Batch Translation Loss:   7.289817 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 04:50:58,908 [Epoch: 009 Step: 00001526] Batch Translation Loss:   6.419685 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 04:52:10,638 [Epoch: 009 Step: 00001527] Batch Translation Loss:   6.386610 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 04:54:36,382 [Epoch: 009 Step: 00001528] Batch Translation Loss:   7.014441 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 04:56:14,435 [Epoch: 009 Step: 00001529] Batch Translation Loss:   6.660819 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 04:57:53,278 [Epoch: 009 Step: 00001530] Batch Translation Loss:   6.677234 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 04:57:53,430 Epoch   9: Total Training Recognition Loss -1.00  Total Training Translation Loss 1161.77 
2022-01-03 04:57:53,431 EPOCH 10
2022-01-03 04:58:19,446 [Epoch: 010 Step: 00001531] Batch Translation Loss:   6.698744 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 04:58:43,452 [Epoch: 010 Step: 00001532] Batch Translation Loss:   6.973543 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 04:59:23,341 [Epoch: 010 Step: 00001533] Batch Translation Loss:   7.301768 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 04:59:52,856 [Epoch: 010 Step: 00001534] Batch Translation Loss:   7.512181 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 05:00:14,529 [Epoch: 010 Step: 00001535] Batch Translation Loss:   6.850672 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 05:00:32,447 [Epoch: 010 Step: 00001536] Batch Translation Loss:   8.238865 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-03 05:00:59,420 [Epoch: 010 Step: 00001537] Batch Translation Loss:   6.754218 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:01:40,773 [Epoch: 010 Step: 00001538] Batch Translation Loss:   7.750142 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:02:14,512 [Epoch: 010 Step: 00001539] Batch Translation Loss:   6.708025 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:03:01,894 [Epoch: 010 Step: 00001540] Batch Translation Loss:   6.583315 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:03:40,953 [Epoch: 010 Step: 00001541] Batch Translation Loss:   7.157218 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:04:09,311 [Epoch: 010 Step: 00001542] Batch Translation Loss:   7.149017 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:04:26,376 [Epoch: 010 Step: 00001543] Batch Translation Loss:   7.045924 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-03 05:05:02,394 [Epoch: 010 Step: 00001544] Batch Translation Loss:   7.170614 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:05:29,484 [Epoch: 010 Step: 00001545] Batch Translation Loss:   6.572484 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 05:05:53,528 [Epoch: 010 Step: 00001546] Batch Translation Loss:   6.355756 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 05:06:28,549 [Epoch: 010 Step: 00001547] Batch Translation Loss:   7.166324 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:06:59,678 [Epoch: 010 Step: 00001548] Batch Translation Loss:   7.084384 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:07:24,751 [Epoch: 010 Step: 00001549] Batch Translation Loss:   7.401526 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:07:44,195 [Epoch: 010 Step: 00001550] Batch Translation Loss:   6.946483 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 05:08:01,022 [Epoch: 010 Step: 00001551] Batch Translation Loss:   6.659127 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 05:08:25,942 [Epoch: 010 Step: 00001552] Batch Translation Loss:   7.160475 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:08:59,504 [Epoch: 010 Step: 00001553] Batch Translation Loss:   6.437206 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:09:24,826 [Epoch: 010 Step: 00001554] Batch Translation Loss:   7.501925 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 05:09:43,910 [Epoch: 010 Step: 00001555] Batch Translation Loss:   6.589521 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 05:10:06,481 [Epoch: 010 Step: 00001556] Batch Translation Loss:   7.292806 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 05:10:35,437 [Epoch: 010 Step: 00001557] Batch Translation Loss:   6.888254 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:11:44,303 [Epoch: 010 Step: 00001558] Batch Translation Loss:   6.216826 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:12:35,355 [Epoch: 010 Step: 00001559] Batch Translation Loss:   6.843881 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:12:59,320 [Epoch: 010 Step: 00001560] Batch Translation Loss:   7.107930 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 05:13:22,626 [Epoch: 010 Step: 00001561] Batch Translation Loss:   6.967536 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 05:14:02,700 [Epoch: 010 Step: 00001562] Batch Translation Loss:   8.118722 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:14:22,570 [Epoch: 010 Step: 00001563] Batch Translation Loss:   6.915842 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 05:14:51,897 [Epoch: 010 Step: 00001564] Batch Translation Loss:   6.230010 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:15:19,867 [Epoch: 010 Step: 00001565] Batch Translation Loss:   7.049932 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:16:07,096 [Epoch: 010 Step: 00001566] Batch Translation Loss:   6.039464 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:16:35,864 [Epoch: 010 Step: 00001567] Batch Translation Loss:   7.268492 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:17:24,126 [Epoch: 010 Step: 00001568] Batch Translation Loss:   7.120701 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:17:50,891 [Epoch: 010 Step: 00001569] Batch Translation Loss:   6.466271 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 05:18:26,330 [Epoch: 010 Step: 00001570] Batch Translation Loss:   7.277062 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:18:58,564 [Epoch: 010 Step: 00001571] Batch Translation Loss:   5.877000 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:19:15,670 [Epoch: 010 Step: 00001572] Batch Translation Loss:   7.423526 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 05:19:46,239 [Epoch: 010 Step: 00001573] Batch Translation Loss:   6.920774 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:20:46,252 [Epoch: 010 Step: 00001574] Batch Translation Loss:   6.443551 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:21:23,773 [Epoch: 010 Step: 00001575] Batch Translation Loss:   6.213529 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:21:51,918 [Epoch: 010 Step: 00001576] Batch Translation Loss:   6.754202 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:22:21,625 [Epoch: 010 Step: 00001577] Batch Translation Loss:   6.182807 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:22:45,251 [Epoch: 010 Step: 00001578] Batch Translation Loss:   6.294275 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 05:23:21,869 [Epoch: 010 Step: 00001579] Batch Translation Loss:   6.775424 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:23:41,440 [Epoch: 010 Step: 00001580] Batch Translation Loss:   6.407618 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 05:24:01,711 [Epoch: 010 Step: 00001581] Batch Translation Loss:   6.732337 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 05:24:47,394 [Epoch: 010 Step: 00001582] Batch Translation Loss:   6.747441 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:25:45,374 [Epoch: 010 Step: 00001583] Batch Translation Loss:   7.026164 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:26:22,679 [Epoch: 010 Step: 00001584] Batch Translation Loss:   6.139521 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:27:02,109 [Epoch: 010 Step: 00001585] Batch Translation Loss:   7.202115 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:27:26,544 [Epoch: 010 Step: 00001586] Batch Translation Loss:   6.557625 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 05:27:52,123 [Epoch: 010 Step: 00001587] Batch Translation Loss:   7.084665 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:28:27,087 [Epoch: 010 Step: 00001588] Batch Translation Loss:   6.612924 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:28:45,800 [Epoch: 010 Step: 00001589] Batch Translation Loss:   6.371889 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 05:29:16,414 [Epoch: 010 Step: 00001590] Batch Translation Loss:   6.250864 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:30:18,457 [Epoch: 010 Step: 00001591] Batch Translation Loss:   6.964906 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:31:06,207 [Epoch: 010 Step: 00001592] Batch Translation Loss:   6.246461 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:31:45,106 [Epoch: 010 Step: 00001593] Batch Translation Loss:   6.861996 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:32:28,125 [Epoch: 010 Step: 00001594] Batch Translation Loss:   7.358944 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:32:54,216 [Epoch: 010 Step: 00001595] Batch Translation Loss:   6.568342 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:33:15,581 [Epoch: 010 Step: 00001596] Batch Translation Loss:   5.927016 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 05:33:49,022 [Epoch: 010 Step: 00001597] Batch Translation Loss:   6.564276 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:34:53,556 [Epoch: 010 Step: 00001598] Batch Translation Loss:   6.843687 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:35:50,261 [Epoch: 010 Step: 00001599] Batch Translation Loss:   6.881313 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:37:00,661 [Epoch: 010 Step: 00001600] Batch Translation Loss:   6.462478 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:44:58,943 Validation result at epoch  10, step     1600: duration: 478.2373s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11045.76367	PPL: 7130.23828
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.53	(DEL: 23.69,	INS: 0.00,	SUB: 74.78)
	Sequence Accuracy 1.79
2022-01-03 05:45:05,972 Logging Recognition and Translation Outputs
2022-01-03 05:45:06,040 ========================================================================================================================
2022-01-03 05:45:06,040 Logging Sequence: deafvideo_3-otismhill82_4609
2022-01-03 05:45:06,041 	Text Reference  :	deafhood foundation
2022-01-03 05:45:06,041 	Text Hypothesis :	******** so        
2022-01-03 05:45:06,041 	Text Alignment  :	D        S         
2022-01-03 05:45:06,042 ========================================================================================================================
2022-01-03 05:45:06,042 Logging Sequence: youtube_1-don_grushkin_2772
2022-01-03 05:45:06,043 	Text Reference  :	dr jefrey lewis
2022-01-03 05:45:06,043 	Text Hypothesis :	** ****** so   
2022-01-03 05:45:06,043 	Text Alignment  :	D  D      S    
2022-01-03 05:45:06,044 ========================================================================================================================
2022-01-03 05:45:06,044 Logging Sequence: deafvideo_3-titans_4693
2022-01-03 05:45:06,045 	Text Reference  :	map
2022-01-03 05:45:06,045 	Text Hypothesis :	asl
2022-01-03 05:45:06,045 	Text Alignment  :	S  
2022-01-03 05:45:06,046 ========================================================================================================================
2022-01-03 05:45:06,046 Logging Sequence: deafvideo_3-deafgoldenhair_3086
2022-01-03 05:45:06,047 	Text Reference  :	ok or
2022-01-03 05:45:06,047 	Text Hypothesis :	** so
2022-01-03 05:45:06,047 	Text Alignment  :	D  S 
2022-01-03 05:45:06,048 ========================================================================================================================
2022-01-03 05:45:06,048 Logging Sequence: deafvideo_3-geoalpha_4555
2022-01-03 05:45:06,048 	Text Reference  :	exalted
2022-01-03 05:45:06,049 	Text Hypothesis :	so     
2022-01-03 05:45:06,049 	Text Alignment  :	S      
2022-01-03 05:45:06,049 ========================================================================================================================
2022-01-03 05:46:55,305 [Epoch: 010 Step: 00001601] Batch Translation Loss:   6.967126 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 05:48:17,620 [Epoch: 010 Step: 00001602] Batch Translation Loss:   6.715967 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 05:49:27,226 [Epoch: 010 Step: 00001603] Batch Translation Loss:   6.558192 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:50:34,103 [Epoch: 010 Step: 00001604] Batch Translation Loss:   6.287916 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:51:31,954 [Epoch: 010 Step: 00001605] Batch Translation Loss:   7.123024 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:52:36,745 [Epoch: 010 Step: 00001606] Batch Translation Loss:   6.157187 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:53:43,776 [Epoch: 010 Step: 00001607] Batch Translation Loss:   6.879378 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:55:00,896 [Epoch: 010 Step: 00001608] Batch Translation Loss:   6.653311 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:55:39,111 [Epoch: 010 Step: 00001609] Batch Translation Loss:   6.962727 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:56:27,866 [Epoch: 010 Step: 00001610] Batch Translation Loss:   7.432678 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 05:57:46,897 [Epoch: 010 Step: 00001611] Batch Translation Loss:   6.742433 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 05:59:15,861 [Epoch: 010 Step: 00001612] Batch Translation Loss:   6.503852 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 06:00:08,353 [Epoch: 010 Step: 00001613] Batch Translation Loss:   6.545060 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 06:01:10,466 [Epoch: 010 Step: 00001614] Batch Translation Loss:   7.250482 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 06:01:35,154 [Epoch: 010 Step: 00001615] Batch Translation Loss:   6.254096 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 06:02:05,895 [Epoch: 010 Step: 00001616] Batch Translation Loss:   7.110025 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 06:03:00,745 [Epoch: 010 Step: 00001617] Batch Translation Loss:   6.198596 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 06:04:33,667 [Epoch: 010 Step: 00001618] Batch Translation Loss:   6.363933 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 06:05:27,663 [Epoch: 010 Step: 00001619] Batch Translation Loss:   6.484208 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 06:06:05,866 [Epoch: 010 Step: 00001620] Batch Translation Loss:   7.242729 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 06:06:44,221 [Epoch: 010 Step: 00001621] Batch Translation Loss:   6.996795 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 06:07:13,148 [Epoch: 010 Step: 00001622] Batch Translation Loss:   5.968705 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 06:08:03,732 [Epoch: 010 Step: 00001623] Batch Translation Loss:   7.257893 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 06:09:22,002 [Epoch: 010 Step: 00001624] Batch Translation Loss:   6.117694 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 06:10:47,858 [Epoch: 010 Step: 00001625] Batch Translation Loss:   5.900442 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 06:11:42,015 [Epoch: 010 Step: 00001626] Batch Translation Loss:   5.472481 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 06:12:36,339 [Epoch: 010 Step: 00001627] Batch Translation Loss:   6.421385 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 06:13:26,536 [Epoch: 010 Step: 00001628] Batch Translation Loss:   6.799591 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 06:14:04,681 [Epoch: 010 Step: 00001629] Batch Translation Loss:   6.276322 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 06:15:50,351 [Epoch: 010 Step: 00001630] Batch Translation Loss:   6.703223 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 06:16:53,720 [Epoch: 010 Step: 00001631] Batch Translation Loss:   6.912927 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 06:17:38,753 [Epoch: 010 Step: 00001632] Batch Translation Loss:   6.046834 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 06:18:12,413 [Epoch: 010 Step: 00001633] Batch Translation Loss:   5.933959 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 06:18:38,861 [Epoch: 010 Step: 00001634] Batch Translation Loss:   6.744900 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 06:19:09,539 [Epoch: 010 Step: 00001635] Batch Translation Loss:   7.113138 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 06:21:17,305 [Epoch: 010 Step: 00001636] Batch Translation Loss:   7.001877 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 06:22:47,719 [Epoch: 010 Step: 00001637] Batch Translation Loss:   6.890783 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 06:23:46,369 [Epoch: 010 Step: 00001638] Batch Translation Loss:   6.481293 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 06:24:45,867 [Epoch: 010 Step: 00001639] Batch Translation Loss:   6.514528 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 06:25:44,840 [Epoch: 010 Step: 00001640] Batch Translation Loss:   6.146870 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 06:27:37,618 [Epoch: 010 Step: 00001641] Batch Translation Loss:   6.645818 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 06:29:43,700 [Epoch: 010 Step: 00001642] Batch Translation Loss:   6.365327 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 06:31:19,583 [Epoch: 010 Step: 00001643] Batch Translation Loss:   7.218021 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 06:33:48,576 [Epoch: 010 Step: 00001644] Batch Translation Loss:   7.309072 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 06:35:34,577 [Epoch: 010 Step: 00001645] Batch Translation Loss:   6.459127 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 06:36:54,190 [Epoch: 010 Step: 00001646] Batch Translation Loss:   6.590016 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 06:38:38,542 [Epoch: 010 Step: 00001647] Batch Translation Loss:   6.417430 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 06:39:50,273 [Epoch: 010 Step: 00001648] Batch Translation Loss:   6.462750 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 06:40:46,458 [Epoch: 010 Step: 00001649] Batch Translation Loss:   6.719614 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 06:41:23,650 [Epoch: 010 Step: 00001650] Batch Translation Loss:   6.696600 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 06:42:29,442 [Epoch: 010 Step: 00001651] Batch Translation Loss:   7.763678 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 06:44:22,347 [Epoch: 010 Step: 00001652] Batch Translation Loss:   6.814913 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 06:45:38,878 [Epoch: 010 Step: 00001653] Batch Translation Loss:   7.337890 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 06:46:23,180 [Epoch: 010 Step: 00001654] Batch Translation Loss:   7.051932 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 06:47:01,628 [Epoch: 010 Step: 00001655] Batch Translation Loss:   5.742584 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 06:48:48,947 [Epoch: 010 Step: 00001656] Batch Translation Loss:   6.749045 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 06:50:51,419 [Epoch: 010 Step: 00001657] Batch Translation Loss:   7.383452 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 06:52:16,805 [Epoch: 010 Step: 00001658] Batch Translation Loss:   6.224682 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 06:55:22,670 [Epoch: 010 Step: 00001659] Batch Translation Loss:   6.150317 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 06:56:46,216 [Epoch: 010 Step: 00001660] Batch Translation Loss:   6.556921 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 06:57:43,770 [Epoch: 010 Step: 00001661] Batch Translation Loss:   6.781185 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 06:59:02,033 [Epoch: 010 Step: 00001662] Batch Translation Loss:   7.332561 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 07:00:52,578 [Epoch: 010 Step: 00001663] Batch Translation Loss:   6.579941 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 07:02:06,159 [Epoch: 010 Step: 00001664] Batch Translation Loss:   6.571245 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 07:02:56,788 [Epoch: 010 Step: 00001665] Batch Translation Loss:   6.390304 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 07:03:40,686 [Epoch: 010 Step: 00001666] Batch Translation Loss:   5.995874 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 07:05:25,344 [Epoch: 010 Step: 00001667] Batch Translation Loss:   6.540341 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 07:07:00,257 [Epoch: 010 Step: 00001668] Batch Translation Loss:   6.719123 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 07:08:21,603 [Epoch: 010 Step: 00001669] Batch Translation Loss:   7.229033 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 07:10:04,429 [Epoch: 010 Step: 00001670] Batch Translation Loss:   7.115180 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 07:11:53,719 [Epoch: 010 Step: 00001671] Batch Translation Loss:   6.240465 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 07:14:27,000 [Epoch: 010 Step: 00001672] Batch Translation Loss:   6.837417 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 07:16:08,965 [Epoch: 010 Step: 00001673] Batch Translation Loss:   6.541550 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 07:17:28,933 [Epoch: 010 Step: 00001674] Batch Translation Loss:   6.042844 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 07:20:25,577 [Epoch: 010 Step: 00001675] Batch Translation Loss:   6.798206 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 07:23:09,988 [Epoch: 010 Step: 00001676] Batch Translation Loss:   6.909328 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 07:24:47,634 [Epoch: 010 Step: 00001677] Batch Translation Loss:   6.477121 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 07:26:08,785 [Epoch: 010 Step: 00001678] Batch Translation Loss:   6.235216 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 07:27:13,744 [Epoch: 010 Step: 00001679] Batch Translation Loss:   6.947197 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 07:28:23,635 [Epoch: 010 Step: 00001680] Batch Translation Loss:   6.939022 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 07:29:59,237 [Epoch: 010 Step: 00001681] Batch Translation Loss:   6.189051 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 07:31:19,050 [Epoch: 010 Step: 00001682] Batch Translation Loss:   6.226842 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 07:32:19,530 [Epoch: 010 Step: 00001683] Batch Translation Loss:   6.896914 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 07:35:00,810 [Epoch: 010 Step: 00001684] Batch Translation Loss:   6.524261 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 07:37:56,439 [Epoch: 010 Step: 00001685] Batch Translation Loss:   6.136860 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 07:40:51,139 [Epoch: 010 Step: 00001686] Batch Translation Loss:   7.216353 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 07:41:54,030 [Epoch: 010 Step: 00001687] Batch Translation Loss:   6.305212 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 07:42:47,034 [Epoch: 010 Step: 00001688] Batch Translation Loss:   6.241383 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 07:44:21,347 [Epoch: 010 Step: 00001689] Batch Translation Loss:   6.995216 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 07:45:38,078 [Epoch: 010 Step: 00001690] Batch Translation Loss:   6.513251 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 07:46:40,243 [Epoch: 010 Step: 00001691] Batch Translation Loss:   6.619455 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 07:47:41,801 [Epoch: 010 Step: 00001692] Batch Translation Loss:   6.543271 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 07:49:22,913 [Epoch: 010 Step: 00001693] Batch Translation Loss:   7.331709 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 07:51:40,785 [Epoch: 010 Step: 00001694] Batch Translation Loss:   6.097577 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 07:53:44,134 [Epoch: 010 Step: 00001695] Batch Translation Loss:   6.430052 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 07:55:15,862 [Epoch: 010 Step: 00001696] Batch Translation Loss:   6.360029 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 07:57:53,935 [Epoch: 010 Step: 00001697] Batch Translation Loss:   7.148863 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 07:59:34,845 [Epoch: 010 Step: 00001698] Batch Translation Loss:   6.152253 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 08:00:54,982 [Epoch: 010 Step: 00001699] Batch Translation Loss:   7.225664 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 08:02:01,831 [Epoch: 010 Step: 00001700] Batch Translation Loss:   7.293664 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 08:10:25,295 Validation result at epoch  10, step     1700: duration: 503.4477s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11488.19434	PPL: 6746.13965
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.30	(DEL: 26.02,	INS: 0.00,	SUB: 72.68)
	Sequence Accuracy 1.66
2022-01-03 08:10:32,719 Logging Recognition and Translation Outputs
2022-01-03 08:10:32,752 ========================================================================================================================
2022-01-03 08:10:32,753 Logging Sequence: deafvideo_2-sddsimple_1559
2022-01-03 08:10:32,753 	Text Reference  :	debg
2022-01-03 08:10:32,753 	Text Hypothesis :	of  
2022-01-03 08:10:32,753 	Text Alignment  :	S   
2022-01-03 08:10:32,754 ========================================================================================================================
2022-01-03 08:10:32,754 Logging Sequence: deafvideo_3-otismhill82_4601
2022-01-03 08:10:32,754 	Text Reference  :	naive
2022-01-03 08:10:32,754 	Text Hypothesis :	pwood
2022-01-03 08:10:32,754 	Text Alignment  :	S    
2022-01-03 08:10:32,754 ========================================================================================================================
2022-01-03 08:10:32,755 Logging Sequence: deafvideo_5-scottnorby_6456
2022-01-03 08:10:32,755 	Text Reference  :	mixer
2022-01-03 08:10:32,755 	Text Hypothesis :	asl  
2022-01-03 08:10:32,755 	Text Alignment  :	S    
2022-01-03 08:10:32,755 ========================================================================================================================
2022-01-03 08:10:32,755 Logging Sequence: youtube_5-jeffrey_spinale_6061
2022-01-03 08:10:32,756 	Text Reference  :	ok
2022-01-03 08:10:32,756 	Text Hypothesis :	or
2022-01-03 08:10:32,756 	Text Alignment  :	S 
2022-01-03 08:10:32,756 ========================================================================================================================
2022-01-03 08:10:32,756 Logging Sequence: deafvideo_2-sddsimple_1586
2022-01-03 08:10:32,757 	Text Reference  :	of all
2022-01-03 08:10:32,757 	Text Hypothesis :	** ok 
2022-01-03 08:10:32,757 	Text Alignment  :	D  S  
2022-01-03 08:10:32,757 ========================================================================================================================
2022-01-03 08:10:33,426 Epoch  10: Total Training Recognition Loss -1.00  Total Training Translation Loss 1142.74 
2022-01-03 08:10:33,426 EPOCH 11
2022-01-03 08:11:14,635 [Epoch: 011 Step: 00001701] Batch Translation Loss:   6.524860 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:12:17,474 [Epoch: 011 Step: 00001702] Batch Translation Loss:   7.440665 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:12:51,381 [Epoch: 011 Step: 00001703] Batch Translation Loss:   7.071526 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:13:19,989 [Epoch: 011 Step: 00001704] Batch Translation Loss:   5.813485 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:14:04,512 [Epoch: 011 Step: 00001705] Batch Translation Loss:   7.445996 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:14:45,223 [Epoch: 011 Step: 00001706] Batch Translation Loss:   7.082079 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:15:04,136 [Epoch: 011 Step: 00001707] Batch Translation Loss:   6.992817 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-03 08:15:25,032 [Epoch: 011 Step: 00001708] Batch Translation Loss:   8.266566 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-03 08:15:53,474 [Epoch: 011 Step: 00001709] Batch Translation Loss:   6.961202 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:16:17,621 [Epoch: 011 Step: 00001710] Batch Translation Loss:   6.340517 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:16:48,848 [Epoch: 011 Step: 00001711] Batch Translation Loss:   7.583848 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:17:23,038 [Epoch: 011 Step: 00001712] Batch Translation Loss:   6.844128 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:17:56,981 [Epoch: 011 Step: 00001713] Batch Translation Loss:   6.557734 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:18:15,945 [Epoch: 011 Step: 00001714] Batch Translation Loss:   6.699064 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:19:11,055 [Epoch: 011 Step: 00001715] Batch Translation Loss:   5.836872 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:20:03,652 [Epoch: 011 Step: 00001716] Batch Translation Loss:   6.724802 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:20:24,506 [Epoch: 011 Step: 00001717] Batch Translation Loss:   6.094953 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:21:11,343 [Epoch: 011 Step: 00001718] Batch Translation Loss:   6.861106 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:21:28,012 [Epoch: 011 Step: 00001719] Batch Translation Loss:   7.571167 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:21:46,816 [Epoch: 011 Step: 00001720] Batch Translation Loss:   6.341433 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:22:23,893 [Epoch: 011 Step: 00001721] Batch Translation Loss:   7.101882 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:22:38,885 [Epoch: 011 Step: 00001722] Batch Translation Loss:   6.326472 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:22:59,912 [Epoch: 011 Step: 00001723] Batch Translation Loss:   6.564039 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:23:22,685 [Epoch: 011 Step: 00001724] Batch Translation Loss:   6.999368 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:23:38,837 [Epoch: 011 Step: 00001725] Batch Translation Loss:   5.934564 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:23:50,525 [Epoch: 011 Step: 00001726] Batch Translation Loss:   6.612580 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-03 08:24:22,075 [Epoch: 011 Step: 00001727] Batch Translation Loss:   6.510707 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:24:53,567 [Epoch: 011 Step: 00001728] Batch Translation Loss:   6.563802 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:26:19,826 [Epoch: 011 Step: 00001729] Batch Translation Loss:   6.065731 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 08:27:15,000 [Epoch: 011 Step: 00001730] Batch Translation Loss:   7.364897 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:27:43,470 [Epoch: 011 Step: 00001731] Batch Translation Loss:   6.291317 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:28:04,391 [Epoch: 011 Step: 00001732] Batch Translation Loss:   6.708121 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:28:23,680 [Epoch: 011 Step: 00001733] Batch Translation Loss:   6.332635 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:28:45,742 [Epoch: 011 Step: 00001734] Batch Translation Loss:   6.371137 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:29:04,522 [Epoch: 011 Step: 00001735] Batch Translation Loss:   7.155342 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-03 08:29:40,445 [Epoch: 011 Step: 00001736] Batch Translation Loss:   7.135409 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:29:56,439 [Epoch: 011 Step: 00001737] Batch Translation Loss:   5.673991 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:30:13,177 [Epoch: 011 Step: 00001738] Batch Translation Loss:   6.987825 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:30:36,247 [Epoch: 011 Step: 00001739] Batch Translation Loss:   6.503363 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:31:56,232 [Epoch: 011 Step: 00001740] Batch Translation Loss:   7.292009 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:32:39,744 [Epoch: 011 Step: 00001741] Batch Translation Loss:   7.570569 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:33:16,008 [Epoch: 011 Step: 00001742] Batch Translation Loss:   6.854484 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:33:40,629 [Epoch: 011 Step: 00001743] Batch Translation Loss:   6.779929 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:34:09,437 [Epoch: 011 Step: 00001744] Batch Translation Loss:   6.575002 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:34:30,754 [Epoch: 011 Step: 00001745] Batch Translation Loss:   6.547090 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:34:54,360 [Epoch: 011 Step: 00001746] Batch Translation Loss:   6.148498 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:35:13,212 [Epoch: 011 Step: 00001747] Batch Translation Loss:   7.212032 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:35:33,056 [Epoch: 011 Step: 00001748] Batch Translation Loss:   6.435385 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:36:16,805 [Epoch: 011 Step: 00001749] Batch Translation Loss:   6.696721 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:36:53,294 [Epoch: 011 Step: 00001750] Batch Translation Loss:   6.915548 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:37:20,175 [Epoch: 011 Step: 00001751] Batch Translation Loss:   6.714769 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:38:07,168 [Epoch: 011 Step: 00001752] Batch Translation Loss:   6.925865 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:39:45,591 [Epoch: 011 Step: 00001753] Batch Translation Loss:   6.322004 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 08:40:15,037 [Epoch: 011 Step: 00001754] Batch Translation Loss:   6.090566 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:40:47,959 [Epoch: 011 Step: 00001755] Batch Translation Loss:   6.200096 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:41:33,929 [Epoch: 011 Step: 00001756] Batch Translation Loss:   6.387552 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:42:06,818 [Epoch: 011 Step: 00001757] Batch Translation Loss:   6.501462 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:42:25,504 [Epoch: 011 Step: 00001758] Batch Translation Loss:   6.447445 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:42:46,726 [Epoch: 011 Step: 00001759] Batch Translation Loss:   6.464838 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:43:05,486 [Epoch: 011 Step: 00001760] Batch Translation Loss:   6.587887 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:43:25,430 [Epoch: 011 Step: 00001761] Batch Translation Loss:   6.387981 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:44:32,184 [Epoch: 011 Step: 00001762] Batch Translation Loss:   6.437566 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:46:28,614 [Epoch: 011 Step: 00001763] Batch Translation Loss:   6.727444 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 08:47:07,430 [Epoch: 011 Step: 00001764] Batch Translation Loss:   6.309525 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:47:33,180 [Epoch: 011 Step: 00001765] Batch Translation Loss:   6.816364 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:48:03,979 [Epoch: 011 Step: 00001766] Batch Translation Loss:   6.319651 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:48:26,052 [Epoch: 011 Step: 00001767] Batch Translation Loss:   6.736304 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:49:15,244 [Epoch: 011 Step: 00001768] Batch Translation Loss:   7.287971 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:49:38,362 [Epoch: 011 Step: 00001769] Batch Translation Loss:   6.511176 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:50:03,408 [Epoch: 011 Step: 00001770] Batch Translation Loss:   6.756519 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:50:31,938 [Epoch: 011 Step: 00001771] Batch Translation Loss:   5.894494 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:51:19,842 [Epoch: 011 Step: 00001772] Batch Translation Loss:   5.748060 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:53:18,312 [Epoch: 011 Step: 00001773] Batch Translation Loss:   5.999461 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 08:54:28,191 [Epoch: 011 Step: 00001774] Batch Translation Loss:   6.606691 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:54:58,502 [Epoch: 011 Step: 00001775] Batch Translation Loss:   6.266834 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:55:22,105 [Epoch: 011 Step: 00001776] Batch Translation Loss:   6.314513 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:55:44,478 [Epoch: 011 Step: 00001777] Batch Translation Loss:   6.262006 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:56:07,858 [Epoch: 011 Step: 00001778] Batch Translation Loss:   6.814139 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:56:32,457 [Epoch: 011 Step: 00001779] Batch Translation Loss:   6.421686 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 08:56:56,677 [Epoch: 011 Step: 00001780] Batch Translation Loss:   6.201544 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 08:58:50,319 [Epoch: 011 Step: 00001781] Batch Translation Loss:   7.056535 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 09:00:15,438 [Epoch: 011 Step: 00001782] Batch Translation Loss:   6.469665 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 09:01:16,117 [Epoch: 011 Step: 00001783] Batch Translation Loss:   6.248608 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:02:03,575 [Epoch: 011 Step: 00001784] Batch Translation Loss:   6.543197 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:02:35,669 [Epoch: 011 Step: 00001785] Batch Translation Loss:   6.203821 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:03:06,727 [Epoch: 011 Step: 00001786] Batch Translation Loss:   6.611166 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:03:32,255 [Epoch: 011 Step: 00001787] Batch Translation Loss:   6.308219 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:03:59,404 [Epoch: 011 Step: 00001788] Batch Translation Loss:   6.662931 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:04:31,269 [Epoch: 011 Step: 00001789] Batch Translation Loss:   6.670792 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:05:58,134 [Epoch: 011 Step: 00001790] Batch Translation Loss:   6.695534 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 09:07:13,723 [Epoch: 011 Step: 00001791] Batch Translation Loss:   7.406209 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 09:08:37,960 [Epoch: 011 Step: 00001792] Batch Translation Loss:   6.507150 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:09:31,829 [Epoch: 011 Step: 00001793] Batch Translation Loss:   6.154731 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:09:57,999 [Epoch: 011 Step: 00001794] Batch Translation Loss:   6.218029 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:10:23,249 [Epoch: 011 Step: 00001795] Batch Translation Loss:   6.664453 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 09:10:53,110 [Epoch: 011 Step: 00001796] Batch Translation Loss:   6.123943 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:11:21,711 [Epoch: 011 Step: 00001797] Batch Translation Loss:   6.257881 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:12:48,857 [Epoch: 011 Step: 00001798] Batch Translation Loss:   6.388697 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 09:14:15,312 [Epoch: 011 Step: 00001799] Batch Translation Loss:   6.509307 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 09:15:36,967 [Epoch: 011 Step: 00001800] Batch Translation Loss:   6.741307 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 09:23:07,597 Validation result at epoch  11, step     1800: duration: 450.5814s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11360.47852	PPL: 7891.34766
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 0.63	(DEL: 24.49,	INS: 0.00,	SUB: 74.88)
	Sequence Accuracy 0.73
2022-01-03 09:23:13,984 Logging Recognition and Translation Outputs
2022-01-03 09:23:14,150 ========================================================================================================================
2022-01-03 09:23:14,150 Logging Sequence: deafvideo_3-otismhill82_4604
2022-01-03 09:23:14,151 	Text Reference  :	asl or
2022-01-03 09:23:14,151 	Text Hypothesis :	asl **
2022-01-03 09:23:14,151 	Text Alignment  :	    D 
2022-01-03 09:23:14,151 ========================================================================================================================
2022-01-03 09:23:14,151 Logging Sequence: youtube_4-howard_rosenblum_5577
2022-01-03 09:23:14,152 	Text Reference  :	dec
2022-01-03 09:23:14,152 	Text Hypothesis :	it 
2022-01-03 09:23:14,152 	Text Alignment  :	S  
2022-01-03 09:23:14,152 ========================================================================================================================
2022-01-03 09:23:14,152 Logging Sequence: deafvideo_2-deafpoweronethumbtwo_1783
2022-01-03 09:23:14,153 	Text Reference  :	oly
2022-01-03 09:23:14,153 	Text Hypothesis :	if 
2022-01-03 09:23:14,153 	Text Alignment  :	S  
2022-01-03 09:23:14,153 ========================================================================================================================
2022-01-03 09:23:14,153 Logging Sequence: deafvideo_3-otismhill82_4594
2022-01-03 09:23:14,154 	Text Reference  :	nfl zone
2022-01-03 09:23:14,154 	Text Hypothesis :	*** awti
2022-01-03 09:23:14,154 	Text Alignment  :	D   S   
2022-01-03 09:23:14,154 ========================================================================================================================
2022-01-03 09:23:14,154 Logging Sequence: youtube_4-lizzie_sorkin_5248
2022-01-03 09:23:14,155 	Text Reference  :	ltway
2022-01-03 09:23:14,155 	Text Hypothesis :	asl  
2022-01-03 09:23:14,155 	Text Alignment  :	S    
2022-01-03 09:23:14,155 ========================================================================================================================
2022-01-03 09:25:29,821 [Epoch: 011 Step: 00001801] Batch Translation Loss:   6.009231 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 09:26:54,867 [Epoch: 011 Step: 00001802] Batch Translation Loss:   6.228789 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 09:28:14,101 [Epoch: 011 Step: 00001803] Batch Translation Loss:   6.177985 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:29:02,592 [Epoch: 011 Step: 00001804] Batch Translation Loss:   6.210443 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:29:38,735 [Epoch: 011 Step: 00001805] Batch Translation Loss:   6.231126 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:30:50,771 [Epoch: 011 Step: 00001806] Batch Translation Loss:   6.084447 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 09:32:24,973 [Epoch: 011 Step: 00001807] Batch Translation Loss:   5.927590 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 09:33:23,467 [Epoch: 011 Step: 00001808] Batch Translation Loss:   6.582295 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:34:10,519 [Epoch: 011 Step: 00001809] Batch Translation Loss:   7.133843 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:34:39,792 [Epoch: 011 Step: 00001810] Batch Translation Loss:   6.311935 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:35:08,735 [Epoch: 011 Step: 00001811] Batch Translation Loss:   6.739750 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:35:39,301 [Epoch: 011 Step: 00001812] Batch Translation Loss:   6.640724 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:36:12,161 [Epoch: 011 Step: 00001813] Batch Translation Loss:   6.058079 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:36:47,225 [Epoch: 011 Step: 00001814] Batch Translation Loss:   6.759326 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:38:25,533 [Epoch: 011 Step: 00001815] Batch Translation Loss:   6.501365 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 09:40:18,774 [Epoch: 011 Step: 00001816] Batch Translation Loss:   6.813005 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 09:41:39,874 [Epoch: 011 Step: 00001817] Batch Translation Loss:   6.806120 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 09:42:47,945 [Epoch: 011 Step: 00001818] Batch Translation Loss:   6.325290 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:43:28,875 [Epoch: 011 Step: 00001819] Batch Translation Loss:   6.387632 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:44:02,225 [Epoch: 011 Step: 00001820] Batch Translation Loss:   5.976962 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:45:00,735 [Epoch: 011 Step: 00001821] Batch Translation Loss:   7.137073 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:47:06,699 [Epoch: 011 Step: 00001822] Batch Translation Loss:   6.333292 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 09:49:05,802 [Epoch: 011 Step: 00001823] Batch Translation Loss:   6.438743 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 09:49:42,866 [Epoch: 011 Step: 00001824] Batch Translation Loss:   6.389912 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:50:46,323 [Epoch: 011 Step: 00001825] Batch Translation Loss:   6.851323 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:51:16,697 [Epoch: 011 Step: 00001826] Batch Translation Loss:   7.225649 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:52:25,187 [Epoch: 011 Step: 00001827] Batch Translation Loss:   6.619246 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:54:27,866 [Epoch: 011 Step: 00001828] Batch Translation Loss:   6.041512 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 09:55:38,694 [Epoch: 011 Step: 00001829] Batch Translation Loss:   6.724809 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:56:32,012 [Epoch: 011 Step: 00001830] Batch Translation Loss:   6.565955 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:57:15,160 [Epoch: 011 Step: 00001831] Batch Translation Loss:   6.238885 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:58:27,170 [Epoch: 011 Step: 00001832] Batch Translation Loss:   7.096837 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 09:59:35,960 [Epoch: 011 Step: 00001833] Batch Translation Loss:   6.292043 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 10:01:52,642 [Epoch: 011 Step: 00001834] Batch Translation Loss:   6.733494 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 10:03:11,378 [Epoch: 011 Step: 00001835] Batch Translation Loss:   7.287525 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 10:03:57,469 [Epoch: 011 Step: 00001836] Batch Translation Loss:   6.513226 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 10:04:38,882 [Epoch: 011 Step: 00001837] Batch Translation Loss:   6.508683 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 10:05:22,675 [Epoch: 011 Step: 00001838] Batch Translation Loss:   6.312397 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 10:06:08,620 [Epoch: 011 Step: 00001839] Batch Translation Loss:   6.687234 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 10:08:14,054 [Epoch: 011 Step: 00001840] Batch Translation Loss:   6.553841 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 10:09:55,005 [Epoch: 011 Step: 00001841] Batch Translation Loss:   6.356296 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 10:11:08,248 [Epoch: 011 Step: 00001842] Batch Translation Loss:   5.935168 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 10:12:20,039 [Epoch: 011 Step: 00001843] Batch Translation Loss:   6.273262 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 10:13:03,530 [Epoch: 011 Step: 00001844] Batch Translation Loss:   7.099501 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 10:13:55,512 [Epoch: 011 Step: 00001845] Batch Translation Loss:   6.477339 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 10:16:11,630 [Epoch: 011 Step: 00001846] Batch Translation Loss:   5.851591 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 10:17:54,804 [Epoch: 011 Step: 00001847] Batch Translation Loss:   5.856000 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 10:18:50,393 [Epoch: 011 Step: 00001848] Batch Translation Loss:   6.943117 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 10:19:38,303 [Epoch: 011 Step: 00001849] Batch Translation Loss:   6.824683 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 10:21:05,639 [Epoch: 011 Step: 00001850] Batch Translation Loss:   5.603562 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 10:23:19,020 [Epoch: 011 Step: 00001851] Batch Translation Loss:   6.849960 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 10:25:04,700 [Epoch: 011 Step: 00001852] Batch Translation Loss:   6.301184 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 10:26:13,068 [Epoch: 011 Step: 00001853] Batch Translation Loss:   6.224133 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 10:27:04,790 [Epoch: 011 Step: 00001854] Batch Translation Loss:   6.023199 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 10:27:49,583 [Epoch: 011 Step: 00001855] Batch Translation Loss:   6.110518 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 10:28:34,706 [Epoch: 011 Step: 00001856] Batch Translation Loss:   6.739680 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 10:30:48,082 [Epoch: 011 Step: 00001857] Batch Translation Loss:   6.791933 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 10:32:39,066 [Epoch: 011 Step: 00001858] Batch Translation Loss:   6.825982 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 10:33:50,868 [Epoch: 011 Step: 00001859] Batch Translation Loss:   7.380098 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 10:34:51,383 [Epoch: 011 Step: 00001860] Batch Translation Loss:   6.241152 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 10:35:39,807 [Epoch: 011 Step: 00001861] Batch Translation Loss:   6.572596 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 10:37:44,159 [Epoch: 011 Step: 00001862] Batch Translation Loss:   6.431870 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 10:39:50,294 [Epoch: 011 Step: 00001863] Batch Translation Loss:   6.094360 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 10:41:19,271 [Epoch: 011 Step: 00001864] Batch Translation Loss:   6.534467 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 10:42:23,520 [Epoch: 011 Step: 00001865] Batch Translation Loss:   5.942003 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 10:43:38,872 [Epoch: 011 Step: 00001866] Batch Translation Loss:   7.041700 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 10:46:06,818 [Epoch: 011 Step: 00001867] Batch Translation Loss:   6.491497 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 10:47:38,730 [Epoch: 011 Step: 00001868] Batch Translation Loss:   5.845411 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 10:49:23,455 [Epoch: 011 Step: 00001869] Batch Translation Loss:   6.983622 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 10:50:02,281 [Epoch: 011 Step: 00001870] Batch Translation Loss:   4.544308 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 10:50:02,406 Epoch  11: Total Training Recognition Loss -1.00  Total Training Translation Loss 1112.84 
2022-01-03 10:50:02,406 EPOCH 12
2022-01-03 10:50:09,141 [Epoch: 012 Step: 00001871] Batch Translation Loss:   7.789446 => Txt Tokens per Sec:        5 || Lr: 0.001000
2022-01-03 10:50:19,949 [Epoch: 012 Step: 00001872] Batch Translation Loss:   7.136109 => Txt Tokens per Sec:        4 || Lr: 0.001000
2022-01-03 10:50:37,730 [Epoch: 012 Step: 00001873] Batch Translation Loss:   7.983892 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 10:51:06,140 [Epoch: 012 Step: 00001874] Batch Translation Loss:   7.502362 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 10:51:39,849 [Epoch: 012 Step: 00001875] Batch Translation Loss:   6.882096 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 10:52:05,624 [Epoch: 012 Step: 00001876] Batch Translation Loss:   7.014071 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 10:52:32,475 [Epoch: 012 Step: 00001877] Batch Translation Loss:   8.499927 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 10:53:10,545 [Epoch: 012 Step: 00001878] Batch Translation Loss:   8.393577 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 10:53:38,356 [Epoch: 012 Step: 00001879] Batch Translation Loss:   6.605602 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 10:53:58,886 [Epoch: 012 Step: 00001880] Batch Translation Loss:   6.631928 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 10:54:39,337 [Epoch: 012 Step: 00001881] Batch Translation Loss:   6.895749 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 10:55:11,648 [Epoch: 012 Step: 00001882] Batch Translation Loss:   7.015212 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 10:55:28,370 [Epoch: 012 Step: 00001883] Batch Translation Loss:   7.500091 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-03 10:55:54,651 [Epoch: 012 Step: 00001884] Batch Translation Loss:   7.477468 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 10:56:13,607 [Epoch: 012 Step: 00001885] Batch Translation Loss:   6.285689 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 10:56:30,329 [Epoch: 012 Step: 00001886] Batch Translation Loss:   7.394523 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 10:56:49,552 [Epoch: 012 Step: 00001887] Batch Translation Loss:   6.961528 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 10:57:20,574 [Epoch: 012 Step: 00001888] Batch Translation Loss:   7.345077 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 10:57:47,440 [Epoch: 012 Step: 00001889] Batch Translation Loss:   7.158495 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 10:58:57,065 [Epoch: 012 Step: 00001890] Batch Translation Loss:   7.164376 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 10:59:26,701 [Epoch: 012 Step: 00001891] Batch Translation Loss:   7.161071 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 10:59:51,819 [Epoch: 012 Step: 00001892] Batch Translation Loss:   5.771330 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:00:20,925 [Epoch: 012 Step: 00001893] Batch Translation Loss:   6.737919 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:00:54,017 [Epoch: 012 Step: 00001894] Batch Translation Loss:   6.863044 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 11:01:19,739 [Epoch: 012 Step: 00001895] Batch Translation Loss:   7.270669 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 11:01:37,821 [Epoch: 012 Step: 00001896] Batch Translation Loss:   6.815708 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 11:02:07,411 [Epoch: 012 Step: 00001897] Batch Translation Loss:   6.448960 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:02:25,720 [Epoch: 012 Step: 00001898] Batch Translation Loss:   6.945518 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-03 11:02:39,154 [Epoch: 012 Step: 00001899] Batch Translation Loss:   6.868949 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-03 11:02:55,378 [Epoch: 012 Step: 00001900] Batch Translation Loss:   6.617527 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-03 11:10:18,803 Validation result at epoch  12, step     1900: duration: 443.3812s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11377.09668	PPL: 8588.66016
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.35	(DEL: 23.17,	INS: 0.00,	SUB: 75.48)
	Sequence Accuracy 1.24
2022-01-03 11:10:27,551 Logging Recognition and Translation Outputs
2022-01-03 11:10:27,571 ========================================================================================================================
2022-01-03 11:10:27,571 Logging Sequence: youtube_5-daniel_durant_5875
2022-01-03 11:10:27,572 	Text Reference  :	hammer
2022-01-03 11:10:27,572 	Text Hypothesis :	of    
2022-01-03 11:10:27,572 	Text Alignment  :	S     
2022-01-03 11:10:27,573 ========================================================================================================================
2022-01-03 11:10:27,573 Logging Sequence: youtube_1-catherine_mackinnon_2834
2022-01-03 11:10:27,573 	Text Reference  :	date
2022-01-03 11:10:27,574 	Text Hypothesis :	asl 
2022-01-03 11:10:27,574 	Text Alignment  :	S   
2022-01-03 11:10:27,574 ========================================================================================================================
2022-01-03 11:10:27,574 Logging Sequence: youtube_5-caroline_jackson_5853
2022-01-03 11:10:27,575 	Text Reference  :	siri  
2022-01-03 11:10:27,575 	Text Hypothesis :	gerald
2022-01-03 11:10:27,575 	Text Alignment  :	S     
2022-01-03 11:10:27,575 ========================================================================================================================
2022-01-03 11:10:27,576 Logging Sequence: youtube_5-daniel_durant_5891
2022-01-03 11:10:27,576 	Text Reference  :	debg
2022-01-03 11:10:27,576 	Text Hypothesis :	of  
2022-01-03 11:10:27,576 	Text Alignment  :	S   
2022-01-03 11:10:27,577 ========================================================================================================================
2022-01-03 11:10:27,577 Logging Sequence: youtube_1-catherine_mackinnon_2820
2022-01-03 11:10:27,577 	Text Reference  :	nbda
2022-01-03 11:10:27,577 	Text Hypothesis :	asl 
2022-01-03 11:10:27,578 	Text Alignment  :	S   
2022-01-03 11:10:27,578 ========================================================================================================================
2022-01-03 11:11:30,854 [Epoch: 012 Step: 00001901] Batch Translation Loss:   5.929196 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 11:12:18,884 [Epoch: 012 Step: 00001902] Batch Translation Loss:   6.893874 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:13:27,140 [Epoch: 012 Step: 00001903] Batch Translation Loss:   6.286047 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:13:54,847 [Epoch: 012 Step: 00001904] Batch Translation Loss:   6.008756 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:14:45,099 [Epoch: 012 Step: 00001905] Batch Translation Loss:   6.871883 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:15:09,406 [Epoch: 012 Step: 00001906] Batch Translation Loss:   6.693707 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:15:44,439 [Epoch: 012 Step: 00001907] Batch Translation Loss:   6.156769 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:15:58,551 [Epoch: 012 Step: 00001908] Batch Translation Loss:   6.094599 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-03 11:16:14,190 [Epoch: 012 Step: 00001909] Batch Translation Loss:   6.652016 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 11:16:29,569 [Epoch: 012 Step: 00001910] Batch Translation Loss:   6.294813 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-03 11:16:56,149 [Epoch: 012 Step: 00001911] Batch Translation Loss:   6.361344 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 11:17:32,106 [Epoch: 012 Step: 00001912] Batch Translation Loss:   6.300928 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:18:24,950 [Epoch: 012 Step: 00001913] Batch Translation Loss:   7.395635 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:19:27,699 [Epoch: 012 Step: 00001914] Batch Translation Loss:   6.106953 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:19:52,487 [Epoch: 012 Step: 00001915] Batch Translation Loss:   6.950233 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:20:14,734 [Epoch: 012 Step: 00001916] Batch Translation Loss:   6.465220 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 11:20:46,453 [Epoch: 012 Step: 00001917] Batch Translation Loss:   6.556280 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:21:06,774 [Epoch: 012 Step: 00001918] Batch Translation Loss:   6.436578 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 11:21:27,821 [Epoch: 012 Step: 00001919] Batch Translation Loss:   6.183123 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 11:21:53,985 [Epoch: 012 Step: 00001920] Batch Translation Loss:   5.854709 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:22:36,296 [Epoch: 012 Step: 00001921] Batch Translation Loss:   6.616876 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:22:56,089 [Epoch: 012 Step: 00001922] Batch Translation Loss:   7.070376 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 11:23:16,133 [Epoch: 012 Step: 00001923] Batch Translation Loss:   6.963690 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 11:23:40,224 [Epoch: 012 Step: 00001924] Batch Translation Loss:   6.572065 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 11:23:57,252 [Epoch: 012 Step: 00001925] Batch Translation Loss:   5.861462 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 11:24:23,361 [Epoch: 012 Step: 00001926] Batch Translation Loss:   7.140245 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 11:25:01,777 [Epoch: 012 Step: 00001927] Batch Translation Loss:   6.522505 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:26:06,406 [Epoch: 012 Step: 00001928] Batch Translation Loss:   6.165305 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:26:50,827 [Epoch: 012 Step: 00001929] Batch Translation Loss:   6.556736 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:27:17,191 [Epoch: 012 Step: 00001930] Batch Translation Loss:   6.289787 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:28:01,712 [Epoch: 012 Step: 00001931] Batch Translation Loss:   6.673218 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:28:48,076 [Epoch: 012 Step: 00001932] Batch Translation Loss:   6.331249 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:29:07,879 [Epoch: 012 Step: 00001933] Batch Translation Loss:   6.199178 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 11:29:33,373 [Epoch: 012 Step: 00001934] Batch Translation Loss:   6.452277 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 11:30:09,726 [Epoch: 012 Step: 00001935] Batch Translation Loss:   7.405307 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:30:32,339 [Epoch: 012 Step: 00001936] Batch Translation Loss:   7.078989 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 11:30:52,753 [Epoch: 012 Step: 00001937] Batch Translation Loss:   6.561679 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 11:31:17,143 [Epoch: 012 Step: 00001938] Batch Translation Loss:   7.154290 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 11:31:36,845 [Epoch: 012 Step: 00001939] Batch Translation Loss:   6.373300 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 11:32:02,780 [Epoch: 012 Step: 00001940] Batch Translation Loss:   6.500470 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 11:33:14,929 [Epoch: 012 Step: 00001941] Batch Translation Loss:   6.665152 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:34:17,630 [Epoch: 012 Step: 00001942] Batch Translation Loss:   6.398554 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:34:53,054 [Epoch: 012 Step: 00001943] Batch Translation Loss:   6.127191 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:35:30,719 [Epoch: 012 Step: 00001944] Batch Translation Loss:   6.546463 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:35:53,739 [Epoch: 012 Step: 00001945] Batch Translation Loss:   6.222106 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 11:36:20,318 [Epoch: 012 Step: 00001946] Batch Translation Loss:   6.021714 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:36:44,892 [Epoch: 012 Step: 00001947] Batch Translation Loss:   6.581752 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 11:37:20,513 [Epoch: 012 Step: 00001948] Batch Translation Loss:   6.533557 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:37:49,355 [Epoch: 012 Step: 00001949] Batch Translation Loss:   6.193090 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:38:15,598 [Epoch: 012 Step: 00001950] Batch Translation Loss:   6.384746 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:38:39,662 [Epoch: 012 Step: 00001951] Batch Translation Loss:   5.730314 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 11:39:05,587 [Epoch: 012 Step: 00001952] Batch Translation Loss:   6.840535 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:39:45,867 [Epoch: 012 Step: 00001953] Batch Translation Loss:   7.234259 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:41:06,312 [Epoch: 012 Step: 00001954] Batch Translation Loss:   7.263558 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 11:42:01,690 [Epoch: 012 Step: 00001955] Batch Translation Loss:   6.593937 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:42:47,081 [Epoch: 012 Step: 00001956] Batch Translation Loss:   5.808699 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:43:18,189 [Epoch: 012 Step: 00001957] Batch Translation Loss:   6.017065 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:44:04,398 [Epoch: 012 Step: 00001958] Batch Translation Loss:   6.288300 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:44:30,983 [Epoch: 012 Step: 00001959] Batch Translation Loss:   6.632207 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:44:55,571 [Epoch: 012 Step: 00001960] Batch Translation Loss:   6.570013 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 11:45:47,474 [Epoch: 012 Step: 00001961] Batch Translation Loss:   6.706013 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:46:13,308 [Epoch: 012 Step: 00001962] Batch Translation Loss:   6.926691 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 11:47:06,398 [Epoch: 012 Step: 00001963] Batch Translation Loss:   6.044674 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:48:34,654 [Epoch: 012 Step: 00001964] Batch Translation Loss:   6.334040 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 11:50:47,765 [Epoch: 012 Step: 00001965] Batch Translation Loss:   6.731563 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 11:51:21,364 [Epoch: 012 Step: 00001966] Batch Translation Loss:   6.054651 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:51:47,486 [Epoch: 012 Step: 00001967] Batch Translation Loss:   6.993857 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 11:52:13,773 [Epoch: 012 Step: 00001968] Batch Translation Loss:   6.359084 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:52:50,731 [Epoch: 012 Step: 00001969] Batch Translation Loss:   6.340999 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:53:29,103 [Epoch: 012 Step: 00001970] Batch Translation Loss:   6.124227 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:54:09,235 [Epoch: 012 Step: 00001971] Batch Translation Loss:   5.989914 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:54:35,603 [Epoch: 012 Step: 00001972] Batch Translation Loss:   6.911397 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:55:34,719 [Epoch: 012 Step: 00001973] Batch Translation Loss:   6.433895 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 11:57:09,057 [Epoch: 012 Step: 00001974] Batch Translation Loss:   6.274501 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 11:59:08,110 [Epoch: 012 Step: 00001975] Batch Translation Loss:   6.594761 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 11:59:42,472 [Epoch: 012 Step: 00001976] Batch Translation Loss:   6.526975 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:00:11,750 [Epoch: 012 Step: 00001977] Batch Translation Loss:   7.078682 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:00:52,437 [Epoch: 012 Step: 00001978] Batch Translation Loss:   6.239373 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:01:32,252 [Epoch: 012 Step: 00001979] Batch Translation Loss:   6.759507 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:02:05,023 [Epoch: 012 Step: 00001980] Batch Translation Loss:   6.122988 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:02:34,174 [Epoch: 012 Step: 00001981] Batch Translation Loss:   6.412160 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:03:02,464 [Epoch: 012 Step: 00001982] Batch Translation Loss:   6.539114 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:04:17,521 [Epoch: 012 Step: 00001983] Batch Translation Loss:   6.297380 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:06:07,541 [Epoch: 012 Step: 00001984] Batch Translation Loss:   6.247152 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 12:07:28,711 [Epoch: 012 Step: 00001985] Batch Translation Loss:   7.036799 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 12:08:45,859 [Epoch: 012 Step: 00001986] Batch Translation Loss:   6.759392 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:09:38,048 [Epoch: 012 Step: 00001987] Batch Translation Loss:   6.052567 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:11:14,383 [Epoch: 012 Step: 00001988] Batch Translation Loss:   6.209769 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 12:12:56,756 [Epoch: 012 Step: 00001989] Batch Translation Loss:   6.539879 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 12:14:44,792 [Epoch: 012 Step: 00001990] Batch Translation Loss:   6.378851 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 12:15:53,584 [Epoch: 012 Step: 00001991] Batch Translation Loss:   6.128861 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:16:49,791 [Epoch: 012 Step: 00001992] Batch Translation Loss:   6.270293 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:17:42,991 [Epoch: 012 Step: 00001993] Batch Translation Loss:   5.852101 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:18:24,134 [Epoch: 012 Step: 00001994] Batch Translation Loss:   6.062114 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:18:58,685 [Epoch: 012 Step: 00001995] Batch Translation Loss:   7.056481 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:20:04,573 [Epoch: 012 Step: 00001996] Batch Translation Loss:   6.939818 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:22:05,825 [Epoch: 012 Step: 00001997] Batch Translation Loss:   6.809016 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 12:23:42,816 [Epoch: 012 Step: 00001998] Batch Translation Loss:   6.467061 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 12:24:27,463 [Epoch: 012 Step: 00001999] Batch Translation Loss:   6.645691 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:25:03,919 [Epoch: 012 Step: 00002000] Batch Translation Loss:   7.150395 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:32:22,117 Validation result at epoch  12, step     2000: duration: 438.1653s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 10966.04492	PPL: 8564.35156
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.98	(DEL: 20.64,	INS: 0.00,	SUB: 77.37)
	Sequence Accuracy 1.87
2022-01-03 12:32:30,799 Logging Recognition and Translation Outputs
2022-01-03 12:32:30,831 ========================================================================================================================
2022-01-03 12:32:30,832 Logging Sequence: youtube_6-myles_de_bastion_6521
2022-01-03 12:32:30,833 	Text Reference  :	emmett do 
2022-01-03 12:32:30,833 	Text Hypothesis :	****** asl
2022-01-03 12:32:30,833 	Text Alignment  :	D      S  
2022-01-03 12:32:30,833 ========================================================================================================================
2022-01-03 12:32:30,833 Logging Sequence: deafvideo_4-titans_4705
2022-01-03 12:32:30,834 	Text Reference  :	acts
2022-01-03 12:32:30,834 	Text Hypothesis :	asl 
2022-01-03 12:32:30,834 	Text Alignment  :	S   
2022-01-03 12:32:30,834 ========================================================================================================================
2022-01-03 12:32:30,835 Logging Sequence: youtube_5-roberta_cordano_6125
2022-01-03 12:32:30,835 	Text Reference  :	disabity
2022-01-03 12:32:30,835 	Text Hypothesis :	asl     
2022-01-03 12:32:30,835 	Text Alignment  :	S       
2022-01-03 12:32:30,836 ========================================================================================================================
2022-01-03 12:32:30,836 Logging Sequence: aslized-suzanne_stecker_0265
2022-01-03 12:32:30,836 	Text Reference  :	rollover
2022-01-03 12:32:30,836 	Text Hypothesis :	ok      
2022-01-03 12:32:30,836 	Text Alignment  :	S       
2022-01-03 12:32:30,837 ========================================================================================================================
2022-01-03 12:32:30,837 Logging Sequence: youtube_5-roberta_cordano_6136
2022-01-03 12:32:30,837 	Text Reference  :	nad
2022-01-03 12:32:30,837 	Text Hypothesis :	asl
2022-01-03 12:32:30,838 	Text Alignment  :	S  
2022-01-03 12:32:30,838 ========================================================================================================================
2022-01-03 12:35:31,953 [Epoch: 012 Step: 00002001] Batch Translation Loss:   7.022121 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 12:37:37,221 [Epoch: 012 Step: 00002002] Batch Translation Loss:   6.345192 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 12:39:31,740 [Epoch: 012 Step: 00002003] Batch Translation Loss:   6.886123 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 12:40:39,101 [Epoch: 012 Step: 00002004] Batch Translation Loss:   6.391965 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:41:29,565 [Epoch: 012 Step: 00002005] Batch Translation Loss:   6.296436 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:42:47,663 [Epoch: 012 Step: 00002006] Batch Translation Loss:   6.311043 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:45:12,762 [Epoch: 012 Step: 00002007] Batch Translation Loss:   6.381484 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 12:46:46,385 [Epoch: 012 Step: 00002008] Batch Translation Loss:   6.535913 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 12:47:39,959 [Epoch: 012 Step: 00002009] Batch Translation Loss:   5.947871 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:48:25,730 [Epoch: 012 Step: 00002010] Batch Translation Loss:   6.341897 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:49:08,832 [Epoch: 012 Step: 00002011] Batch Translation Loss:   6.213223 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:49:51,895 [Epoch: 012 Step: 00002012] Batch Translation Loss:   6.667443 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:50:41,760 [Epoch: 012 Step: 00002013] Batch Translation Loss:   6.562766 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:51:53,793 [Epoch: 012 Step: 00002014] Batch Translation Loss:   6.367992 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:54:20,286 [Epoch: 012 Step: 00002015] Batch Translation Loss:   6.309335 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 12:55:48,557 [Epoch: 012 Step: 00002016] Batch Translation Loss:   6.719080 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 12:56:41,032 [Epoch: 012 Step: 00002017] Batch Translation Loss:   5.923255 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:57:25,395 [Epoch: 012 Step: 00002018] Batch Translation Loss:   7.095225 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:58:17,420 [Epoch: 012 Step: 00002019] Batch Translation Loss:   6.404341 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:58:55,339 [Epoch: 012 Step: 00002020] Batch Translation Loss:   6.367786 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 12:59:32,920 [Epoch: 012 Step: 00002021] Batch Translation Loss:   6.635822 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:01:35,323 [Epoch: 012 Step: 00002022] Batch Translation Loss:   6.490565 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 13:04:03,059 [Epoch: 012 Step: 00002023] Batch Translation Loss:   6.968059 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 13:06:00,916 [Epoch: 012 Step: 00002024] Batch Translation Loss:   6.636120 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 13:07:13,616 [Epoch: 012 Step: 00002025] Batch Translation Loss:   6.125594 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 13:07:56,062 [Epoch: 012 Step: 00002026] Batch Translation Loss:   5.782651 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:12:20,342 [Epoch: 012 Step: 00002027] Batch Translation Loss:   6.459359 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 13:13:51,215 [Epoch: 012 Step: 00002028] Batch Translation Loss:   7.003374 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 13:15:05,592 [Epoch: 012 Step: 00002029] Batch Translation Loss:   6.408989 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:16:32,991 [Epoch: 012 Step: 00002030] Batch Translation Loss:   7.020899 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 13:19:02,351 [Epoch: 012 Step: 00002031] Batch Translation Loss:   6.971754 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 13:21:14,532 [Epoch: 012 Step: 00002032] Batch Translation Loss:   6.251156 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 13:22:45,428 [Epoch: 012 Step: 00002033] Batch Translation Loss:   6.676862 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 13:23:55,025 [Epoch: 012 Step: 00002034] Batch Translation Loss:   6.249894 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:24:36,272 [Epoch: 012 Step: 00002035] Batch Translation Loss:   6.160162 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:25:37,901 [Epoch: 012 Step: 00002036] Batch Translation Loss:   6.290858 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:28:05,199 [Epoch: 012 Step: 00002037] Batch Translation Loss:   6.859632 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 13:29:30,936 [Epoch: 012 Step: 00002038] Batch Translation Loss:   6.683476 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 13:31:31,037 [Epoch: 012 Step: 00002039] Batch Translation Loss:   6.503064 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 13:32:51,864 [Epoch: 012 Step: 00002040] Batch Translation Loss:   6.783854 => Txt Tokens per Sec:        0 || Lr: 0.001000
2022-01-03 13:32:51,996 Epoch  12: Total Training Recognition Loss -1.00  Total Training Translation Loss 1122.23 
2022-01-03 13:32:51,997 EPOCH 13
2022-01-03 13:33:00,116 [Epoch: 013 Step: 00002041] Batch Translation Loss:   6.298779 => Txt Tokens per Sec:        5 || Lr: 0.001000
2022-01-03 13:33:08,257 [Epoch: 013 Step: 00002042] Batch Translation Loss:   6.965666 => Txt Tokens per Sec:        5 || Lr: 0.001000
2022-01-03 13:33:28,249 [Epoch: 013 Step: 00002043] Batch Translation Loss:   6.695339 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 13:33:51,540 [Epoch: 013 Step: 00002044] Batch Translation Loss:   6.987532 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 13:34:51,101 [Epoch: 013 Step: 00002045] Batch Translation Loss:   6.808519 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:35:41,753 [Epoch: 013 Step: 00002046] Batch Translation Loss:   7.254827 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:36:08,011 [Epoch: 013 Step: 00002047] Batch Translation Loss:   6.740569 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:36:34,285 [Epoch: 013 Step: 00002048] Batch Translation Loss:   7.183577 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 13:36:55,090 [Epoch: 013 Step: 00002049] Batch Translation Loss:   6.924727 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 13:37:37,576 [Epoch: 013 Step: 00002050] Batch Translation Loss:   6.580715 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:38:08,089 [Epoch: 013 Step: 00002051] Batch Translation Loss:   6.460067 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:38:30,772 [Epoch: 013 Step: 00002052] Batch Translation Loss:   7.172038 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 13:38:52,117 [Epoch: 013 Step: 00002053] Batch Translation Loss:   7.354008 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 13:39:07,974 [Epoch: 013 Step: 00002054] Batch Translation Loss:   6.501810 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-03 13:39:42,000 [Epoch: 013 Step: 00002055] Batch Translation Loss:   6.852323 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:39:57,023 [Epoch: 013 Step: 00002056] Batch Translation Loss:   7.208747 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-03 13:40:15,555 [Epoch: 013 Step: 00002057] Batch Translation Loss:   6.028005 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 13:40:34,503 [Epoch: 013 Step: 00002058] Batch Translation Loss:   7.149137 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 13:41:08,365 [Epoch: 013 Step: 00002059] Batch Translation Loss:   6.842999 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:41:38,686 [Epoch: 013 Step: 00002060] Batch Translation Loss:   6.545465 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:42:19,771 [Epoch: 013 Step: 00002061] Batch Translation Loss:   6.290823 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:43:17,166 [Epoch: 013 Step: 00002062] Batch Translation Loss:   6.804023 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:43:41,689 [Epoch: 013 Step: 00002063] Batch Translation Loss:   6.412898 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 13:44:12,332 [Epoch: 013 Step: 00002064] Batch Translation Loss:   6.911299 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:44:32,886 [Epoch: 013 Step: 00002065] Batch Translation Loss:   6.960937 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 13:44:56,610 [Epoch: 013 Step: 00002066] Batch Translation Loss:   7.450076 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 13:45:28,234 [Epoch: 013 Step: 00002067] Batch Translation Loss:   6.361438 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:45:42,661 [Epoch: 013 Step: 00002068] Batch Translation Loss:   6.465219 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 13:46:13,035 [Epoch: 013 Step: 00002069] Batch Translation Loss:   6.974053 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:46:26,567 [Epoch: 013 Step: 00002070] Batch Translation Loss:   6.700051 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-03 13:46:39,700 [Epoch: 013 Step: 00002071] Batch Translation Loss:   5.699255 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-03 13:46:59,090 [Epoch: 013 Step: 00002072] Batch Translation Loss:   6.693884 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 13:47:27,124 [Epoch: 013 Step: 00002073] Batch Translation Loss:   6.142385 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 13:47:54,684 [Epoch: 013 Step: 00002074] Batch Translation Loss:   6.666570 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 13:48:12,046 [Epoch: 013 Step: 00002075] Batch Translation Loss:   6.950566 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 13:48:25,290 [Epoch: 013 Step: 00002076] Batch Translation Loss:   6.658458 => Txt Tokens per Sec:        3 || Lr: 0.001000
2022-01-03 13:48:43,077 [Epoch: 013 Step: 00002077] Batch Translation Loss:   6.108636 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 13:49:10,456 [Epoch: 013 Step: 00002078] Batch Translation Loss:   7.110931 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 13:49:51,611 [Epoch: 013 Step: 00002079] Batch Translation Loss:   7.097888 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:50:39,837 [Epoch: 013 Step: 00002080] Batch Translation Loss:   6.276987 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:51:20,641 [Epoch: 013 Step: 00002081] Batch Translation Loss:   7.417908 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:51:55,737 [Epoch: 013 Step: 00002082] Batch Translation Loss:   6.283978 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:52:16,763 [Epoch: 013 Step: 00002083] Batch Translation Loss:   6.395558 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 13:52:35,044 [Epoch: 013 Step: 00002084] Batch Translation Loss:   6.460654 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 13:53:03,532 [Epoch: 013 Step: 00002085] Batch Translation Loss:   6.102308 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:53:45,091 [Epoch: 013 Step: 00002086] Batch Translation Loss:   6.034838 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:54:09,258 [Epoch: 013 Step: 00002087] Batch Translation Loss:   5.754551 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:54:49,975 [Epoch: 013 Step: 00002088] Batch Translation Loss:   7.314285 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:55:19,229 [Epoch: 013 Step: 00002089] Batch Translation Loss:   6.271315 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:56:02,974 [Epoch: 013 Step: 00002090] Batch Translation Loss:   6.862978 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:56:21,580 [Epoch: 013 Step: 00002091] Batch Translation Loss:   6.095303 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 13:56:48,085 [Epoch: 013 Step: 00002092] Batch Translation Loss:   6.878078 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 13:57:25,681 [Epoch: 013 Step: 00002093] Batch Translation Loss:   6.285200 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:58:27,560 [Epoch: 013 Step: 00002094] Batch Translation Loss:   6.627019 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:59:10,085 [Epoch: 013 Step: 00002095] Batch Translation Loss:   6.515780 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 13:59:40,156 [Epoch: 013 Step: 00002096] Batch Translation Loss:   6.897773 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 14:00:11,576 [Epoch: 013 Step: 00002097] Batch Translation Loss:   6.652383 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 14:00:46,343 [Epoch: 013 Step: 00002098] Batch Translation Loss:   6.024428 => Txt Tokens per Sec:        1 || Lr: 0.001000
2022-01-03 14:01:07,322 [Epoch: 013 Step: 00002099] Batch Translation Loss:   6.354031 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 14:01:28,613 [Epoch: 013 Step: 00002100] Batch Translation Loss:   6.500531 => Txt Tokens per Sec:        2 || Lr: 0.001000
2022-01-03 14:09:22,182 Validation result at epoch  13, step     2100: duration: 473.4901s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11366.00391	PPL: 8213.08594
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 2.70	(DEL: 23.95,	INS: 0.00,	SUB: 73.35)
	Sequence Accuracy 2.71
2022-01-03 14:09:29,539 Logging Recognition and Translation Outputs
2022-01-03 14:09:29,613 ========================================================================================================================
2022-01-03 14:09:29,613 Logging Sequence: deafvideo_3-deafgoldenhair_3073
2022-01-03 14:09:29,613 	Text Reference  :	android
2022-01-03 14:09:29,614 	Text Hypothesis :	so     
2022-01-03 14:09:29,614 	Text Alignment  :	S      
2022-01-03 14:09:29,614 ========================================================================================================================
2022-01-03 14:09:29,614 Logging Sequence: youtube_6-myles_de_bastion_6518
2022-01-03 14:09:29,614 	Text Reference  :	gis
2022-01-03 14:09:29,615 	Text Hypothesis :	asl
2022-01-03 14:09:29,615 	Text Alignment  :	S  
2022-01-03 14:09:29,615 ========================================================================================================================
2022-01-03 14:09:29,615 Logging Sequence: deafvideo_3-geoalpha_4555
2022-01-03 14:09:29,615 	Text Reference  :	md 
2022-01-03 14:09:29,616 	Text Hypothesis :	asl
2022-01-03 14:09:29,616 	Text Alignment  :	S  
2022-01-03 14:09:29,616 ========================================================================================================================
2022-01-03 14:09:29,616 Logging Sequence: deafvideo_2-sddsimple_1567
2022-01-03 14:09:29,616 	Text Reference  :	flash manual on
2022-01-03 14:09:29,617 	Text Hypothesis :	***** ****** so
2022-01-03 14:09:29,617 	Text Alignment  :	D     D      S 
2022-01-03 14:09:29,617 ========================================================================================================================
2022-01-03 14:09:29,617 Logging Sequence: deafvideo_3-titans_4692
2022-01-03 14:09:29,617 	Text Reference  :	stakeholders
2022-01-03 14:09:29,618 	Text Hypothesis :	asl         
2022-01-03 14:09:29,618 	Text Alignment  :	S           
2022-01-03 14:09:29,618 ========================================================================================================================
2022-01-03 14:11:11,738 [Epoch: 013 Step: 00002101] Batch Translation Loss:   6.513521 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 14:12:25,368 [Epoch: 013 Step: 00002102] Batch Translation Loss:   6.017264 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:13:10,586 [Epoch: 013 Step: 00002103] Batch Translation Loss:   6.032368 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:14:28,569 [Epoch: 013 Step: 00002104] Batch Translation Loss:   6.621673 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 14:15:04,417 [Epoch: 013 Step: 00002105] Batch Translation Loss:   6.366418 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:15:30,465 [Epoch: 013 Step: 00002106] Batch Translation Loss:   6.035922 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:15:56,926 [Epoch: 013 Step: 00002107] Batch Translation Loss:   6.339266 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:16:26,993 [Epoch: 013 Step: 00002108] Batch Translation Loss:   5.823736 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:16:53,610 [Epoch: 013 Step: 00002109] Batch Translation Loss:   6.300923 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:17:18,374 [Epoch: 013 Step: 00002110] Batch Translation Loss:   6.262426 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 14:17:42,407 [Epoch: 013 Step: 00002111] Batch Translation Loss:   5.941769 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 14:18:22,555 [Epoch: 013 Step: 00002112] Batch Translation Loss:   6.447413 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:18:59,703 [Epoch: 013 Step: 00002113] Batch Translation Loss:   6.049763 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:20:13,447 [Epoch: 013 Step: 00002114] Batch Translation Loss:   6.406181 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:21:17,270 [Epoch: 013 Step: 00002115] Batch Translation Loss:   6.033100 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:22:09,785 [Epoch: 013 Step: 00002116] Batch Translation Loss:   6.154217 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:22:56,172 [Epoch: 013 Step: 00002117] Batch Translation Loss:   6.455577 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:23:35,098 [Epoch: 013 Step: 00002118] Batch Translation Loss:   6.057178 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:24:06,958 [Epoch: 013 Step: 00002119] Batch Translation Loss:   6.548839 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:24:29,263 [Epoch: 013 Step: 00002120] Batch Translation Loss:   6.175330 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 14:24:56,529 [Epoch: 013 Step: 00002121] Batch Translation Loss:   6.407532 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:25:47,608 [Epoch: 013 Step: 00002122] Batch Translation Loss:   6.546604 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:26:15,952 [Epoch: 013 Step: 00002123] Batch Translation Loss:   6.025262 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:27:23,883 [Epoch: 013 Step: 00002124] Batch Translation Loss:   6.615002 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:28:57,237 [Epoch: 013 Step: 00002125] Batch Translation Loss:   6.224109 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 14:29:54,087 [Epoch: 013 Step: 00002126] Batch Translation Loss:   6.216062 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:30:37,924 [Epoch: 013 Step: 00002127] Batch Translation Loss:   6.953239 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:31:05,187 [Epoch: 013 Step: 00002128] Batch Translation Loss:   6.053537 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 14:31:30,638 [Epoch: 013 Step: 00002129] Batch Translation Loss:   6.062112 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:31:55,764 [Epoch: 013 Step: 00002130] Batch Translation Loss:   6.394760 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 14:32:25,401 [Epoch: 013 Step: 00002131] Batch Translation Loss:   5.967001 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:32:51,900 [Epoch: 013 Step: 00002132] Batch Translation Loss:   6.470261 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:33:22,667 [Epoch: 013 Step: 00002133] Batch Translation Loss:   6.823058 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:33:50,539 [Epoch: 013 Step: 00002134] Batch Translation Loss:   6.267622 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:34:17,890 [Epoch: 013 Step: 00002135] Batch Translation Loss:   6.781622 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:35:06,615 [Epoch: 013 Step: 00002136] Batch Translation Loss:   6.612557 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:36:57,064 [Epoch: 013 Step: 00002137] Batch Translation Loss:   6.980981 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 14:38:20,615 [Epoch: 013 Step: 00002138] Batch Translation Loss:   5.920485 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 14:39:16,141 [Epoch: 013 Step: 00002139] Batch Translation Loss:   5.880942 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:40:13,842 [Epoch: 013 Step: 00002140] Batch Translation Loss:   6.570650 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:40:53,711 [Epoch: 013 Step: 00002141] Batch Translation Loss:   6.114209 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:41:33,943 [Epoch: 013 Step: 00002142] Batch Translation Loss:   6.596743 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:42:08,171 [Epoch: 013 Step: 00002143] Batch Translation Loss:   5.873619 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:42:38,971 [Epoch: 013 Step: 00002144] Batch Translation Loss:   5.867980 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:43:09,272 [Epoch: 013 Step: 00002145] Batch Translation Loss:   5.749632 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:43:39,927 [Epoch: 013 Step: 00002146] Batch Translation Loss:   5.963592 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:44:28,167 [Epoch: 013 Step: 00002147] Batch Translation Loss:   5.733780 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:46:11,048 [Epoch: 013 Step: 00002148] Batch Translation Loss:   6.105488 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 14:47:27,306 [Epoch: 013 Step: 00002149] Batch Translation Loss:   6.933548 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:48:01,613 [Epoch: 013 Step: 00002150] Batch Translation Loss:   6.157566 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:48:38,092 [Epoch: 013 Step: 00002151] Batch Translation Loss:   6.443338 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:49:12,643 [Epoch: 013 Step: 00002152] Batch Translation Loss:   5.890602 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:50:00,160 [Epoch: 013 Step: 00002153] Batch Translation Loss:   6.919424 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:50:44,248 [Epoch: 013 Step: 00002154] Batch Translation Loss:   6.599973 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:51:17,543 [Epoch: 013 Step: 00002155] Batch Translation Loss:   6.079647 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:52:04,791 [Epoch: 013 Step: 00002156] Batch Translation Loss:   6.181928 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:53:09,104 [Epoch: 013 Step: 00002157] Batch Translation Loss:   6.635848 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:54:58,209 [Epoch: 013 Step: 00002158] Batch Translation Loss:   6.436146 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 14:55:58,558 [Epoch: 013 Step: 00002159] Batch Translation Loss:   7.165493 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:56:35,409 [Epoch: 013 Step: 00002160] Batch Translation Loss:   6.886614 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:57:17,246 [Epoch: 013 Step: 00002161] Batch Translation Loss:   6.272647 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 14:58:56,466 [Epoch: 013 Step: 00002162] Batch Translation Loss:   6.365779 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 14:59:27,969 [Epoch: 013 Step: 00002163] Batch Translation Loss:   6.008850 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 15:00:27,141 [Epoch: 013 Step: 00002164] Batch Translation Loss:   6.387542 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 15:01:00,831 [Epoch: 013 Step: 00002165] Batch Translation Loss:   6.058406 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 15:02:02,957 [Epoch: 013 Step: 00002166] Batch Translation Loss:   6.583692 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 15:03:51,964 [Epoch: 013 Step: 00002167] Batch Translation Loss:   6.050810 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 15:04:59,228 [Epoch: 013 Step: 00002168] Batch Translation Loss:   6.428562 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 15:05:47,069 [Epoch: 013 Step: 00002169] Batch Translation Loss:   5.902897 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 15:06:29,777 [Epoch: 013 Step: 00002170] Batch Translation Loss:   6.034002 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 15:07:09,460 [Epoch: 013 Step: 00002171] Batch Translation Loss:   6.163681 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 15:07:50,425 [Epoch: 013 Step: 00002172] Batch Translation Loss:   6.438272 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 15:08:30,085 [Epoch: 013 Step: 00002173] Batch Translation Loss:   6.377306 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 15:09:12,086 [Epoch: 013 Step: 00002174] Batch Translation Loss:   6.928605 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 15:09:48,515 [Epoch: 013 Step: 00002175] Batch Translation Loss:   6.053402 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 15:11:00,401 [Epoch: 013 Step: 00002176] Batch Translation Loss:   6.098115 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 15:13:14,822 [Epoch: 013 Step: 00002177] Batch Translation Loss:   7.251573 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 15:14:36,624 [Epoch: 013 Step: 00002178] Batch Translation Loss:   6.335444 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 15:15:20,014 [Epoch: 013 Step: 00002179] Batch Translation Loss:   5.914175 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 15:16:09,373 [Epoch: 013 Step: 00002180] Batch Translation Loss:   5.988879 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 15:17:20,929 [Epoch: 013 Step: 00002181] Batch Translation Loss:   6.494308 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 15:18:13,314 [Epoch: 013 Step: 00002182] Batch Translation Loss:   6.384605 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 15:18:48,451 [Epoch: 013 Step: 00002183] Batch Translation Loss:   6.446733 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 15:19:53,548 [Epoch: 013 Step: 00002184] Batch Translation Loss:   6.292979 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 15:22:19,011 [Epoch: 013 Step: 00002185] Batch Translation Loss:   5.742197 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 15:24:02,425 [Epoch: 013 Step: 00002186] Batch Translation Loss:   6.228388 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 15:25:04,279 [Epoch: 013 Step: 00002187] Batch Translation Loss:   6.490861 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 15:26:02,177 [Epoch: 013 Step: 00002188] Batch Translation Loss:   6.367367 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 15:26:49,867 [Epoch: 013 Step: 00002189] Batch Translation Loss:   5.590714 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 15:27:31,709 [Epoch: 013 Step: 00002190] Batch Translation Loss:   7.521285 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 15:28:20,171 [Epoch: 013 Step: 00002191] Batch Translation Loss:   6.463542 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 15:30:31,015 [Epoch: 013 Step: 00002192] Batch Translation Loss:   6.080400 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 15:32:07,131 [Epoch: 013 Step: 00002193] Batch Translation Loss:   6.470485 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 15:33:10,506 [Epoch: 013 Step: 00002194] Batch Translation Loss:   5.926681 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 15:33:59,091 [Epoch: 013 Step: 00002195] Batch Translation Loss:   5.484376 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 15:34:41,472 [Epoch: 013 Step: 00002196] Batch Translation Loss:   5.895413 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 15:37:06,464 [Epoch: 013 Step: 00002197] Batch Translation Loss:   6.665460 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 15:39:05,749 [Epoch: 013 Step: 00002198] Batch Translation Loss:   6.097905 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 15:40:53,743 [Epoch: 013 Step: 00002199] Batch Translation Loss:   5.938751 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 15:42:00,748 [Epoch: 013 Step: 00002200] Batch Translation Loss:   6.626296 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 15:50:03,615 Validation result at epoch  13, step     2200: duration: 482.8250s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11545.30957	PPL: 8685.16113
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 2.59	(DEL: 24.59,	INS: 0.00,	SUB: 72.82)
	Sequence Accuracy 2.50
2022-01-03 15:50:11,242 Logging Recognition and Translation Outputs
2022-01-03 15:50:11,260 ========================================================================================================================
2022-01-03 15:50:11,260 Logging Sequence: youtube_4-tim_albert_5273
2022-01-03 15:50:11,261 	Text Reference  :	emmett do 
2022-01-03 15:50:11,261 	Text Hypothesis :	****** asl
2022-01-03 15:50:11,262 	Text Alignment  :	D      S  
2022-01-03 15:50:11,262 ========================================================================================================================
2022-01-03 15:50:11,262 Logging Sequence: deafvideo_3-yesyes_3111
2022-01-03 15:50:11,263 	Text Reference  :	emtt
2022-01-03 15:50:11,263 	Text Hypothesis :	or  
2022-01-03 15:50:11,263 	Text Alignment  :	S   
2022-01-03 15:50:11,263 ========================================================================================================================
2022-01-03 15:50:11,264 Logging Sequence: youtube_5-daniel_durant_5896
2022-01-03 15:50:11,264 	Text Reference  :	yr 
2022-01-03 15:50:11,264 	Text Hypothesis :	asl
2022-01-03 15:50:11,264 	Text Alignment  :	S  
2022-01-03 15:50:11,265 ========================================================================================================================
2022-01-03 15:50:11,265 Logging Sequence: deafvideo_3-deafgoldenhair_3066
2022-01-03 15:50:11,265 	Text Reference  :	nirmod
2022-01-03 15:50:11,266 	Text Hypothesis :	dr    
2022-01-03 15:50:11,266 	Text Alignment  :	S     
2022-01-03 15:50:11,266 ========================================================================================================================
2022-01-03 15:50:11,266 Logging Sequence: youtube_1-don_grushkin_2771
2022-01-03 15:50:11,267 	Text Reference  :	camaspace
2022-01-03 15:50:11,267 	Text Hypothesis :	dr       
2022-01-03 15:50:11,267 	Text Alignment  :	S        
2022-01-03 15:50:11,268 ========================================================================================================================
2022-01-03 15:53:12,263 [Epoch: 013 Step: 00002201] Batch Translation Loss:   6.275182 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 15:55:27,333 [Epoch: 013 Step: 00002202] Batch Translation Loss:   6.175866 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 15:57:37,419 [Epoch: 013 Step: 00002203] Batch Translation Loss:   6.210586 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 15:58:51,302 [Epoch: 013 Step: 00002204] Batch Translation Loss:   6.143015 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:00:35,332 [Epoch: 013 Step: 00002205] Batch Translation Loss:   6.446818 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 16:01:15,055 [Epoch: 013 Step: 00002206] Batch Translation Loss:   7.003582 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:02:20,421 [Epoch: 013 Step: 00002207] Batch Translation Loss:   6.466285 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:06:14,781 [Epoch: 013 Step: 00002208] Batch Translation Loss:   6.504869 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 16:07:21,949 [Epoch: 013 Step: 00002209] Batch Translation Loss:   6.141904 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:08:03,475 [Epoch: 013 Step: 00002210] Batch Translation Loss:   7.570755 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 16:08:03,659 Epoch  13: Total Training Recognition Loss -1.00  Total Training Translation Loss 1093.50 
2022-01-03 16:08:03,659 EPOCH 14
2022-01-03 16:08:10,807 [Epoch: 014 Step: 00002211] Batch Translation Loss:   6.259648 => Txt Tokens per Sec:        5 || Lr: 0.000700
2022-01-03 16:08:18,572 [Epoch: 014 Step: 00002212] Batch Translation Loss:   6.706912 => Txt Tokens per Sec:        5 || Lr: 0.000700
2022-01-03 16:08:29,349 [Epoch: 014 Step: 00002213] Batch Translation Loss:   7.133857 => Txt Tokens per Sec:        4 || Lr: 0.000700
2022-01-03 16:08:49,477 [Epoch: 014 Step: 00002214] Batch Translation Loss:   6.608937 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:09:28,181 [Epoch: 014 Step: 00002215] Batch Translation Loss:   7.280859 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:09:55,437 [Epoch: 014 Step: 00002216] Batch Translation Loss:   6.137658 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:10:29,769 [Epoch: 014 Step: 00002217] Batch Translation Loss:   7.273086 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:11:19,982 [Epoch: 014 Step: 00002218] Batch Translation Loss:   6.884167 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:11:50,134 [Epoch: 014 Step: 00002219] Batch Translation Loss:   6.608253 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:12:17,081 [Epoch: 014 Step: 00002220] Batch Translation Loss:   6.542840 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:13:02,313 [Epoch: 014 Step: 00002221] Batch Translation Loss:   6.480907 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:13:47,410 [Epoch: 014 Step: 00002222] Batch Translation Loss:   6.145832 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:14:07,483 [Epoch: 014 Step: 00002223] Batch Translation Loss:   6.703300 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-03 16:14:51,579 [Epoch: 014 Step: 00002224] Batch Translation Loss:   6.932189 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:15:27,796 [Epoch: 014 Step: 00002225] Batch Translation Loss:   6.230430 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:16:00,172 [Epoch: 014 Step: 00002226] Batch Translation Loss:   6.771338 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:16:27,569 [Epoch: 014 Step: 00002227] Batch Translation Loss:   5.943237 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:16:41,881 [Epoch: 014 Step: 00002228] Batch Translation Loss:   6.022892 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-03 16:16:54,925 [Epoch: 014 Step: 00002229] Batch Translation Loss:   7.106861 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-03 16:17:19,700 [Epoch: 014 Step: 00002230] Batch Translation Loss:   6.553667 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:17:35,511 [Epoch: 014 Step: 00002231] Batch Translation Loss:   6.395990 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-03 16:17:49,470 [Epoch: 014 Step: 00002232] Batch Translation Loss:   6.588975 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-03 16:18:16,929 [Epoch: 014 Step: 00002233] Batch Translation Loss:   6.751753 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:18:40,540 [Epoch: 014 Step: 00002234] Batch Translation Loss:   6.415953 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:19:13,257 [Epoch: 014 Step: 00002235] Batch Translation Loss:   6.513216 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:19:32,995 [Epoch: 014 Step: 00002236] Batch Translation Loss:   6.019955 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:20:00,214 [Epoch: 014 Step: 00002237] Batch Translation Loss:   7.310347 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:20:42,765 [Epoch: 014 Step: 00002238] Batch Translation Loss:   6.115520 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:21:25,438 [Epoch: 014 Step: 00002239] Batch Translation Loss:   6.615803 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:22:02,572 [Epoch: 014 Step: 00002240] Batch Translation Loss:   6.136616 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:22:37,139 [Epoch: 014 Step: 00002241] Batch Translation Loss:   6.438874 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:23:08,144 [Epoch: 014 Step: 00002242] Batch Translation Loss:   6.796884 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:23:53,552 [Epoch: 014 Step: 00002243] Batch Translation Loss:   5.990587 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:24:12,859 [Epoch: 014 Step: 00002244] Batch Translation Loss:   6.349683 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:24:27,513 [Epoch: 014 Step: 00002245] Batch Translation Loss:   6.369360 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:25:00,548 [Epoch: 014 Step: 00002246] Batch Translation Loss:   6.370197 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:25:24,766 [Epoch: 014 Step: 00002247] Batch Translation Loss:   6.243332 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:25:40,134 [Epoch: 014 Step: 00002248] Batch Translation Loss:   6.508240 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-03 16:26:01,254 [Epoch: 014 Step: 00002249] Batch Translation Loss:   6.184823 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:26:18,270 [Epoch: 014 Step: 00002250] Batch Translation Loss:   6.657620 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-03 16:26:36,754 [Epoch: 014 Step: 00002251] Batch Translation Loss:   5.890132 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:27:00,178 [Epoch: 014 Step: 00002252] Batch Translation Loss:   6.381691 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:27:26,308 [Epoch: 014 Step: 00002253] Batch Translation Loss:   5.986645 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:28:01,859 [Epoch: 014 Step: 00002254] Batch Translation Loss:   6.310446 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:28:24,729 [Epoch: 014 Step: 00002255] Batch Translation Loss:   6.197090 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:29:36,892 [Epoch: 014 Step: 00002256] Batch Translation Loss:   6.524963 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:30:29,305 [Epoch: 014 Step: 00002257] Batch Translation Loss:   6.769285 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:31:09,338 [Epoch: 014 Step: 00002258] Batch Translation Loss:   6.901149 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:31:43,756 [Epoch: 014 Step: 00002259] Batch Translation Loss:   6.386847 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:32:08,184 [Epoch: 014 Step: 00002260] Batch Translation Loss:   6.375540 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:32:32,805 [Epoch: 014 Step: 00002261] Batch Translation Loss:   6.444003 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:32:56,040 [Epoch: 014 Step: 00002262] Batch Translation Loss:   6.129521 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:33:15,041 [Epoch: 014 Step: 00002263] Batch Translation Loss:   6.121898 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:33:54,533 [Epoch: 014 Step: 00002264] Batch Translation Loss:   6.808192 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:34:15,989 [Epoch: 014 Step: 00002265] Batch Translation Loss:   5.520044 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:34:34,492 [Epoch: 014 Step: 00002266] Batch Translation Loss:   6.637334 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:35:12,880 [Epoch: 014 Step: 00002267] Batch Translation Loss:   6.537462 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:35:32,540 [Epoch: 014 Step: 00002268] Batch Translation Loss:   6.480824 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:36:07,936 [Epoch: 014 Step: 00002269] Batch Translation Loss:   6.345674 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:36:28,357 [Epoch: 014 Step: 00002270] Batch Translation Loss:   7.455920 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:37:11,116 [Epoch: 014 Step: 00002271] Batch Translation Loss:   6.081111 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:38:09,501 [Epoch: 014 Step: 00002272] Batch Translation Loss:   6.216496 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:39:06,875 [Epoch: 014 Step: 00002273] Batch Translation Loss:   6.686392 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:39:48,543 [Epoch: 014 Step: 00002274] Batch Translation Loss:   6.257863 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:40:21,366 [Epoch: 014 Step: 00002275] Batch Translation Loss:   6.620105 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:40:48,232 [Epoch: 014 Step: 00002276] Batch Translation Loss:   6.912449 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:41:08,945 [Epoch: 014 Step: 00002277] Batch Translation Loss:   6.019579 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:41:38,939 [Epoch: 014 Step: 00002278] Batch Translation Loss:   6.428623 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:42:05,271 [Epoch: 014 Step: 00002279] Batch Translation Loss:   5.976096 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:42:39,569 [Epoch: 014 Step: 00002280] Batch Translation Loss:   6.780631 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:43:05,338 [Epoch: 014 Step: 00002281] Batch Translation Loss:   5.969115 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:43:28,301 [Epoch: 014 Step: 00002282] Batch Translation Loss:   5.895484 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:43:53,039 [Epoch: 014 Step: 00002283] Batch Translation Loss:   5.639214 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:44:15,898 [Epoch: 014 Step: 00002284] Batch Translation Loss:   6.065168 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:44:40,758 [Epoch: 014 Step: 00002285] Batch Translation Loss:   6.426250 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:45:02,718 [Epoch: 014 Step: 00002286] Batch Translation Loss:   5.795344 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:45:27,187 [Epoch: 014 Step: 00002287] Batch Translation Loss:   5.817747 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:46:01,221 [Epoch: 014 Step: 00002288] Batch Translation Loss:   6.120322 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:47:05,686 [Epoch: 014 Step: 00002289] Batch Translation Loss:   6.385632 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:48:54,952 [Epoch: 014 Step: 00002290] Batch Translation Loss:   6.778679 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 16:49:49,670 [Epoch: 014 Step: 00002291] Batch Translation Loss:   6.228133 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:50:11,015 [Epoch: 014 Step: 00002292] Batch Translation Loss:   6.466671 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:50:38,281 [Epoch: 014 Step: 00002293] Batch Translation Loss:   6.104677 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:51:06,768 [Epoch: 014 Step: 00002294] Batch Translation Loss:   6.957300 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:51:36,922 [Epoch: 014 Step: 00002295] Batch Translation Loss:   5.892268 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:52:02,539 [Epoch: 014 Step: 00002296] Batch Translation Loss:   6.548779 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:52:31,076 [Epoch: 014 Step: 00002297] Batch Translation Loss:   5.918573 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:52:55,905 [Epoch: 014 Step: 00002298] Batch Translation Loss:   6.734354 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 16:53:20,553 [Epoch: 014 Step: 00002299] Batch Translation Loss:   6.020582 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 16:53:45,438 [Epoch: 014 Step: 00002300] Batch Translation Loss:   6.637424 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:00:51,552 Validation result at epoch  14, step     2300: duration: 426.0848s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11440.94629	PPL: 9303.40625
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 2.56	(DEL: 22.84,	INS: 0.00,	SUB: 74.60)
	Sequence Accuracy 2.69
2022-01-03 17:00:59,188 Logging Recognition and Translation Outputs
2022-01-03 17:00:59,236 ========================================================================================================================
2022-01-03 17:00:59,236 Logging Sequence: deafvideo_3-crossover_3864
2022-01-03 17:00:59,236 	Text Reference  :	myles
2022-01-03 17:00:59,236 	Text Hypothesis :	of   
2022-01-03 17:00:59,236 	Text Alignment  :	S    
2022-01-03 17:00:59,236 ========================================================================================================================
2022-01-03 17:00:59,236 Logging Sequence: youtube_5-debra_patkin_5788
2022-01-03 17:00:59,236 	Text Reference  :	if 
2022-01-03 17:00:59,237 	Text Hypothesis :	asl
2022-01-03 17:00:59,237 	Text Alignment  :	S  
2022-01-03 17:00:59,237 ========================================================================================================================
2022-01-03 17:00:59,237 Logging Sequence: youtube_1-catherine_mackinnon_2800
2022-01-03 17:00:59,237 	Text Reference  :	pasion
2022-01-03 17:00:59,237 	Text Hypothesis :	asl   
2022-01-03 17:00:59,237 	Text Alignment  :	S     
2022-01-03 17:00:59,237 ========================================================================================================================
2022-01-03 17:00:59,237 Logging Sequence: deafvideo_3-geoalpha_4548
2022-01-03 17:00:59,237 	Text Reference  :	sock
2022-01-03 17:00:59,237 	Text Hypothesis :	asl 
2022-01-03 17:00:59,237 	Text Alignment  :	S   
2022-01-03 17:00:59,238 ========================================================================================================================
2022-01-03 17:00:59,238 Logging Sequence: youtube_1-shoshannah_stern_2388
2022-01-03 17:00:59,238 	Text Reference  :	whine
2022-01-03 17:00:59,238 	Text Hypothesis :	asl  
2022-01-03 17:00:59,238 	Text Alignment  :	S    
2022-01-03 17:00:59,238 ========================================================================================================================
2022-01-03 17:03:14,803 [Epoch: 014 Step: 00002301] Batch Translation Loss:   6.821826 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 17:04:52,364 [Epoch: 014 Step: 00002302] Batch Translation Loss:   6.515796 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 17:06:07,069 [Epoch: 014 Step: 00002303] Batch Translation Loss:   5.877066 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 17:06:56,776 [Epoch: 014 Step: 00002304] Batch Translation Loss:   5.959651 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:07:35,116 [Epoch: 014 Step: 00002305] Batch Translation Loss:   6.408443 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:08:07,428 [Epoch: 014 Step: 00002306] Batch Translation Loss:   6.707129 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:08:31,527 [Epoch: 014 Step: 00002307] Batch Translation Loss:   6.363028 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:08:58,914 [Epoch: 014 Step: 00002308] Batch Translation Loss:   5.824575 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:09:25,578 [Epoch: 014 Step: 00002309] Batch Translation Loss:   6.616363 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:09:56,012 [Epoch: 014 Step: 00002310] Batch Translation Loss:   6.042746 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:10:22,788 [Epoch: 014 Step: 00002311] Batch Translation Loss:   6.708474 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:10:50,643 [Epoch: 014 Step: 00002312] Batch Translation Loss:   6.250557 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:11:20,333 [Epoch: 014 Step: 00002313] Batch Translation Loss:   6.308352 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:11:45,930 [Epoch: 014 Step: 00002314] Batch Translation Loss:   6.381168 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:12:13,503 [Epoch: 014 Step: 00002315] Batch Translation Loss:   6.100293 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:12:45,348 [Epoch: 014 Step: 00002316] Batch Translation Loss:   6.036099 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:13:26,567 [Epoch: 014 Step: 00002317] Batch Translation Loss:   6.152224 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:15:54,072 [Epoch: 014 Step: 00002318] Batch Translation Loss:   6.587232 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 17:17:41,616 [Epoch: 014 Step: 00002319] Batch Translation Loss:   5.941729 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 17:18:50,847 [Epoch: 014 Step: 00002320] Batch Translation Loss:   5.895262 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:19:37,628 [Epoch: 014 Step: 00002321] Batch Translation Loss:   6.204543 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:20:31,968 [Epoch: 014 Step: 00002322] Batch Translation Loss:   6.595131 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:21:05,949 [Epoch: 014 Step: 00002323] Batch Translation Loss:   6.528255 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:22:28,518 [Epoch: 014 Step: 00002324] Batch Translation Loss:   6.487807 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:24:20,073 [Epoch: 014 Step: 00002325] Batch Translation Loss:   6.441983 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 17:26:07,759 [Epoch: 014 Step: 00002326] Batch Translation Loss:   5.770186 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 17:26:47,581 [Epoch: 014 Step: 00002327] Batch Translation Loss:   6.168627 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:27:23,154 [Epoch: 014 Step: 00002328] Batch Translation Loss:   6.220519 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:27:56,575 [Epoch: 014 Step: 00002329] Batch Translation Loss:   6.613739 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:28:25,117 [Epoch: 014 Step: 00002330] Batch Translation Loss:   6.493723 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:29:03,041 [Epoch: 014 Step: 00002331] Batch Translation Loss:   6.126429 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:29:36,345 [Epoch: 014 Step: 00002332] Batch Translation Loss:   6.192508 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:30:38,548 [Epoch: 014 Step: 00002333] Batch Translation Loss:   6.027462 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:31:16,093 [Epoch: 014 Step: 00002334] Batch Translation Loss:   6.561047 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:32:06,663 [Epoch: 014 Step: 00002335] Batch Translation Loss:   6.721058 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:33:58,593 [Epoch: 014 Step: 00002336] Batch Translation Loss:   5.824306 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 17:36:05,288 [Epoch: 014 Step: 00002337] Batch Translation Loss:   6.796704 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 17:36:46,689 [Epoch: 014 Step: 00002338] Batch Translation Loss:   6.999474 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:37:34,755 [Epoch: 014 Step: 00002339] Batch Translation Loss:   5.848806 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:38:29,532 [Epoch: 014 Step: 00002340] Batch Translation Loss:   6.960166 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:39:16,476 [Epoch: 014 Step: 00002341] Batch Translation Loss:   5.659668 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:39:56,661 [Epoch: 014 Step: 00002342] Batch Translation Loss:   6.769641 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:40:35,510 [Epoch: 014 Step: 00002343] Batch Translation Loss:   6.271049 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:41:31,548 [Epoch: 014 Step: 00002344] Batch Translation Loss:   5.605751 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 17:44:18,772 [Epoch: 014 Step: 00002345] Batch Translation Loss:   6.170280 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 17:46:05,722 [Epoch: 014 Step: 00002346] Batch Translation Loss:   6.644888 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 17:48:39,262 [Epoch: 014 Step: 00002347] Batch Translation Loss:   6.034266 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 17:53:54,289 [Epoch: 014 Step: 00002348] Batch Translation Loss:   6.364550 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 17:56:40,573 [Epoch: 014 Step: 00002349] Batch Translation Loss:   6.253193 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 17:58:44,297 [Epoch: 014 Step: 00002350] Batch Translation Loss:   6.291883 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 18:00:51,351 [Epoch: 014 Step: 00002351] Batch Translation Loss:   6.010284 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 18:02:57,199 [Epoch: 014 Step: 00002352] Batch Translation Loss:   7.214159 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 18:08:09,799 [Epoch: 014 Step: 00002353] Batch Translation Loss:   5.887169 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 18:09:50,728 [Epoch: 014 Step: 00002354] Batch Translation Loss:   6.734798 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 18:11:42,894 [Epoch: 014 Step: 00002355] Batch Translation Loss:   6.333365 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 18:15:22,205 [Epoch: 014 Step: 00002356] Batch Translation Loss:   6.187738 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 18:17:30,987 [Epoch: 014 Step: 00002357] Batch Translation Loss:   6.204339 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 18:18:56,318 [Epoch: 014 Step: 00002358] Batch Translation Loss:   6.451548 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 18:20:31,818 [Epoch: 014 Step: 00002359] Batch Translation Loss:   6.234622 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 18:22:08,085 [Epoch: 014 Step: 00002360] Batch Translation Loss:   5.743840 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 18:26:03,915 [Epoch: 014 Step: 00002361] Batch Translation Loss:   6.392149 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 18:26:59,580 [Epoch: 014 Step: 00002362] Batch Translation Loss:   6.963112 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 18:27:56,099 [Epoch: 014 Step: 00002363] Batch Translation Loss:   6.094159 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 18:28:52,401 [Epoch: 014 Step: 00002364] Batch Translation Loss:   6.449792 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 18:29:56,432 [Epoch: 014 Step: 00002365] Batch Translation Loss:   6.211958 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 18:31:07,545 [Epoch: 014 Step: 00002366] Batch Translation Loss:   6.264430 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 18:32:04,122 [Epoch: 014 Step: 00002367] Batch Translation Loss:   6.390308 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 18:32:59,054 [Epoch: 014 Step: 00002368] Batch Translation Loss:   6.292659 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 18:33:46,985 [Epoch: 014 Step: 00002369] Batch Translation Loss:   6.438329 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 18:35:41,185 [Epoch: 014 Step: 00002370] Batch Translation Loss:   6.221221 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 18:36:40,452 [Epoch: 014 Step: 00002371] Batch Translation Loss:   6.607468 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 18:37:39,859 [Epoch: 014 Step: 00002372] Batch Translation Loss:   6.062132 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 18:38:41,611 [Epoch: 014 Step: 00002373] Batch Translation Loss:   5.943340 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 18:39:49,049 [Epoch: 014 Step: 00002374] Batch Translation Loss:   6.343037 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 18:40:51,390 [Epoch: 014 Step: 00002375] Batch Translation Loss:   5.988266 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 18:41:44,533 [Epoch: 014 Step: 00002376] Batch Translation Loss:   6.389381 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 18:42:48,648 [Epoch: 014 Step: 00002377] Batch Translation Loss:   5.878578 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 18:43:49,423 [Epoch: 014 Step: 00002378] Batch Translation Loss:   6.856992 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 18:44:58,845 [Epoch: 014 Step: 00002379] Batch Translation Loss:   7.134016 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 18:46:32,736 [Epoch: 014 Step: 00002380] Batch Translation Loss:   6.639902 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 18:46:33,054 Epoch  14: Total Training Recognition Loss -1.00  Total Training Translation Loss 1083.40 
2022-01-03 18:46:33,055 EPOCH 15
2022-01-03 18:46:48,314 [Epoch: 015 Step: 00002381] Batch Translation Loss:   5.896852 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 18:46:56,316 [Epoch: 015 Step: 00002382] Batch Translation Loss:   6.521853 => Txt Tokens per Sec:        4 || Lr: 0.000700
2022-01-03 18:47:15,115 [Epoch: 015 Step: 00002383] Batch Translation Loss:   6.420073 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 18:47:32,902 [Epoch: 015 Step: 00002384] Batch Translation Loss:   6.600659 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 18:47:45,134 [Epoch: 015 Step: 00002385] Batch Translation Loss:   6.273507 => Txt Tokens per Sec:        4 || Lr: 0.000700
2022-01-03 18:48:05,548 [Epoch: 015 Step: 00002386] Batch Translation Loss:   6.281538 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 18:48:17,853 [Epoch: 015 Step: 00002387] Batch Translation Loss:   6.722318 => Txt Tokens per Sec:        4 || Lr: 0.000700
2022-01-03 18:48:46,407 [Epoch: 015 Step: 00002388] Batch Translation Loss:   5.881345 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 18:49:06,251 [Epoch: 015 Step: 00002389] Batch Translation Loss:   6.450527 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 18:49:20,929 [Epoch: 015 Step: 00002390] Batch Translation Loss:   6.206439 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-03 18:49:45,116 [Epoch: 015 Step: 00002391] Batch Translation Loss:   6.643541 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 18:50:02,616 [Epoch: 015 Step: 00002392] Batch Translation Loss:   6.308521 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 18:50:22,374 [Epoch: 015 Step: 00002393] Batch Translation Loss:   5.951583 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 18:50:41,701 [Epoch: 015 Step: 00002394] Batch Translation Loss:   6.426895 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 18:50:57,715 [Epoch: 015 Step: 00002395] Batch Translation Loss:   6.383556 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 18:51:15,070 [Epoch: 015 Step: 00002396] Batch Translation Loss:   6.444674 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 18:51:42,558 [Epoch: 015 Step: 00002397] Batch Translation Loss:   5.979153 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 18:51:57,472 [Epoch: 015 Step: 00002398] Batch Translation Loss:   6.128904 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 18:52:21,438 [Epoch: 015 Step: 00002399] Batch Translation Loss:   5.806431 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 18:52:44,217 [Epoch: 015 Step: 00002400] Batch Translation Loss:   6.447487 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 19:02:53,397 Validation result at epoch  15, step     2400: duration: 609.1410s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11519.38281	PPL: 9832.43945
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.52	(DEL: 24.18,	INS: 0.00,	SUB: 74.30)
	Sequence Accuracy 1.58
2022-01-03 19:03:00,905 Logging Recognition and Translation Outputs
2022-01-03 19:03:00,906 ========================================================================================================================
2022-01-03 19:03:00,906 Logging Sequence: youtube_1-catherine_mackinnon_2825
2022-01-03 19:03:00,907 	Text Reference  :	yout
2022-01-03 19:03:00,907 	Text Hypothesis :	so  
2022-01-03 19:03:00,907 	Text Alignment  :	S   
2022-01-03 19:03:00,908 ========================================================================================================================
2022-01-03 19:03:00,908 Logging Sequence: deafvideo_2-fairytales9_2274
2022-01-03 19:03:00,908 	Text Reference  :	page
2022-01-03 19:03:00,908 	Text Hypothesis :	so  
2022-01-03 19:03:00,909 	Text Alignment  :	S   
2022-01-03 19:03:00,909 ========================================================================================================================
2022-01-03 19:03:00,909 Logging Sequence: deafvideo_3-geoalpha_4557
2022-01-03 19:03:00,909 	Text Reference  :	dr kristin mulrooney
2022-01-03 19:03:00,910 	Text Hypothesis :	dr ******* *********
2022-01-03 19:03:00,910 	Text Alignment  :	   D       D        
2022-01-03 19:03:00,910 ========================================================================================================================
2022-01-03 19:03:00,910 Logging Sequence: deafvideo_3-otismhill82_4594
2022-01-03 19:03:00,911 	Text Reference  :	xmic
2022-01-03 19:03:00,911 	Text Hypothesis :	so  
2022-01-03 19:03:00,911 	Text Alignment  :	S   
2022-01-03 19:03:00,911 ========================================================================================================================
2022-01-03 19:03:00,911 Logging Sequence: deafvideo_3-otismhill82_4591
2022-01-03 19:03:00,912 	Text Reference  :	it 
2022-01-03 19:03:00,912 	Text Hypothesis :	asl
2022-01-03 19:03:00,912 	Text Alignment  :	S  
2022-01-03 19:03:00,912 ========================================================================================================================
2022-01-03 19:03:49,981 [Epoch: 015 Step: 00002401] Batch Translation Loss:   6.497052 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:04:08,897 [Epoch: 015 Step: 00002402] Batch Translation Loss:   6.788553 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 19:04:37,457 [Epoch: 015 Step: 00002403] Batch Translation Loss:   6.371601 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:04:59,081 [Epoch: 015 Step: 00002404] Batch Translation Loss:   6.153243 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 19:05:17,838 [Epoch: 015 Step: 00002405] Batch Translation Loss:   6.591171 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 19:05:41,966 [Epoch: 015 Step: 00002406] Batch Translation Loss:   6.487761 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 19:06:12,174 [Epoch: 015 Step: 00002407] Batch Translation Loss:   5.873091 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:06:58,819 [Epoch: 015 Step: 00002408] Batch Translation Loss:   6.833062 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:07:15,965 [Epoch: 015 Step: 00002409] Batch Translation Loss:   6.959378 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-03 19:07:39,038 [Epoch: 015 Step: 00002410] Batch Translation Loss:   6.076394 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 19:08:00,558 [Epoch: 015 Step: 00002411] Batch Translation Loss:   5.893501 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 19:08:25,555 [Epoch: 015 Step: 00002412] Batch Translation Loss:   5.929482 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:08:57,037 [Epoch: 015 Step: 00002413] Batch Translation Loss:   5.793497 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:09:26,769 [Epoch: 015 Step: 00002414] Batch Translation Loss:   6.739604 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:09:56,531 [Epoch: 015 Step: 00002415] Batch Translation Loss:   6.238142 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:10:28,253 [Epoch: 015 Step: 00002416] Batch Translation Loss:   6.770948 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:10:59,286 [Epoch: 015 Step: 00002417] Batch Translation Loss:   5.972233 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:11:46,659 [Epoch: 015 Step: 00002418] Batch Translation Loss:   6.972183 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:12:16,732 [Epoch: 015 Step: 00002419] Batch Translation Loss:   6.633339 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:12:37,935 [Epoch: 015 Step: 00002420] Batch Translation Loss:   6.346058 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-03 19:13:04,622 [Epoch: 015 Step: 00002421] Batch Translation Loss:   6.469882 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:13:33,726 [Epoch: 015 Step: 00002422] Batch Translation Loss:   6.946216 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:13:51,521 [Epoch: 015 Step: 00002423] Batch Translation Loss:   6.130912 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-03 19:14:48,655 [Epoch: 015 Step: 00002424] Batch Translation Loss:   6.045419 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:15:43,483 [Epoch: 015 Step: 00002425] Batch Translation Loss:   5.830067 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:16:27,696 [Epoch: 015 Step: 00002426] Batch Translation Loss:   6.429812 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:17:24,514 [Epoch: 015 Step: 00002427] Batch Translation Loss:   6.515404 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:18:40,703 [Epoch: 015 Step: 00002428] Batch Translation Loss:   6.453199 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 19:20:46,507 [Epoch: 015 Step: 00002429] Batch Translation Loss:   6.028369 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 19:21:29,204 [Epoch: 015 Step: 00002430] Batch Translation Loss:   6.715646 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:23:03,549 [Epoch: 015 Step: 00002431] Batch Translation Loss:   6.471500 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 19:24:05,129 [Epoch: 015 Step: 00002432] Batch Translation Loss:   6.679535 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:24:40,980 [Epoch: 015 Step: 00002433] Batch Translation Loss:   6.682462 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:26:07,183 [Epoch: 015 Step: 00002434] Batch Translation Loss:   6.988509 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 19:26:56,202 [Epoch: 015 Step: 00002435] Batch Translation Loss:   6.275623 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:27:46,740 [Epoch: 015 Step: 00002436] Batch Translation Loss:   6.863801 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:28:36,536 [Epoch: 015 Step: 00002437] Batch Translation Loss:   5.968657 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:29:50,143 [Epoch: 015 Step: 00002438] Batch Translation Loss:   6.776414 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:31:01,581 [Epoch: 015 Step: 00002439] Batch Translation Loss:   5.867461 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:32:09,308 [Epoch: 015 Step: 00002440] Batch Translation Loss:   6.282558 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 19:34:10,622 [Epoch: 015 Step: 00002441] Batch Translation Loss:   6.385250 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 19:36:21,608 [Epoch: 015 Step: 00002442] Batch Translation Loss:   6.854077 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 19:37:27,028 [Epoch: 015 Step: 00002443] Batch Translation Loss:   6.339567 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:38:56,920 [Epoch: 015 Step: 00002444] Batch Translation Loss:   6.161849 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:39:56,011 [Epoch: 015 Step: 00002445] Batch Translation Loss:   6.206987 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:40:50,522 [Epoch: 015 Step: 00002446] Batch Translation Loss:   6.458102 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:41:53,900 [Epoch: 015 Step: 00002447] Batch Translation Loss:   6.391279 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:43:19,562 [Epoch: 015 Step: 00002448] Batch Translation Loss:   6.399436 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 19:45:27,365 [Epoch: 015 Step: 00002449] Batch Translation Loss:   6.996897 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 19:46:48,972 [Epoch: 015 Step: 00002450] Batch Translation Loss:   6.352042 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:47:56,444 [Epoch: 015 Step: 00002451] Batch Translation Loss:   6.944195 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:49:14,474 [Epoch: 015 Step: 00002452] Batch Translation Loss:   5.965624 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 19:50:32,173 [Epoch: 015 Step: 00002453] Batch Translation Loss:   6.333826 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 19:51:42,695 [Epoch: 015 Step: 00002454] Batch Translation Loss:   6.415966 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:53:07,960 [Epoch: 015 Step: 00002455] Batch Translation Loss:   6.194312 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 19:54:34,781 [Epoch: 015 Step: 00002456] Batch Translation Loss:   6.297671 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 19:55:53,779 [Epoch: 015 Step: 00002457] Batch Translation Loss:   6.370782 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 19:58:26,195 [Epoch: 015 Step: 00002458] Batch Translation Loss:   5.995592 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 19:59:40,724 [Epoch: 015 Step: 00002459] Batch Translation Loss:   6.339996 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 20:00:57,904 [Epoch: 015 Step: 00002460] Batch Translation Loss:   6.531599 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 20:02:21,666 [Epoch: 015 Step: 00002461] Batch Translation Loss:   6.567967 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 20:04:15,754 [Epoch: 015 Step: 00002462] Batch Translation Loss:   7.154067 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 20:05:28,727 [Epoch: 015 Step: 00002463] Batch Translation Loss:   6.193575 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 20:07:03,844 [Epoch: 015 Step: 00002464] Batch Translation Loss:   5.791503 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 20:09:28,888 [Epoch: 015 Step: 00002465] Batch Translation Loss:   6.025734 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 20:11:07,086 [Epoch: 015 Step: 00002466] Batch Translation Loss:   6.239893 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 20:12:21,397 [Epoch: 015 Step: 00002467] Batch Translation Loss:   6.320903 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 20:15:34,192 [Epoch: 015 Step: 00002468] Batch Translation Loss:   5.695867 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 20:16:32,435 [Epoch: 015 Step: 00002469] Batch Translation Loss:   6.440735 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 20:17:55,445 [Epoch: 015 Step: 00002470] Batch Translation Loss:   6.107165 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 20:19:03,281 [Epoch: 015 Step: 00002471] Batch Translation Loss:   6.905311 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 20:20:53,983 [Epoch: 015 Step: 00002472] Batch Translation Loss:   6.610271 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 20:22:12,881 [Epoch: 015 Step: 00002473] Batch Translation Loss:   5.756919 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 20:23:47,682 [Epoch: 015 Step: 00002474] Batch Translation Loss:   6.333426 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 20:25:25,271 [Epoch: 015 Step: 00002475] Batch Translation Loss:   6.020562 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 20:26:32,500 [Epoch: 015 Step: 00002476] Batch Translation Loss:   6.131039 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 20:27:58,910 [Epoch: 015 Step: 00002477] Batch Translation Loss:   5.634300 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 20:29:35,277 [Epoch: 015 Step: 00002478] Batch Translation Loss:   6.594244 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 20:31:06,838 [Epoch: 015 Step: 00002479] Batch Translation Loss:   6.124272 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 20:32:44,724 [Epoch: 015 Step: 00002480] Batch Translation Loss:   5.853146 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 20:34:01,889 [Epoch: 015 Step: 00002481] Batch Translation Loss:   5.656996 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 20:35:37,801 [Epoch: 015 Step: 00002482] Batch Translation Loss:   6.297268 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 20:39:10,668 [Epoch: 015 Step: 00002483] Batch Translation Loss:   6.231551 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 20:40:45,930 [Epoch: 015 Step: 00002484] Batch Translation Loss:   6.308177 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 20:43:44,653 [Epoch: 015 Step: 00002485] Batch Translation Loss:   5.962112 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 20:45:29,383 [Epoch: 015 Step: 00002486] Batch Translation Loss:   6.324225 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 20:48:39,321 [Epoch: 015 Step: 00002487] Batch Translation Loss:   6.278584 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 20:50:23,992 [Epoch: 015 Step: 00002488] Batch Translation Loss:   6.481433 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 20:51:58,224 [Epoch: 015 Step: 00002489] Batch Translation Loss:   6.291598 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 20:53:51,601 [Epoch: 015 Step: 00002490] Batch Translation Loss:   6.845488 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 20:55:36,273 [Epoch: 015 Step: 00002491] Batch Translation Loss:   6.540580 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 20:57:22,728 [Epoch: 015 Step: 00002492] Batch Translation Loss:   7.032834 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 20:59:57,816 [Epoch: 015 Step: 00002493] Batch Translation Loss:   5.883854 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 21:01:54,106 [Epoch: 015 Step: 00002494] Batch Translation Loss:   6.284370 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 21:05:18,222 [Epoch: 015 Step: 00002495] Batch Translation Loss:   6.428555 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 21:08:43,656 [Epoch: 015 Step: 00002496] Batch Translation Loss:   6.347402 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 21:10:38,980 [Epoch: 015 Step: 00002497] Batch Translation Loss:   5.789642 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 21:13:08,971 [Epoch: 015 Step: 00002498] Batch Translation Loss:   6.009213 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 21:14:47,360 [Epoch: 015 Step: 00002499] Batch Translation Loss:   6.305641 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 21:18:17,815 [Epoch: 015 Step: 00002500] Batch Translation Loss:   6.317755 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 21:39:16,590 Validation result at epoch  15, step     2500: duration: 1258.7301s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11180.57715	PPL: 9993.60449
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.24	(DEL: 20.59,	INS: 0.00,	SUB: 78.17)
	Sequence Accuracy 1.35
2022-01-03 21:39:28,445 Logging Recognition and Translation Outputs
2022-01-03 21:39:28,476 ========================================================================================================================
2022-01-03 21:39:28,477 Logging Sequence: deafvideo_4-tax_tips_by_irs_4963
2022-01-03 21:39:28,477 	Text Reference  :	csubia
2022-01-03 21:39:28,478 	Text Hypothesis :	dr    
2022-01-03 21:39:28,478 	Text Alignment  :	S     
2022-01-03 21:39:28,478 ========================================================================================================================
2022-01-03 21:39:28,478 Logging Sequence: youtube_1-shoshannah_stern_2377
2022-01-03 21:39:28,478 	Text Reference  :	dvtv
2022-01-03 21:39:28,478 	Text Hypothesis :	asl 
2022-01-03 21:39:28,478 	Text Alignment  :	S   
2022-01-03 21:39:28,478 ========================================================================================================================
2022-01-03 21:39:28,478 Logging Sequence: youtube_5-roberta_cordano_6138
2022-01-03 21:39:28,479 	Text Reference  :	grassrots
2022-01-03 21:39:28,479 	Text Hypothesis :	so       
2022-01-03 21:39:28,479 	Text Alignment  :	S        
2022-01-03 21:39:28,479 ========================================================================================================================
2022-01-03 21:39:28,479 Logging Sequence: deafvideo_3-titans_4692
2022-01-03 21:39:28,479 	Text Reference  :	ck
2022-01-03 21:39:28,479 	Text Hypothesis :	so
2022-01-03 21:39:28,479 	Text Alignment  :	S 
2022-01-03 21:39:28,479 ========================================================================================================================
2022-01-03 21:39:28,479 Logging Sequence: youtube_5-tanea_brown_6037
2022-01-03 21:39:28,480 	Text Reference  :	asl
2022-01-03 21:39:28,480 	Text Hypothesis :	so 
2022-01-03 21:39:28,480 	Text Alignment  :	S  
2022-01-03 21:39:28,480 ========================================================================================================================
2022-01-03 21:42:02,244 [Epoch: 015 Step: 00002501] Batch Translation Loss:   6.089185 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 21:43:52,429 [Epoch: 015 Step: 00002502] Batch Translation Loss:   6.269958 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 21:45:59,224 [Epoch: 015 Step: 00002503] Batch Translation Loss:   6.372669 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 21:47:54,849 [Epoch: 015 Step: 00002504] Batch Translation Loss:   6.007893 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 21:49:53,317 [Epoch: 015 Step: 00002505] Batch Translation Loss:   6.730286 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 21:52:04,791 [Epoch: 015 Step: 00002506] Batch Translation Loss:   6.710357 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 21:55:40,197 [Epoch: 015 Step: 00002507] Batch Translation Loss:   5.930086 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 21:57:35,148 [Epoch: 015 Step: 00002508] Batch Translation Loss:   6.034449 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 21:59:53,513 [Epoch: 015 Step: 00002509] Batch Translation Loss:   6.126886 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 22:01:42,228 [Epoch: 015 Step: 00002510] Batch Translation Loss:   6.375907 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 22:03:48,520 [Epoch: 015 Step: 00002511] Batch Translation Loss:   6.382008 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 22:05:35,495 [Epoch: 015 Step: 00002512] Batch Translation Loss:   6.738172 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 22:09:48,274 [Epoch: 015 Step: 00002513] Batch Translation Loss:   6.413784 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 22:12:28,704 [Epoch: 015 Step: 00002514] Batch Translation Loss:   6.190375 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 22:14:49,741 [Epoch: 015 Step: 00002515] Batch Translation Loss:   6.180439 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 22:17:23,777 [Epoch: 015 Step: 00002516] Batch Translation Loss:   6.072296 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 22:20:07,243 [Epoch: 015 Step: 00002517] Batch Translation Loss:   6.073003 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 22:22:33,527 [Epoch: 015 Step: 00002518] Batch Translation Loss:   6.484751 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 22:25:33,761 [Epoch: 015 Step: 00002519] Batch Translation Loss:   6.251435 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 22:28:12,420 [Epoch: 015 Step: 00002520] Batch Translation Loss:   6.253220 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 22:30:51,352 [Epoch: 015 Step: 00002521] Batch Translation Loss:   6.670026 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 22:33:31,182 [Epoch: 015 Step: 00002522] Batch Translation Loss:   5.524620 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 22:38:22,984 [Epoch: 015 Step: 00002523] Batch Translation Loss:   6.113023 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 22:40:35,797 [Epoch: 015 Step: 00002524] Batch Translation Loss:   7.022532 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 22:43:01,180 [Epoch: 015 Step: 00002525] Batch Translation Loss:   6.441560 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 22:45:23,478 [Epoch: 015 Step: 00002526] Batch Translation Loss:   5.988188 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 22:47:42,249 [Epoch: 015 Step: 00002527] Batch Translation Loss:   5.524125 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 22:49:36,684 [Epoch: 015 Step: 00002528] Batch Translation Loss:   5.841065 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 22:53:50,172 [Epoch: 015 Step: 00002529] Batch Translation Loss:   6.142042 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 22:56:08,643 [Epoch: 015 Step: 00002530] Batch Translation Loss:   6.680103 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 22:58:06,108 [Epoch: 015 Step: 00002531] Batch Translation Loss:   6.652341 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 23:00:06,240 [Epoch: 015 Step: 00002532] Batch Translation Loss:   6.106414 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 23:01:59,718 [Epoch: 015 Step: 00002533] Batch Translation Loss:   6.349632 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 23:04:36,893 [Epoch: 015 Step: 00002534] Batch Translation Loss:   6.320176 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 23:07:08,832 [Epoch: 015 Step: 00002535] Batch Translation Loss:   6.401738 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 23:08:59,466 [Epoch: 015 Step: 00002536] Batch Translation Loss:   5.610603 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 23:13:30,264 [Epoch: 015 Step: 00002537] Batch Translation Loss:   6.019784 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 23:16:08,098 [Epoch: 015 Step: 00002538] Batch Translation Loss:   6.761980 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 23:18:40,513 [Epoch: 015 Step: 00002539] Batch Translation Loss:   5.311736 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 23:23:55,267 [Epoch: 015 Step: 00002540] Batch Translation Loss:   6.433208 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 23:26:24,914 [Epoch: 015 Step: 00002541] Batch Translation Loss:   6.027138 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 23:28:54,656 [Epoch: 015 Step: 00002542] Batch Translation Loss:   6.986891 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 23:31:19,823 [Epoch: 015 Step: 00002543] Batch Translation Loss:   5.983752 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 23:33:15,873 [Epoch: 015 Step: 00002544] Batch Translation Loss:   6.189924 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 23:35:35,123 [Epoch: 015 Step: 00002545] Batch Translation Loss:   6.049101 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 23:37:31,324 [Epoch: 015 Step: 00002546] Batch Translation Loss:   6.053184 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 23:39:29,896 [Epoch: 015 Step: 00002547] Batch Translation Loss:   6.176493 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 23:43:43,220 [Epoch: 015 Step: 00002548] Batch Translation Loss:   6.496503 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 23:49:29,954 [Epoch: 015 Step: 00002549] Batch Translation Loss:   6.728212 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 23:51:14,478 [Epoch: 015 Step: 00002550] Batch Translation Loss:   6.727694 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-03 23:51:14,642 Epoch  15: Total Training Recognition Loss -1.00  Total Training Translation Loss 1073.19 
2022-01-03 23:51:14,643 EPOCH 16
2022-01-03 23:51:46,317 [Epoch: 016 Step: 00002551] Batch Translation Loss:   6.167854 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 23:52:24,113 [Epoch: 016 Step: 00002552] Batch Translation Loss:   5.753403 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 23:53:09,565 [Epoch: 016 Step: 00002553] Batch Translation Loss:   6.746997 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 23:54:16,453 [Epoch: 016 Step: 00002554] Batch Translation Loss:   6.780725 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 23:54:59,911 [Epoch: 016 Step: 00002555] Batch Translation Loss:   7.279674 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 23:55:29,424 [Epoch: 016 Step: 00002556] Batch Translation Loss:   6.039325 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 23:56:12,166 [Epoch: 016 Step: 00002557] Batch Translation Loss:   6.503506 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 23:57:17,517 [Epoch: 016 Step: 00002558] Batch Translation Loss:   6.432473 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 23:58:31,716 [Epoch: 016 Step: 00002559] Batch Translation Loss:   6.716954 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 23:59:24,208 [Epoch: 016 Step: 00002560] Batch Translation Loss:   6.037762 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-03 23:59:55,447 [Epoch: 016 Step: 00002561] Batch Translation Loss:   6.008717 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:00:33,229 [Epoch: 016 Step: 00002562] Batch Translation Loss:   6.708133 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:01:15,578 [Epoch: 016 Step: 00002563] Batch Translation Loss:   5.864008 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:03:07,688 [Epoch: 016 Step: 00002564] Batch Translation Loss:   6.403057 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 00:04:03,608 [Epoch: 016 Step: 00002565] Batch Translation Loss:   6.715374 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:04:43,189 [Epoch: 016 Step: 00002566] Batch Translation Loss:   5.971629 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:05:37,028 [Epoch: 016 Step: 00002567] Batch Translation Loss:   5.872983 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:07:07,994 [Epoch: 016 Step: 00002568] Batch Translation Loss:   5.672787 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 00:08:02,136 [Epoch: 016 Step: 00002569] Batch Translation Loss:   6.369983 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:08:55,674 [Epoch: 016 Step: 00002570] Batch Translation Loss:   6.351571 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:09:52,643 [Epoch: 016 Step: 00002571] Batch Translation Loss:   5.922236 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:11:30,584 [Epoch: 016 Step: 00002572] Batch Translation Loss:   6.382909 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 00:13:21,068 [Epoch: 016 Step: 00002573] Batch Translation Loss:   5.983552 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 00:14:03,807 [Epoch: 016 Step: 00002574] Batch Translation Loss:   6.384372 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:15:36,941 [Epoch: 016 Step: 00002575] Batch Translation Loss:   6.192181 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 00:16:45,976 [Epoch: 016 Step: 00002576] Batch Translation Loss:   6.218934 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:18:00,404 [Epoch: 016 Step: 00002577] Batch Translation Loss:   6.620475 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:18:58,355 [Epoch: 016 Step: 00002578] Batch Translation Loss:   5.974536 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:19:59,229 [Epoch: 016 Step: 00002579] Batch Translation Loss:   6.519431 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:22:28,550 [Epoch: 016 Step: 00002580] Batch Translation Loss:   6.270552 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 00:23:34,281 [Epoch: 016 Step: 00002581] Batch Translation Loss:   6.592915 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:24:38,523 [Epoch: 016 Step: 00002582] Batch Translation Loss:   6.512708 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:25:45,026 [Epoch: 016 Step: 00002583] Batch Translation Loss:   5.901021 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:26:46,553 [Epoch: 016 Step: 00002584] Batch Translation Loss:   6.588137 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:28:16,941 [Epoch: 016 Step: 00002585] Batch Translation Loss:   5.928941 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 00:29:11,039 [Epoch: 016 Step: 00002586] Batch Translation Loss:   6.116034 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:30:14,418 [Epoch: 016 Step: 00002587] Batch Translation Loss:   5.840343 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:31:37,065 [Epoch: 016 Step: 00002588] Batch Translation Loss:   6.194358 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 00:32:37,807 [Epoch: 016 Step: 00002589] Batch Translation Loss:   5.647355 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:33:35,528 [Epoch: 016 Step: 00002590] Batch Translation Loss:   6.610504 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:34:46,971 [Epoch: 016 Step: 00002591] Batch Translation Loss:   6.940966 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:36:55,997 [Epoch: 016 Step: 00002592] Batch Translation Loss:   6.321609 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 00:38:00,764 [Epoch: 016 Step: 00002593] Batch Translation Loss:   5.991735 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:39:02,587 [Epoch: 016 Step: 00002594] Batch Translation Loss:   6.050360 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:40:18,811 [Epoch: 016 Step: 00002595] Batch Translation Loss:   6.678805 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:41:31,269 [Epoch: 016 Step: 00002596] Batch Translation Loss:   6.286416 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:42:38,653 [Epoch: 016 Step: 00002597] Batch Translation Loss:   6.251597 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:43:43,609 [Epoch: 016 Step: 00002598] Batch Translation Loss:   6.467934 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:44:49,456 [Epoch: 016 Step: 00002599] Batch Translation Loss:   7.123433 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 00:46:18,019 [Epoch: 016 Step: 00002600] Batch Translation Loss:   6.249408 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 01:15:33,091 Hooray! New best validation result [eval_metric]!
2022-01-04 01:15:33,100 Saving new checkpoint.
2022-01-04 01:15:37,220 Validation result at epoch  16, step     2600: duration: 1759.1709s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 10211.52930	PPL: 6505.05908
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 3.53	(DEL: 16.17,	INS: 0.00,	SUB: 80.31)
	Sequence Accuracy 4.00
2022-01-04 01:15:44,998 Logging Recognition and Translation Outputs
2022-01-04 01:15:45,079 ========================================================================================================================
2022-01-04 01:15:45,079 Logging Sequence: deafvideo_3-damien23_3605
2022-01-04 01:15:45,079 	Text Reference  :	so 
2022-01-04 01:15:45,079 	Text Hypothesis :	asl
2022-01-04 01:15:45,079 	Text Alignment  :	S  
2022-01-04 01:15:45,080 ========================================================================================================================
2022-01-04 01:15:45,080 Logging Sequence: deafvideo_2-goatman_1528
2022-01-04 01:15:45,080 	Text Reference  :	ntid
2022-01-04 01:15:45,080 	Text Hypothesis :	asl 
2022-01-04 01:15:45,080 	Text Alignment  :	S   
2022-01-04 01:15:45,080 ========================================================================================================================
2022-01-04 01:15:45,080 Logging Sequence: deafvideo_3-otismhill82_4620
2022-01-04 01:15:45,080 	Text Reference  :	all
2022-01-04 01:15:45,080 	Text Hypothesis :	asl
2022-01-04 01:15:45,080 	Text Alignment  :	S  
2022-01-04 01:15:45,080 ========================================================================================================================
2022-01-04 01:15:45,080 Logging Sequence: aslized-suzanne_stecker_0195
2022-01-04 01:15:45,081 	Text Reference  :	tump
2022-01-04 01:15:45,081 	Text Hypothesis :	asl 
2022-01-04 01:15:45,081 	Text Alignment  :	S   
2022-01-04 01:15:45,081 ========================================================================================================================
2022-01-04 01:15:45,081 Logging Sequence: deafvideo_5-morningstar_6245
2022-01-04 01:15:45,081 	Text Reference  :	civic resistnace
2022-01-04 01:15:45,081 	Text Hypothesis :	***** asl       
2022-01-04 01:15:45,081 	Text Alignment  :	D     S         
2022-01-04 01:15:45,081 ========================================================================================================================
2022-01-04 01:17:17,652 [Epoch: 016 Step: 00002601] Batch Translation Loss:   6.453013 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 01:18:37,848 [Epoch: 016 Step: 00002602] Batch Translation Loss:   6.240382 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 01:20:07,491 [Epoch: 016 Step: 00002603] Batch Translation Loss:   5.864275 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 01:21:25,200 [Epoch: 016 Step: 00002604] Batch Translation Loss:   7.061470 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 01:23:15,192 [Epoch: 016 Step: 00002605] Batch Translation Loss:   6.609828 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 01:24:39,521 [Epoch: 016 Step: 00002606] Batch Translation Loss:   6.018404 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 01:26:02,493 [Epoch: 016 Step: 00002607] Batch Translation Loss:   5.771327 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 01:27:21,260 [Epoch: 016 Step: 00002608] Batch Translation Loss:   6.025257 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 01:29:03,851 [Epoch: 016 Step: 00002609] Batch Translation Loss:   6.550127 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 01:30:25,906 [Epoch: 016 Step: 00002610] Batch Translation Loss:   6.021701 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 01:31:39,480 [Epoch: 016 Step: 00002611] Batch Translation Loss:   6.234936 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 01:33:14,079 [Epoch: 016 Step: 00002612] Batch Translation Loss:   6.412462 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 01:35:04,270 [Epoch: 016 Step: 00002613] Batch Translation Loss:   6.129607 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 01:36:51,074 [Epoch: 016 Step: 00002614] Batch Translation Loss:   6.136980 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 01:38:27,417 [Epoch: 016 Step: 00002615] Batch Translation Loss:   5.452775 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 01:39:44,052 [Epoch: 016 Step: 00002616] Batch Translation Loss:   6.674155 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 01:41:05,570 [Epoch: 016 Step: 00002617] Batch Translation Loss:   6.299140 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 01:44:26,878 [Epoch: 016 Step: 00002618] Batch Translation Loss:   6.069105 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 01:46:52,696 [Epoch: 016 Step: 00002619] Batch Translation Loss:   5.973543 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 01:48:38,614 [Epoch: 016 Step: 00002620] Batch Translation Loss:   6.241093 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 01:50:47,076 [Epoch: 016 Step: 00002621] Batch Translation Loss:   5.712824 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 01:52:10,370 [Epoch: 016 Step: 00002622] Batch Translation Loss:   6.078756 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 01:55:31,853 [Epoch: 016 Step: 00002623] Batch Translation Loss:   6.197185 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 01:56:55,794 [Epoch: 016 Step: 00002624] Batch Translation Loss:   6.035469 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 01:58:54,591 [Epoch: 016 Step: 00002625] Batch Translation Loss:   6.161854 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 02:00:37,304 [Epoch: 016 Step: 00002626] Batch Translation Loss:   6.949679 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 02:02:05,706 [Epoch: 016 Step: 00002627] Batch Translation Loss:   5.970726 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 02:03:56,142 [Epoch: 016 Step: 00002628] Batch Translation Loss:   6.346087 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 02:05:47,521 [Epoch: 016 Step: 00002629] Batch Translation Loss:   5.630340 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 02:07:48,501 [Epoch: 016 Step: 00002630] Batch Translation Loss:   6.497432 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 02:08:23,131 [Epoch: 016 Step: 00002631] Batch Translation Loss:   6.293666 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:08:59,437 [Epoch: 016 Step: 00002632] Batch Translation Loss:   5.478168 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:09:57,116 [Epoch: 016 Step: 00002633] Batch Translation Loss:   6.142319 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:10:37,293 [Epoch: 016 Step: 00002634] Batch Translation Loss:   5.536013 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:12:01,638 [Epoch: 016 Step: 00002635] Batch Translation Loss:   6.045127 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 02:12:41,848 [Epoch: 016 Step: 00002636] Batch Translation Loss:   6.449711 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:13:22,734 [Epoch: 016 Step: 00002637] Batch Translation Loss:   5.529295 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:14:11,053 [Epoch: 016 Step: 00002638] Batch Translation Loss:   6.289588 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:15:08,032 [Epoch: 016 Step: 00002639] Batch Translation Loss:   6.085702 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:15:42,620 [Epoch: 016 Step: 00002640] Batch Translation Loss:   5.972014 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:16:49,571 [Epoch: 016 Step: 00002641] Batch Translation Loss:   6.193809 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:17:26,879 [Epoch: 016 Step: 00002642] Batch Translation Loss:   6.520886 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:17:58,521 [Epoch: 016 Step: 00002643] Batch Translation Loss:   6.454668 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:18:55,810 [Epoch: 016 Step: 00002644] Batch Translation Loss:   5.872890 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:19:43,062 [Epoch: 016 Step: 00002645] Batch Translation Loss:   6.805792 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:20:36,567 [Epoch: 016 Step: 00002646] Batch Translation Loss:   6.285369 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:21:22,896 [Epoch: 016 Step: 00002647] Batch Translation Loss:   6.323945 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:21:59,371 [Epoch: 016 Step: 00002648] Batch Translation Loss:   6.644077 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:22:58,450 [Epoch: 016 Step: 00002649] Batch Translation Loss:   6.041796 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:23:44,521 [Epoch: 016 Step: 00002650] Batch Translation Loss:   6.416078 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:24:37,340 [Epoch: 016 Step: 00002651] Batch Translation Loss:   6.575450 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:25:22,672 [Epoch: 016 Step: 00002652] Batch Translation Loss:   6.168261 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:26:09,034 [Epoch: 016 Step: 00002653] Batch Translation Loss:   7.113997 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:27:09,503 [Epoch: 016 Step: 00002654] Batch Translation Loss:   5.984489 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:27:54,576 [Epoch: 016 Step: 00002655] Batch Translation Loss:   6.265664 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:28:48,475 [Epoch: 016 Step: 00002656] Batch Translation Loss:   6.331090 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:29:40,114 [Epoch: 016 Step: 00002657] Batch Translation Loss:   6.633598 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:30:29,489 [Epoch: 016 Step: 00002658] Batch Translation Loss:   6.565569 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:31:26,580 [Epoch: 016 Step: 00002659] Batch Translation Loss:   6.314336 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:32:37,961 [Epoch: 016 Step: 00002660] Batch Translation Loss:   5.982011 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:33:26,008 [Epoch: 016 Step: 00002661] Batch Translation Loss:   6.259424 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:35:06,167 [Epoch: 016 Step: 00002662] Batch Translation Loss:   6.592826 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 02:36:02,377 [Epoch: 016 Step: 00002663] Batch Translation Loss:   5.835518 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:36:54,305 [Epoch: 016 Step: 00002664] Batch Translation Loss:   5.963328 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:37:58,456 [Epoch: 016 Step: 00002665] Batch Translation Loss:   6.328357 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:38:50,888 [Epoch: 016 Step: 00002666] Batch Translation Loss:   5.762839 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:39:47,605 [Epoch: 016 Step: 00002667] Batch Translation Loss:   5.991031 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:40:51,471 [Epoch: 016 Step: 00002668] Batch Translation Loss:   6.260703 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:41:51,696 [Epoch: 016 Step: 00002669] Batch Translation Loss:   6.390873 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:42:56,524 [Epoch: 016 Step: 00002670] Batch Translation Loss:   6.336687 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:43:57,224 [Epoch: 016 Step: 00002671] Batch Translation Loss:   6.200913 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:45:02,441 [Epoch: 016 Step: 00002672] Batch Translation Loss:   5.911850 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:46:01,007 [Epoch: 016 Step: 00002673] Batch Translation Loss:   5.602854 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:46:55,062 [Epoch: 016 Step: 00002674] Batch Translation Loss:   7.267586 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:47:57,653 [Epoch: 016 Step: 00002675] Batch Translation Loss:   6.891798 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:48:52,284 [Epoch: 016 Step: 00002676] Batch Translation Loss:   6.733202 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:49:48,695 [Epoch: 016 Step: 00002677] Batch Translation Loss:   6.466365 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:50:57,546 [Epoch: 016 Step: 00002678] Batch Translation Loss:   6.330061 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:51:53,860 [Epoch: 016 Step: 00002679] Batch Translation Loss:   6.523272 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:52:51,377 [Epoch: 016 Step: 00002680] Batch Translation Loss:   6.514021 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:54:35,000 [Epoch: 016 Step: 00002681] Batch Translation Loss:   5.931786 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 02:55:45,361 [Epoch: 016 Step: 00002682] Batch Translation Loss:   6.929513 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:56:53,713 [Epoch: 016 Step: 00002683] Batch Translation Loss:   5.921177 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 02:58:01,478 [Epoch: 016 Step: 00002684] Batch Translation Loss:   6.778723 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:58:53,046 [Epoch: 016 Step: 00002685] Batch Translation Loss:   5.933560 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 02:59:48,907 [Epoch: 016 Step: 00002686] Batch Translation Loss:   5.784048 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:01:25,470 [Epoch: 016 Step: 00002687] Batch Translation Loss:   6.103087 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 03:02:59,027 [Epoch: 016 Step: 00002688] Batch Translation Loss:   6.567530 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 03:04:06,792 [Epoch: 016 Step: 00002689] Batch Translation Loss:   6.422270 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:04:43,604 [Epoch: 016 Step: 00002690] Batch Translation Loss:   6.086741 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:05:36,247 [Epoch: 016 Step: 00002691] Batch Translation Loss:   5.806263 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:06:29,220 [Epoch: 016 Step: 00002692] Batch Translation Loss:   5.787960 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:07:16,206 [Epoch: 016 Step: 00002693] Batch Translation Loss:   5.597155 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:08:23,342 [Epoch: 016 Step: 00002694] Batch Translation Loss:   5.792091 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 03:09:12,171 [Epoch: 016 Step: 00002695] Batch Translation Loss:   6.874184 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:10:06,975 [Epoch: 016 Step: 00002696] Batch Translation Loss:   6.218609 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:11:17,605 [Epoch: 016 Step: 00002697] Batch Translation Loss:   5.614271 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:12:44,699 [Epoch: 016 Step: 00002698] Batch Translation Loss:   6.245942 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 03:13:38,916 [Epoch: 016 Step: 00002699] Batch Translation Loss:   5.694703 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:14:40,439 [Epoch: 016 Step: 00002700] Batch Translation Loss:   6.186200 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:25:29,276 Validation result at epoch  16, step     2700: duration: 648.8352s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11732.79980	PPL: 10512.28320
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.03	(DEL: 24.31,	INS: 0.00,	SUB: 74.66)
	Sequence Accuracy 1.04
2022-01-04 03:25:35,136 Logging Recognition and Translation Outputs
2022-01-04 03:25:35,136 ========================================================================================================================
2022-01-04 03:25:35,136 Logging Sequence: youtube_5-jeffrey_spinale_6061
2022-01-04 03:25:35,137 	Text Reference  :	well
2022-01-04 03:25:35,137 	Text Hypothesis :	asl 
2022-01-04 03:25:35,137 	Text Alignment  :	S   
2022-01-04 03:25:35,138 ========================================================================================================================
2022-01-04 03:25:35,138 Logging Sequence: deafvideo_3-titans_4704
2022-01-04 03:25:35,138 	Text Reference  :	jles dameron
2022-01-04 03:25:35,138 	Text Hypothesis :	**** absl   
2022-01-04 03:25:35,139 	Text Alignment  :	D    S      
2022-01-04 03:25:35,139 ========================================================================================================================
2022-01-04 03:25:35,139 Logging Sequence: deafvideo_5-silentoneye_7322
2022-01-04 03:25:35,139 	Text Reference  :	ada
2022-01-04 03:25:35,139 	Text Hypothesis :	asl
2022-01-04 03:25:35,140 	Text Alignment  :	S  
2022-01-04 03:25:35,140 ========================================================================================================================
2022-01-04 03:25:35,140 Logging Sequence: aslized-suzanne_stecker_0266
2022-01-04 03:25:35,140 	Text Reference  :	all
2022-01-04 03:25:35,140 	Text Hypothesis :	if 
2022-01-04 03:25:35,141 	Text Alignment  :	S  
2022-01-04 03:25:35,141 ========================================================================================================================
2022-01-04 03:25:35,141 Logging Sequence: youtube_4-tim_albert_5271
2022-01-04 03:25:35,141 	Text Reference  :	grandchildr grandchildren
2022-01-04 03:25:35,142 	Text Hypothesis :	*********** fla          
2022-01-04 03:25:35,142 	Text Alignment  :	D           S            
2022-01-04 03:25:35,142 ========================================================================================================================
2022-01-04 03:26:30,168 [Epoch: 016 Step: 00002701] Batch Translation Loss:   6.114289 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:27:22,280 [Epoch: 016 Step: 00002702] Batch Translation Loss:   6.097488 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:28:16,566 [Epoch: 016 Step: 00002703] Batch Translation Loss:   5.990739 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:30:19,006 [Epoch: 016 Step: 00002704] Batch Translation Loss:   6.293355 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 03:31:58,934 [Epoch: 016 Step: 00002705] Batch Translation Loss:   6.321410 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 03:32:52,908 [Epoch: 016 Step: 00002706] Batch Translation Loss:   5.505775 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:34:30,277 [Epoch: 016 Step: 00002707] Batch Translation Loss:   6.696416 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 03:35:26,490 [Epoch: 016 Step: 00002708] Batch Translation Loss:   6.363536 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:36:06,866 [Epoch: 016 Step: 00002709] Batch Translation Loss:   7.122229 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:36:52,706 [Epoch: 016 Step: 00002710] Batch Translation Loss:   5.165660 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:37:42,408 [Epoch: 016 Step: 00002711] Batch Translation Loss:   6.069860 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:38:38,725 [Epoch: 016 Step: 00002712] Batch Translation Loss:   6.426714 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:39:32,869 [Epoch: 016 Step: 00002713] Batch Translation Loss:   6.360262 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:40:28,104 [Epoch: 016 Step: 00002714] Batch Translation Loss:   5.906838 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:42:01,629 [Epoch: 016 Step: 00002715] Batch Translation Loss:   6.333053 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 03:43:02,761 [Epoch: 016 Step: 00002716] Batch Translation Loss:   6.142792 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:44:08,648 [Epoch: 016 Step: 00002717] Batch Translation Loss:   6.350734 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:45:01,413 [Epoch: 016 Step: 00002718] Batch Translation Loss:   6.162085 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:46:07,634 [Epoch: 016 Step: 00002719] Batch Translation Loss:   6.204451 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:47:59,430 [Epoch: 016 Step: 00002720] Batch Translation Loss:   6.803510 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 03:47:59,726 Epoch  16: Total Training Recognition Loss -1.00  Total Training Translation Loss 1061.17 
2022-01-04 03:47:59,727 EPOCH 17
2022-01-04 03:48:13,161 [Epoch: 017 Step: 00002721] Batch Translation Loss:   6.342768 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-04 03:48:32,817 [Epoch: 017 Step: 00002722] Batch Translation Loss:   6.307481 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 03:48:52,180 [Epoch: 017 Step: 00002723] Batch Translation Loss:   6.231647 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 03:49:10,783 [Epoch: 017 Step: 00002724] Batch Translation Loss:   6.700417 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 03:49:32,649 [Epoch: 017 Step: 00002725] Batch Translation Loss:   6.145078 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 03:49:53,927 [Epoch: 017 Step: 00002726] Batch Translation Loss:   6.463922 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 03:50:13,944 [Epoch: 017 Step: 00002727] Batch Translation Loss:   6.177719 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 03:50:33,949 [Epoch: 017 Step: 00002728] Batch Translation Loss:   6.426636 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 03:51:04,687 [Epoch: 017 Step: 00002729] Batch Translation Loss:   6.281212 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:51:22,511 [Epoch: 017 Step: 00002730] Batch Translation Loss:   5.916018 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 03:51:46,516 [Epoch: 017 Step: 00002731] Batch Translation Loss:   6.252342 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 03:52:13,700 [Epoch: 017 Step: 00002732] Batch Translation Loss:   5.615294 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 03:52:34,982 [Epoch: 017 Step: 00002733] Batch Translation Loss:   6.768140 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 03:53:06,257 [Epoch: 017 Step: 00002734] Batch Translation Loss:   6.385530 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 03:53:30,916 [Epoch: 017 Step: 00002735] Batch Translation Loss:   6.348238 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 03:53:54,197 [Epoch: 017 Step: 00002736] Batch Translation Loss:   6.229706 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:54:17,349 [Epoch: 017 Step: 00002737] Batch Translation Loss:   5.373834 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 03:54:45,801 [Epoch: 017 Step: 00002738] Batch Translation Loss:   6.700331 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 03:55:17,535 [Epoch: 017 Step: 00002739] Batch Translation Loss:   5.833736 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:55:45,265 [Epoch: 017 Step: 00002740] Batch Translation Loss:   6.121349 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:56:24,637 [Epoch: 017 Step: 00002741] Batch Translation Loss:   6.569717 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:56:52,473 [Epoch: 017 Step: 00002742] Batch Translation Loss:   5.991072 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:57:19,401 [Epoch: 017 Step: 00002743] Batch Translation Loss:   6.068464 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:57:43,288 [Epoch: 017 Step: 00002744] Batch Translation Loss:   6.450284 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 03:58:05,108 [Epoch: 017 Step: 00002745] Batch Translation Loss:   6.190459 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 03:58:34,763 [Epoch: 017 Step: 00002746] Batch Translation Loss:   5.920809 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:58:59,901 [Epoch: 017 Step: 00002747] Batch Translation Loss:   6.082600 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 03:59:25,836 [Epoch: 017 Step: 00002748] Batch Translation Loss:   6.127971 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 03:59:51,427 [Epoch: 017 Step: 00002749] Batch Translation Loss:   6.865197 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:00:19,538 [Epoch: 017 Step: 00002750] Batch Translation Loss:   6.489221 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 04:00:52,980 [Epoch: 017 Step: 00002751] Batch Translation Loss:   6.963514 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:01:09,164 [Epoch: 017 Step: 00002752] Batch Translation Loss:   5.849378 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 04:01:35,968 [Epoch: 017 Step: 00002753] Batch Translation Loss:   6.723783 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 04:01:59,887 [Epoch: 017 Step: 00002754] Batch Translation Loss:   6.239710 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:02:26,442 [Epoch: 017 Step: 00002755] Batch Translation Loss:   6.326503 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 04:02:55,239 [Epoch: 017 Step: 00002756] Batch Translation Loss:   6.385833 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:03:21,379 [Epoch: 017 Step: 00002757] Batch Translation Loss:   6.192715 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 04:03:47,984 [Epoch: 017 Step: 00002758] Batch Translation Loss:   6.052953 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:04:21,914 [Epoch: 017 Step: 00002759] Batch Translation Loss:   6.630902 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:04:48,818 [Epoch: 017 Step: 00002760] Batch Translation Loss:   5.930044 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:05:17,779 [Epoch: 017 Step: 00002761] Batch Translation Loss:   5.841624 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:05:57,344 [Epoch: 017 Step: 00002762] Batch Translation Loss:   6.246787 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:06:52,645 [Epoch: 017 Step: 00002763] Batch Translation Loss:   6.643528 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:07:21,893 [Epoch: 017 Step: 00002764] Batch Translation Loss:   7.039092 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:08:00,901 [Epoch: 017 Step: 00002765] Batch Translation Loss:   6.469083 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:08:33,039 [Epoch: 017 Step: 00002766] Batch Translation Loss:   6.860266 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:09:08,180 [Epoch: 017 Step: 00002767] Batch Translation Loss:   6.714481 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:09:41,165 [Epoch: 017 Step: 00002768] Batch Translation Loss:   6.265946 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:10:18,618 [Epoch: 017 Step: 00002769] Batch Translation Loss:   6.393748 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:10:39,325 [Epoch: 017 Step: 00002770] Batch Translation Loss:   6.006757 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 04:11:04,961 [Epoch: 017 Step: 00002771] Batch Translation Loss:   6.237712 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:11:44,792 [Epoch: 017 Step: 00002772] Batch Translation Loss:   5.925937 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:12:21,324 [Epoch: 017 Step: 00002773] Batch Translation Loss:   6.231537 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:13:14,108 [Epoch: 017 Step: 00002774] Batch Translation Loss:   6.116176 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:13:50,132 [Epoch: 017 Step: 00002775] Batch Translation Loss:   6.196603 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:14:20,736 [Epoch: 017 Step: 00002776] Batch Translation Loss:   5.735116 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:15:08,092 [Epoch: 017 Step: 00002777] Batch Translation Loss:   5.982169 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:15:49,142 [Epoch: 017 Step: 00002778] Batch Translation Loss:   6.243992 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:16:15,798 [Epoch: 017 Step: 00002779] Batch Translation Loss:   6.494742 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:16:48,410 [Epoch: 017 Step: 00002780] Batch Translation Loss:   6.249912 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:17:17,510 [Epoch: 017 Step: 00002781] Batch Translation Loss:   6.078964 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:17:51,359 [Epoch: 017 Step: 00002782] Batch Translation Loss:   6.813869 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:18:10,376 [Epoch: 017 Step: 00002783] Batch Translation Loss:   5.988505 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 04:18:56,125 [Epoch: 017 Step: 00002784] Batch Translation Loss:   6.057255 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:19:30,731 [Epoch: 017 Step: 00002785] Batch Translation Loss:   5.925114 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:20:02,806 [Epoch: 017 Step: 00002786] Batch Translation Loss:   6.269691 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:20:36,099 [Epoch: 017 Step: 00002787] Batch Translation Loss:   6.254276 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:21:02,358 [Epoch: 017 Step: 00002788] Batch Translation Loss:   5.807959 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:21:35,225 [Epoch: 017 Step: 00002789] Batch Translation Loss:   5.937109 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:22:02,735 [Epoch: 017 Step: 00002790] Batch Translation Loss:   6.701416 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:22:32,227 [Epoch: 017 Step: 00002791] Batch Translation Loss:   5.542962 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:23:04,510 [Epoch: 017 Step: 00002792] Batch Translation Loss:   6.408065 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:23:36,506 [Epoch: 017 Step: 00002793] Batch Translation Loss:   6.478542 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:24:11,626 [Epoch: 017 Step: 00002794] Batch Translation Loss:   5.907990 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:24:50,240 [Epoch: 017 Step: 00002795] Batch Translation Loss:   6.564937 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:25:19,672 [Epoch: 017 Step: 00002796] Batch Translation Loss:   5.882705 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:26:00,692 [Epoch: 017 Step: 00002797] Batch Translation Loss:   6.395789 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:26:38,609 [Epoch: 017 Step: 00002798] Batch Translation Loss:   6.404938 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:27:19,439 [Epoch: 017 Step: 00002799] Batch Translation Loss:   6.354040 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:28:00,887 [Epoch: 017 Step: 00002800] Batch Translation Loss:   6.155351 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:41:24,926 Validation result at epoch  17, step     2800: duration: 804.0247s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 12024.68066	PPL: 13639.55176
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.19	(DEL: 24.54,	INS: 0.00,	SUB: 74.27)
	Sequence Accuracy 1.36
2022-01-04 04:41:34,833 Logging Recognition and Translation Outputs
2022-01-04 04:41:34,859 ========================================================================================================================
2022-01-04 04:41:34,860 Logging Sequence: deafvideo_2-deafpoweronethumbtwo_1792
2022-01-04 04:41:34,860 	Text Reference  :	matsl
2022-01-04 04:41:34,860 	Text Hypothesis :	asl  
2022-01-04 04:41:34,860 	Text Alignment  :	S    
2022-01-04 04:41:34,860 ========================================================================================================================
2022-01-04 04:41:34,860 Logging Sequence: youtube_5-sean_berdy_6118
2022-01-04 04:41:34,860 	Text Reference  :	ian
2022-01-04 04:41:34,861 	Text Hypothesis :	ok 
2022-01-04 04:41:34,861 	Text Alignment  :	S  
2022-01-04 04:41:34,861 ========================================================================================================================
2022-01-04 04:41:34,861 Logging Sequence: deafvideo_3-yellowbirdie84_4669
2022-01-04 04:41:34,861 	Text Reference  :	fund
2022-01-04 04:41:34,861 	Text Hypothesis :	ok  
2022-01-04 04:41:34,861 	Text Alignment  :	S   
2022-01-04 04:41:34,861 ========================================================================================================================
2022-01-04 04:41:34,861 Logging Sequence: deafvideo_2-goatman_1524
2022-01-04 04:41:34,862 	Text Reference  :	inox
2022-01-04 04:41:34,862 	Text Hypothesis :	ok  
2022-01-04 04:41:34,862 	Text Alignment  :	S   
2022-01-04 04:41:34,862 ========================================================================================================================
2022-01-04 04:41:34,862 Logging Sequence: deafvideo_2-fairytales9_2286
2022-01-04 04:41:34,862 	Text Reference  :	to
2022-01-04 04:41:34,862 	Text Hypothesis :	ok
2022-01-04 04:41:34,862 	Text Alignment  :	S 
2022-01-04 04:41:34,862 ========================================================================================================================
2022-01-04 04:42:04,346 [Epoch: 017 Step: 00002801] Batch Translation Loss:   6.151012 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:42:45,311 [Epoch: 017 Step: 00002802] Batch Translation Loss:   6.868428 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:43:32,161 [Epoch: 017 Step: 00002803] Batch Translation Loss:   6.226981 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:43:54,157 [Epoch: 017 Step: 00002804] Batch Translation Loss:   5.988729 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 04:44:39,107 [Epoch: 017 Step: 00002805] Batch Translation Loss:   6.496433 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:45:49,477 [Epoch: 017 Step: 00002806] Batch Translation Loss:   6.160788 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:46:36,729 [Epoch: 017 Step: 00002807] Batch Translation Loss:   6.087747 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:47:14,811 [Epoch: 017 Step: 00002808] Batch Translation Loss:   5.348827 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:48:15,833 [Epoch: 017 Step: 00002809] Batch Translation Loss:   6.039128 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:49:00,050 [Epoch: 017 Step: 00002810] Batch Translation Loss:   6.321922 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:49:46,768 [Epoch: 017 Step: 00002811] Batch Translation Loss:   6.198002 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:50:35,104 [Epoch: 017 Step: 00002812] Batch Translation Loss:   5.883789 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:52:10,130 [Epoch: 017 Step: 00002813] Batch Translation Loss:   6.546914 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 04:53:06,689 [Epoch: 017 Step: 00002814] Batch Translation Loss:   6.214917 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:53:52,576 [Epoch: 017 Step: 00002815] Batch Translation Loss:   6.196225 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:54:30,434 [Epoch: 017 Step: 00002816] Batch Translation Loss:   6.168744 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:55:14,227 [Epoch: 017 Step: 00002817] Batch Translation Loss:   6.649961 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:56:04,825 [Epoch: 017 Step: 00002818] Batch Translation Loss:   5.435982 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:57:25,619 [Epoch: 017 Step: 00002819] Batch Translation Loss:   6.102156 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 04:58:16,132 [Epoch: 017 Step: 00002820] Batch Translation Loss:   6.299204 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:59:12,177 [Epoch: 017 Step: 00002821] Batch Translation Loss:   6.266024 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 04:59:54,056 [Epoch: 017 Step: 00002822] Batch Translation Loss:   6.035366 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:00:38,848 [Epoch: 017 Step: 00002823] Batch Translation Loss:   5.622110 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:02:16,223 [Epoch: 017 Step: 00002824] Batch Translation Loss:   6.173848 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 05:03:03,895 [Epoch: 017 Step: 00002825] Batch Translation Loss:   6.112888 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:03:47,854 [Epoch: 017 Step: 00002826] Batch Translation Loss:   6.177906 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:04:51,912 [Epoch: 017 Step: 00002827] Batch Translation Loss:   5.823789 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:06:18,315 [Epoch: 017 Step: 00002828] Batch Translation Loss:   5.923127 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 05:07:30,295 [Epoch: 017 Step: 00002829] Batch Translation Loss:   5.578094 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:08:45,507 [Epoch: 017 Step: 00002830] Batch Translation Loss:   5.968804 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 05:09:16,697 [Epoch: 017 Step: 00002831] Batch Translation Loss:   6.144652 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:10:32,215 [Epoch: 017 Step: 00002832] Batch Translation Loss:   6.187793 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 05:11:36,835 [Epoch: 017 Step: 00002833] Batch Translation Loss:   6.469833 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:12:19,698 [Epoch: 017 Step: 00002834] Batch Translation Loss:   6.112280 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:13:09,653 [Epoch: 017 Step: 00002835] Batch Translation Loss:   5.867548 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:13:58,446 [Epoch: 017 Step: 00002836] Batch Translation Loss:   6.210404 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:14:43,997 [Epoch: 017 Step: 00002837] Batch Translation Loss:   6.301023 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:15:28,913 [Epoch: 017 Step: 00002838] Batch Translation Loss:   6.466766 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:16:14,322 [Epoch: 017 Step: 00002839] Batch Translation Loss:   6.029697 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:17:02,431 [Epoch: 017 Step: 00002840] Batch Translation Loss:   5.631650 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:17:42,879 [Epoch: 017 Step: 00002841] Batch Translation Loss:   6.236844 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:18:41,719 [Epoch: 017 Step: 00002842] Batch Translation Loss:   5.875138 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:19:32,248 [Epoch: 017 Step: 00002843] Batch Translation Loss:   6.693207 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:20:25,339 [Epoch: 017 Step: 00002844] Batch Translation Loss:   6.287364 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:21:08,547 [Epoch: 017 Step: 00002845] Batch Translation Loss:   6.146943 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:22:02,896 [Epoch: 017 Step: 00002846] Batch Translation Loss:   5.998724 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:23:57,007 [Epoch: 017 Step: 00002847] Batch Translation Loss:   6.027886 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 05:24:42,438 [Epoch: 017 Step: 00002848] Batch Translation Loss:   6.457586 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:25:47,316 [Epoch: 017 Step: 00002849] Batch Translation Loss:   6.394942 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:26:46,076 [Epoch: 017 Step: 00002850] Batch Translation Loss:   5.932099 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:27:41,087 [Epoch: 017 Step: 00002851] Batch Translation Loss:   6.129915 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:28:38,493 [Epoch: 017 Step: 00002852] Batch Translation Loss:   6.090185 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:30:13,725 [Epoch: 017 Step: 00002853] Batch Translation Loss:   6.099530 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 05:32:05,554 [Epoch: 017 Step: 00002854] Batch Translation Loss:   5.583817 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 05:33:11,779 [Epoch: 017 Step: 00002855] Batch Translation Loss:   6.359341 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:33:59,283 [Epoch: 017 Step: 00002856] Batch Translation Loss:   6.411007 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:35:09,174 [Epoch: 017 Step: 00002857] Batch Translation Loss:   6.233829 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:36:52,691 [Epoch: 017 Step: 00002858] Batch Translation Loss:   6.015827 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 05:37:47,863 [Epoch: 017 Step: 00002859] Batch Translation Loss:   6.184590 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:38:27,375 [Epoch: 017 Step: 00002860] Batch Translation Loss:   5.898423 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:39:20,421 [Epoch: 017 Step: 00002861] Batch Translation Loss:   5.806372 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:40:16,325 [Epoch: 017 Step: 00002862] Batch Translation Loss:   5.961774 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:41:04,859 [Epoch: 017 Step: 00002863] Batch Translation Loss:   6.183630 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:42:01,728 [Epoch: 017 Step: 00002864] Batch Translation Loss:   5.787468 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:42:50,276 [Epoch: 017 Step: 00002865] Batch Translation Loss:   5.990857 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:43:49,969 [Epoch: 017 Step: 00002866] Batch Translation Loss:   6.095706 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:44:43,906 [Epoch: 017 Step: 00002867] Batch Translation Loss:   6.209547 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:45:20,301 [Epoch: 017 Step: 00002868] Batch Translation Loss:   6.234673 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:46:54,260 [Epoch: 017 Step: 00002869] Batch Translation Loss:   6.600884 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 05:48:41,468 [Epoch: 017 Step: 00002870] Batch Translation Loss:   6.517513 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 05:50:29,973 [Epoch: 017 Step: 00002871] Batch Translation Loss:   6.113251 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 05:51:47,479 [Epoch: 017 Step: 00002872] Batch Translation Loss:   6.732918 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 05:54:05,726 [Epoch: 017 Step: 00002873] Batch Translation Loss:   6.264760 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 05:55:38,323 [Epoch: 017 Step: 00002874] Batch Translation Loss:   6.415582 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 05:56:45,347 [Epoch: 017 Step: 00002875] Batch Translation Loss:   5.924859 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:57:40,431 [Epoch: 017 Step: 00002876] Batch Translation Loss:   6.270435 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 05:59:20,721 [Epoch: 017 Step: 00002877] Batch Translation Loss:   5.976935 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 06:00:25,240 [Epoch: 017 Step: 00002878] Batch Translation Loss:   5.973364 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:02:09,626 [Epoch: 017 Step: 00002879] Batch Translation Loss:   6.437252 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 06:03:12,813 [Epoch: 017 Step: 00002880] Batch Translation Loss:   5.411189 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:04:07,328 [Epoch: 017 Step: 00002881] Batch Translation Loss:   6.055055 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:05:10,127 [Epoch: 017 Step: 00002882] Batch Translation Loss:   5.993847 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:06:09,303 [Epoch: 017 Step: 00002883] Batch Translation Loss:   5.528348 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:07:17,367 [Epoch: 017 Step: 00002884] Batch Translation Loss:   6.430646 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:08:38,631 [Epoch: 017 Step: 00002885] Batch Translation Loss:   5.881627 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 06:09:47,187 [Epoch: 017 Step: 00002886] Batch Translation Loss:   6.307998 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 06:10:38,098 [Epoch: 017 Step: 00002887] Batch Translation Loss:   5.854148 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:11:46,048 [Epoch: 017 Step: 00002888] Batch Translation Loss:   6.580997 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:13:54,740 [Epoch: 017 Step: 00002889] Batch Translation Loss:   6.728789 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 06:16:03,468 [Epoch: 017 Step: 00002890] Batch Translation Loss:   7.155930 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 06:16:03,555 Epoch  17: Total Training Recognition Loss -1.00  Total Training Translation Loss 1053.47 
2022-01-04 06:16:03,555 EPOCH 18
2022-01-04 06:16:16,709 [Epoch: 018 Step: 00002891] Batch Translation Loss:   6.356689 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-04 06:16:34,232 [Epoch: 018 Step: 00002892] Batch Translation Loss:   6.373597 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 06:16:57,807 [Epoch: 018 Step: 00002893] Batch Translation Loss:   6.798674 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 06:17:11,887 [Epoch: 018 Step: 00002894] Batch Translation Loss:   6.431215 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-04 06:17:41,454 [Epoch: 018 Step: 00002895] Batch Translation Loss:   6.615685 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:17:56,967 [Epoch: 018 Step: 00002896] Batch Translation Loss:   6.222991 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-04 06:18:15,234 [Epoch: 018 Step: 00002897] Batch Translation Loss:   6.968445 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-04 06:18:38,346 [Epoch: 018 Step: 00002898] Batch Translation Loss:   6.399675 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 06:19:06,281 [Epoch: 018 Step: 00002899] Batch Translation Loss:   6.341426 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:19:33,968 [Epoch: 018 Step: 00002900] Batch Translation Loss:   6.227471 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 06:32:40,943 Validation result at epoch  18, step     2900: duration: 786.9449s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 12505.24609	PPL: 12378.25488
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 0.90	(DEL: 28.26,	INS: 0.00,	SUB: 70.84)
	Sequence Accuracy 0.53
2022-01-04 06:32:49,826 Logging Recognition and Translation Outputs
2022-01-04 06:32:49,827 ========================================================================================================================
2022-01-04 06:32:49,827 Logging Sequence: deafvideo_5-silentoneye_7320
2022-01-04 06:32:49,827 	Text Reference  :	him     
2022-01-04 06:32:49,827 	Text Hypothesis :	eugenics
2022-01-04 06:32:49,827 	Text Alignment  :	S       
2022-01-04 06:32:49,827 ========================================================================================================================
2022-01-04 06:32:49,828 Logging Sequence: deafvideo_2-sddsimple_1596
2022-01-04 06:32:49,828 	Text Reference  :	nad
2022-01-04 06:32:49,828 	Text Hypothesis :	ok 
2022-01-04 06:32:49,828 	Text Alignment  :	S  
2022-01-04 06:32:49,828 ========================================================================================================================
2022-01-04 06:32:49,828 Logging Sequence: deafvideo_5-silentoneye_7323
2022-01-04 06:32:49,829 	Text Reference  :	deaf nfl vloggers
2022-01-04 06:32:49,829 	Text Hypothesis :	**** *** asl     
2022-01-04 06:32:49,829 	Text Alignment  :	D    D   S       
2022-01-04 06:32:49,829 ========================================================================================================================
2022-01-04 06:32:49,829 Logging Sequence: deafvideo_2-sddsimple_1593
2022-01-04 06:32:49,829 	Text Reference  :	rollover
2022-01-04 06:32:49,830 	Text Hypothesis :	ok      
2022-01-04 06:32:49,830 	Text Alignment  :	S       
2022-01-04 06:32:49,830 ========================================================================================================================
2022-01-04 06:32:49,830 Logging Sequence: deafvideo_2-fairytales9_2298
2022-01-04 06:32:49,830 	Text Reference  :	saw
2022-01-04 06:32:49,830 	Text Hypothesis :	ok 
2022-01-04 06:32:49,830 	Text Alignment  :	S  
2022-01-04 06:32:49,830 ========================================================================================================================
2022-01-04 06:33:06,148 [Epoch: 018 Step: 00002901] Batch Translation Loss:   6.172764 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 06:33:22,425 [Epoch: 018 Step: 00002902] Batch Translation Loss:   6.303169 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-04 06:33:45,117 [Epoch: 018 Step: 00002903] Batch Translation Loss:   6.277030 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 06:34:04,124 [Epoch: 018 Step: 00002904] Batch Translation Loss:   6.063468 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 06:34:24,488 [Epoch: 018 Step: 00002905] Batch Translation Loss:   5.975561 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 06:34:41,549 [Epoch: 018 Step: 00002906] Batch Translation Loss:   6.334134 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 06:35:03,611 [Epoch: 018 Step: 00002907] Batch Translation Loss:   6.209070 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 06:35:28,613 [Epoch: 018 Step: 00002908] Batch Translation Loss:   6.349042 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 06:35:45,014 [Epoch: 018 Step: 00002909] Batch Translation Loss:   6.538358 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 06:36:21,823 [Epoch: 018 Step: 00002910] Batch Translation Loss:   6.185880 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:36:46,440 [Epoch: 018 Step: 00002911] Batch Translation Loss:   6.919481 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 06:37:05,794 [Epoch: 018 Step: 00002912] Batch Translation Loss:   6.472520 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 06:37:34,051 [Epoch: 018 Step: 00002913] Batch Translation Loss:   6.200767 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:37:50,928 [Epoch: 018 Step: 00002914] Batch Translation Loss:   6.090626 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 06:38:03,363 [Epoch: 018 Step: 00002915] Batch Translation Loss:   6.078647 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-04 06:38:28,397 [Epoch: 018 Step: 00002916] Batch Translation Loss:   6.137979 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 06:38:52,789 [Epoch: 018 Step: 00002917] Batch Translation Loss:   5.730364 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 06:39:11,798 [Epoch: 018 Step: 00002918] Batch Translation Loss:   6.548895 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 06:39:35,574 [Epoch: 018 Step: 00002919] Batch Translation Loss:   6.398701 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 06:39:55,239 [Epoch: 018 Step: 00002920] Batch Translation Loss:   5.632047 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 06:40:21,096 [Epoch: 018 Step: 00002921] Batch Translation Loss:   5.924197 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 06:40:39,872 [Epoch: 018 Step: 00002922] Batch Translation Loss:   6.209144 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 06:41:06,242 [Epoch: 018 Step: 00002923] Batch Translation Loss:   5.966985 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:41:36,997 [Epoch: 018 Step: 00002924] Batch Translation Loss:   6.627656 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:42:20,845 [Epoch: 018 Step: 00002925] Batch Translation Loss:   5.887110 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:42:48,892 [Epoch: 018 Step: 00002926] Batch Translation Loss:   6.179552 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:43:15,103 [Epoch: 018 Step: 00002927] Batch Translation Loss:   6.337439 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 06:44:04,120 [Epoch: 018 Step: 00002928] Batch Translation Loss:   5.942975 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:44:32,566 [Epoch: 018 Step: 00002929] Batch Translation Loss:   7.159560 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:45:09,657 [Epoch: 018 Step: 00002930] Batch Translation Loss:   6.472497 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:45:45,279 [Epoch: 018 Step: 00002931] Batch Translation Loss:   5.765164 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:46:22,912 [Epoch: 018 Step: 00002932] Batch Translation Loss:   6.110548 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:46:55,467 [Epoch: 018 Step: 00002933] Batch Translation Loss:   6.133532 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:47:27,895 [Epoch: 018 Step: 00002934] Batch Translation Loss:   5.613865 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:48:03,610 [Epoch: 018 Step: 00002935] Batch Translation Loss:   6.282784 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:48:38,532 [Epoch: 018 Step: 00002936] Batch Translation Loss:   6.380120 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:49:05,426 [Epoch: 018 Step: 00002937] Batch Translation Loss:   6.792053 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:49:39,522 [Epoch: 018 Step: 00002938] Batch Translation Loss:   6.435573 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:50:17,076 [Epoch: 018 Step: 00002939] Batch Translation Loss:   6.472974 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:50:42,092 [Epoch: 018 Step: 00002940] Batch Translation Loss:   6.305387 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:51:11,375 [Epoch: 018 Step: 00002941] Batch Translation Loss:   6.456326 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:51:42,677 [Epoch: 018 Step: 00002942] Batch Translation Loss:   6.178103 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:52:14,834 [Epoch: 018 Step: 00002943] Batch Translation Loss:   5.982141 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:53:20,203 [Epoch: 018 Step: 00002944] Batch Translation Loss:   6.563527 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:53:57,285 [Epoch: 018 Step: 00002945] Batch Translation Loss:   6.637133 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:54:33,475 [Epoch: 018 Step: 00002946] Batch Translation Loss:   6.533692 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:55:07,784 [Epoch: 018 Step: 00002947] Batch Translation Loss:   6.000340 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:55:41,747 [Epoch: 018 Step: 00002948] Batch Translation Loss:   5.572779 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:56:46,918 [Epoch: 018 Step: 00002949] Batch Translation Loss:   6.514279 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:57:34,929 [Epoch: 018 Step: 00002950] Batch Translation Loss:   6.244604 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:58:12,786 [Epoch: 018 Step: 00002951] Batch Translation Loss:   6.275307 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:59:25,914 [Epoch: 018 Step: 00002952] Batch Translation Loss:   6.257765 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 06:59:55,945 [Epoch: 018 Step: 00002953] Batch Translation Loss:   5.322090 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:00:20,089 [Epoch: 018 Step: 00002954] Batch Translation Loss:   6.016109 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 07:01:13,347 [Epoch: 018 Step: 00002955] Batch Translation Loss:   6.643081 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:01:52,146 [Epoch: 018 Step: 00002956] Batch Translation Loss:   6.539339 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:02:11,502 [Epoch: 018 Step: 00002957] Batch Translation Loss:   6.289823 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 07:02:41,092 [Epoch: 018 Step: 00002958] Batch Translation Loss:   5.632304 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:03:12,984 [Epoch: 018 Step: 00002959] Batch Translation Loss:   6.119502 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:03:48,481 [Epoch: 018 Step: 00002960] Batch Translation Loss:   5.863926 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:04:43,203 [Epoch: 018 Step: 00002961] Batch Translation Loss:   6.013121 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:05:49,399 [Epoch: 018 Step: 00002962] Batch Translation Loss:   5.454865 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:06:30,512 [Epoch: 018 Step: 00002963] Batch Translation Loss:   6.142489 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:07:04,481 [Epoch: 018 Step: 00002964] Batch Translation Loss:   6.242468 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:07:50,505 [Epoch: 018 Step: 00002965] Batch Translation Loss:   6.727412 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:08:27,397 [Epoch: 018 Step: 00002966] Batch Translation Loss:   6.413157 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:08:57,370 [Epoch: 018 Step: 00002967] Batch Translation Loss:   6.072776 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:09:37,864 [Epoch: 018 Step: 00002968] Batch Translation Loss:   6.612617 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:10:19,555 [Epoch: 018 Step: 00002969] Batch Translation Loss:   5.556543 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:11:03,675 [Epoch: 018 Step: 00002970] Batch Translation Loss:   6.729402 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:11:58,874 [Epoch: 018 Step: 00002971] Batch Translation Loss:   6.522810 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:12:53,689 [Epoch: 018 Step: 00002972] Batch Translation Loss:   5.604905 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:13:30,639 [Epoch: 018 Step: 00002973] Batch Translation Loss:   6.514492 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:14:13,551 [Epoch: 018 Step: 00002974] Batch Translation Loss:   6.058413 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:15:20,911 [Epoch: 018 Step: 00002975] Batch Translation Loss:   6.341997 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:15:51,819 [Epoch: 018 Step: 00002976] Batch Translation Loss:   6.291693 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:16:37,076 [Epoch: 018 Step: 00002977] Batch Translation Loss:   5.636760 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:17:18,881 [Epoch: 018 Step: 00002978] Batch Translation Loss:   5.825586 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:17:57,060 [Epoch: 018 Step: 00002979] Batch Translation Loss:   5.969180 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:18:33,894 [Epoch: 018 Step: 00002980] Batch Translation Loss:   6.345405 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:19:18,329 [Epoch: 018 Step: 00002981] Batch Translation Loss:   6.326849 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:20:08,012 [Epoch: 018 Step: 00002982] Batch Translation Loss:   5.700486 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:20:59,565 [Epoch: 018 Step: 00002983] Batch Translation Loss:   6.472113 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:21:39,654 [Epoch: 018 Step: 00002984] Batch Translation Loss:   5.864238 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:22:25,659 [Epoch: 018 Step: 00002985] Batch Translation Loss:   6.575886 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:22:52,897 [Epoch: 018 Step: 00002986] Batch Translation Loss:   5.976425 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:23:47,296 [Epoch: 018 Step: 00002987] Batch Translation Loss:   5.704175 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:24:22,669 [Epoch: 018 Step: 00002988] Batch Translation Loss:   5.519949 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:25:05,691 [Epoch: 018 Step: 00002989] Batch Translation Loss:   6.394869 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:25:51,994 [Epoch: 018 Step: 00002990] Batch Translation Loss:   5.736960 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:26:39,287 [Epoch: 018 Step: 00002991] Batch Translation Loss:   6.078660 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:27:34,988 [Epoch: 018 Step: 00002992] Batch Translation Loss:   6.090567 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:28:16,027 [Epoch: 018 Step: 00002993] Batch Translation Loss:   6.422197 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:29:39,482 [Epoch: 018 Step: 00002994] Batch Translation Loss:   6.986574 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 07:31:15,599 [Epoch: 018 Step: 00002995] Batch Translation Loss:   5.430360 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 07:31:58,057 [Epoch: 018 Step: 00002996] Batch Translation Loss:   6.306890 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:32:41,138 [Epoch: 018 Step: 00002997] Batch Translation Loss:   6.103362 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:33:22,956 [Epoch: 018 Step: 00002998] Batch Translation Loss:   6.281711 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:34:09,836 [Epoch: 018 Step: 00002999] Batch Translation Loss:   6.081607 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:35:07,054 [Epoch: 018 Step: 00003000] Batch Translation Loss:   6.539123 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:48:33,264 Validation result at epoch  18, step     3000: duration: 806.2086s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11387.30566	PPL: 11143.15430
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 0.90	(DEL: 21.36,	INS: 0.00,	SUB: 77.74)
	Sequence Accuracy 1.14
2022-01-04 07:48:39,483 Logging Recognition and Translation Outputs
2022-01-04 07:48:39,483 ========================================================================================================================
2022-01-04 07:48:39,483 Logging Sequence: deafvideo_3-fieldstreamasl_4038
2022-01-04 07:48:39,484 	Text Reference  :	past
2022-01-04 07:48:39,484 	Text Hypothesis :	ok  
2022-01-04 07:48:39,484 	Text Alignment  :	S   
2022-01-04 07:48:39,484 ========================================================================================================================
2022-01-04 07:48:39,484 Logging Sequence: youtube_5-sean_berdy_6103
2022-01-04 07:48:39,485 	Text Reference  :	map
2022-01-04 07:48:39,485 	Text Hypothesis :	asl
2022-01-04 07:48:39,485 	Text Alignment  :	S  
2022-01-04 07:48:39,485 ========================================================================================================================
2022-01-04 07:48:39,485 Logging Sequence: youtube_5-roberta_cordano_6134
2022-01-04 07:48:39,486 	Text Reference  :	ton
2022-01-04 07:48:39,486 	Text Hypothesis :	asl
2022-01-04 07:48:39,486 	Text Alignment  :	S  
2022-01-04 07:48:39,486 ========================================================================================================================
2022-01-04 07:48:39,486 Logging Sequence: youtube_1-don_grushkin_2767
2022-01-04 07:48:39,487 	Text Reference  :	nad
2022-01-04 07:48:39,487 	Text Hypothesis :	asl
2022-01-04 07:48:39,487 	Text Alignment  :	S  
2022-01-04 07:48:39,487 ========================================================================================================================
2022-01-04 07:48:39,487 Logging Sequence: aslized-suzanne_stecker_0283
2022-01-04 07:48:39,488 	Text Reference  :	microfsoft
2022-01-04 07:48:39,488 	Text Hypothesis :	ok        
2022-01-04 07:48:39,488 	Text Alignment  :	S         
2022-01-04 07:48:39,488 ========================================================================================================================
2022-01-04 07:49:11,862 [Epoch: 018 Step: 00003001] Batch Translation Loss:   6.230552 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:49:53,320 [Epoch: 018 Step: 00003002] Batch Translation Loss:   6.409671 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:50:47,297 [Epoch: 018 Step: 00003003] Batch Translation Loss:   6.784374 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:51:37,181 [Epoch: 018 Step: 00003004] Batch Translation Loss:   5.295248 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:52:40,591 [Epoch: 018 Step: 00003005] Batch Translation Loss:   6.457942 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:53:39,757 [Epoch: 018 Step: 00003006] Batch Translation Loss:   6.127733 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:54:36,063 [Epoch: 018 Step: 00003007] Batch Translation Loss:   6.116209 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:55:30,132 [Epoch: 018 Step: 00003008] Batch Translation Loss:   6.238703 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:56:23,033 [Epoch: 018 Step: 00003009] Batch Translation Loss:   6.404605 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:57:22,711 [Epoch: 018 Step: 00003010] Batch Translation Loss:   6.050044 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:58:19,156 [Epoch: 018 Step: 00003011] Batch Translation Loss:   6.631351 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 07:59:00,810 [Epoch: 018 Step: 00003012] Batch Translation Loss:   6.532471 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:00:13,886 [Epoch: 018 Step: 00003013] Batch Translation Loss:   5.981516 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:01:46,720 [Epoch: 018 Step: 00003014] Batch Translation Loss:   5.592958 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 08:02:35,108 [Epoch: 018 Step: 00003015] Batch Translation Loss:   5.787824 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:03:17,330 [Epoch: 018 Step: 00003016] Batch Translation Loss:   6.636666 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:04:07,776 [Epoch: 018 Step: 00003017] Batch Translation Loss:   6.076677 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:05:09,299 [Epoch: 018 Step: 00003018] Batch Translation Loss:   6.274349 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:05:57,155 [Epoch: 018 Step: 00003019] Batch Translation Loss:   6.053853 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:07:28,601 [Epoch: 018 Step: 00003020] Batch Translation Loss:   6.529599 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 08:08:14,148 [Epoch: 018 Step: 00003021] Batch Translation Loss:   6.247023 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:09:14,029 [Epoch: 018 Step: 00003022] Batch Translation Loss:   6.091470 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:10:51,898 [Epoch: 018 Step: 00003023] Batch Translation Loss:   6.097394 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 08:11:34,835 [Epoch: 018 Step: 00003024] Batch Translation Loss:   6.269018 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:13:17,548 [Epoch: 018 Step: 00003025] Batch Translation Loss:   5.817343 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 08:14:15,200 [Epoch: 018 Step: 00003026] Batch Translation Loss:   6.354650 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:15:20,143 [Epoch: 018 Step: 00003027] Batch Translation Loss:   6.417778 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:16:11,301 [Epoch: 018 Step: 00003028] Batch Translation Loss:   5.967451 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:16:58,900 [Epoch: 018 Step: 00003029] Batch Translation Loss:   6.230157 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:17:56,765 [Epoch: 018 Step: 00003030] Batch Translation Loss:   5.314703 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:18:52,226 [Epoch: 018 Step: 00003031] Batch Translation Loss:   6.382169 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:20:24,262 [Epoch: 018 Step: 00003032] Batch Translation Loss:   5.679498 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 08:21:33,017 [Epoch: 018 Step: 00003033] Batch Translation Loss:   5.970245 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:22:26,226 [Epoch: 018 Step: 00003034] Batch Translation Loss:   6.415795 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:23:17,551 [Epoch: 018 Step: 00003035] Batch Translation Loss:   6.077621 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:24:14,277 [Epoch: 018 Step: 00003036] Batch Translation Loss:   6.253081 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:25:13,799 [Epoch: 018 Step: 00003037] Batch Translation Loss:   6.446479 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:26:09,822 [Epoch: 018 Step: 00003038] Batch Translation Loss:   5.575017 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:27:05,822 [Epoch: 018 Step: 00003039] Batch Translation Loss:   6.067173 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:28:28,479 [Epoch: 018 Step: 00003040] Batch Translation Loss:   5.356302 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 08:29:56,779 [Epoch: 018 Step: 00003041] Batch Translation Loss:   5.684322 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 08:30:52,779 [Epoch: 018 Step: 00003042] Batch Translation Loss:   6.573083 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:31:58,708 [Epoch: 018 Step: 00003043] Batch Translation Loss:   5.924601 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:33:02,016 [Epoch: 018 Step: 00003044] Batch Translation Loss:   6.057640 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:34:09,063 [Epoch: 018 Step: 00003045] Batch Translation Loss:   5.958992 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:35:08,541 [Epoch: 018 Step: 00003046] Batch Translation Loss:   6.392301 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:36:08,866 [Epoch: 018 Step: 00003047] Batch Translation Loss:   5.873344 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:37:08,270 [Epoch: 018 Step: 00003048] Batch Translation Loss:   5.884719 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:38:20,711 [Epoch: 018 Step: 00003049] Batch Translation Loss:   5.993499 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:39:17,991 [Epoch: 018 Step: 00003050] Batch Translation Loss:   6.106430 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:40:22,104 [Epoch: 018 Step: 00003051] Batch Translation Loss:   6.304549 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:41:27,323 [Epoch: 018 Step: 00003052] Batch Translation Loss:   5.801919 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:42:37,440 [Epoch: 018 Step: 00003053] Batch Translation Loss:   6.211489 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:43:31,864 [Epoch: 018 Step: 00003054] Batch Translation Loss:   6.163629 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:44:23,473 [Epoch: 018 Step: 00003055] Batch Translation Loss:   5.826386 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:45:25,299 [Epoch: 018 Step: 00003056] Batch Translation Loss:   5.872541 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:46:23,618 [Epoch: 018 Step: 00003057] Batch Translation Loss:   6.111258 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:47:26,841 [Epoch: 018 Step: 00003058] Batch Translation Loss:   6.210250 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:48:36,630 [Epoch: 018 Step: 00003059] Batch Translation Loss:   6.468662 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:50:04,192 [Epoch: 018 Step: 00003060] Batch Translation Loss:   6.087163 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 08:50:04,493 Epoch  18: Total Training Recognition Loss -1.00  Total Training Translation Loss 1050.41 
2022-01-04 08:50:04,494 EPOCH 19
2022-01-04 08:50:18,505 [Epoch: 019 Step: 00003061] Batch Translation Loss:   5.223225 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 08:50:32,608 [Epoch: 019 Step: 00003062] Batch Translation Loss:   5.999774 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 08:50:45,228 [Epoch: 019 Step: 00003063] Batch Translation Loss:   6.406466 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-04 08:51:06,440 [Epoch: 019 Step: 00003064] Batch Translation Loss:   5.906745 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 08:51:21,716 [Epoch: 019 Step: 00003065] Batch Translation Loss:   5.989826 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-04 08:51:35,098 [Epoch: 019 Step: 00003066] Batch Translation Loss:   6.804334 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-04 08:52:00,917 [Epoch: 019 Step: 00003067] Batch Translation Loss:   6.844992 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 08:52:16,053 [Epoch: 019 Step: 00003068] Batch Translation Loss:   6.443188 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-04 08:52:46,350 [Epoch: 019 Step: 00003069] Batch Translation Loss:   5.990911 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:53:08,477 [Epoch: 019 Step: 00003070] Batch Translation Loss:   6.242771 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 08:53:37,972 [Epoch: 019 Step: 00003071] Batch Translation Loss:   6.053971 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 08:53:54,590 [Epoch: 019 Step: 00003072] Batch Translation Loss:   6.160404 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 08:54:14,555 [Epoch: 019 Step: 00003073] Batch Translation Loss:   6.014638 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-04 08:54:38,818 [Epoch: 019 Step: 00003074] Batch Translation Loss:   6.576877 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 08:55:01,443 [Epoch: 019 Step: 00003075] Batch Translation Loss:   6.192470 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 08:55:27,699 [Epoch: 019 Step: 00003076] Batch Translation Loss:   6.735553 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:55:50,893 [Epoch: 019 Step: 00003077] Batch Translation Loss:   5.427010 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:56:18,753 [Epoch: 019 Step: 00003078] Batch Translation Loss:   6.604320 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 08:56:42,552 [Epoch: 019 Step: 00003079] Batch Translation Loss:   6.286422 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 08:57:12,685 [Epoch: 019 Step: 00003080] Batch Translation Loss:   6.476386 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 08:57:36,741 [Epoch: 019 Step: 00003081] Batch Translation Loss:   6.200963 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 08:58:11,531 [Epoch: 019 Step: 00003082] Batch Translation Loss:   6.237085 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:58:26,796 [Epoch: 019 Step: 00003083] Batch Translation Loss:   5.498274 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 08:58:53,317 [Epoch: 019 Step: 00003084] Batch Translation Loss:   6.250518 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 08:59:15,238 [Epoch: 019 Step: 00003085] Batch Translation Loss:   5.821500 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 08:59:36,185 [Epoch: 019 Step: 00003086] Batch Translation Loss:   5.850513 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 08:59:49,920 [Epoch: 019 Step: 00003087] Batch Translation Loss:   6.027077 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-04 09:00:11,236 [Epoch: 019 Step: 00003088] Batch Translation Loss:   5.778842 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 09:00:42,623 [Epoch: 019 Step: 00003089] Batch Translation Loss:   6.268090 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:01:16,223 [Epoch: 019 Step: 00003090] Batch Translation Loss:   6.323071 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:01:50,116 [Epoch: 019 Step: 00003091] Batch Translation Loss:   6.252882 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:02:26,557 [Epoch: 019 Step: 00003092] Batch Translation Loss:   6.659435 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:02:55,772 [Epoch: 019 Step: 00003093] Batch Translation Loss:   6.226882 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:03:30,765 [Epoch: 019 Step: 00003094] Batch Translation Loss:   6.467529 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:03:57,922 [Epoch: 019 Step: 00003095] Batch Translation Loss:   6.432833 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:04:31,311 [Epoch: 019 Step: 00003096] Batch Translation Loss:   5.524118 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:04:56,618 [Epoch: 019 Step: 00003097] Batch Translation Loss:   6.201561 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 09:05:22,549 [Epoch: 019 Step: 00003098] Batch Translation Loss:   5.878121 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 09:05:47,593 [Epoch: 019 Step: 00003099] Batch Translation Loss:   6.534862 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 09:06:06,167 [Epoch: 019 Step: 00003100] Batch Translation Loss:   6.172065 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 09:18:54,880 Validation result at epoch  19, step     3100: duration: 768.7128s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11144.92383	PPL: 9558.95410
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.97	(DEL: 21.22,	INS: 0.00,	SUB: 76.81)
	Sequence Accuracy 1.98
2022-01-04 09:19:12,186 Logging Recognition and Translation Outputs
2022-01-04 09:19:12,404 ========================================================================================================================
2022-01-04 09:19:12,404 Logging Sequence: youtube_1-don_grushkin_2773
2022-01-04 09:19:12,404 	Text Reference  :	asl
2022-01-04 09:19:12,404 	Text Hypothesis :	ok 
2022-01-04 09:19:12,405 	Text Alignment  :	S  
2022-01-04 09:19:12,405 ========================================================================================================================
2022-01-04 09:19:12,405 Logging Sequence: youtube_6-roberta_cordano_6473
2022-01-04 09:19:12,405 	Text Reference  :	microfsoft
2022-01-04 09:19:12,405 	Text Hypothesis :	ok        
2022-01-04 09:19:12,405 	Text Alignment  :	S         
2022-01-04 09:19:12,405 ========================================================================================================================
2022-01-04 09:19:12,405 Logging Sequence: youtube_4-sean_berdy_5757
2022-01-04 09:19:12,405 	Text Reference  :	wow
2022-01-04 09:19:12,405 	Text Hypothesis :	ok 
2022-01-04 09:19:12,406 	Text Alignment  :	S  
2022-01-04 09:19:12,406 ========================================================================================================================
2022-01-04 09:19:12,406 Logging Sequence: deafvideo_3-titans_4697
2022-01-04 09:19:12,406 	Text Reference  :	ussr
2022-01-04 09:19:12,406 	Text Hypothesis :	asl 
2022-01-04 09:19:12,406 	Text Alignment  :	S   
2022-01-04 09:19:12,406 ========================================================================================================================
2022-01-04 09:19:12,406 Logging Sequence: youtube_5-sean_berdy_6097
2022-01-04 09:19:12,406 	Text Reference  :	flash manual on
2022-01-04 09:19:12,406 	Text Hypothesis :	***** ****** ok
2022-01-04 09:19:12,407 	Text Alignment  :	D     D      S 
2022-01-04 09:19:12,407 ========================================================================================================================
2022-01-04 09:19:41,815 [Epoch: 019 Step: 00003101] Batch Translation Loss:   6.199064 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:20:33,921 [Epoch: 019 Step: 00003102] Batch Translation Loss:   6.311241 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:21:04,510 [Epoch: 019 Step: 00003103] Batch Translation Loss:   5.725692 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:21:36,739 [Epoch: 019 Step: 00003104] Batch Translation Loss:   5.955518 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:22:04,679 [Epoch: 019 Step: 00003105] Batch Translation Loss:   5.664145 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:22:31,582 [Epoch: 019 Step: 00003106] Batch Translation Loss:   5.792069 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:23:31,514 [Epoch: 019 Step: 00003107] Batch Translation Loss:   6.076540 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:24:26,012 [Epoch: 019 Step: 00003108] Batch Translation Loss:   6.094461 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:24:59,672 [Epoch: 019 Step: 00003109] Batch Translation Loss:   6.102985 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:25:23,464 [Epoch: 019 Step: 00003110] Batch Translation Loss:   5.745034 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:25:48,263 [Epoch: 019 Step: 00003111] Batch Translation Loss:   6.086998 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:26:49,132 [Epoch: 019 Step: 00003112] Batch Translation Loss:   5.960374 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:27:31,847 [Epoch: 019 Step: 00003113] Batch Translation Loss:   6.155775 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:28:04,455 [Epoch: 019 Step: 00003114] Batch Translation Loss:   6.034087 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:28:25,764 [Epoch: 019 Step: 00003115] Batch Translation Loss:   6.032641 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 09:28:44,012 [Epoch: 019 Step: 00003116] Batch Translation Loss:   6.579383 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 09:29:04,886 [Epoch: 019 Step: 00003117] Batch Translation Loss:   6.108138 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 09:29:28,249 [Epoch: 019 Step: 00003118] Batch Translation Loss:   5.693027 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 09:30:14,774 [Epoch: 019 Step: 00003119] Batch Translation Loss:   6.312316 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:30:38,190 [Epoch: 019 Step: 00003120] Batch Translation Loss:   6.640724 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 09:31:06,135 [Epoch: 019 Step: 00003121] Batch Translation Loss:   6.333241 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 09:31:33,002 [Epoch: 019 Step: 00003122] Batch Translation Loss:   5.291161 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:31:54,117 [Epoch: 019 Step: 00003123] Batch Translation Loss:   5.769512 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 09:32:18,049 [Epoch: 019 Step: 00003124] Batch Translation Loss:   6.226688 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:32:48,533 [Epoch: 019 Step: 00003125] Batch Translation Loss:   5.737330 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:33:29,869 [Epoch: 019 Step: 00003126] Batch Translation Loss:   5.716191 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:34:26,770 [Epoch: 019 Step: 00003127] Batch Translation Loss:   5.915517 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:34:58,739 [Epoch: 019 Step: 00003128] Batch Translation Loss:   5.651620 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:35:20,393 [Epoch: 019 Step: 00003129] Batch Translation Loss:   6.652127 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 09:35:44,711 [Epoch: 019 Step: 00003130] Batch Translation Loss:   6.562458 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 09:36:16,231 [Epoch: 019 Step: 00003131] Batch Translation Loss:   6.218199 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:36:45,400 [Epoch: 019 Step: 00003132] Batch Translation Loss:   5.983340 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:37:09,272 [Epoch: 019 Step: 00003133] Batch Translation Loss:   5.982325 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:38:08,353 [Epoch: 019 Step: 00003134] Batch Translation Loss:   5.853083 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:38:54,669 [Epoch: 019 Step: 00003135] Batch Translation Loss:   6.374608 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:39:33,910 [Epoch: 019 Step: 00003136] Batch Translation Loss:   6.014585 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:40:12,480 [Epoch: 019 Step: 00003137] Batch Translation Loss:   6.285751 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:40:56,719 [Epoch: 019 Step: 00003138] Batch Translation Loss:   6.665809 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:41:33,959 [Epoch: 019 Step: 00003139] Batch Translation Loss:   6.400161 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:42:03,878 [Epoch: 019 Step: 00003140] Batch Translation Loss:   5.894242 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:42:38,760 [Epoch: 019 Step: 00003141] Batch Translation Loss:   5.946471 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:43:20,088 [Epoch: 019 Step: 00003142] Batch Translation Loss:   6.403664 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:44:01,018 [Epoch: 019 Step: 00003143] Batch Translation Loss:   6.662244 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:44:33,197 [Epoch: 019 Step: 00003144] Batch Translation Loss:   6.094856 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:45:20,837 [Epoch: 019 Step: 00003145] Batch Translation Loss:   6.105923 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:46:23,632 [Epoch: 019 Step: 00003146] Batch Translation Loss:   6.500449 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:46:50,281 [Epoch: 019 Step: 00003147] Batch Translation Loss:   5.994294 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:47:28,930 [Epoch: 019 Step: 00003148] Batch Translation Loss:   6.339770 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:48:18,441 [Epoch: 019 Step: 00003149] Batch Translation Loss:   6.044022 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:49:10,627 [Epoch: 019 Step: 00003150] Batch Translation Loss:   5.708342 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:50:02,048 [Epoch: 019 Step: 00003151] Batch Translation Loss:   6.050014 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:50:46,733 [Epoch: 019 Step: 00003152] Batch Translation Loss:   6.950535 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:51:37,319 [Epoch: 019 Step: 00003153] Batch Translation Loss:   6.126614 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:52:22,889 [Epoch: 019 Step: 00003154] Batch Translation Loss:   5.556977 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:53:09,423 [Epoch: 019 Step: 00003155] Batch Translation Loss:   5.871702 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:53:45,468 [Epoch: 019 Step: 00003156] Batch Translation Loss:   6.490366 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:54:28,497 [Epoch: 019 Step: 00003157] Batch Translation Loss:   6.131475 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:55:14,820 [Epoch: 019 Step: 00003158] Batch Translation Loss:   6.796216 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:56:13,451 [Epoch: 019 Step: 00003159] Batch Translation Loss:   6.092546 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:56:52,897 [Epoch: 019 Step: 00003160] Batch Translation Loss:   6.200027 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:57:34,467 [Epoch: 019 Step: 00003161] Batch Translation Loss:   6.130976 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:58:24,561 [Epoch: 019 Step: 00003162] Batch Translation Loss:   6.296443 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 09:59:23,008 [Epoch: 019 Step: 00003163] Batch Translation Loss:   6.365616 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:00:17,728 [Epoch: 019 Step: 00003164] Batch Translation Loss:   6.284526 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:01:07,931 [Epoch: 019 Step: 00003165] Batch Translation Loss:   5.436829 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:01:52,353 [Epoch: 019 Step: 00003166] Batch Translation Loss:   6.153805 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:03:16,683 [Epoch: 019 Step: 00003167] Batch Translation Loss:   6.226556 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 10:04:53,771 [Epoch: 019 Step: 00003168] Batch Translation Loss:   5.765607 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 10:05:53,075 [Epoch: 019 Step: 00003169] Batch Translation Loss:   6.804507 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:06:39,572 [Epoch: 019 Step: 00003170] Batch Translation Loss:   5.265051 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:07:43,778 [Epoch: 019 Step: 00003171] Batch Translation Loss:   5.954778 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:08:34,175 [Epoch: 019 Step: 00003172] Batch Translation Loss:   6.119298 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:09:33,493 [Epoch: 019 Step: 00003173] Batch Translation Loss:   5.415776 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:10:46,070 [Epoch: 019 Step: 00003174] Batch Translation Loss:   5.794883 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:11:40,764 [Epoch: 019 Step: 00003175] Batch Translation Loss:   6.230380 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:12:40,482 [Epoch: 019 Step: 00003176] Batch Translation Loss:   5.227391 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:13:37,017 [Epoch: 019 Step: 00003177] Batch Translation Loss:   5.779521 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:14:44,057 [Epoch: 019 Step: 00003178] Batch Translation Loss:   5.378430 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:15:28,864 [Epoch: 019 Step: 00003179] Batch Translation Loss:   6.152255 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:16:21,253 [Epoch: 019 Step: 00003180] Batch Translation Loss:   5.698600 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:17:56,644 [Epoch: 019 Step: 00003181] Batch Translation Loss:   5.837309 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 10:19:33,850 [Epoch: 019 Step: 00003182] Batch Translation Loss:   5.963219 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 10:20:26,934 [Epoch: 019 Step: 00003183] Batch Translation Loss:   6.300574 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:21:13,747 [Epoch: 019 Step: 00003184] Batch Translation Loss:   6.239425 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:22:14,496 [Epoch: 019 Step: 00003185] Batch Translation Loss:   5.856379 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:23:16,518 [Epoch: 019 Step: 00003186] Batch Translation Loss:   6.315509 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:24:55,365 [Epoch: 019 Step: 00003187] Batch Translation Loss:   5.306763 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 10:25:56,501 [Epoch: 019 Step: 00003188] Batch Translation Loss:   6.703252 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:26:49,244 [Epoch: 019 Step: 00003189] Batch Translation Loss:   6.255075 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:28:26,835 [Epoch: 019 Step: 00003190] Batch Translation Loss:   5.946482 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 10:29:11,260 [Epoch: 019 Step: 00003191] Batch Translation Loss:   6.206879 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:30:41,020 [Epoch: 019 Step: 00003192] Batch Translation Loss:   5.769759 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 10:31:46,631 [Epoch: 019 Step: 00003193] Batch Translation Loss:   5.934226 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:33:04,010 [Epoch: 019 Step: 00003194] Batch Translation Loss:   6.669924 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:33:46,587 [Epoch: 019 Step: 00003195] Batch Translation Loss:   6.021894 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:34:37,330 [Epoch: 019 Step: 00003196] Batch Translation Loss:   6.259355 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:35:26,682 [Epoch: 019 Step: 00003197] Batch Translation Loss:   6.329705 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:36:06,557 [Epoch: 019 Step: 00003198] Batch Translation Loss:   5.542335 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:36:54,035 [Epoch: 019 Step: 00003199] Batch Translation Loss:   6.316343 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:37:46,680 [Epoch: 019 Step: 00003200] Batch Translation Loss:   6.390661 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:49:41,720 Validation result at epoch  19, step     3200: duration: 715.0377s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 12436.52344	PPL: 15378.34375
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 2.40	(DEL: 25.58,	INS: 0.00,	SUB: 72.02)
	Sequence Accuracy 1.88
2022-01-04 10:49:50,924 Logging Recognition and Translation Outputs
2022-01-04 10:49:50,925 ========================================================================================================================
2022-01-04 10:49:50,925 Logging Sequence: youtube_1-don_grushkin_2335
2022-01-04 10:49:50,926 	Text Reference  :	flint
2022-01-04 10:49:50,926 	Text Hypothesis :	or   
2022-01-04 10:49:50,926 	Text Alignment  :	S    
2022-01-04 10:49:50,926 ========================================================================================================================
2022-01-04 10:49:50,926 Logging Sequence: deafvideo_2-deafpoweronethumbtwo_1792
2022-01-04 10:49:50,926 	Text Reference  :	asl or
2022-01-04 10:49:50,926 	Text Hypothesis :	*** or
2022-01-04 10:49:50,927 	Text Alignment  :	D     
2022-01-04 10:49:50,927 ========================================================================================================================
2022-01-04 10:49:50,927 Logging Sequence: deafvideo_5-silentoneye_7319
2022-01-04 10:49:50,927 	Text Reference  :	dfhd dfhd
2022-01-04 10:49:50,927 	Text Hypothesis :	**** or  
2022-01-04 10:49:50,927 	Text Alignment  :	D    S   
2022-01-04 10:49:50,928 ========================================================================================================================
2022-01-04 10:49:50,928 Logging Sequence: youtube_3-ben_bahan_4531
2022-01-04 10:49:50,928 	Text Reference  :	fb
2022-01-04 10:49:50,928 	Text Hypothesis :	or
2022-01-04 10:49:50,929 	Text Alignment  :	S 
2022-01-04 10:49:50,929 ========================================================================================================================
2022-01-04 10:49:50,929 Logging Sequence: deafvideo_2-confederateboy_1667
2022-01-04 10:49:50,929 	Text Reference  :	dvtv
2022-01-04 10:49:50,929 	Text Hypothesis :	or  
2022-01-04 10:49:50,929 	Text Alignment  :	S   
2022-01-04 10:49:50,930 ========================================================================================================================
2022-01-04 10:50:48,632 [Epoch: 019 Step: 00003201] Batch Translation Loss:   6.369852 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:51:44,830 [Epoch: 019 Step: 00003202] Batch Translation Loss:   5.221005 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:52:36,940 [Epoch: 019 Step: 00003203] Batch Translation Loss:   6.191472 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:53:38,647 [Epoch: 019 Step: 00003204] Batch Translation Loss:   6.558351 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:54:44,503 [Epoch: 019 Step: 00003205] Batch Translation Loss:   5.496012 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:55:40,383 [Epoch: 019 Step: 00003206] Batch Translation Loss:   6.190331 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:56:22,630 [Epoch: 019 Step: 00003207] Batch Translation Loss:   6.294507 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:57:09,366 [Epoch: 019 Step: 00003208] Batch Translation Loss:   6.246725 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:57:56,913 [Epoch: 019 Step: 00003209] Batch Translation Loss:   6.221598 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:58:45,340 [Epoch: 019 Step: 00003210] Batch Translation Loss:   6.225858 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 10:59:25,544 [Epoch: 019 Step: 00003211] Batch Translation Loss:   5.998189 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:00:08,695 [Epoch: 019 Step: 00003212] Batch Translation Loss:   5.535304 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:00:51,364 [Epoch: 019 Step: 00003213] Batch Translation Loss:   6.067748 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:01:38,000 [Epoch: 019 Step: 00003214] Batch Translation Loss:   6.280825 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:02:25,020 [Epoch: 019 Step: 00003215] Batch Translation Loss:   5.821500 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:03:10,534 [Epoch: 019 Step: 00003216] Batch Translation Loss:   6.243451 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:04:06,935 [Epoch: 019 Step: 00003217] Batch Translation Loss:   5.788983 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:05:11,805 [Epoch: 019 Step: 00003218] Batch Translation Loss:   5.814754 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:06:01,055 [Epoch: 019 Step: 00003219] Batch Translation Loss:   6.461149 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:06:55,960 [Epoch: 019 Step: 00003220] Batch Translation Loss:   6.139822 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:07:47,400 [Epoch: 019 Step: 00003221] Batch Translation Loss:   6.146581 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:08:43,308 [Epoch: 019 Step: 00003222] Batch Translation Loss:   5.849697 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:09:39,635 [Epoch: 019 Step: 00003223] Batch Translation Loss:   5.818223 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:11:57,128 [Epoch: 019 Step: 00003224] Batch Translation Loss:   5.755528 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 11:13:06,427 [Epoch: 019 Step: 00003225] Batch Translation Loss:   6.009374 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:14:08,698 [Epoch: 019 Step: 00003226] Batch Translation Loss:   6.412362 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:15:51,128 [Epoch: 019 Step: 00003227] Batch Translation Loss:   6.294942 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 11:17:30,344 [Epoch: 019 Step: 00003228] Batch Translation Loss:   6.899715 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 11:20:29,047 [Epoch: 019 Step: 00003229] Batch Translation Loss:   6.508712 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 11:22:20,760 [Epoch: 019 Step: 00003230] Batch Translation Loss:   6.274608 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 11:22:20,906 Epoch  19: Total Training Recognition Loss -1.00  Total Training Translation Loss 1037.63 
2022-01-04 11:22:20,906 EPOCH 20
2022-01-04 11:22:34,853 [Epoch: 020 Step: 00003231] Batch Translation Loss:   6.465173 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 11:22:56,833 [Epoch: 020 Step: 00003232] Batch Translation Loss:   6.178206 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 11:23:10,950 [Epoch: 020 Step: 00003233] Batch Translation Loss:   6.253766 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-04 11:23:32,984 [Epoch: 020 Step: 00003234] Batch Translation Loss:   6.494713 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 11:23:56,263 [Epoch: 020 Step: 00003235] Batch Translation Loss:   6.404043 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 11:24:15,645 [Epoch: 020 Step: 00003236] Batch Translation Loss:   6.113423 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 11:24:37,125 [Epoch: 020 Step: 00003237] Batch Translation Loss:   6.530316 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 11:25:02,053 [Epoch: 020 Step: 00003238] Batch Translation Loss:   6.282226 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 11:25:27,587 [Epoch: 020 Step: 00003239] Batch Translation Loss:   6.539281 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 11:25:46,134 [Epoch: 020 Step: 00003240] Batch Translation Loss:   6.416727 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 11:26:05,237 [Epoch: 020 Step: 00003241] Batch Translation Loss:   5.752848 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-04 11:26:19,187 [Epoch: 020 Step: 00003242] Batch Translation Loss:   5.744553 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-04 11:26:43,503 [Epoch: 020 Step: 00003243] Batch Translation Loss:   5.857769 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 11:27:00,688 [Epoch: 020 Step: 00003244] Batch Translation Loss:   6.589478 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 11:27:30,300 [Epoch: 020 Step: 00003245] Batch Translation Loss:   5.977098 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 11:27:48,556 [Epoch: 020 Step: 00003246] Batch Translation Loss:   6.137621 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 11:28:09,373 [Epoch: 020 Step: 00003247] Batch Translation Loss:   5.897643 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 11:28:25,016 [Epoch: 020 Step: 00003248] Batch Translation Loss:   5.718723 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 11:28:50,432 [Epoch: 020 Step: 00003249] Batch Translation Loss:   5.603047 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:29:08,054 [Epoch: 020 Step: 00003250] Batch Translation Loss:   6.385575 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 11:29:43,831 [Epoch: 020 Step: 00003251] Batch Translation Loss:   6.834305 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:30:16,058 [Epoch: 020 Step: 00003252] Batch Translation Loss:   5.141527 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:30:42,273 [Epoch: 020 Step: 00003253] Batch Translation Loss:   5.572010 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 11:31:10,306 [Epoch: 020 Step: 00003254] Batch Translation Loss:   6.280125 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:31:37,823 [Epoch: 020 Step: 00003255] Batch Translation Loss:   6.365364 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 11:32:07,200 [Epoch: 020 Step: 00003256] Batch Translation Loss:   6.046039 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:32:26,839 [Epoch: 020 Step: 00003257] Batch Translation Loss:   5.885025 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 11:32:54,489 [Epoch: 020 Step: 00003258] Batch Translation Loss:   6.440385 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 11:33:14,786 [Epoch: 020 Step: 00003259] Batch Translation Loss:   5.488413 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 11:33:43,830 [Epoch: 020 Step: 00003260] Batch Translation Loss:   5.849401 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:34:08,156 [Epoch: 020 Step: 00003261] Batch Translation Loss:   6.243181 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 11:34:56,045 [Epoch: 020 Step: 00003262] Batch Translation Loss:   5.855004 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:35:21,259 [Epoch: 020 Step: 00003263] Batch Translation Loss:   6.071638 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:35:49,883 [Epoch: 020 Step: 00003264] Batch Translation Loss:   5.765915 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:36:23,749 [Epoch: 020 Step: 00003265] Batch Translation Loss:   6.464387 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:36:54,567 [Epoch: 020 Step: 00003266] Batch Translation Loss:   5.886757 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:37:51,118 [Epoch: 020 Step: 00003267] Batch Translation Loss:   5.914340 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:38:24,971 [Epoch: 020 Step: 00003268] Batch Translation Loss:   6.216086 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 11:38:58,512 [Epoch: 020 Step: 00003269] Batch Translation Loss:   6.260243 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:39:27,849 [Epoch: 020 Step: 00003270] Batch Translation Loss:   5.864888 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:40:16,981 [Epoch: 020 Step: 00003271] Batch Translation Loss:   5.873931 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:40:42,272 [Epoch: 020 Step: 00003272] Batch Translation Loss:   5.606374 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:41:08,712 [Epoch: 020 Step: 00003273] Batch Translation Loss:   5.886140 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 11:41:38,432 [Epoch: 020 Step: 00003274] Batch Translation Loss:   6.419328 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:42:33,916 [Epoch: 020 Step: 00003275] Batch Translation Loss:   5.798697 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:43:04,790 [Epoch: 020 Step: 00003276] Batch Translation Loss:   5.731837 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:44:28,133 [Epoch: 020 Step: 00003277] Batch Translation Loss:   6.188851 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:44:56,974 [Epoch: 020 Step: 00003278] Batch Translation Loss:   6.149997 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:45:27,701 [Epoch: 020 Step: 00003279] Batch Translation Loss:   5.924202 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:46:01,565 [Epoch: 020 Step: 00003280] Batch Translation Loss:   6.084620 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:46:34,807 [Epoch: 020 Step: 00003281] Batch Translation Loss:   6.221423 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:47:03,262 [Epoch: 020 Step: 00003282] Batch Translation Loss:   6.102059 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:47:38,756 [Epoch: 020 Step: 00003283] Batch Translation Loss:   6.175953 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:48:05,939 [Epoch: 020 Step: 00003284] Batch Translation Loss:   5.525676 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:48:39,466 [Epoch: 020 Step: 00003285] Batch Translation Loss:   6.617889 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:49:30,603 [Epoch: 020 Step: 00003286] Batch Translation Loss:   5.908689 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:50:08,764 [Epoch: 020 Step: 00003287] Batch Translation Loss:   6.331184 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:50:43,039 [Epoch: 020 Step: 00003288] Batch Translation Loss:   6.174185 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:51:17,578 [Epoch: 020 Step: 00003289] Batch Translation Loss:   6.414089 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:51:53,157 [Epoch: 020 Step: 00003290] Batch Translation Loss:   5.902153 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:52:34,752 [Epoch: 020 Step: 00003291] Batch Translation Loss:   5.878784 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:53:39,041 [Epoch: 020 Step: 00003292] Batch Translation Loss:   5.967803 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:54:02,268 [Epoch: 020 Step: 00003293] Batch Translation Loss:   6.260045 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 11:54:38,767 [Epoch: 020 Step: 00003294] Batch Translation Loss:   6.072966 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:55:17,840 [Epoch: 020 Step: 00003295] Batch Translation Loss:   6.586169 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:56:21,256 [Epoch: 020 Step: 00003296] Batch Translation Loss:   6.103313 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:57:03,217 [Epoch: 020 Step: 00003297] Batch Translation Loss:   6.756664 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:57:45,304 [Epoch: 020 Step: 00003298] Batch Translation Loss:   6.115567 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:58:26,870 [Epoch: 020 Step: 00003299] Batch Translation Loss:   5.948604 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 11:58:58,121 [Epoch: 020 Step: 00003300] Batch Translation Loss:   6.311722 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:11:59,022 Validation result at epoch  20, step     3300: duration: 780.8992s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11966.36328	PPL: 13024.07715
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.19	(DEL: 24.07,	INS: 0.00,	SUB: 74.74)
	Sequence Accuracy 1.46
2022-01-04 12:12:05,603 Logging Recognition and Translation Outputs
2022-01-04 12:12:05,604 ========================================================================================================================
2022-01-04 12:12:05,605 Logging Sequence: youtube_1-don_grushkin_2758
2022-01-04 12:12:05,605 	Text Reference  :	disq 
2022-01-04 12:12:05,605 	Text Hypothesis :	adult
2022-01-04 12:12:05,606 	Text Alignment  :	S    
2022-01-04 12:12:05,606 ========================================================================================================================
2022-01-04 12:12:05,606 Logging Sequence: youtube_1-don_grushkin_2775
2022-01-04 12:12:05,607 	Text Reference  :	dr kristin mulrooney
2022-01-04 12:12:05,607 	Text Hypothesis :	** ******* so       
2022-01-04 12:12:05,607 	Text Alignment  :	D  D       S        
2022-01-04 12:12:05,607 ========================================================================================================================
2022-01-04 12:12:05,607 Logging Sequence: deafvideo_3-yellowbirdie84_4665
2022-01-04 12:12:05,608 	Text Reference  :	aclu
2022-01-04 12:12:05,608 	Text Hypothesis :	so  
2022-01-04 12:12:05,608 	Text Alignment  :	S   
2022-01-04 12:12:05,608 ========================================================================================================================
2022-01-04 12:12:05,608 Logging Sequence: youtube_5-jeffrey_spinale_6044
2022-01-04 12:12:05,609 	Text Reference  :	debg
2022-01-04 12:12:05,609 	Text Hypothesis :	of  
2022-01-04 12:12:05,609 	Text Alignment  :	S   
2022-01-04 12:12:05,610 ========================================================================================================================
2022-01-04 12:12:05,610 Logging Sequence: youtube_1-catherine_mackinnon_2809
2022-01-04 12:12:05,610 	Text Reference  :	saw
2022-01-04 12:12:05,610 	Text Hypothesis :	so 
2022-01-04 12:12:05,611 	Text Alignment  :	S  
2022-01-04 12:12:05,611 ========================================================================================================================
2022-01-04 12:12:40,463 [Epoch: 020 Step: 00003301] Batch Translation Loss:   6.738060 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:13:07,340 [Epoch: 020 Step: 00003302] Batch Translation Loss:   5.732743 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:14:16,953 [Epoch: 020 Step: 00003303] Batch Translation Loss:   5.447926 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:14:54,000 [Epoch: 020 Step: 00003304] Batch Translation Loss:   6.365783 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:15:27,393 [Epoch: 020 Step: 00003305] Batch Translation Loss:   6.468243 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:16:21,043 [Epoch: 020 Step: 00003306] Batch Translation Loss:   5.958758 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:17:06,947 [Epoch: 020 Step: 00003307] Batch Translation Loss:   5.374914 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:17:37,605 [Epoch: 020 Step: 00003308] Batch Translation Loss:   6.402442 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:18:20,266 [Epoch: 020 Step: 00003309] Batch Translation Loss:   6.473360 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:19:06,702 [Epoch: 020 Step: 00003310] Batch Translation Loss:   6.503151 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:19:40,547 [Epoch: 020 Step: 00003311] Batch Translation Loss:   6.140717 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:20:18,670 [Epoch: 020 Step: 00003312] Batch Translation Loss:   5.712944 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:21:03,054 [Epoch: 020 Step: 00003313] Batch Translation Loss:   5.638267 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:21:34,669 [Epoch: 020 Step: 00003314] Batch Translation Loss:   5.767266 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:22:11,955 [Epoch: 020 Step: 00003315] Batch Translation Loss:   6.479351 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:22:38,476 [Epoch: 020 Step: 00003316] Batch Translation Loss:   5.757307 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:23:10,980 [Epoch: 020 Step: 00003317] Batch Translation Loss:   6.305290 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:24:03,614 [Epoch: 020 Step: 00003318] Batch Translation Loss:   5.919728 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:24:38,340 [Epoch: 020 Step: 00003319] Batch Translation Loss:   5.974830 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:25:22,575 [Epoch: 020 Step: 00003320] Batch Translation Loss:   5.969189 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:26:02,800 [Epoch: 020 Step: 00003321] Batch Translation Loss:   6.263577 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:27:00,462 [Epoch: 020 Step: 00003322] Batch Translation Loss:   5.929099 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:27:47,702 [Epoch: 020 Step: 00003323] Batch Translation Loss:   5.586020 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:28:26,362 [Epoch: 020 Step: 00003324] Batch Translation Loss:   6.027235 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:29:05,928 [Epoch: 020 Step: 00003325] Batch Translation Loss:   6.208238 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:29:42,358 [Epoch: 020 Step: 00003326] Batch Translation Loss:   6.224036 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:30:55,142 [Epoch: 020 Step: 00003327] Batch Translation Loss:   6.194786 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:31:34,299 [Epoch: 020 Step: 00003328] Batch Translation Loss:   5.568120 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:32:26,848 [Epoch: 020 Step: 00003329] Batch Translation Loss:   6.103220 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:33:00,272 [Epoch: 020 Step: 00003330] Batch Translation Loss:   6.081748 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:33:29,894 [Epoch: 020 Step: 00003331] Batch Translation Loss:   6.013447 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:33:55,544 [Epoch: 020 Step: 00003332] Batch Translation Loss:   6.194781 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:34:32,638 [Epoch: 020 Step: 00003333] Batch Translation Loss:   5.819624 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:35:04,547 [Epoch: 020 Step: 00003334] Batch Translation Loss:   5.971621 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:35:38,443 [Epoch: 020 Step: 00003335] Batch Translation Loss:   6.261587 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:36:46,704 [Epoch: 020 Step: 00003336] Batch Translation Loss:   6.410992 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:37:30,003 [Epoch: 020 Step: 00003337] Batch Translation Loss:   6.119322 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:38:08,176 [Epoch: 020 Step: 00003338] Batch Translation Loss:   6.579808 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:38:50,195 [Epoch: 020 Step: 00003339] Batch Translation Loss:   5.435136 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:39:26,880 [Epoch: 020 Step: 00003340] Batch Translation Loss:   5.763733 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:40:45,417 [Epoch: 020 Step: 00003341] Batch Translation Loss:   6.080304 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:42:21,848 [Epoch: 020 Step: 00003342] Batch Translation Loss:   6.493909 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 12:43:04,507 [Epoch: 020 Step: 00003343] Batch Translation Loss:   6.434644 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:44:42,533 [Epoch: 020 Step: 00003344] Batch Translation Loss:   6.613145 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 12:45:34,751 [Epoch: 020 Step: 00003345] Batch Translation Loss:   6.027614 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:46:33,904 [Epoch: 020 Step: 00003346] Batch Translation Loss:   5.854333 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:47:32,679 [Epoch: 020 Step: 00003347] Batch Translation Loss:   6.263671 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:48:22,271 [Epoch: 020 Step: 00003348] Batch Translation Loss:   5.584116 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:49:17,538 [Epoch: 020 Step: 00003349] Batch Translation Loss:   6.212955 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:50:16,244 [Epoch: 020 Step: 00003350] Batch Translation Loss:   5.756145 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:51:15,783 [Epoch: 020 Step: 00003351] Batch Translation Loss:   5.866892 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:52:15,332 [Epoch: 020 Step: 00003352] Batch Translation Loss:   5.733146 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:53:13,270 [Epoch: 020 Step: 00003353] Batch Translation Loss:   5.781372 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:54:22,478 [Epoch: 020 Step: 00003354] Batch Translation Loss:   6.793893 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:55:16,154 [Epoch: 020 Step: 00003355] Batch Translation Loss:   6.287638 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:56:25,881 [Epoch: 020 Step: 00003356] Batch Translation Loss:   6.109146 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:57:25,222 [Epoch: 020 Step: 00003357] Batch Translation Loss:   5.781464 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 12:58:23,847 [Epoch: 020 Step: 00003358] Batch Translation Loss:   6.149055 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:00:09,315 [Epoch: 020 Step: 00003359] Batch Translation Loss:   5.988793 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 13:01:02,436 [Epoch: 020 Step: 00003360] Batch Translation Loss:   6.052259 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:02:01,914 [Epoch: 020 Step: 00003361] Batch Translation Loss:   6.117609 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:02:58,543 [Epoch: 020 Step: 00003362] Batch Translation Loss:   5.877148 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:03:58,932 [Epoch: 020 Step: 00003363] Batch Translation Loss:   6.290887 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:05:16,320 [Epoch: 020 Step: 00003364] Batch Translation Loss:   6.859836 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:06:15,196 [Epoch: 020 Step: 00003365] Batch Translation Loss:   6.142253 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:07:16,211 [Epoch: 020 Step: 00003366] Batch Translation Loss:   5.770234 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:08:18,763 [Epoch: 020 Step: 00003367] Batch Translation Loss:   6.538884 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:09:24,315 [Epoch: 020 Step: 00003368] Batch Translation Loss:   6.544972 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:10:09,767 [Epoch: 020 Step: 00003369] Batch Translation Loss:   5.973983 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:11:13,402 [Epoch: 020 Step: 00003370] Batch Translation Loss:   5.704566 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:12:24,706 [Epoch: 020 Step: 00003371] Batch Translation Loss:   6.047891 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:13:15,562 [Epoch: 020 Step: 00003372] Batch Translation Loss:   5.651289 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:14:05,916 [Epoch: 020 Step: 00003373] Batch Translation Loss:   5.736042 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:14:55,626 [Epoch: 020 Step: 00003374] Batch Translation Loss:   6.213174 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:15:49,692 [Epoch: 020 Step: 00003375] Batch Translation Loss:   5.747439 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:16:48,342 [Epoch: 020 Step: 00003376] Batch Translation Loss:   5.920708 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:17:41,616 [Epoch: 020 Step: 00003377] Batch Translation Loss:   6.035401 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:20:09,531 [Epoch: 020 Step: 00003378] Batch Translation Loss:   5.868803 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 13:21:13,581 [Epoch: 020 Step: 00003379] Batch Translation Loss:   5.869472 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:22:14,041 [Epoch: 020 Step: 00003380] Batch Translation Loss:   6.328741 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:23:15,062 [Epoch: 020 Step: 00003381] Batch Translation Loss:   6.171431 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:24:09,548 [Epoch: 020 Step: 00003382] Batch Translation Loss:   5.680075 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:25:24,531 [Epoch: 020 Step: 00003383] Batch Translation Loss:   5.798196 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:26:25,394 [Epoch: 020 Step: 00003384] Batch Translation Loss:   6.580651 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:28:10,736 [Epoch: 020 Step: 00003385] Batch Translation Loss:   6.270644 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 13:29:08,967 [Epoch: 020 Step: 00003386] Batch Translation Loss:   6.297832 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:30:08,777 [Epoch: 020 Step: 00003387] Batch Translation Loss:   5.818415 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:31:07,193 [Epoch: 020 Step: 00003388] Batch Translation Loss:   6.270383 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:32:06,266 [Epoch: 020 Step: 00003389] Batch Translation Loss:   6.325120 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:33:49,274 [Epoch: 020 Step: 00003390] Batch Translation Loss:   6.254994 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 13:35:26,509 [Epoch: 020 Step: 00003391] Batch Translation Loss:   6.003603 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 13:36:30,453 [Epoch: 020 Step: 00003392] Batch Translation Loss:   6.033309 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:38:35,710 [Epoch: 020 Step: 00003393] Batch Translation Loss:   5.792516 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 13:39:43,840 [Epoch: 020 Step: 00003394] Batch Translation Loss:   6.075626 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:40:46,902 [Epoch: 020 Step: 00003395] Batch Translation Loss:   5.705440 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:41:53,447 [Epoch: 020 Step: 00003396] Batch Translation Loss:   5.754214 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:42:48,569 [Epoch: 020 Step: 00003397] Batch Translation Loss:   6.212101 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:43:44,928 [Epoch: 020 Step: 00003398] Batch Translation Loss:   5.879086 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 13:45:54,886 [Epoch: 020 Step: 00003399] Batch Translation Loss:   6.405055 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 13:48:08,108 [Epoch: 020 Step: 00003400] Batch Translation Loss:   5.623551 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 14:01:13,423 Validation result at epoch  20, step     3400: duration: 785.3134s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 12310.26465	PPL: 16330.01172
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.18	(DEL: 24.67,	INS: 0.00,	SUB: 74.15)
	Sequence Accuracy 1.15
2022-01-04 14:01:25,906 Logging Recognition and Translation Outputs
2022-01-04 14:01:25,911 ========================================================================================================================
2022-01-04 14:01:25,912 Logging Sequence: aslized-suzanne_stecker_0198
2022-01-04 14:01:25,912 	Text Reference  :	land
2022-01-04 14:01:25,912 	Text Hypothesis :	if  
2022-01-04 14:01:25,912 	Text Alignment  :	S   
2022-01-04 14:01:25,912 ========================================================================================================================
2022-01-04 14:01:25,913 Logging Sequence: deafvideo_3-deafgoldenhair_3079
2022-01-04 14:01:25,913 	Text Reference  :	dfhd dfhd
2022-01-04 14:01:25,913 	Text Hypothesis :	**** ok  
2022-01-04 14:01:25,913 	Text Alignment  :	D    S   
2022-01-04 14:01:25,913 ========================================================================================================================
2022-01-04 14:01:25,913 Logging Sequence: aslized-suzanne_stecker_0280
2022-01-04 14:01:25,914 	Text Reference  :	facess
2022-01-04 14:01:25,914 	Text Hypothesis :	ok    
2022-01-04 14:01:25,914 	Text Alignment  :	S     
2022-01-04 14:01:25,914 ========================================================================================================================
2022-01-04 14:01:25,914 Logging Sequence: deafvideo_3-crossover_3865
2022-01-04 14:01:25,914 	Text Reference  :	to
2022-01-04 14:01:25,915 	Text Hypothesis :	ok
2022-01-04 14:01:25,915 	Text Alignment  :	S 
2022-01-04 14:01:25,915 ========================================================================================================================
2022-01-04 14:01:25,915 Logging Sequence: youtube_4-tim_albert_5269
2022-01-04 14:01:25,915 	Text Reference  :	rollover
2022-01-04 14:01:25,915 	Text Hypothesis :	if      
2022-01-04 14:01:25,915 	Text Alignment  :	S       
2022-01-04 14:01:25,915 ========================================================================================================================
2022-01-04 14:01:26,521 Epoch  20: Total Training Recognition Loss -1.00  Total Training Translation Loss 1032.77 
2022-01-04 14:01:26,522 EPOCH 21
2022-01-04 14:01:43,178 [Epoch: 021 Step: 00003401] Batch Translation Loss:   5.727202 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:01:58,562 [Epoch: 021 Step: 00003402] Batch Translation Loss:   5.862825 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-04 14:02:20,720 [Epoch: 021 Step: 00003403] Batch Translation Loss:   6.754992 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:02:42,501 [Epoch: 021 Step: 00003404] Batch Translation Loss:   6.690614 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:03:01,318 [Epoch: 021 Step: 00003405] Batch Translation Loss:   6.680511 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:03:25,766 [Epoch: 021 Step: 00003406] Batch Translation Loss:   6.193862 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:03:49,497 [Epoch: 021 Step: 00003407] Batch Translation Loss:   6.205433 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:04:20,072 [Epoch: 021 Step: 00003408] Batch Translation Loss:   6.466494 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:04:45,958 [Epoch: 021 Step: 00003409] Batch Translation Loss:   6.241183 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:05:08,285 [Epoch: 021 Step: 00003410] Batch Translation Loss:   5.606102 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:05:26,204 [Epoch: 021 Step: 00003411] Batch Translation Loss:   6.341237 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:05:54,701 [Epoch: 021 Step: 00003412] Batch Translation Loss:   6.459067 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:06:07,116 [Epoch: 021 Step: 00003413] Batch Translation Loss:   5.851416 => Txt Tokens per Sec:        3 || Lr: 0.000700
2022-01-04 14:06:38,119 [Epoch: 021 Step: 00003414] Batch Translation Loss:   5.964758 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:06:59,267 [Epoch: 021 Step: 00003415] Batch Translation Loss:   6.074361 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:07:34,413 [Epoch: 021 Step: 00003416] Batch Translation Loss:   5.542221 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:07:58,860 [Epoch: 021 Step: 00003417] Batch Translation Loss:   5.700282 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:08:29,941 [Epoch: 021 Step: 00003418] Batch Translation Loss:   6.518975 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:09:06,630 [Epoch: 021 Step: 00003419] Batch Translation Loss:   6.416371 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:09:36,063 [Epoch: 021 Step: 00003420] Batch Translation Loss:   5.738749 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:10:14,101 [Epoch: 021 Step: 00003421] Batch Translation Loss:   5.962008 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:10:35,926 [Epoch: 021 Step: 00003422] Batch Translation Loss:   5.919246 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:11:03,023 [Epoch: 021 Step: 00003423] Batch Translation Loss:   6.463945 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:11:33,042 [Epoch: 021 Step: 00003424] Batch Translation Loss:   5.998578 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:12:01,097 [Epoch: 021 Step: 00003425] Batch Translation Loss:   6.795762 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:12:25,273 [Epoch: 021 Step: 00003426] Batch Translation Loss:   6.427141 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:12:42,400 [Epoch: 021 Step: 00003427] Batch Translation Loss:   5.834983 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:13:03,403 [Epoch: 021 Step: 00003428] Batch Translation Loss:   6.182424 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:13:28,834 [Epoch: 021 Step: 00003429] Batch Translation Loss:   6.096281 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:14:03,987 [Epoch: 021 Step: 00003430] Batch Translation Loss:   5.912832 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:14:21,255 [Epoch: 021 Step: 00003431] Batch Translation Loss:   5.768417 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:14:45,235 [Epoch: 021 Step: 00003432] Batch Translation Loss:   6.818710 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:15:14,815 [Epoch: 021 Step: 00003433] Batch Translation Loss:   6.246971 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:15:36,616 [Epoch: 021 Step: 00003434] Batch Translation Loss:   6.449797 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:15:54,869 [Epoch: 021 Step: 00003435] Batch Translation Loss:   6.266134 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:16:20,329 [Epoch: 021 Step: 00003436] Batch Translation Loss:   6.183350 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:17:12,942 [Epoch: 021 Step: 00003437] Batch Translation Loss:   6.895809 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:17:55,699 [Epoch: 021 Step: 00003438] Batch Translation Loss:   6.092811 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:18:24,421 [Epoch: 021 Step: 00003439] Batch Translation Loss:   5.944155 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:18:56,183 [Epoch: 021 Step: 00003440] Batch Translation Loss:   6.048585 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:19:25,597 [Epoch: 021 Step: 00003441] Batch Translation Loss:   6.073874 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:19:47,574 [Epoch: 021 Step: 00003442] Batch Translation Loss:   5.785353 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:20:22,168 [Epoch: 021 Step: 00003443] Batch Translation Loss:   6.312819 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:21:01,109 [Epoch: 021 Step: 00003444] Batch Translation Loss:   5.482807 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:21:23,608 [Epoch: 021 Step: 00003445] Batch Translation Loss:   5.543798 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:21:50,666 [Epoch: 021 Step: 00003446] Batch Translation Loss:   5.771291 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:22:15,871 [Epoch: 021 Step: 00003447] Batch Translation Loss:   6.276752 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:22:36,273 [Epoch: 021 Step: 00003448] Batch Translation Loss:   5.752387 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:23:06,758 [Epoch: 021 Step: 00003449] Batch Translation Loss:   5.608333 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:23:28,233 [Epoch: 021 Step: 00003450] Batch Translation Loss:   5.764024 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:24:01,459 [Epoch: 021 Step: 00003451] Batch Translation Loss:   6.455022 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:24:26,851 [Epoch: 021 Step: 00003452] Batch Translation Loss:   5.968504 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:25:22,660 [Epoch: 021 Step: 00003453] Batch Translation Loss:   5.708983 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:25:57,478 [Epoch: 021 Step: 00003454] Batch Translation Loss:   5.838083 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:26:24,627 [Epoch: 021 Step: 00003455] Batch Translation Loss:   5.670700 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:26:53,367 [Epoch: 021 Step: 00003456] Batch Translation Loss:   5.770519 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:27:13,230 [Epoch: 021 Step: 00003457] Batch Translation Loss:   5.933787 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:27:48,433 [Epoch: 021 Step: 00003458] Batch Translation Loss:   5.185353 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:28:55,876 [Epoch: 021 Step: 00003459] Batch Translation Loss:   6.074135 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 14:29:17,346 [Epoch: 021 Step: 00003460] Batch Translation Loss:   6.621214 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:29:58,568 [Epoch: 021 Step: 00003461] Batch Translation Loss:   5.894663 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:30:31,423 [Epoch: 021 Step: 00003462] Batch Translation Loss:   5.776065 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:31:10,426 [Epoch: 021 Step: 00003463] Batch Translation Loss:   6.312809 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:31:46,886 [Epoch: 021 Step: 00003464] Batch Translation Loss:   6.234550 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:32:19,324 [Epoch: 021 Step: 00003465] Batch Translation Loss:   5.920486 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:32:58,501 [Epoch: 021 Step: 00003466] Batch Translation Loss:   5.920878 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:33:41,489 [Epoch: 021 Step: 00003467] Batch Translation Loss:   6.050911 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:34:06,858 [Epoch: 021 Step: 00003468] Batch Translation Loss:   5.919414 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:34:41,254 [Epoch: 021 Step: 00003469] Batch Translation Loss:   6.050814 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:35:18,117 [Epoch: 021 Step: 00003470] Batch Translation Loss:   5.616738 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:36:15,161 [Epoch: 021 Step: 00003471] Batch Translation Loss:   6.278889 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:36:58,345 [Epoch: 021 Step: 00003472] Batch Translation Loss:   6.351301 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:37:34,991 [Epoch: 021 Step: 00003473] Batch Translation Loss:   6.663817 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:38:17,743 [Epoch: 021 Step: 00003474] Batch Translation Loss:   6.280438 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:38:39,625 [Epoch: 021 Step: 00003475] Batch Translation Loss:   6.248314 => Txt Tokens per Sec:        2 || Lr: 0.000700
2022-01-04 14:39:16,690 [Epoch: 021 Step: 00003476] Batch Translation Loss:   5.750828 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:40:10,584 [Epoch: 021 Step: 00003477] Batch Translation Loss:   5.797948 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:41:46,371 [Epoch: 021 Step: 00003478] Batch Translation Loss:   5.334982 => Txt Tokens per Sec:        0 || Lr: 0.000700
2022-01-04 14:42:45,608 [Epoch: 021 Step: 00003479] Batch Translation Loss:   5.536765 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:43:19,623 [Epoch: 021 Step: 00003480] Batch Translation Loss:   6.494697 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:44:08,170 [Epoch: 021 Step: 00003481] Batch Translation Loss:   6.231289 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:44:40,428 [Epoch: 021 Step: 00003482] Batch Translation Loss:   6.064791 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:45:21,844 [Epoch: 021 Step: 00003483] Batch Translation Loss:   6.261211 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:46:00,604 [Epoch: 021 Step: 00003484] Batch Translation Loss:   5.970972 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:46:44,555 [Epoch: 021 Step: 00003485] Batch Translation Loss:   6.049401 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:47:35,903 [Epoch: 021 Step: 00003486] Batch Translation Loss:   6.315939 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:48:17,711 [Epoch: 021 Step: 00003487] Batch Translation Loss:   5.728129 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:49:04,038 [Epoch: 021 Step: 00003488] Batch Translation Loss:   6.596195 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:49:58,005 [Epoch: 021 Step: 00003489] Batch Translation Loss:   6.266073 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:50:34,616 [Epoch: 021 Step: 00003490] Batch Translation Loss:   5.795154 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:51:36,859 [Epoch: 021 Step: 00003491] Batch Translation Loss:   6.216712 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:52:15,707 [Epoch: 021 Step: 00003492] Batch Translation Loss:   5.350681 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:53:00,861 [Epoch: 021 Step: 00003493] Batch Translation Loss:   6.433841 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:53:39,649 [Epoch: 021 Step: 00003494] Batch Translation Loss:   5.972081 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:54:30,494 [Epoch: 021 Step: 00003495] Batch Translation Loss:   6.467032 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:55:13,453 [Epoch: 021 Step: 00003496] Batch Translation Loss:   6.090067 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:56:25,044 [Epoch: 021 Step: 00003497] Batch Translation Loss:   5.440838 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:57:09,553 [Epoch: 021 Step: 00003498] Batch Translation Loss:   6.643623 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:57:52,362 [Epoch: 021 Step: 00003499] Batch Translation Loss:   6.405465 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 14:58:31,071 [Epoch: 021 Step: 00003500] Batch Translation Loss:   6.052135 => Txt Tokens per Sec:        1 || Lr: 0.000700
2022-01-04 15:10:20,756 Validation result at epoch  21, step     3500: duration: 709.6837s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11600.02441	PPL: 11212.43359
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 0.88	(DEL: 21.95,	INS: 0.00,	SUB: 77.17)
	Sequence Accuracy 1.03
2022-01-04 15:10:27,331 Logging Recognition and Translation Outputs
2022-01-04 15:10:27,331 ========================================================================================================================
2022-01-04 15:10:27,331 Logging Sequence: youtube_1-shoshannah_stern_2397
2022-01-04 15:10:27,332 	Text Reference  :	co chairs
2022-01-04 15:10:27,332 	Text Hypothesis :	** if    
2022-01-04 15:10:27,332 	Text Alignment  :	D  S     
2022-01-04 15:10:27,332 ========================================================================================================================
2022-01-04 15:10:27,332 Logging Sequence: youtube_5-sean_berdy_6086
2022-01-04 15:10:27,333 	Text Reference  :	siri    
2022-01-04 15:10:27,333 	Text Hypothesis :	handling
2022-01-04 15:10:27,333 	Text Alignment  :	S       
2022-01-04 15:10:27,333 ========================================================================================================================
2022-01-04 15:10:27,333 Logging Sequence: youtube_1-don_grushkin_2759
2022-01-04 15:10:27,333 	Text Reference  :	fun
2022-01-04 15:10:27,333 	Text Hypothesis :	if 
2022-01-04 15:10:27,334 	Text Alignment  :	S  
2022-01-04 15:10:27,334 ========================================================================================================================
2022-01-04 15:10:27,334 Logging Sequence: aslized-suzanne_stecker_0203
2022-01-04 15:10:27,334 	Text Reference  :	but     
2022-01-04 15:10:27,334 	Text Hypothesis :	handling
2022-01-04 15:10:27,334 	Text Alignment  :	S       
2022-01-04 15:10:27,334 ========================================================================================================================
2022-01-04 15:10:27,334 Logging Sequence: deafvideo_2-goatman_1525
2022-01-04 15:10:27,335 	Text Reference  :	crew
2022-01-04 15:10:27,335 	Text Hypothesis :	asl 
2022-01-04 15:10:27,335 	Text Alignment  :	S   
2022-01-04 15:10:27,335 ========================================================================================================================
2022-01-04 15:11:15,302 [Epoch: 021 Step: 00003501] Batch Translation Loss:   6.371694 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:12:03,055 [Epoch: 021 Step: 00003502] Batch Translation Loss:   5.800947 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:13:28,303 [Epoch: 021 Step: 00003503] Batch Translation Loss:   5.971112 => Txt Tokens per Sec:        0 || Lr: 0.000490
2022-01-04 15:14:09,954 [Epoch: 021 Step: 00003504] Batch Translation Loss:   5.619817 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:15:02,147 [Epoch: 021 Step: 00003505] Batch Translation Loss:   5.933559 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:15:56,800 [Epoch: 021 Step: 00003506] Batch Translation Loss:   5.681393 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:16:43,354 [Epoch: 021 Step: 00003507] Batch Translation Loss:   6.387522 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:17:18,772 [Epoch: 021 Step: 00003508] Batch Translation Loss:   6.106314 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:17:51,477 [Epoch: 021 Step: 00003509] Batch Translation Loss:   5.377283 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:18:26,167 [Epoch: 021 Step: 00003510] Batch Translation Loss:   6.423820 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:19:03,390 [Epoch: 021 Step: 00003511] Batch Translation Loss:   6.039869 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:19:37,625 [Epoch: 021 Step: 00003512] Batch Translation Loss:   5.903683 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:20:15,186 [Epoch: 021 Step: 00003513] Batch Translation Loss:   6.195186 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:20:50,160 [Epoch: 021 Step: 00003514] Batch Translation Loss:   5.912383 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:21:23,794 [Epoch: 021 Step: 00003515] Batch Translation Loss:   6.454566 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:21:55,741 [Epoch: 021 Step: 00003516] Batch Translation Loss:   5.978451 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:22:27,553 [Epoch: 021 Step: 00003517] Batch Translation Loss:   5.731550 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:23:02,581 [Epoch: 021 Step: 00003518] Batch Translation Loss:   6.208671 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:24:16,923 [Epoch: 021 Step: 00003519] Batch Translation Loss:   5.893272 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:25:29,163 [Epoch: 021 Step: 00003520] Batch Translation Loss:   6.610542 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:26:04,545 [Epoch: 021 Step: 00003521] Batch Translation Loss:   5.670438 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:26:40,374 [Epoch: 021 Step: 00003522] Batch Translation Loss:   6.057868 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:27:27,462 [Epoch: 021 Step: 00003523] Batch Translation Loss:   6.078140 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:28:14,964 [Epoch: 021 Step: 00003524] Batch Translation Loss:   5.905538 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:29:01,937 [Epoch: 021 Step: 00003525] Batch Translation Loss:   6.229786 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:29:29,816 [Epoch: 021 Step: 00003526] Batch Translation Loss:   5.972050 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:29:59,582 [Epoch: 021 Step: 00003527] Batch Translation Loss:   5.821742 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:30:29,731 [Epoch: 021 Step: 00003528] Batch Translation Loss:   6.360965 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:31:15,864 [Epoch: 021 Step: 00003529] Batch Translation Loss:   6.037941 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:31:47,366 [Epoch: 021 Step: 00003530] Batch Translation Loss:   5.794149 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:32:18,495 [Epoch: 021 Step: 00003531] Batch Translation Loss:   6.219961 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:32:49,062 [Epoch: 021 Step: 00003532] Batch Translation Loss:   6.027539 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:33:17,653 [Epoch: 021 Step: 00003533] Batch Translation Loss:   5.490647 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:33:50,168 [Epoch: 021 Step: 00003534] Batch Translation Loss:   5.828282 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:34:22,813 [Epoch: 021 Step: 00003535] Batch Translation Loss:   6.193563 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:34:59,377 [Epoch: 021 Step: 00003536] Batch Translation Loss:   5.788279 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:35:33,514 [Epoch: 021 Step: 00003537] Batch Translation Loss:   6.422791 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:36:20,227 [Epoch: 021 Step: 00003538] Batch Translation Loss:   5.349935 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:36:56,531 [Epoch: 021 Step: 00003539] Batch Translation Loss:   5.992382 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:37:33,726 [Epoch: 021 Step: 00003540] Batch Translation Loss:   6.121856 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:38:22,092 [Epoch: 021 Step: 00003541] Batch Translation Loss:   5.704535 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:39:35,922 [Epoch: 021 Step: 00003542] Batch Translation Loss:   6.064946 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:41:22,711 [Epoch: 021 Step: 00003543] Batch Translation Loss:   5.784551 => Txt Tokens per Sec:        0 || Lr: 0.000490
2022-01-04 15:42:02,783 [Epoch: 021 Step: 00003544] Batch Translation Loss:   6.112353 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:42:46,686 [Epoch: 021 Step: 00003545] Batch Translation Loss:   6.128484 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:43:34,306 [Epoch: 021 Step: 00003546] Batch Translation Loss:   6.132724 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:45:02,996 [Epoch: 021 Step: 00003547] Batch Translation Loss:   5.976200 => Txt Tokens per Sec:        0 || Lr: 0.000490
2022-01-04 15:46:04,529 [Epoch: 021 Step: 00003548] Batch Translation Loss:   6.257132 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:47:24,185 [Epoch: 021 Step: 00003549] Batch Translation Loss:   6.122631 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:48:05,333 [Epoch: 021 Step: 00003550] Batch Translation Loss:   6.070454 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:48:45,509 [Epoch: 021 Step: 00003551] Batch Translation Loss:   5.610565 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:49:18,966 [Epoch: 021 Step: 00003552] Batch Translation Loss:   5.836973 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:50:00,538 [Epoch: 021 Step: 00003553] Batch Translation Loss:   6.099015 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:50:43,313 [Epoch: 021 Step: 00003554] Batch Translation Loss:   6.538483 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:51:30,457 [Epoch: 021 Step: 00003555] Batch Translation Loss:   6.297702 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:52:13,075 [Epoch: 021 Step: 00003556] Batch Translation Loss:   5.969442 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:52:54,539 [Epoch: 021 Step: 00003557] Batch Translation Loss:   6.475277 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:53:24,553 [Epoch: 021 Step: 00003558] Batch Translation Loss:   6.090124 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:54:12,954 [Epoch: 021 Step: 00003559] Batch Translation Loss:   5.727213 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:55:04,585 [Epoch: 021 Step: 00003560] Batch Translation Loss:   6.318144 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:56:32,037 [Epoch: 021 Step: 00003561] Batch Translation Loss:   5.889575 => Txt Tokens per Sec:        0 || Lr: 0.000490
2022-01-04 15:57:18,748 [Epoch: 021 Step: 00003562] Batch Translation Loss:   5.760770 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:58:03,297 [Epoch: 021 Step: 00003563] Batch Translation Loss:   5.719298 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:58:53,734 [Epoch: 021 Step: 00003564] Batch Translation Loss:   6.176108 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 15:59:41,029 [Epoch: 021 Step: 00003565] Batch Translation Loss:   5.894348 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:00:25,085 [Epoch: 021 Step: 00003566] Batch Translation Loss:   5.928097 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:01:09,814 [Epoch: 021 Step: 00003567] Batch Translation Loss:   6.043137 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:01:56,508 [Epoch: 021 Step: 00003568] Batch Translation Loss:   6.129715 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:02:45,472 [Epoch: 021 Step: 00003569] Batch Translation Loss:   6.478773 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:04:09,319 [Epoch: 021 Step: 00003570] Batch Translation Loss:   5.951107 => Txt Tokens per Sec:        0 || Lr: 0.000490
2022-01-04 16:04:09,524 Epoch  21: Total Training Recognition Loss -1.00  Total Training Translation Loss 1028.98 
2022-01-04 16:04:09,525 EPOCH 22
2022-01-04 16:04:23,207 [Epoch: 022 Step: 00003571] Batch Translation Loss:   5.512847 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 16:04:32,243 [Epoch: 022 Step: 00003572] Batch Translation Loss:   5.894559 => Txt Tokens per Sec:        4 || Lr: 0.000490
2022-01-04 16:04:47,647 [Epoch: 022 Step: 00003573] Batch Translation Loss:   5.798517 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:04:58,563 [Epoch: 022 Step: 00003574] Batch Translation Loss:   6.250294 => Txt Tokens per Sec:        4 || Lr: 0.000490
2022-01-04 16:05:18,610 [Epoch: 022 Step: 00003575] Batch Translation Loss:   6.493245 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:05:29,730 [Epoch: 022 Step: 00003576] Batch Translation Loss:   6.578144 => Txt Tokens per Sec:        4 || Lr: 0.000490
2022-01-04 16:05:49,306 [Epoch: 022 Step: 00003577] Batch Translation Loss:   5.767395 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:06:08,680 [Epoch: 022 Step: 00003578] Batch Translation Loss:   6.063279 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:06:20,750 [Epoch: 022 Step: 00003579] Batch Translation Loss:   6.295153 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 16:06:45,253 [Epoch: 022 Step: 00003580] Batch Translation Loss:   5.878479 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:07:01,975 [Epoch: 022 Step: 00003581] Batch Translation Loss:   5.880303 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 16:07:28,657 [Epoch: 022 Step: 00003582] Batch Translation Loss:   5.859816 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:07:43,719 [Epoch: 022 Step: 00003583] Batch Translation Loss:   5.849357 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:07:54,259 [Epoch: 022 Step: 00003584] Batch Translation Loss:   6.162961 => Txt Tokens per Sec:        4 || Lr: 0.000490
2022-01-04 16:08:16,180 [Epoch: 022 Step: 00003585] Batch Translation Loss:   6.375773 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:08:38,088 [Epoch: 022 Step: 00003586] Batch Translation Loss:   6.280910 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:09:00,028 [Epoch: 022 Step: 00003587] Batch Translation Loss:   5.431485 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:09:25,688 [Epoch: 022 Step: 00003588] Batch Translation Loss:   6.291054 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:09:44,062 [Epoch: 022 Step: 00003589] Batch Translation Loss:   5.928257 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:10:14,144 [Epoch: 022 Step: 00003590] Batch Translation Loss:   6.118803 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:10:29,902 [Epoch: 022 Step: 00003591] Batch Translation Loss:   6.221052 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:10:50,116 [Epoch: 022 Step: 00003592] Batch Translation Loss:   6.194273 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:11:13,970 [Epoch: 022 Step: 00003593] Batch Translation Loss:   5.655207 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:11:33,700 [Epoch: 022 Step: 00003594] Batch Translation Loss:   5.428717 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:11:57,798 [Epoch: 022 Step: 00003595] Batch Translation Loss:   6.333742 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:12:19,968 [Epoch: 022 Step: 00003596] Batch Translation Loss:   5.891849 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:12:33,069 [Epoch: 022 Step: 00003597] Batch Translation Loss:   5.274444 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 16:12:54,639 [Epoch: 022 Step: 00003598] Batch Translation Loss:   6.015831 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:13:21,785 [Epoch: 022 Step: 00003599] Batch Translation Loss:   5.809326 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:13:37,238 [Epoch: 022 Step: 00003600] Batch Translation Loss:   5.876755 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:23:54,283 Validation result at epoch  22, step     3600: duration: 617.0443s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 13234.79395	PPL: 24226.20312
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.30	(DEL: 26.70,	INS: 0.00,	SUB: 72.01)
	Sequence Accuracy 1.35
2022-01-04 16:24:04,048 Logging Recognition and Translation Outputs
2022-01-04 16:24:04,051 ========================================================================================================================
2022-01-04 16:24:04,051 Logging Sequence: deafvideo_2-goatman_1525
2022-01-04 16:24:04,052 	Text Reference  :	simlar
2022-01-04 16:24:04,052 	Text Hypothesis :	or    
2022-01-04 16:24:04,052 	Text Alignment  :	S     
2022-01-04 16:24:04,052 ========================================================================================================================
2022-01-04 16:24:04,052 Logging Sequence: aslized-joy_maisel_6441
2022-01-04 16:24:04,053 	Text Reference  :	stcy larence
2022-01-04 16:24:04,053 	Text Hypothesis :	**** if     
2022-01-04 16:24:04,053 	Text Alignment  :	D    S      
2022-01-04 16:24:04,053 ========================================================================================================================
2022-01-04 16:24:04,053 Logging Sequence: youtube_1-don_grushkin_2331
2022-01-04 16:24:04,054 	Text Reference  :	sb
2022-01-04 16:24:04,054 	Text Hypothesis :	if
2022-01-04 16:24:04,054 	Text Alignment  :	S 
2022-01-04 16:24:04,054 ========================================================================================================================
2022-01-04 16:24:04,054 Logging Sequence: aslized-suzanne_stecker_0284
2022-01-04 16:24:04,054 	Text Reference  :	text
2022-01-04 16:24:04,055 	Text Hypothesis :	of  
2022-01-04 16:24:04,055 	Text Alignment  :	S   
2022-01-04 16:24:04,055 ========================================================================================================================
2022-01-04 16:24:04,055 Logging Sequence: youtube_1-catherine_mackinnon_2840
2022-01-04 16:24:04,055 	Text Reference  :	dvt
2022-01-04 16:24:04,056 	Text Hypothesis :	ok 
2022-01-04 16:24:04,056 	Text Alignment  :	S  
2022-01-04 16:24:04,056 ========================================================================================================================
2022-01-04 16:24:22,327 [Epoch: 022 Step: 00003601] Batch Translation Loss:   6.021185 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:24:46,465 [Epoch: 022 Step: 00003602] Batch Translation Loss:   6.466451 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:25:00,904 [Epoch: 022 Step: 00003603] Batch Translation Loss:   6.050266 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 16:25:23,915 [Epoch: 022 Step: 00003604] Batch Translation Loss:   6.100718 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:25:54,732 [Epoch: 022 Step: 00003605] Batch Translation Loss:   6.229260 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:26:16,609 [Epoch: 022 Step: 00003606] Batch Translation Loss:   5.783598 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:26:35,491 [Epoch: 022 Step: 00003607] Batch Translation Loss:   5.618250 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:26:57,654 [Epoch: 022 Step: 00003608] Batch Translation Loss:   5.532620 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:27:15,792 [Epoch: 022 Step: 00003609] Batch Translation Loss:   6.022796 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:27:55,088 [Epoch: 022 Step: 00003610] Batch Translation Loss:   6.111411 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:28:25,826 [Epoch: 022 Step: 00003611] Batch Translation Loss:   6.101499 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:28:54,222 [Epoch: 022 Step: 00003612] Batch Translation Loss:   5.540197 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:29:09,847 [Epoch: 022 Step: 00003613] Batch Translation Loss:   6.030105 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:29:36,857 [Epoch: 022 Step: 00003614] Batch Translation Loss:   5.368551 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:30:09,584 [Epoch: 022 Step: 00003615] Batch Translation Loss:   5.504709 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:30:29,025 [Epoch: 022 Step: 00003616] Batch Translation Loss:   6.304611 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:30:44,487 [Epoch: 022 Step: 00003617] Batch Translation Loss:   5.559633 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:31:15,428 [Epoch: 022 Step: 00003618] Batch Translation Loss:   6.171375 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:31:33,001 [Epoch: 022 Step: 00003619] Batch Translation Loss:   6.343039 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:31:58,198 [Epoch: 022 Step: 00003620] Batch Translation Loss:   6.233090 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:32:34,023 [Epoch: 022 Step: 00003621] Batch Translation Loss:   5.775288 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:32:55,375 [Epoch: 022 Step: 00003622] Batch Translation Loss:   6.005279 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:33:20,992 [Epoch: 022 Step: 00003623] Batch Translation Loss:   5.618888 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:33:45,276 [Epoch: 022 Step: 00003624] Batch Translation Loss:   6.028687 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:34:16,693 [Epoch: 022 Step: 00003625] Batch Translation Loss:   6.099408 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:34:37,175 [Epoch: 022 Step: 00003626] Batch Translation Loss:   5.682581 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:35:02,569 [Epoch: 022 Step: 00003627] Batch Translation Loss:   6.043080 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:35:47,258 [Epoch: 022 Step: 00003628] Batch Translation Loss:   5.655384 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:36:09,650 [Epoch: 022 Step: 00003629] Batch Translation Loss:   5.959360 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:36:34,200 [Epoch: 022 Step: 00003630] Batch Translation Loss:   5.390835 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:37:17,829 [Epoch: 022 Step: 00003631] Batch Translation Loss:   5.925450 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:37:38,057 [Epoch: 022 Step: 00003632] Batch Translation Loss:   6.520450 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:38:42,088 [Epoch: 022 Step: 00003633] Batch Translation Loss:   5.906896 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:39:13,579 [Epoch: 022 Step: 00003634] Batch Translation Loss:   6.336243 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:39:32,217 [Epoch: 022 Step: 00003635] Batch Translation Loss:   6.660106 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:39:48,753 [Epoch: 022 Step: 00003636] Batch Translation Loss:   5.052647 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:40:09,410 [Epoch: 022 Step: 00003637] Batch Translation Loss:   6.168518 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:40:28,695 [Epoch: 022 Step: 00003638] Batch Translation Loss:   6.128300 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:40:46,597 [Epoch: 022 Step: 00003639] Batch Translation Loss:   5.716187 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:41:06,028 [Epoch: 022 Step: 00003640] Batch Translation Loss:   6.274605 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:41:39,038 [Epoch: 022 Step: 00003641] Batch Translation Loss:   6.101172 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:41:56,945 [Epoch: 022 Step: 00003642] Batch Translation Loss:   5.736617 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:42:15,775 [Epoch: 022 Step: 00003643] Batch Translation Loss:   5.948969 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:42:35,762 [Epoch: 022 Step: 00003644] Batch Translation Loss:   6.164338 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:42:56,439 [Epoch: 022 Step: 00003645] Batch Translation Loss:   6.272323 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:43:32,291 [Epoch: 022 Step: 00003646] Batch Translation Loss:   6.392768 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:44:11,034 [Epoch: 022 Step: 00003647] Batch Translation Loss:   6.274886 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:44:34,107 [Epoch: 022 Step: 00003648] Batch Translation Loss:   6.209382 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:44:53,578 [Epoch: 022 Step: 00003649] Batch Translation Loss:   5.294495 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:45:18,578 [Epoch: 022 Step: 00003650] Batch Translation Loss:   5.970541 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:45:42,749 [Epoch: 022 Step: 00003651] Batch Translation Loss:   5.498543 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:46:08,190 [Epoch: 022 Step: 00003652] Batch Translation Loss:   6.369473 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:46:48,807 [Epoch: 022 Step: 00003653] Batch Translation Loss:   5.723833 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:47:14,789 [Epoch: 022 Step: 00003654] Batch Translation Loss:   5.808981 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:47:36,350 [Epoch: 022 Step: 00003655] Batch Translation Loss:   5.940254 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:47:58,486 [Epoch: 022 Step: 00003656] Batch Translation Loss:   5.668492 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:48:22,499 [Epoch: 022 Step: 00003657] Batch Translation Loss:   5.428979 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:48:49,370 [Epoch: 022 Step: 00003658] Batch Translation Loss:   6.539091 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:49:13,903 [Epoch: 022 Step: 00003659] Batch Translation Loss:   6.033652 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:49:38,957 [Epoch: 022 Step: 00003660] Batch Translation Loss:   5.911961 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:50:06,463 [Epoch: 022 Step: 00003661] Batch Translation Loss:   5.888993 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:50:33,811 [Epoch: 022 Step: 00003662] Batch Translation Loss:   5.649735 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:51:06,148 [Epoch: 022 Step: 00003663] Batch Translation Loss:   6.410000 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:51:30,827 [Epoch: 022 Step: 00003664] Batch Translation Loss:   6.166117 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:51:55,067 [Epoch: 022 Step: 00003665] Batch Translation Loss:   5.569150 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:52:17,851 [Epoch: 022 Step: 00003666] Batch Translation Loss:   5.706238 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:52:44,318 [Epoch: 022 Step: 00003667] Batch Translation Loss:   5.944563 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:53:12,206 [Epoch: 022 Step: 00003668] Batch Translation Loss:   5.992985 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:53:39,297 [Epoch: 022 Step: 00003669] Batch Translation Loss:   6.734578 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:54:05,468 [Epoch: 022 Step: 00003670] Batch Translation Loss:   6.129975 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:54:32,785 [Epoch: 022 Step: 00003671] Batch Translation Loss:   6.266871 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:55:00,527 [Epoch: 022 Step: 00003672] Batch Translation Loss:   5.451236 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:55:24,380 [Epoch: 022 Step: 00003673] Batch Translation Loss:   5.455614 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:55:53,190 [Epoch: 022 Step: 00003674] Batch Translation Loss:   6.370285 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:56:20,150 [Epoch: 022 Step: 00003675] Batch Translation Loss:   5.900889 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:56:51,276 [Epoch: 022 Step: 00003676] Batch Translation Loss:   5.491038 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:57:19,634 [Epoch: 022 Step: 00003677] Batch Translation Loss:   6.444750 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:57:47,813 [Epoch: 022 Step: 00003678] Batch Translation Loss:   5.659505 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:58:21,254 [Epoch: 022 Step: 00003679] Batch Translation Loss:   5.921488 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:58:49,478 [Epoch: 022 Step: 00003680] Batch Translation Loss:   5.571296 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 16:59:21,743 [Epoch: 022 Step: 00003681] Batch Translation Loss:   6.033192 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 16:59:53,245 [Epoch: 022 Step: 00003682] Batch Translation Loss:   6.320028 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:00:25,591 [Epoch: 022 Step: 00003683] Batch Translation Loss:   6.103232 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:00:55,037 [Epoch: 022 Step: 00003684] Batch Translation Loss:   6.063496 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:01:37,752 [Epoch: 022 Step: 00003685] Batch Translation Loss:   6.442037 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:02:34,783 [Epoch: 022 Step: 00003686] Batch Translation Loss:   5.876054 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:03:29,380 [Epoch: 022 Step: 00003687] Batch Translation Loss:   6.524744 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:04:02,889 [Epoch: 022 Step: 00003688] Batch Translation Loss:   5.560761 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:04:34,349 [Epoch: 022 Step: 00003689] Batch Translation Loss:   5.960711 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:05:05,364 [Epoch: 022 Step: 00003690] Batch Translation Loss:   6.131359 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:05:44,591 [Epoch: 022 Step: 00003691] Batch Translation Loss:   6.235363 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:06:15,155 [Epoch: 022 Step: 00003692] Batch Translation Loss:   6.124464 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:06:54,156 [Epoch: 022 Step: 00003693] Batch Translation Loss:   6.406631 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:07:28,459 [Epoch: 022 Step: 00003694] Batch Translation Loss:   6.481250 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:08:04,694 [Epoch: 022 Step: 00003695] Batch Translation Loss:   6.048717 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:08:36,728 [Epoch: 022 Step: 00003696] Batch Translation Loss:   6.040027 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:09:10,664 [Epoch: 022 Step: 00003697] Batch Translation Loss:   5.677406 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:09:46,275 [Epoch: 022 Step: 00003698] Batch Translation Loss:   6.250560 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:10:24,607 [Epoch: 022 Step: 00003699] Batch Translation Loss:   5.863462 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:11:00,605 [Epoch: 022 Step: 00003700] Batch Translation Loss:   5.613328 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:19:17,514 Validation result at epoch  22, step     3700: duration: 496.9078s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 11898.86914	PPL: 17208.71094
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 2.38	(DEL: 20.74,	INS: 0.00,	SUB: 76.89)
	Sequence Accuracy 1.96
2022-01-04 17:19:23,521 Logging Recognition and Translation Outputs
2022-01-04 17:19:23,522 ========================================================================================================================
2022-01-04 17:19:23,522 Logging Sequence: youtube_1-don_grushkin_2334
2022-01-04 17:19:23,522 	Text Reference  :	asl
2022-01-04 17:19:23,523 	Text Hypothesis :	or 
2022-01-04 17:19:23,523 	Text Alignment  :	S  
2022-01-04 17:19:23,523 ========================================================================================================================
2022-01-04 17:19:23,523 Logging Sequence: deafvideo_3-yesyes_3113
2022-01-04 17:19:23,523 	Text Reference  :	cuonil de manos
2022-01-04 17:19:23,523 	Text Hypothesis :	****** ** if   
2022-01-04 17:19:23,523 	Text Alignment  :	D      D  S    
2022-01-04 17:19:23,523 ========================================================================================================================
2022-01-04 17:19:23,523 Logging Sequence: deafvideo_2-goatman_1536
2022-01-04 17:19:23,524 	Text Reference  :	aclu
2022-01-04 17:19:23,524 	Text Hypothesis :	or  
2022-01-04 17:19:23,524 	Text Alignment  :	S   
2022-01-04 17:19:23,524 ========================================================================================================================
2022-01-04 17:19:23,524 Logging Sequence: deafvideo_3-deafgoldenhair_3060
2022-01-04 17:19:23,524 	Text Reference  :	savior
2022-01-04 17:19:23,524 	Text Hypothesis :	if    
2022-01-04 17:19:23,524 	Text Alignment  :	S     
2022-01-04 17:19:23,524 ========================================================================================================================
2022-01-04 17:19:23,524 Logging Sequence: aslized-joy_maisel_6433
2022-01-04 17:19:23,525 	Text Reference  :	video
2022-01-04 17:19:23,525 	Text Hypothesis :	or   
2022-01-04 17:19:23,525 	Text Alignment  :	S    
2022-01-04 17:19:23,525 ========================================================================================================================
2022-01-04 17:20:02,880 [Epoch: 022 Step: 00003701] Batch Translation Loss:   6.148818 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:20:37,900 [Epoch: 022 Step: 00003702] Batch Translation Loss:   6.019265 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:21:21,731 [Epoch: 022 Step: 00003703] Batch Translation Loss:   6.310097 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:22:01,188 [Epoch: 022 Step: 00003704] Batch Translation Loss:   6.007923 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:22:53,632 [Epoch: 022 Step: 00003705] Batch Translation Loss:   5.695356 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:23:31,111 [Epoch: 022 Step: 00003706] Batch Translation Loss:   5.274600 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:24:19,260 [Epoch: 022 Step: 00003707] Batch Translation Loss:   5.946521 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:24:57,002 [Epoch: 022 Step: 00003708] Batch Translation Loss:   6.533504 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:25:39,972 [Epoch: 022 Step: 00003709] Batch Translation Loss:   5.614739 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:26:30,646 [Epoch: 022 Step: 00003710] Batch Translation Loss:   6.292749 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:27:23,019 [Epoch: 022 Step: 00003711] Batch Translation Loss:   5.786818 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:28:03,610 [Epoch: 022 Step: 00003712] Batch Translation Loss:   5.626045 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:29:16,081 [Epoch: 022 Step: 00003713] Batch Translation Loss:   6.180559 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:29:56,096 [Epoch: 022 Step: 00003714] Batch Translation Loss:   5.928771 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:30:34,054 [Epoch: 022 Step: 00003715] Batch Translation Loss:   5.944983 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:31:13,585 [Epoch: 022 Step: 00003716] Batch Translation Loss:   5.742229 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:31:57,515 [Epoch: 022 Step: 00003717] Batch Translation Loss:   5.686398 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:32:34,722 [Epoch: 022 Step: 00003718] Batch Translation Loss:   5.771564 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:33:17,198 [Epoch: 022 Step: 00003719] Batch Translation Loss:   6.183894 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:34:03,944 [Epoch: 022 Step: 00003720] Batch Translation Loss:   5.649495 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:34:50,664 [Epoch: 022 Step: 00003721] Batch Translation Loss:   6.265189 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:36:20,904 [Epoch: 022 Step: 00003722] Batch Translation Loss:   5.525810 => Txt Tokens per Sec:        0 || Lr: 0.000490
2022-01-04 17:37:07,465 [Epoch: 022 Step: 00003723] Batch Translation Loss:   6.101899 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:37:49,272 [Epoch: 022 Step: 00003724] Batch Translation Loss:   6.084159 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:38:34,849 [Epoch: 022 Step: 00003725] Batch Translation Loss:   6.619547 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:39:06,688 [Epoch: 022 Step: 00003726] Batch Translation Loss:   5.927106 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:39:39,909 [Epoch: 022 Step: 00003727] Batch Translation Loss:   5.068809 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:40:16,024 [Epoch: 022 Step: 00003728] Batch Translation Loss:   6.408639 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:40:55,269 [Epoch: 022 Step: 00003729] Batch Translation Loss:   5.355942 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:41:30,098 [Epoch: 022 Step: 00003730] Batch Translation Loss:   6.208841 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:42:07,690 [Epoch: 022 Step: 00003731] Batch Translation Loss:   5.873689 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:43:14,580 [Epoch: 022 Step: 00003732] Batch Translation Loss:   6.227411 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:43:53,704 [Epoch: 022 Step: 00003733] Batch Translation Loss:   5.682030 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:44:35,795 [Epoch: 022 Step: 00003734] Batch Translation Loss:   6.070463 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:45:14,387 [Epoch: 022 Step: 00003735] Batch Translation Loss:   5.856186 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:45:53,592 [Epoch: 022 Step: 00003736] Batch Translation Loss:   5.698059 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:46:33,523 [Epoch: 022 Step: 00003737] Batch Translation Loss:   6.017349 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:47:38,978 [Epoch: 022 Step: 00003738] Batch Translation Loss:   5.869343 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:49:11,109 [Epoch: 022 Step: 00003739] Batch Translation Loss:   6.024028 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 17:50:30,290 Epoch  22: Total Training Recognition Loss -1.00  Total Training Translation Loss 1008.45 
2022-01-04 17:50:30,291 EPOCH 23
2022-01-04 17:50:42,432 [Epoch: 023 Step: 00003740] Batch Translation Loss:   5.891603 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 17:50:53,902 [Epoch: 023 Step: 00003741] Batch Translation Loss:   5.644650 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 17:51:10,232 [Epoch: 023 Step: 00003742] Batch Translation Loss:   6.291440 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 17:51:27,515 [Epoch: 023 Step: 00003743] Batch Translation Loss:   6.511122 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 17:51:41,091 [Epoch: 023 Step: 00003744] Batch Translation Loss:   6.211825 => Txt Tokens per Sec:        4 || Lr: 0.000490
2022-01-04 17:51:59,645 [Epoch: 023 Step: 00003745] Batch Translation Loss:   6.335909 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 17:52:09,404 [Epoch: 023 Step: 00003746] Batch Translation Loss:   6.151074 => Txt Tokens per Sec:        4 || Lr: 0.000490
2022-01-04 17:52:30,052 [Epoch: 023 Step: 00003747] Batch Translation Loss:   5.661421 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 17:52:42,033 [Epoch: 023 Step: 00003748] Batch Translation Loss:   6.423694 => Txt Tokens per Sec:        4 || Lr: 0.000490
2022-01-04 17:53:01,006 [Epoch: 023 Step: 00003749] Batch Translation Loss:   5.879608 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 17:53:20,511 [Epoch: 023 Step: 00003750] Batch Translation Loss:   5.882460 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 17:53:36,797 [Epoch: 023 Step: 00003751] Batch Translation Loss:   6.274270 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 17:53:52,519 [Epoch: 023 Step: 00003752] Batch Translation Loss:   5.764994 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 17:54:16,680 [Epoch: 023 Step: 00003753] Batch Translation Loss:   6.043395 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 17:54:29,188 [Epoch: 023 Step: 00003754] Batch Translation Loss:   5.647633 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 17:54:49,628 [Epoch: 023 Step: 00003755] Batch Translation Loss:   6.121383 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 17:55:10,945 [Epoch: 023 Step: 00003756] Batch Translation Loss:   6.060668 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 17:55:34,175 [Epoch: 023 Step: 00003757] Batch Translation Loss:   6.107557 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 17:55:57,342 [Epoch: 023 Step: 00003758] Batch Translation Loss:   6.202884 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 17:56:13,933 [Epoch: 023 Step: 00003759] Batch Translation Loss:   6.031983 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 17:56:30,659 [Epoch: 023 Step: 00003760] Batch Translation Loss:   5.769171 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 17:56:55,474 [Epoch: 023 Step: 00003761] Batch Translation Loss:   6.148892 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 17:57:14,065 [Epoch: 023 Step: 00003762] Batch Translation Loss:   6.188796 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 17:57:33,852 [Epoch: 023 Step: 00003763] Batch Translation Loss:   5.739929 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 17:57:52,376 [Epoch: 023 Step: 00003764] Batch Translation Loss:   6.334539 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 17:58:07,990 [Epoch: 023 Step: 00003765] Batch Translation Loss:   6.017694 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 17:58:27,018 [Epoch: 023 Step: 00003766] Batch Translation Loss:   6.017264 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 17:58:41,876 [Epoch: 023 Step: 00003767] Batch Translation Loss:   5.707369 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 17:58:55,613 [Epoch: 023 Step: 00003768] Batch Translation Loss:   6.624149 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 17:59:17,992 [Epoch: 023 Step: 00003769] Batch Translation Loss:   6.123574 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 17:59:40,307 [Epoch: 023 Step: 00003770] Batch Translation Loss:   5.879986 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 17:59:56,509 [Epoch: 023 Step: 00003771] Batch Translation Loss:   5.934514 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:00:17,585 [Epoch: 023 Step: 00003772] Batch Translation Loss:   6.164285 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:00:37,032 [Epoch: 023 Step: 00003773] Batch Translation Loss:   5.989735 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:01:01,085 [Epoch: 023 Step: 00003774] Batch Translation Loss:   5.456618 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:01:33,261 [Epoch: 023 Step: 00003775] Batch Translation Loss:   5.493855 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:02:04,489 [Epoch: 023 Step: 00003776] Batch Translation Loss:   6.165806 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:02:21,554 [Epoch: 023 Step: 00003777] Batch Translation Loss:   5.947939 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:02:46,519 [Epoch: 023 Step: 00003778] Batch Translation Loss:   5.780862 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:03:02,665 [Epoch: 023 Step: 00003779] Batch Translation Loss:   5.876659 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:03:27,967 [Epoch: 023 Step: 00003780] Batch Translation Loss:   6.014319 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:03:41,023 [Epoch: 023 Step: 00003781] Batch Translation Loss:   6.063412 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 18:04:01,174 [Epoch: 023 Step: 00003782] Batch Translation Loss:   5.527820 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:04:31,294 [Epoch: 023 Step: 00003783] Batch Translation Loss:   5.147211 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:05:10,206 [Epoch: 023 Step: 00003784] Batch Translation Loss:   5.989619 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:05:31,053 [Epoch: 023 Step: 00003785] Batch Translation Loss:   5.987051 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:05:51,672 [Epoch: 023 Step: 00003786] Batch Translation Loss:   5.418408 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:06:33,166 [Epoch: 023 Step: 00003787] Batch Translation Loss:   5.897050 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:07:11,817 [Epoch: 023 Step: 00003788] Batch Translation Loss:   6.083694 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:07:34,580 [Epoch: 023 Step: 00003789] Batch Translation Loss:   5.862740 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:08:20,729 [Epoch: 023 Step: 00003790] Batch Translation Loss:   5.769738 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:08:56,654 [Epoch: 023 Step: 00003791] Batch Translation Loss:   6.201598 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:09:20,670 [Epoch: 023 Step: 00003792] Batch Translation Loss:   5.954730 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:09:38,520 [Epoch: 023 Step: 00003793] Batch Translation Loss:   6.200183 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:09:58,233 [Epoch: 023 Step: 00003794] Batch Translation Loss:   5.894509 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:10:23,388 [Epoch: 023 Step: 00003795] Batch Translation Loss:   6.165638 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:10:53,951 [Epoch: 023 Step: 00003796] Batch Translation Loss:   6.405489 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:11:15,850 [Epoch: 023 Step: 00003797] Batch Translation Loss:   6.010374 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:11:40,483 [Epoch: 023 Step: 00003798] Batch Translation Loss:   6.180007 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:11:58,368 [Epoch: 023 Step: 00003799] Batch Translation Loss:   5.427386 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:12:28,459 [Epoch: 023 Step: 00003800] Batch Translation Loss:   5.290382 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:21:26,906 Validation result at epoch  23, step     3800: duration: 538.4454s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 12758.47852	PPL: 18854.47070
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 0.31	(DEL: 25.23,	INS: 0.00,	SUB: 74.46)
	Sequence Accuracy 0.41
2022-01-04 18:21:34,919 Logging Recognition and Translation Outputs
2022-01-04 18:21:34,921 ========================================================================================================================
2022-01-04 18:21:34,921 Logging Sequence: youtube_1-catherine_mackinnon_2808
2022-01-04 18:21:34,927 	Text Reference  :	raja rajeshwari
2022-01-04 18:21:34,928 	Text Hypothesis :	**** if        
2022-01-04 18:21:34,932 	Text Alignment  :	D    S         
2022-01-04 18:21:34,932 ========================================================================================================================
2022-01-04 18:21:34,932 Logging Sequence: aslized-joy_maisel_6435
2022-01-04 18:21:34,933 	Text Reference  :	weite
2022-01-04 18:21:34,933 	Text Hypothesis :	if   
2022-01-04 18:21:34,933 	Text Alignment  :	S    
2022-01-04 18:21:34,933 ========================================================================================================================
2022-01-04 18:21:34,933 Logging Sequence: deafvideo_3-geoalpha_4543
2022-01-04 18:21:34,933 	Text Reference  :	do
2022-01-04 18:21:34,933 	Text Hypothesis :	if
2022-01-04 18:21:34,933 	Text Alignment  :	S 
2022-01-04 18:21:34,933 ========================================================================================================================
2022-01-04 18:21:34,934 Logging Sequence: deafvideo_2-sddsimple_1584
2022-01-04 18:21:34,934 	Text Reference  :	syran
2022-01-04 18:21:34,934 	Text Hypothesis :	absl 
2022-01-04 18:21:34,934 	Text Alignment  :	S    
2022-01-04 18:21:34,934 ========================================================================================================================
2022-01-04 18:21:34,934 Logging Sequence: deafvideo_3-geoalpha_4567
2022-01-04 18:21:34,934 	Text Reference  :	abces
2022-01-04 18:21:34,934 	Text Hypothesis :	if   
2022-01-04 18:21:34,935 	Text Alignment  :	S    
2022-01-04 18:21:34,935 ========================================================================================================================
2022-01-04 18:22:21,744 [Epoch: 023 Step: 00003801] Batch Translation Loss:   5.991874 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:23:16,066 [Epoch: 023 Step: 00003802] Batch Translation Loss:   6.090617 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:23:52,381 [Epoch: 023 Step: 00003803] Batch Translation Loss:   5.876346 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:24:20,837 [Epoch: 023 Step: 00003804] Batch Translation Loss:   5.789752 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:24:56,394 [Epoch: 023 Step: 00003805] Batch Translation Loss:   5.847682 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:25:18,981 [Epoch: 023 Step: 00003806] Batch Translation Loss:   6.107166 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:25:49,530 [Epoch: 023 Step: 00003807] Batch Translation Loss:   5.608878 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:26:21,558 [Epoch: 023 Step: 00003808] Batch Translation Loss:   5.458961 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:26:46,400 [Epoch: 023 Step: 00003809] Batch Translation Loss:   6.658800 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:27:35,504 [Epoch: 023 Step: 00003810] Batch Translation Loss:   5.911207 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:28:10,303 [Epoch: 023 Step: 00003811] Batch Translation Loss:   6.234415 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:28:28,480 [Epoch: 023 Step: 00003812] Batch Translation Loss:   6.458026 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:29:05,861 [Epoch: 023 Step: 00003813] Batch Translation Loss:   5.712544 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:29:24,221 [Epoch: 023 Step: 00003814] Batch Translation Loss:   6.064547 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:29:44,186 [Epoch: 023 Step: 00003815] Batch Translation Loss:   5.792618 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:30:09,398 [Epoch: 023 Step: 00003816] Batch Translation Loss:   5.953250 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:30:32,489 [Epoch: 023 Step: 00003817] Batch Translation Loss:   6.268879 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:30:59,848 [Epoch: 023 Step: 00003818] Batch Translation Loss:   5.695487 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:31:24,511 [Epoch: 023 Step: 00003819] Batch Translation Loss:   5.672308 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:31:50,116 [Epoch: 023 Step: 00003820] Batch Translation Loss:   6.152974 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:32:12,048 [Epoch: 023 Step: 00003821] Batch Translation Loss:   5.961226 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:32:39,344 [Epoch: 023 Step: 00003822] Batch Translation Loss:   5.477444 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:33:22,881 [Epoch: 023 Step: 00003823] Batch Translation Loss:   6.161370 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:33:50,950 [Epoch: 023 Step: 00003824] Batch Translation Loss:   6.557086 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:34:14,028 [Epoch: 023 Step: 00003825] Batch Translation Loss:   5.876258 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:34:37,173 [Epoch: 023 Step: 00003826] Batch Translation Loss:   5.989023 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:35:05,178 [Epoch: 023 Step: 00003827] Batch Translation Loss:   5.912837 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:35:31,762 [Epoch: 023 Step: 00003828] Batch Translation Loss:   5.544394 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:35:57,509 [Epoch: 023 Step: 00003829] Batch Translation Loss:   5.253118 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:36:20,846 [Epoch: 023 Step: 00003830] Batch Translation Loss:   5.582670 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:36:45,313 [Epoch: 023 Step: 00003831] Batch Translation Loss:   5.611162 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:37:16,757 [Epoch: 023 Step: 00003832] Batch Translation Loss:   5.569442 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:38:01,903 [Epoch: 023 Step: 00003833] Batch Translation Loss:   6.179907 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:38:26,502 [Epoch: 023 Step: 00003834] Batch Translation Loss:   5.878288 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:38:53,790 [Epoch: 023 Step: 00003835] Batch Translation Loss:   5.924629 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:39:23,762 [Epoch: 023 Step: 00003836] Batch Translation Loss:   5.664077 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:39:48,367 [Epoch: 023 Step: 00003837] Batch Translation Loss:   5.884723 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:40:10,594 [Epoch: 023 Step: 00003838] Batch Translation Loss:   5.836653 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:40:33,658 [Epoch: 023 Step: 00003839] Batch Translation Loss:   5.655849 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:40:56,696 [Epoch: 023 Step: 00003840] Batch Translation Loss:   5.696637 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:41:20,639 [Epoch: 023 Step: 00003841] Batch Translation Loss:   6.007572 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:41:46,533 [Epoch: 023 Step: 00003842] Batch Translation Loss:   5.779861 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:42:12,065 [Epoch: 023 Step: 00003843] Batch Translation Loss:   5.596713 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:42:37,662 [Epoch: 023 Step: 00003844] Batch Translation Loss:   6.075465 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:43:04,421 [Epoch: 023 Step: 00003845] Batch Translation Loss:   6.043122 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:43:40,557 [Epoch: 023 Step: 00003846] Batch Translation Loss:   6.027364 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:44:12,501 [Epoch: 023 Step: 00003847] Batch Translation Loss:   6.028710 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:44:58,242 [Epoch: 023 Step: 00003848] Batch Translation Loss:   5.991913 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:45:24,639 [Epoch: 023 Step: 00003849] Batch Translation Loss:   6.015990 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 18:45:55,309 [Epoch: 023 Step: 00003850] Batch Translation Loss:   5.630100 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:46:25,180 [Epoch: 023 Step: 00003851] Batch Translation Loss:   6.287135 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:46:52,664 [Epoch: 023 Step: 00003852] Batch Translation Loss:   5.826714 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:47:49,889 [Epoch: 023 Step: 00003853] Batch Translation Loss:   6.018542 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:48:20,828 [Epoch: 023 Step: 00003854] Batch Translation Loss:   6.185756 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:48:49,005 [Epoch: 023 Step: 00003855] Batch Translation Loss:   5.771994 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:49:21,355 [Epoch: 023 Step: 00003856] Batch Translation Loss:   5.850950 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:50:03,794 [Epoch: 023 Step: 00003857] Batch Translation Loss:   5.664020 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:50:39,803 [Epoch: 023 Step: 00003858] Batch Translation Loss:   5.364272 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:51:16,164 [Epoch: 023 Step: 00003859] Batch Translation Loss:   5.623084 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:51:44,502 [Epoch: 023 Step: 00003860] Batch Translation Loss:   5.681211 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:52:19,408 [Epoch: 023 Step: 00003861] Batch Translation Loss:   5.844176 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:53:06,318 [Epoch: 023 Step: 00003862] Batch Translation Loss:   6.007048 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:53:40,462 [Epoch: 023 Step: 00003863] Batch Translation Loss:   5.885594 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:54:14,508 [Epoch: 023 Step: 00003864] Batch Translation Loss:   5.374778 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:54:46,091 [Epoch: 023 Step: 00003865] Batch Translation Loss:   5.633633 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:55:23,478 [Epoch: 023 Step: 00003866] Batch Translation Loss:   5.723228 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:55:53,046 [Epoch: 023 Step: 00003867] Batch Translation Loss:   6.107196 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:56:28,639 [Epoch: 023 Step: 00003868] Batch Translation Loss:   5.773273 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:57:08,729 [Epoch: 023 Step: 00003869] Batch Translation Loss:   5.982787 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:57:42,229 [Epoch: 023 Step: 00003870] Batch Translation Loss:   5.838014 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:58:20,650 [Epoch: 023 Step: 00003871] Batch Translation Loss:   5.572688 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 18:59:06,751 [Epoch: 023 Step: 00003872] Batch Translation Loss:   6.092692 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:00:22,236 [Epoch: 023 Step: 00003873] Batch Translation Loss:   6.169263 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:01:05,120 [Epoch: 023 Step: 00003874] Batch Translation Loss:   5.920006 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:01:37,048 [Epoch: 023 Step: 00003875] Batch Translation Loss:   6.303809 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:02:14,756 [Epoch: 023 Step: 00003876] Batch Translation Loss:   6.151051 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:02:50,945 [Epoch: 023 Step: 00003877] Batch Translation Loss:   5.934762 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:03:36,010 [Epoch: 023 Step: 00003878] Batch Translation Loss:   6.125435 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:04:16,584 [Epoch: 023 Step: 00003879] Batch Translation Loss:   6.039838 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:04:55,925 [Epoch: 023 Step: 00003880] Batch Translation Loss:   5.948997 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:05:38,925 [Epoch: 023 Step: 00003881] Batch Translation Loss:   5.826596 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:06:19,269 [Epoch: 023 Step: 00003882] Batch Translation Loss:   5.597450 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:06:57,521 [Epoch: 023 Step: 00003883] Batch Translation Loss:   6.217192 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:07:32,421 [Epoch: 023 Step: 00003884] Batch Translation Loss:   5.894483 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:08:13,608 [Epoch: 023 Step: 00003885] Batch Translation Loss:   5.241358 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:08:55,320 [Epoch: 023 Step: 00003886] Batch Translation Loss:   6.152084 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:10:03,125 [Epoch: 023 Step: 00003887] Batch Translation Loss:   5.815633 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:10:45,888 [Epoch: 023 Step: 00003888] Batch Translation Loss:   6.456147 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:11:30,572 [Epoch: 023 Step: 00003889] Batch Translation Loss:   5.714979 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:12:15,448 [Epoch: 023 Step: 00003890] Batch Translation Loss:   5.830174 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:13:01,573 [Epoch: 023 Step: 00003891] Batch Translation Loss:   5.369864 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:13:47,412 [Epoch: 023 Step: 00003892] Batch Translation Loss:   6.180558 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:14:31,338 [Epoch: 023 Step: 00003893] Batch Translation Loss:   6.270319 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:15:12,106 [Epoch: 023 Step: 00003894] Batch Translation Loss:   5.639108 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:16:12,674 [Epoch: 023 Step: 00003895] Batch Translation Loss:   5.451148 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:16:45,984 [Epoch: 023 Step: 00003896] Batch Translation Loss:   5.977805 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:17:37,217 [Epoch: 023 Step: 00003897] Batch Translation Loss:   5.495908 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:18:36,327 [Epoch: 023 Step: 00003898] Batch Translation Loss:   5.441529 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:19:19,904 [Epoch: 023 Step: 00003899] Batch Translation Loss:   6.750200 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:20:03,793 [Epoch: 023 Step: 00003900] Batch Translation Loss:   6.366870 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:29:17,698 Validation result at epoch  23, step     3900: duration: 553.9015s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 12726.78906	PPL: 21460.56445
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 0.86	(DEL: 24.53,	INS: 0.00,	SUB: 74.61)
	Sequence Accuracy 1.04
2022-01-04 19:29:23,303 Logging Recognition and Translation Outputs
2022-01-04 19:29:23,304 ========================================================================================================================
2022-01-04 19:29:23,304 Logging Sequence: youtube_1-catherine_mackinnon_2784
2022-01-04 19:29:23,304 	Text Reference  :	by
2022-01-04 19:29:23,304 	Text Hypothesis :	if
2022-01-04 19:29:23,305 	Text Alignment  :	S 
2022-01-04 19:29:23,305 ========================================================================================================================
2022-01-04 19:29:23,305 Logging Sequence: youtube_1-don_grushkin_2766
2022-01-04 19:29:23,305 	Text Reference  :	matosead
2022-01-04 19:29:23,305 	Text Hypothesis :	if      
2022-01-04 19:29:23,305 	Text Alignment  :	S       
2022-01-04 19:29:23,305 ========================================================================================================================
2022-01-04 19:29:23,305 Logging Sequence: deafvideo_3-titans_4701
2022-01-04 19:29:23,306 	Text Reference  :	are all
2022-01-04 19:29:23,306 	Text Hypothesis :	*** asl
2022-01-04 19:29:23,306 	Text Alignment  :	D   S  
2022-01-04 19:29:23,306 ========================================================================================================================
2022-01-04 19:29:23,306 Logging Sequence: deafvideo_2-fairytales9_2284
2022-01-04 19:29:23,306 	Text Reference  :	rollovers
2022-01-04 19:29:23,306 	Text Hypothesis :	if       
2022-01-04 19:29:23,306 	Text Alignment  :	S        
2022-01-04 19:29:23,306 ========================================================================================================================
2022-01-04 19:29:23,306 Logging Sequence: youtube_1-melvin_patterson_2357
2022-01-04 19:29:23,307 	Text Reference  :	yap
2022-01-04 19:29:23,307 	Text Hypothesis :	asl
2022-01-04 19:29:23,307 	Text Alignment  :	S  
2022-01-04 19:29:23,307 ========================================================================================================================
2022-01-04 19:30:12,448 [Epoch: 023 Step: 00003901] Batch Translation Loss:   5.579820 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:30:55,858 [Epoch: 023 Step: 00003902] Batch Translation Loss:   5.741581 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:31:40,143 [Epoch: 023 Step: 00003903] Batch Translation Loss:   5.916709 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:33:08,872 [Epoch: 023 Step: 00003904] Batch Translation Loss:   6.338441 => Txt Tokens per Sec:        0 || Lr: 0.000490
2022-01-04 19:33:53,427 [Epoch: 023 Step: 00003905] Batch Translation Loss:   6.085664 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:34:45,694 [Epoch: 023 Step: 00003906] Batch Translation Loss:   6.242335 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:35:32,296 [Epoch: 023 Step: 00003907] Batch Translation Loss:   6.039440 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:36:27,187 [Epoch: 023 Step: 00003908] Batch Translation Loss:   5.990322 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:37:24,914 [Epoch: 023 Step: 00003909] Batch Translation Loss:   6.124482 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:37:25,031 Epoch  23: Total Training Recognition Loss -1.00  Total Training Translation Loss 1007.20 
2022-01-04 19:37:25,031 EPOCH 24
2022-01-04 19:37:32,102 [Epoch: 024 Step: 00003910] Batch Translation Loss:   5.804618 => Txt Tokens per Sec:        5 || Lr: 0.000490
2022-01-04 19:37:39,385 [Epoch: 024 Step: 00003911] Batch Translation Loss:   6.139348 => Txt Tokens per Sec:        6 || Lr: 0.000490
2022-01-04 19:37:53,250 [Epoch: 024 Step: 00003912] Batch Translation Loss:   6.568958 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 19:38:07,439 [Epoch: 024 Step: 00003913] Batch Translation Loss:   6.024652 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 19:38:25,461 [Epoch: 024 Step: 00003914] Batch Translation Loss:   6.208740 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 19:38:38,680 [Epoch: 024 Step: 00003915] Batch Translation Loss:   5.999216 => Txt Tokens per Sec:        4 || Lr: 0.000490
2022-01-04 19:38:58,991 [Epoch: 024 Step: 00003916] Batch Translation Loss:   6.023315 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:39:19,147 [Epoch: 024 Step: 00003917] Batch Translation Loss:   6.139726 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:39:34,853 [Epoch: 024 Step: 00003918] Batch Translation Loss:   5.925094 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 19:39:59,532 [Epoch: 024 Step: 00003919] Batch Translation Loss:   5.926876 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:40:21,909 [Epoch: 024 Step: 00003920] Batch Translation Loss:   6.109652 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:40:42,222 [Epoch: 024 Step: 00003921] Batch Translation Loss:   6.083642 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:41:04,476 [Epoch: 024 Step: 00003922] Batch Translation Loss:   5.486283 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:41:23,426 [Epoch: 024 Step: 00003923] Batch Translation Loss:   5.654729 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:41:44,170 [Epoch: 024 Step: 00003924] Batch Translation Loss:   6.391447 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:42:00,826 [Epoch: 024 Step: 00003925] Batch Translation Loss:   6.069312 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 19:42:15,940 [Epoch: 024 Step: 00003926] Batch Translation Loss:   5.961691 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:42:40,337 [Epoch: 024 Step: 00003927] Batch Translation Loss:   6.615405 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:42:57,349 [Epoch: 024 Step: 00003928] Batch Translation Loss:   5.748861 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:43:16,447 [Epoch: 024 Step: 00003929] Batch Translation Loss:   6.060419 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:43:46,165 [Epoch: 024 Step: 00003930] Batch Translation Loss:   5.584777 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:44:01,465 [Epoch: 024 Step: 00003931] Batch Translation Loss:   5.456192 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 19:44:14,682 [Epoch: 024 Step: 00003932] Batch Translation Loss:   5.953195 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 19:44:35,632 [Epoch: 024 Step: 00003933] Batch Translation Loss:   6.189350 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:44:47,290 [Epoch: 024 Step: 00003934] Batch Translation Loss:   6.100327 => Txt Tokens per Sec:        4 || Lr: 0.000490
2022-01-04 19:44:57,713 [Epoch: 024 Step: 00003935] Batch Translation Loss:   5.349807 => Txt Tokens per Sec:        4 || Lr: 0.000490
2022-01-04 19:45:27,714 [Epoch: 024 Step: 00003936] Batch Translation Loss:   5.933796 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:45:49,190 [Epoch: 024 Step: 00003937] Batch Translation Loss:   5.229002 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:46:09,888 [Epoch: 024 Step: 00003938] Batch Translation Loss:   5.389426 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:46:21,894 [Epoch: 024 Step: 00003939] Batch Translation Loss:   5.917516 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 19:46:35,746 [Epoch: 024 Step: 00003940] Batch Translation Loss:   5.822881 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 19:47:01,196 [Epoch: 024 Step: 00003941] Batch Translation Loss:   6.193274 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:47:16,197 [Epoch: 024 Step: 00003942] Batch Translation Loss:   5.994960 => Txt Tokens per Sec:        4 || Lr: 0.000490
2022-01-04 19:47:32,344 [Epoch: 024 Step: 00003943] Batch Translation Loss:   5.620178 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 19:47:48,246 [Epoch: 024 Step: 00003944] Batch Translation Loss:   6.166791 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 19:48:03,126 [Epoch: 024 Step: 00003945] Batch Translation Loss:   6.086880 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:48:26,249 [Epoch: 024 Step: 00003946] Batch Translation Loss:   6.163833 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:48:39,938 [Epoch: 024 Step: 00003947] Batch Translation Loss:   5.950803 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 19:48:53,370 [Epoch: 024 Step: 00003948] Batch Translation Loss:   5.823402 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 19:49:19,899 [Epoch: 024 Step: 00003949] Batch Translation Loss:   6.100985 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:49:38,040 [Epoch: 024 Step: 00003950] Batch Translation Loss:   6.016951 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:49:54,948 [Epoch: 024 Step: 00003951] Batch Translation Loss:   6.187751 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:50:12,851 [Epoch: 024 Step: 00003952] Batch Translation Loss:   5.100641 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 19:50:31,204 [Epoch: 024 Step: 00003953] Batch Translation Loss:   6.089773 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 19:50:48,084 [Epoch: 024 Step: 00003954] Batch Translation Loss:   5.948221 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:51:20,388 [Epoch: 024 Step: 00003955] Batch Translation Loss:   5.879009 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:51:34,440 [Epoch: 024 Step: 00003956] Batch Translation Loss:   5.862464 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 19:51:52,129 [Epoch: 024 Step: 00003957] Batch Translation Loss:   6.084037 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:52:09,713 [Epoch: 024 Step: 00003958] Batch Translation Loss:   6.046168 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:52:26,235 [Epoch: 024 Step: 00003959] Batch Translation Loss:   5.814600 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:53:03,362 [Epoch: 024 Step: 00003960] Batch Translation Loss:   6.286511 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:53:26,554 [Epoch: 024 Step: 00003961] Batch Translation Loss:   5.779545 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:53:47,539 [Epoch: 024 Step: 00003962] Batch Translation Loss:   5.660601 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:54:03,986 [Epoch: 024 Step: 00003963] Batch Translation Loss:   5.458942 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:54:25,872 [Epoch: 024 Step: 00003964] Batch Translation Loss:   5.773707 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:54:53,369 [Epoch: 024 Step: 00003965] Batch Translation Loss:   5.463511 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:55:20,379 [Epoch: 024 Step: 00003966] Batch Translation Loss:   5.746395 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:55:42,958 [Epoch: 024 Step: 00003967] Batch Translation Loss:   5.960381 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:56:14,613 [Epoch: 024 Step: 00003968] Batch Translation Loss:   6.118047 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:56:38,105 [Epoch: 024 Step: 00003969] Batch Translation Loss:   6.103709 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:56:58,701 [Epoch: 024 Step: 00003970] Batch Translation Loss:   6.022070 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:57:17,681 [Epoch: 024 Step: 00003971] Batch Translation Loss:   6.450255 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:57:48,440 [Epoch: 024 Step: 00003972] Batch Translation Loss:   5.503456 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:58:12,608 [Epoch: 024 Step: 00003973] Batch Translation Loss:   6.161144 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 19:58:38,401 [Epoch: 024 Step: 00003974] Batch Translation Loss:   5.236650 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:59:08,612 [Epoch: 024 Step: 00003975] Batch Translation Loss:   6.047442 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 19:59:40,730 [Epoch: 024 Step: 00003976] Batch Translation Loss:   5.729220 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:00:03,074 [Epoch: 024 Step: 00003977] Batch Translation Loss:   6.033088 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 20:00:30,972 [Epoch: 024 Step: 00003978] Batch Translation Loss:   5.740390 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:01:22,249 [Epoch: 024 Step: 00003979] Batch Translation Loss:   5.234816 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:02:08,776 [Epoch: 024 Step: 00003980] Batch Translation Loss:   5.844258 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:02:42,107 [Epoch: 024 Step: 00003981] Batch Translation Loss:   5.311443 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:03:32,352 [Epoch: 024 Step: 00003982] Batch Translation Loss:   5.659509 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:04:07,123 [Epoch: 024 Step: 00003983] Batch Translation Loss:   5.484535 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:04:37,916 [Epoch: 024 Step: 00003984] Batch Translation Loss:   5.971443 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:05:00,482 [Epoch: 024 Step: 00003985] Batch Translation Loss:   5.914245 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 20:06:00,216 [Epoch: 024 Step: 00003986] Batch Translation Loss:   6.201575 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:06:54,625 [Epoch: 024 Step: 00003987] Batch Translation Loss:   6.280111 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:07:21,054 [Epoch: 024 Step: 00003988] Batch Translation Loss:   5.408300 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:07:43,535 [Epoch: 024 Step: 00003989] Batch Translation Loss:   5.542517 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 20:08:20,446 [Epoch: 024 Step: 00003990] Batch Translation Loss:   5.992194 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:08:43,109 [Epoch: 024 Step: 00003991] Batch Translation Loss:   5.421530 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:09:16,335 [Epoch: 024 Step: 00003992] Batch Translation Loss:   6.167840 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:09:51,066 [Epoch: 024 Step: 00003993] Batch Translation Loss:   5.474690 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:10:16,581 [Epoch: 024 Step: 00003994] Batch Translation Loss:   6.074148 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:10:47,222 [Epoch: 024 Step: 00003995] Batch Translation Loss:   5.958270 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:11:23,742 [Epoch: 024 Step: 00003996] Batch Translation Loss:   6.131895 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:11:52,315 [Epoch: 024 Step: 00003997] Batch Translation Loss:   5.864935 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:12:43,467 [Epoch: 024 Step: 00003998] Batch Translation Loss:   5.561445 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:13:12,697 [Epoch: 024 Step: 00003999] Batch Translation Loss:   5.608484 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:13:46,879 [Epoch: 024 Step: 00004000] Batch Translation Loss:   5.808910 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:22:02,444 Validation result at epoch  24, step     4000: duration: 495.5634s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 12440.56348	PPL: 19408.44531
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 0.56	(DEL: 23.25,	INS: 0.00,	SUB: 76.19)
	Sequence Accuracy 0.52
2022-01-04 20:22:07,630 Logging Recognition and Translation Outputs
2022-01-04 20:22:07,630 ========================================================================================================================
2022-01-04 20:22:07,630 Logging Sequence: deafvideo_2-deafpoweronethumbtwo_1787
2022-01-04 20:22:07,630 	Text Reference  :	fuck you
2022-01-04 20:22:07,631 	Text Hypothesis :	**** it 
2022-01-04 20:22:07,631 	Text Alignment  :	D    S  
2022-01-04 20:22:07,631 ========================================================================================================================
2022-01-04 20:22:07,631 Logging Sequence: youtube_5-roberta_cordano_6126
2022-01-04 20:22:07,631 	Text Reference  :	whine
2022-01-04 20:22:07,631 	Text Hypothesis :	if   
2022-01-04 20:22:07,631 	Text Alignment  :	S    
2022-01-04 20:22:07,631 ========================================================================================================================
2022-01-04 20:22:07,631 Logging Sequence: youtube_5-daniel_durant_5876
2022-01-04 20:22:07,631 	Text Reference  :	violence
2022-01-04 20:22:07,632 	Text Hypothesis :	if      
2022-01-04 20:22:07,632 	Text Alignment  :	S       
2022-01-04 20:22:07,632 ========================================================================================================================
2022-01-04 20:22:07,632 Logging Sequence: youtube_5-jeffrey_spinale_6052
2022-01-04 20:22:07,632 	Text Reference  :	deanne bray
2022-01-04 20:22:07,632 	Text Hypothesis :	****** it  
2022-01-04 20:22:07,632 	Text Alignment  :	D      S   
2022-01-04 20:22:07,632 ========================================================================================================================
2022-01-04 20:22:07,632 Logging Sequence: aslized-joy_maisel_6432
2022-01-04 20:22:07,632 	Text Reference  :	demend it
2022-01-04 20:22:07,632 	Text Hypothesis :	****** it
2022-01-04 20:22:07,633 	Text Alignment  :	D        
2022-01-04 20:22:07,633 ========================================================================================================================
2022-01-04 20:22:35,923 [Epoch: 024 Step: 00004001] Batch Translation Loss:   5.825384 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:23:02,037 [Epoch: 024 Step: 00004002] Batch Translation Loss:   6.287593 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:23:24,069 [Epoch: 024 Step: 00004003] Batch Translation Loss:   6.224363 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 20:23:49,293 [Epoch: 024 Step: 00004004] Batch Translation Loss:   5.752019 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 20:24:17,183 [Epoch: 024 Step: 00004005] Batch Translation Loss:   5.537703 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:24:40,274 [Epoch: 024 Step: 00004006] Batch Translation Loss:   5.704868 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 20:25:08,528 [Epoch: 024 Step: 00004007] Batch Translation Loss:   5.554310 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:25:37,100 [Epoch: 024 Step: 00004008] Batch Translation Loss:   6.071398 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:26:02,879 [Epoch: 024 Step: 00004009] Batch Translation Loss:   6.006872 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 20:26:32,912 [Epoch: 024 Step: 00004010] Batch Translation Loss:   5.863819 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:27:00,616 [Epoch: 024 Step: 00004011] Batch Translation Loss:   6.231298 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:27:31,082 [Epoch: 024 Step: 00004012] Batch Translation Loss:   5.887457 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:28:22,486 [Epoch: 024 Step: 00004013] Batch Translation Loss:   5.616769 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:28:54,667 [Epoch: 024 Step: 00004014] Batch Translation Loss:   6.402280 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:29:54,333 [Epoch: 024 Step: 00004015] Batch Translation Loss:   5.641294 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:30:23,094 [Epoch: 024 Step: 00004016] Batch Translation Loss:   5.831823 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:30:50,628 [Epoch: 024 Step: 00004017] Batch Translation Loss:   6.028132 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 20:31:21,322 [Epoch: 024 Step: 00004018] Batch Translation Loss:   5.538470 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:31:52,966 [Epoch: 024 Step: 00004019] Batch Translation Loss:   6.079613 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:32:23,033 [Epoch: 024 Step: 00004020] Batch Translation Loss:   6.143239 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:33:06,092 [Epoch: 024 Step: 00004021] Batch Translation Loss:   5.322124 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:33:39,589 [Epoch: 024 Step: 00004022] Batch Translation Loss:   5.460967 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:34:12,843 [Epoch: 024 Step: 00004023] Batch Translation Loss:   5.875362 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:34:48,004 [Epoch: 024 Step: 00004024] Batch Translation Loss:   5.645004 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:35:26,594 [Epoch: 024 Step: 00004025] Batch Translation Loss:   5.422765 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:36:08,310 [Epoch: 024 Step: 00004026] Batch Translation Loss:   5.440007 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:36:43,740 [Epoch: 024 Step: 00004027] Batch Translation Loss:   5.989842 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:37:32,074 [Epoch: 024 Step: 00004028] Batch Translation Loss:   6.188311 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:38:08,699 [Epoch: 024 Step: 00004029] Batch Translation Loss:   5.945508 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:39:00,470 [Epoch: 024 Step: 00004030] Batch Translation Loss:   5.557397 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:39:34,486 [Epoch: 024 Step: 00004031] Batch Translation Loss:   6.207388 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:40:10,732 [Epoch: 024 Step: 00004032] Batch Translation Loss:   6.420323 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:40:49,600 [Epoch: 024 Step: 00004033] Batch Translation Loss:   5.838334 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:41:22,363 [Epoch: 024 Step: 00004034] Batch Translation Loss:   5.808994 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:41:58,603 [Epoch: 024 Step: 00004035] Batch Translation Loss:   5.675920 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:42:41,522 [Epoch: 024 Step: 00004036] Batch Translation Loss:   5.821279 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:43:28,518 [Epoch: 024 Step: 00004037] Batch Translation Loss:   6.496069 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:43:56,362 [Epoch: 024 Step: 00004038] Batch Translation Loss:   6.135709 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:44:26,630 [Epoch: 024 Step: 00004039] Batch Translation Loss:   5.885758 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:44:58,691 [Epoch: 024 Step: 00004040] Batch Translation Loss:   5.746881 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:46:09,285 [Epoch: 024 Step: 00004041] Batch Translation Loss:   5.676260 => Txt Tokens per Sec:        0 || Lr: 0.000490
2022-01-04 20:46:40,637 [Epoch: 024 Step: 00004042] Batch Translation Loss:   5.946882 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:47:11,619 [Epoch: 024 Step: 00004043] Batch Translation Loss:   5.617361 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:47:43,667 [Epoch: 024 Step: 00004044] Batch Translation Loss:   6.156003 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:48:14,189 [Epoch: 024 Step: 00004045] Batch Translation Loss:   6.235899 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:48:43,124 [Epoch: 024 Step: 00004046] Batch Translation Loss:   6.537544 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:49:18,398 [Epoch: 024 Step: 00004047] Batch Translation Loss:   5.775630 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:49:52,441 [Epoch: 024 Step: 00004048] Batch Translation Loss:   5.479330 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:50:27,142 [Epoch: 024 Step: 00004049] Batch Translation Loss:   5.743775 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:51:29,816 [Epoch: 024 Step: 00004050] Batch Translation Loss:   5.993837 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:52:03,406 [Epoch: 024 Step: 00004051] Batch Translation Loss:   5.504295 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:52:40,411 [Epoch: 024 Step: 00004052] Batch Translation Loss:   5.575586 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:53:15,495 [Epoch: 024 Step: 00004053] Batch Translation Loss:   6.303946 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:54:33,611 [Epoch: 024 Step: 00004054] Batch Translation Loss:   6.078655 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:55:53,124 [Epoch: 024 Step: 00004055] Batch Translation Loss:   6.116179 => Txt Tokens per Sec:        0 || Lr: 0.000490
2022-01-04 20:56:35,785 [Epoch: 024 Step: 00004056] Batch Translation Loss:   5.905062 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:57:26,157 [Epoch: 024 Step: 00004057] Batch Translation Loss:   6.009800 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:58:20,428 [Epoch: 024 Step: 00004058] Batch Translation Loss:   5.221225 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 20:59:00,741 [Epoch: 024 Step: 00004059] Batch Translation Loss:   5.938910 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:00:18,740 [Epoch: 024 Step: 00004060] Batch Translation Loss:   6.151134 => Txt Tokens per Sec:        0 || Lr: 0.000490
2022-01-04 21:01:01,657 [Epoch: 024 Step: 00004061] Batch Translation Loss:   6.088301 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:01:40,523 [Epoch: 024 Step: 00004062] Batch Translation Loss:   5.944820 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:02:20,621 [Epoch: 024 Step: 00004063] Batch Translation Loss:   5.997573 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:03:13,964 [Epoch: 024 Step: 00004064] Batch Translation Loss:   6.149004 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:03:53,827 [Epoch: 024 Step: 00004065] Batch Translation Loss:   5.747016 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:04:35,107 [Epoch: 024 Step: 00004066] Batch Translation Loss:   5.802196 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:05:21,512 [Epoch: 024 Step: 00004067] Batch Translation Loss:   6.133576 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:05:54,677 [Epoch: 024 Step: 00004068] Batch Translation Loss:   5.985985 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:06:32,792 [Epoch: 024 Step: 00004069] Batch Translation Loss:   5.612044 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:07:16,863 [Epoch: 024 Step: 00004070] Batch Translation Loss:   5.592794 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:08:15,251 [Epoch: 024 Step: 00004071] Batch Translation Loss:   5.827889 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:09:13,552 [Epoch: 024 Step: 00004072] Batch Translation Loss:   5.816568 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:10:41,160 [Epoch: 024 Step: 00004073] Batch Translation Loss:   6.388946 => Txt Tokens per Sec:        0 || Lr: 0.000490
2022-01-04 21:11:30,133 [Epoch: 024 Step: 00004074] Batch Translation Loss:   6.218828 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:12:13,694 [Epoch: 024 Step: 00004075] Batch Translation Loss:   5.349119 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:13:08,320 [Epoch: 024 Step: 00004076] Batch Translation Loss:   5.783823 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:13:56,122 [Epoch: 024 Step: 00004077] Batch Translation Loss:   5.818400 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:15:17,690 [Epoch: 024 Step: 00004078] Batch Translation Loss:   6.199722 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:16:39,564 [Epoch: 024 Step: 00004079] Batch Translation Loss:   6.838170 => Txt Tokens per Sec:        0 || Lr: 0.000490
2022-01-04 21:16:39,874 Epoch  24: Total Training Recognition Loss -1.00  Total Training Translation Loss 1001.57 
2022-01-04 21:16:39,874 EPOCH 25
2022-01-04 21:16:47,291 [Epoch: 025 Step: 00004080] Batch Translation Loss:   5.187346 => Txt Tokens per Sec:        6 || Lr: 0.000490
2022-01-04 21:17:02,818 [Epoch: 025 Step: 00004081] Batch Translation Loss:   6.244676 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 21:17:11,948 [Epoch: 025 Step: 00004082] Batch Translation Loss:   5.957700 => Txt Tokens per Sec:        4 || Lr: 0.000490
2022-01-04 21:17:28,804 [Epoch: 025 Step: 00004083] Batch Translation Loss:   5.460618 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 21:17:40,537 [Epoch: 025 Step: 00004084] Batch Translation Loss:   6.372869 => Txt Tokens per Sec:        4 || Lr: 0.000490
2022-01-04 21:17:56,754 [Epoch: 025 Step: 00004085] Batch Translation Loss:   6.095949 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 21:18:14,594 [Epoch: 025 Step: 00004086] Batch Translation Loss:   6.288755 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 21:18:25,947 [Epoch: 025 Step: 00004087] Batch Translation Loss:   6.095021 => Txt Tokens per Sec:        4 || Lr: 0.000490
2022-01-04 21:18:45,580 [Epoch: 025 Step: 00004088] Batch Translation Loss:   6.384741 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 21:18:57,903 [Epoch: 025 Step: 00004089] Batch Translation Loss:   6.000982 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 21:19:15,535 [Epoch: 025 Step: 00004090] Batch Translation Loss:   6.436236 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:19:28,166 [Epoch: 025 Step: 00004091] Batch Translation Loss:   5.665836 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 21:19:43,179 [Epoch: 025 Step: 00004092] Batch Translation Loss:   5.619223 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:20:02,414 [Epoch: 025 Step: 00004093] Batch Translation Loss:   5.673338 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:20:17,866 [Epoch: 025 Step: 00004094] Batch Translation Loss:   5.703192 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:20:41,893 [Epoch: 025 Step: 00004095] Batch Translation Loss:   5.976720 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:21:05,161 [Epoch: 025 Step: 00004096] Batch Translation Loss:   6.189661 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:21:17,514 [Epoch: 025 Step: 00004097] Batch Translation Loss:   5.455313 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 21:21:41,275 [Epoch: 025 Step: 00004098] Batch Translation Loss:   5.946556 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:21:53,978 [Epoch: 025 Step: 00004099] Batch Translation Loss:   6.027651 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 21:22:14,125 [Epoch: 025 Step: 00004100] Batch Translation Loss:   5.677518 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:31:08,850 Validation result at epoch  25, step     4100: duration: 534.7227s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 12561.44336	PPL: 16942.02734
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.09	(DEL: 25.89,	INS: 0.00,	SUB: 73.02)
	Sequence Accuracy 1.26
2022-01-04 21:31:16,076 Logging Recognition and Translation Outputs
2022-01-04 21:31:16,080 ========================================================================================================================
2022-01-04 21:31:16,080 Logging Sequence: youtube_3-ben_bahan_4530
2022-01-04 21:31:16,081 	Text Reference  :	nikons
2022-01-04 21:31:16,081 	Text Hypothesis :	if    
2022-01-04 21:31:16,081 	Text Alignment  :	S     
2022-01-04 21:31:16,082 ========================================================================================================================
2022-01-04 21:31:16,082 Logging Sequence: deafvideo_2-sddsimple_1572
2022-01-04 21:31:16,082 	Text Reference  :	jd
2022-01-04 21:31:16,082 	Text Hypothesis :	if
2022-01-04 21:31:16,082 	Text Alignment  :	S 
2022-01-04 21:31:16,082 ========================================================================================================================
2022-01-04 21:31:16,083 Logging Sequence: deafvideo_5-scottnorby_6462
2022-01-04 21:31:16,083 	Text Reference  :	tool
2022-01-04 21:31:16,083 	Text Hypothesis :	if  
2022-01-04 21:31:16,083 	Text Alignment  :	S   
2022-01-04 21:31:16,083 ========================================================================================================================
2022-01-04 21:31:16,083 Logging Sequence: deafvideo_2-fairytales9_2299
2022-01-04 21:31:16,084 	Text Reference  :	kathyjo
2022-01-04 21:31:16,084 	Text Hypothesis :	awti   
2022-01-04 21:31:16,084 	Text Alignment  :	S      
2022-01-04 21:31:16,084 ========================================================================================================================
2022-01-04 21:31:16,084 Logging Sequence: aslized-suzanne_stecker_0280
2022-01-04 21:31:16,084 	Text Reference  :	faceles
2022-01-04 21:31:16,085 	Text Hypothesis :	if     
2022-01-04 21:31:16,085 	Text Alignment  :	S      
2022-01-04 21:31:16,085 ========================================================================================================================
2022-01-04 21:31:32,141 [Epoch: 025 Step: 00004101] Batch Translation Loss:   5.782526 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:31:54,530 [Epoch: 025 Step: 00004102] Batch Translation Loss:   6.182190 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:32:08,419 [Epoch: 025 Step: 00004103] Batch Translation Loss:   6.462253 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 21:32:28,295 [Epoch: 025 Step: 00004104] Batch Translation Loss:   6.461488 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:33:00,474 [Epoch: 025 Step: 00004105] Batch Translation Loss:   6.033472 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:33:22,774 [Epoch: 025 Step: 00004106] Batch Translation Loss:   5.938442 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:33:37,014 [Epoch: 025 Step: 00004107] Batch Translation Loss:   6.275292 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 21:34:00,799 [Epoch: 025 Step: 00004108] Batch Translation Loss:   5.654145 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:34:15,631 [Epoch: 025 Step: 00004109] Batch Translation Loss:   5.936314 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 21:34:47,368 [Epoch: 025 Step: 00004110] Batch Translation Loss:   6.063802 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:35:10,636 [Epoch: 025 Step: 00004111] Batch Translation Loss:   5.939332 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:35:26,039 [Epoch: 025 Step: 00004112] Batch Translation Loss:   5.797117 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:35:46,653 [Epoch: 025 Step: 00004113] Batch Translation Loss:   5.567555 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:36:05,141 [Epoch: 025 Step: 00004114] Batch Translation Loss:   6.064039 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:36:40,655 [Epoch: 025 Step: 00004115] Batch Translation Loss:   6.059058 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:37:01,427 [Epoch: 025 Step: 00004116] Batch Translation Loss:   6.043371 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:37:20,234 [Epoch: 025 Step: 00004117] Batch Translation Loss:   5.644969 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:37:42,551 [Epoch: 025 Step: 00004118] Batch Translation Loss:   5.974423 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:38:03,743 [Epoch: 025 Step: 00004119] Batch Translation Loss:   5.520546 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:38:35,621 [Epoch: 025 Step: 00004120] Batch Translation Loss:   5.248002 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:38:56,175 [Epoch: 025 Step: 00004121] Batch Translation Loss:   5.836298 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:39:16,794 [Epoch: 025 Step: 00004122] Batch Translation Loss:   5.284277 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:39:49,180 [Epoch: 025 Step: 00004123] Batch Translation Loss:   5.590911 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:40:17,522 [Epoch: 025 Step: 00004124] Batch Translation Loss:   5.828277 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:40:35,328 [Epoch: 025 Step: 00004125] Batch Translation Loss:   5.826660 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:41:02,306 [Epoch: 025 Step: 00004126] Batch Translation Loss:   5.549108 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:41:33,257 [Epoch: 025 Step: 00004127] Batch Translation Loss:   5.838715 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:42:14,347 [Epoch: 025 Step: 00004128] Batch Translation Loss:   5.802034 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:42:38,747 [Epoch: 025 Step: 00004129] Batch Translation Loss:   5.764025 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:42:59,440 [Epoch: 025 Step: 00004130] Batch Translation Loss:   6.097374 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:43:23,263 [Epoch: 025 Step: 00004131] Batch Translation Loss:   5.843412 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:43:50,873 [Epoch: 025 Step: 00004132] Batch Translation Loss:   5.827369 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:44:20,209 [Epoch: 025 Step: 00004133] Batch Translation Loss:   5.134100 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:44:42,828 [Epoch: 025 Step: 00004134] Batch Translation Loss:   5.850101 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:45:13,423 [Epoch: 025 Step: 00004135] Batch Translation Loss:   5.582815 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:45:40,672 [Epoch: 025 Step: 00004136] Batch Translation Loss:   6.137825 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:46:25,877 [Epoch: 025 Step: 00004137] Batch Translation Loss:   5.858034 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:46:52,438 [Epoch: 025 Step: 00004138] Batch Translation Loss:   5.507388 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:47:13,155 [Epoch: 025 Step: 00004139] Batch Translation Loss:   5.362034 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:47:43,698 [Epoch: 025 Step: 00004140] Batch Translation Loss:   5.973892 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:48:12,869 [Epoch: 025 Step: 00004141] Batch Translation Loss:   6.361959 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:48:37,103 [Epoch: 025 Step: 00004142] Batch Translation Loss:   5.563350 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:49:07,949 [Epoch: 025 Step: 00004143] Batch Translation Loss:   5.641218 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:49:39,261 [Epoch: 025 Step: 00004144] Batch Translation Loss:   5.585084 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:50:04,340 [Epoch: 025 Step: 00004145] Batch Translation Loss:   5.711944 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:50:31,715 [Epoch: 025 Step: 00004146] Batch Translation Loss:   6.127874 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:51:00,020 [Epoch: 025 Step: 00004147] Batch Translation Loss:   5.820703 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:51:25,511 [Epoch: 025 Step: 00004148] Batch Translation Loss:   5.229110 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:51:58,296 [Epoch: 025 Step: 00004149] Batch Translation Loss:   6.748096 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:52:30,924 [Epoch: 025 Step: 00004150] Batch Translation Loss:   5.735923 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:53:01,526 [Epoch: 025 Step: 00004151] Batch Translation Loss:   5.968972 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:53:26,822 [Epoch: 025 Step: 00004152] Batch Translation Loss:   6.168816 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:53:58,420 [Epoch: 025 Step: 00004153] Batch Translation Loss:   6.066319 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:54:24,892 [Epoch: 025 Step: 00004154] Batch Translation Loss:   6.260536 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 21:54:51,957 [Epoch: 025 Step: 00004155] Batch Translation Loss:   6.178807 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:55:24,998 [Epoch: 025 Step: 00004156] Batch Translation Loss:   5.882474 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:56:14,346 [Epoch: 025 Step: 00004157] Batch Translation Loss:   5.683551 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:56:53,245 [Epoch: 025 Step: 00004158] Batch Translation Loss:   5.796967 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:57:23,903 [Epoch: 025 Step: 00004159] Batch Translation Loss:   5.851351 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:57:53,933 [Epoch: 025 Step: 00004160] Batch Translation Loss:   5.675622 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:58:30,353 [Epoch: 025 Step: 00004161] Batch Translation Loss:   5.842782 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:59:04,916 [Epoch: 025 Step: 00004162] Batch Translation Loss:   5.985409 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 21:59:30,670 [Epoch: 025 Step: 00004163] Batch Translation Loss:   6.129759 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:00:01,703 [Epoch: 025 Step: 00004164] Batch Translation Loss:   6.018850 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:00:21,432 [Epoch: 025 Step: 00004165] Batch Translation Loss:   5.318252 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 22:00:43,079 [Epoch: 025 Step: 00004166] Batch Translation Loss:   5.904581 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 22:01:05,029 [Epoch: 025 Step: 00004167] Batch Translation Loss:   5.672648 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 22:01:28,641 [Epoch: 025 Step: 00004168] Batch Translation Loss:   5.697236 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 22:01:52,439 [Epoch: 025 Step: 00004169] Batch Translation Loss:   6.168102 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 22:02:13,692 [Epoch: 025 Step: 00004170] Batch Translation Loss:   5.555775 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 22:02:39,541 [Epoch: 025 Step: 00004171] Batch Translation Loss:   5.669235 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:03:04,526 [Epoch: 025 Step: 00004172] Batch Translation Loss:   5.437918 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 22:03:29,349 [Epoch: 025 Step: 00004173] Batch Translation Loss:   5.679634 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:03:55,030 [Epoch: 025 Step: 00004174] Batch Translation Loss:   6.565153 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:04:24,789 [Epoch: 025 Step: 00004175] Batch Translation Loss:   5.627135 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:04:50,694 [Epoch: 025 Step: 00004176] Batch Translation Loss:   5.858362 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:05:17,146 [Epoch: 025 Step: 00004177] Batch Translation Loss:   5.799511 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:05:42,967 [Epoch: 025 Step: 00004178] Batch Translation Loss:   5.762214 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:06:06,918 [Epoch: 025 Step: 00004179] Batch Translation Loss:   6.026873 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 22:06:34,134 [Epoch: 025 Step: 00004180] Batch Translation Loss:   6.220062 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:06:59,770 [Epoch: 025 Step: 00004181] Batch Translation Loss:   5.951077 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:07:25,281 [Epoch: 025 Step: 00004182] Batch Translation Loss:   5.856517 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:07:53,724 [Epoch: 025 Step: 00004183] Batch Translation Loss:   5.904727 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:08:18,596 [Epoch: 025 Step: 00004184] Batch Translation Loss:   6.510530 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 22:08:48,084 [Epoch: 025 Step: 00004185] Batch Translation Loss:   5.709259 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:09:20,271 [Epoch: 025 Step: 00004186] Batch Translation Loss:   5.458010 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:09:53,516 [Epoch: 025 Step: 00004187] Batch Translation Loss:   5.571560 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:10:16,867 [Epoch: 025 Step: 00004188] Batch Translation Loss:   5.938421 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 22:10:45,499 [Epoch: 025 Step: 00004189] Batch Translation Loss:   6.269934 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:11:11,654 [Epoch: 025 Step: 00004190] Batch Translation Loss:   5.990753 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:11:36,526 [Epoch: 025 Step: 00004191] Batch Translation Loss:   5.117624 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 22:12:05,872 [Epoch: 025 Step: 00004192] Batch Translation Loss:   6.046165 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:12:33,410 [Epoch: 025 Step: 00004193] Batch Translation Loss:   5.826649 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:13:07,592 [Epoch: 025 Step: 00004194] Batch Translation Loss:   5.576163 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:13:58,650 [Epoch: 025 Step: 00004195] Batch Translation Loss:   5.480589 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:14:31,266 [Epoch: 025 Step: 00004196] Batch Translation Loss:   6.163341 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:15:02,032 [Epoch: 025 Step: 00004197] Batch Translation Loss:   6.035750 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:16:01,050 [Epoch: 025 Step: 00004198] Batch Translation Loss:   5.840434 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:16:29,137 [Epoch: 025 Step: 00004199] Batch Translation Loss:   5.716887 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:17:17,711 [Epoch: 025 Step: 00004200] Batch Translation Loss:   5.831131 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:25:03,231 Validation result at epoch  25, step     4200: duration: 465.5188s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 12531.42090	PPL: 22587.14062
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 0.88	(DEL: 22.96,	INS: 0.00,	SUB: 76.16)
	Sequence Accuracy 0.93
2022-01-04 22:25:14,365 Logging Recognition and Translation Outputs
2022-01-04 22:25:14,366 ========================================================================================================================
2022-01-04 22:25:14,366 Logging Sequence: deafvideo_2-sddsimple_1571
2022-01-04 22:25:14,366 	Text Reference  :	ice
2022-01-04 22:25:14,366 	Text Hypothesis :	ok 
2022-01-04 22:25:14,366 	Text Alignment  :	S  
2022-01-04 22:25:14,366 ========================================================================================================================
2022-01-04 22:25:14,366 Logging Sequence: youtube_1-don_grushkin_2335
2022-01-04 22:25:14,367 	Text Reference  :	of all
2022-01-04 22:25:14,367 	Text Hypothesis :	** if 
2022-01-04 22:25:14,367 	Text Alignment  :	D  S  
2022-01-04 22:25:14,367 ========================================================================================================================
2022-01-04 22:25:14,367 Logging Sequence: deafvideo_2-goatman_1524
2022-01-04 22:25:14,367 	Text Reference  :	haker
2022-01-04 22:25:14,367 	Text Hypothesis :	ok   
2022-01-04 22:25:14,367 	Text Alignment  :	S    
2022-01-04 22:25:14,367 ========================================================================================================================
2022-01-04 22:25:14,368 Logging Sequence: youtube_5-daniel_durant_5891
2022-01-04 22:25:14,368 	Text Reference  :	media
2022-01-04 22:25:14,368 	Text Hypothesis :	asl  
2022-01-04 22:25:14,368 	Text Alignment  :	S    
2022-01-04 22:25:14,368 ========================================================================================================================
2022-01-04 22:25:14,368 Logging Sequence: youtube_1-catherine_mackinnon_2781
2022-01-04 22:25:14,368 	Text Reference  :	textfields
2022-01-04 22:25:14,368 	Text Hypothesis :	ok        
2022-01-04 22:25:14,368 	Text Alignment  :	S         
2022-01-04 22:25:14,369 ========================================================================================================================
2022-01-04 22:25:44,049 [Epoch: 025 Step: 00004201] Batch Translation Loss:   6.266829 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:26:22,252 [Epoch: 025 Step: 00004202] Batch Translation Loss:   6.478824 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:26:55,275 [Epoch: 025 Step: 00004203] Batch Translation Loss:   6.079311 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:27:27,687 [Epoch: 025 Step: 00004204] Batch Translation Loss:   5.903739 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:28:03,956 [Epoch: 025 Step: 00004205] Batch Translation Loss:   6.318840 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:28:52,032 [Epoch: 025 Step: 00004206] Batch Translation Loss:   6.087382 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:29:28,544 [Epoch: 025 Step: 00004207] Batch Translation Loss:   5.566678 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:30:02,718 [Epoch: 025 Step: 00004208] Batch Translation Loss:   5.577946 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:30:36,576 [Epoch: 025 Step: 00004209] Batch Translation Loss:   5.812591 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:31:16,187 [Epoch: 025 Step: 00004210] Batch Translation Loss:   6.032793 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:32:25,310 [Epoch: 025 Step: 00004211] Batch Translation Loss:   5.895046 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:32:58,882 [Epoch: 025 Step: 00004212] Batch Translation Loss:   6.047618 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:33:35,378 [Epoch: 025 Step: 00004213] Batch Translation Loss:   6.100860 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:34:20,507 [Epoch: 025 Step: 00004214] Batch Translation Loss:   6.217721 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:34:58,689 [Epoch: 025 Step: 00004215] Batch Translation Loss:   6.418479 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:35:33,360 [Epoch: 025 Step: 00004216] Batch Translation Loss:   5.878211 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:36:11,211 [Epoch: 025 Step: 00004217] Batch Translation Loss:   6.220893 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:36:57,529 [Epoch: 025 Step: 00004218] Batch Translation Loss:   5.252069 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:37:49,903 [Epoch: 025 Step: 00004219] Batch Translation Loss:   6.140664 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:38:30,981 [Epoch: 025 Step: 00004220] Batch Translation Loss:   5.676497 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:39:54,958 [Epoch: 025 Step: 00004221] Batch Translation Loss:   6.069495 => Txt Tokens per Sec:        0 || Lr: 0.000490
2022-01-04 22:40:37,660 [Epoch: 025 Step: 00004222] Batch Translation Loss:   5.918402 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:41:47,506 [Epoch: 025 Step: 00004223] Batch Translation Loss:   5.761990 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:42:29,378 [Epoch: 025 Step: 00004224] Batch Translation Loss:   5.969708 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:43:11,032 [Epoch: 025 Step: 00004225] Batch Translation Loss:   5.688967 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:44:03,747 [Epoch: 025 Step: 00004226] Batch Translation Loss:   6.228878 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:44:52,071 [Epoch: 025 Step: 00004227] Batch Translation Loss:   5.736113 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:45:34,108 [Epoch: 025 Step: 00004228] Batch Translation Loss:   5.765558 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:46:18,319 [Epoch: 025 Step: 00004229] Batch Translation Loss:   5.659696 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:47:19,594 [Epoch: 025 Step: 00004230] Batch Translation Loss:   5.502855 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:48:00,186 [Epoch: 025 Step: 00004231] Batch Translation Loss:   5.757808 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:48:43,122 [Epoch: 025 Step: 00004232] Batch Translation Loss:   5.675064 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:49:34,305 [Epoch: 025 Step: 00004233] Batch Translation Loss:   5.574564 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:50:13,882 [Epoch: 025 Step: 00004234] Batch Translation Loss:   5.327815 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:50:46,924 [Epoch: 025 Step: 00004235] Batch Translation Loss:   5.350966 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:51:21,287 [Epoch: 025 Step: 00004236] Batch Translation Loss:   5.492480 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:51:55,619 [Epoch: 025 Step: 00004237] Batch Translation Loss:   5.303409 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:52:32,032 [Epoch: 025 Step: 00004238] Batch Translation Loss:   5.821152 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:53:07,604 [Epoch: 025 Step: 00004239] Batch Translation Loss:   5.863795 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:53:43,188 [Epoch: 025 Step: 00004240] Batch Translation Loss:   6.116404 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:54:18,827 [Epoch: 025 Step: 00004241] Batch Translation Loss:   6.089653 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:54:58,670 [Epoch: 025 Step: 00004242] Batch Translation Loss:   5.807724 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:55:36,143 [Epoch: 025 Step: 00004243] Batch Translation Loss:   5.636457 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:56:12,950 [Epoch: 025 Step: 00004244] Batch Translation Loss:   5.632947 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:56:55,643 [Epoch: 025 Step: 00004245] Batch Translation Loss:   5.885552 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:57:31,521 [Epoch: 025 Step: 00004246] Batch Translation Loss:   5.334990 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 22:58:50,064 [Epoch: 025 Step: 00004247] Batch Translation Loss:   6.032187 => Txt Tokens per Sec:        0 || Lr: 0.000490
2022-01-04 22:59:43,685 [Epoch: 025 Step: 00004248] Batch Translation Loss:   6.298995 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:01:15,599 [Epoch: 025 Step: 00004249] Batch Translation Loss:   6.011710 => Txt Tokens per Sec:        0 || Lr: 0.000490
2022-01-04 23:01:15,865 Epoch  25: Total Training Recognition Loss -1.00  Total Training Translation Loss 996.68 
2022-01-04 23:01:15,866 EPOCH 26
2022-01-04 23:01:27,430 [Epoch: 026 Step: 00004250] Batch Translation Loss:   5.864750 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 23:01:36,605 [Epoch: 026 Step: 00004251] Batch Translation Loss:   6.020214 => Txt Tokens per Sec:        4 || Lr: 0.000490
2022-01-04 23:01:52,315 [Epoch: 026 Step: 00004252] Batch Translation Loss:   6.187634 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 23:02:00,745 [Epoch: 026 Step: 00004253] Batch Translation Loss:   6.161287 => Txt Tokens per Sec:        5 || Lr: 0.000490
2022-01-04 23:02:21,310 [Epoch: 026 Step: 00004254] Batch Translation Loss:   5.633776 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:02:32,895 [Epoch: 026 Step: 00004255] Batch Translation Loss:   6.042079 => Txt Tokens per Sec:        4 || Lr: 0.000490
2022-01-04 23:02:49,692 [Epoch: 026 Step: 00004256] Batch Translation Loss:   5.853724 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 23:03:03,433 [Epoch: 026 Step: 00004257] Batch Translation Loss:   5.551251 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 23:03:21,670 [Epoch: 026 Step: 00004258] Batch Translation Loss:   5.926132 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 23:03:41,841 [Epoch: 026 Step: 00004259] Batch Translation Loss:   5.871485 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 23:03:53,997 [Epoch: 026 Step: 00004260] Batch Translation Loss:   5.752501 => Txt Tokens per Sec:        4 || Lr: 0.000490
2022-01-04 23:04:16,444 [Epoch: 026 Step: 00004261] Batch Translation Loss:   5.835020 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:04:32,499 [Epoch: 026 Step: 00004262] Batch Translation Loss:   6.367424 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 23:04:50,334 [Epoch: 026 Step: 00004263] Batch Translation Loss:   5.679369 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 23:05:03,281 [Epoch: 026 Step: 00004264] Batch Translation Loss:   5.496431 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 23:05:24,713 [Epoch: 026 Step: 00004265] Batch Translation Loss:   5.797015 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:05:47,112 [Epoch: 026 Step: 00004266] Batch Translation Loss:   5.952450 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:05:59,268 [Epoch: 026 Step: 00004267] Batch Translation Loss:   5.443410 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 23:06:24,927 [Epoch: 026 Step: 00004268] Batch Translation Loss:   5.780206 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:06:49,254 [Epoch: 026 Step: 00004269] Batch Translation Loss:   5.886992 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:07:02,704 [Epoch: 026 Step: 00004270] Batch Translation Loss:   5.749533 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 23:07:23,885 [Epoch: 026 Step: 00004271] Batch Translation Loss:   5.494420 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:07:37,587 [Epoch: 026 Step: 00004272] Batch Translation Loss:   5.770414 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 23:08:11,356 [Epoch: 026 Step: 00004273] Batch Translation Loss:   5.586495 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:08:26,006 [Epoch: 026 Step: 00004274] Batch Translation Loss:   5.733828 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 23:08:48,333 [Epoch: 026 Step: 00004275] Batch Translation Loss:   5.942481 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:09:05,647 [Epoch: 026 Step: 00004276] Batch Translation Loss:   5.965818 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 23:09:30,513 [Epoch: 026 Step: 00004277] Batch Translation Loss:   5.918828 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:09:52,780 [Epoch: 026 Step: 00004278] Batch Translation Loss:   5.523308 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:10:07,843 [Epoch: 026 Step: 00004279] Batch Translation Loss:   5.698192 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 23:10:36,187 [Epoch: 026 Step: 00004280] Batch Translation Loss:   5.693439 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:10:57,509 [Epoch: 026 Step: 00004281] Batch Translation Loss:   5.903742 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:11:11,656 [Epoch: 026 Step: 00004282] Batch Translation Loss:   6.124010 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 23:11:34,276 [Epoch: 026 Step: 00004283] Batch Translation Loss:   5.570365 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:11:50,271 [Epoch: 026 Step: 00004284] Batch Translation Loss:   5.713177 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:12:15,462 [Epoch: 026 Step: 00004285] Batch Translation Loss:   5.551153 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:12:28,536 [Epoch: 026 Step: 00004286] Batch Translation Loss:   5.940357 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 23:12:53,941 [Epoch: 026 Step: 00004287] Batch Translation Loss:   5.674738 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:13:09,697 [Epoch: 026 Step: 00004288] Batch Translation Loss:   5.782044 => Txt Tokens per Sec:        3 || Lr: 0.000490
2022-01-04 23:13:41,543 [Epoch: 026 Step: 00004289] Batch Translation Loss:   6.198730 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:14:07,267 [Epoch: 026 Step: 00004290] Batch Translation Loss:   5.691313 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:14:24,194 [Epoch: 026 Step: 00004291] Batch Translation Loss:   5.552097 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:15:00,976 [Epoch: 026 Step: 00004292] Batch Translation Loss:   5.669898 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:15:23,446 [Epoch: 026 Step: 00004293] Batch Translation Loss:   6.012644 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:15:42,510 [Epoch: 026 Step: 00004294] Batch Translation Loss:   6.092207 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:16:14,536 [Epoch: 026 Step: 00004295] Batch Translation Loss:   5.482445 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:16:35,472 [Epoch: 026 Step: 00004296] Batch Translation Loss:   6.173183 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:17:15,030 [Epoch: 026 Step: 00004297] Batch Translation Loss:   5.635417 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:17:52,832 [Epoch: 026 Step: 00004298] Batch Translation Loss:   5.710350 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:18:23,217 [Epoch: 026 Step: 00004299] Batch Translation Loss:   5.501192 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:18:39,832 [Epoch: 026 Step: 00004300] Batch Translation Loss:   6.171454 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:28:07,987 Validation result at epoch  26, step     4300: duration: 568.1545s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 12543.47168	PPL: 17888.92188
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.56	(DEL: 25.21,	INS: 0.00,	SUB: 73.22)
	Sequence Accuracy 1.67
2022-01-04 23:28:13,689 Logging Recognition and Translation Outputs
2022-01-04 23:28:13,689 ========================================================================================================================
2022-01-04 23:28:13,689 Logging Sequence: youtube_1-catherine_mackinnon_2818
2022-01-04 23:28:13,690 	Text Reference  :	shebaby
2022-01-04 23:28:13,690 	Text Hypothesis :	if     
2022-01-04 23:28:13,690 	Text Alignment  :	S      
2022-01-04 23:28:13,690 ========================================================================================================================
2022-01-04 23:28:13,690 Logging Sequence: deafvideo_2-deafpoweronethumbtwo_1785
2022-01-04 23:28:13,690 	Text Reference  :	faceles
2022-01-04 23:28:13,691 	Text Hypothesis :	asl    
2022-01-04 23:28:13,691 	Text Alignment  :	S      
2022-01-04 23:28:13,691 ========================================================================================================================
2022-01-04 23:28:13,691 Logging Sequence: youtube_5-roberta_cordano_6133
2022-01-04 23:28:13,691 	Text Reference  :	season
2022-01-04 23:28:13,691 	Text Hypothesis :	if    
2022-01-04 23:28:13,691 	Text Alignment  :	S     
2022-01-04 23:28:13,691 ========================================================================================================================
2022-01-04 23:28:13,691 Logging Sequence: youtube_1-catherine_mackinnon_2836
2022-01-04 23:28:13,691 	Text Reference  :	chard
2022-01-04 23:28:13,691 	Text Hypothesis :	if   
2022-01-04 23:28:13,691 	Text Alignment  :	S    
2022-01-04 23:28:13,691 ========================================================================================================================
2022-01-04 23:28:13,692 Logging Sequence: youtube_5-jeffrey_spinale_6051
2022-01-04 23:28:13,692 	Text Reference  :	bus
2022-01-04 23:28:13,692 	Text Hypothesis :	asl
2022-01-04 23:28:13,692 	Text Alignment  :	S  
2022-01-04 23:28:13,692 ========================================================================================================================
2022-01-04 23:28:39,926 [Epoch: 026 Step: 00004301] Batch Translation Loss:   5.515944 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:29:02,463 [Epoch: 026 Step: 00004302] Batch Translation Loss:   5.675438 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:29:29,001 [Epoch: 026 Step: 00004303] Batch Translation Loss:   6.274902 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:29:48,304 [Epoch: 026 Step: 00004304] Batch Translation Loss:   5.884418 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:30:14,227 [Epoch: 026 Step: 00004305] Batch Translation Loss:   5.507723 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:30:47,785 [Epoch: 026 Step: 00004306] Batch Translation Loss:   5.385063 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:31:17,835 [Epoch: 026 Step: 00004307] Batch Translation Loss:   5.970227 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:31:41,240 [Epoch: 026 Step: 00004308] Batch Translation Loss:   6.127364 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:32:10,507 [Epoch: 026 Step: 00004309] Batch Translation Loss:   6.699683 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:32:36,177 [Epoch: 026 Step: 00004310] Batch Translation Loss:   5.969943 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:33:02,451 [Epoch: 026 Step: 00004311] Batch Translation Loss:   5.991056 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:33:47,460 [Epoch: 026 Step: 00004312] Batch Translation Loss:   5.572706 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:34:21,334 [Epoch: 026 Step: 00004313] Batch Translation Loss:   5.872897 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:34:50,141 [Epoch: 026 Step: 00004314] Batch Translation Loss:   5.899133 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:35:10,554 [Epoch: 026 Step: 00004315] Batch Translation Loss:   4.938809 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:35:43,936 [Epoch: 026 Step: 00004316] Batch Translation Loss:   5.685678 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:36:04,894 [Epoch: 026 Step: 00004317] Batch Translation Loss:   6.482059 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:36:29,343 [Epoch: 026 Step: 00004318] Batch Translation Loss:   5.909709 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:36:53,702 [Epoch: 026 Step: 00004319] Batch Translation Loss:   5.872120 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:37:38,640 [Epoch: 026 Step: 00004320] Batch Translation Loss:   5.957114 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:38:23,613 [Epoch: 026 Step: 00004321] Batch Translation Loss:   5.316716 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:38:47,084 [Epoch: 026 Step: 00004322] Batch Translation Loss:   6.084627 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:39:17,909 [Epoch: 026 Step: 00004323] Batch Translation Loss:   6.440457 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:39:51,434 [Epoch: 026 Step: 00004324] Batch Translation Loss:   5.776599 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:40:42,721 [Epoch: 026 Step: 00004325] Batch Translation Loss:   5.850604 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:41:15,827 [Epoch: 026 Step: 00004326] Batch Translation Loss:   5.772025 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:41:41,528 [Epoch: 026 Step: 00004327] Batch Translation Loss:   5.611189 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:42:11,093 [Epoch: 026 Step: 00004328] Batch Translation Loss:   5.597386 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:43:01,704 [Epoch: 026 Step: 00004329] Batch Translation Loss:   5.682845 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:43:59,533 [Epoch: 026 Step: 00004330] Batch Translation Loss:   6.053502 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:44:20,442 [Epoch: 026 Step: 00004331] Batch Translation Loss:   5.656917 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:44:40,520 [Epoch: 026 Step: 00004332] Batch Translation Loss:   5.539319 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:45:00,937 [Epoch: 026 Step: 00004333] Batch Translation Loss:   5.788380 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:45:22,186 [Epoch: 026 Step: 00004334] Batch Translation Loss:   5.851038 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:46:00,764 [Epoch: 026 Step: 00004335] Batch Translation Loss:   5.713500 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:46:45,840 [Epoch: 026 Step: 00004336] Batch Translation Loss:   5.315587 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:47:12,926 [Epoch: 026 Step: 00004337] Batch Translation Loss:   5.718422 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:47:37,671 [Epoch: 026 Step: 00004338] Batch Translation Loss:   5.868003 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:48:03,788 [Epoch: 026 Step: 00004339] Batch Translation Loss:   6.097648 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:48:27,535 [Epoch: 026 Step: 00004340] Batch Translation Loss:   6.067794 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:48:54,968 [Epoch: 026 Step: 00004341] Batch Translation Loss:   5.868680 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:49:22,689 [Epoch: 026 Step: 00004342] Batch Translation Loss:   5.467032 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:49:50,236 [Epoch: 026 Step: 00004343] Batch Translation Loss:   6.647995 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:50:16,598 [Epoch: 026 Step: 00004344] Batch Translation Loss:   6.217998 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:50:40,172 [Epoch: 026 Step: 00004345] Batch Translation Loss:   5.980155 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:51:13,621 [Epoch: 026 Step: 00004346] Batch Translation Loss:   5.912380 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:51:38,947 [Epoch: 026 Step: 00004347] Batch Translation Loss:   5.718680 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:52:06,638 [Epoch: 026 Step: 00004348] Batch Translation Loss:   5.344121 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:52:32,706 [Epoch: 026 Step: 00004349] Batch Translation Loss:   5.713897 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:52:56,856 [Epoch: 026 Step: 00004350] Batch Translation Loss:   5.696652 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:53:38,667 [Epoch: 026 Step: 00004351] Batch Translation Loss:   6.143877 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:54:00,850 [Epoch: 026 Step: 00004352] Batch Translation Loss:   5.961912 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:54:27,901 [Epoch: 026 Step: 00004353] Batch Translation Loss:   5.971231 => Txt Tokens per Sec:        2 || Lr: 0.000490
2022-01-04 23:54:55,634 [Epoch: 026 Step: 00004354] Batch Translation Loss:   5.751628 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:55:23,533 [Epoch: 026 Step: 00004355] Batch Translation Loss:   5.918975 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:55:51,491 [Epoch: 026 Step: 00004356] Batch Translation Loss:   5.655935 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:56:25,722 [Epoch: 026 Step: 00004357] Batch Translation Loss:   6.306390 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:56:51,198 [Epoch: 026 Step: 00004358] Batch Translation Loss:   5.560985 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:57:19,912 [Epoch: 026 Step: 00004359] Batch Translation Loss:   6.202833 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:57:48,739 [Epoch: 026 Step: 00004360] Batch Translation Loss:   5.899185 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:58:18,665 [Epoch: 026 Step: 00004361] Batch Translation Loss:   5.858864 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:58:48,824 [Epoch: 026 Step: 00004362] Batch Translation Loss:   5.756807 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-04 23:59:37,972 [Epoch: 026 Step: 00004363] Batch Translation Loss:   5.601594 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:00:09,243 [Epoch: 026 Step: 00004364] Batch Translation Loss:   5.640825 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:00:41,377 [Epoch: 026 Step: 00004365] Batch Translation Loss:   5.857774 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:01:14,059 [Epoch: 026 Step: 00004366] Batch Translation Loss:   5.982409 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:01:52,162 [Epoch: 026 Step: 00004367] Batch Translation Loss:   5.661050 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:02:29,429 [Epoch: 026 Step: 00004368] Batch Translation Loss:   6.178996 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:03:00,616 [Epoch: 026 Step: 00004369] Batch Translation Loss:   5.989105 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:03:34,228 [Epoch: 026 Step: 00004370] Batch Translation Loss:   5.841145 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:04:27,370 [Epoch: 026 Step: 00004371] Batch Translation Loss:   5.691339 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:05:01,602 [Epoch: 026 Step: 00004372] Batch Translation Loss:   5.808184 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:05:32,045 [Epoch: 026 Step: 00004373] Batch Translation Loss:   6.261543 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:06:07,338 [Epoch: 026 Step: 00004374] Batch Translation Loss:   6.100378 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:06:36,952 [Epoch: 026 Step: 00004375] Batch Translation Loss:   5.427516 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:07:13,034 [Epoch: 026 Step: 00004376] Batch Translation Loss:   6.181110 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:07:49,876 [Epoch: 026 Step: 00004377] Batch Translation Loss:   6.178269 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:08:23,764 [Epoch: 026 Step: 00004378] Batch Translation Loss:   5.605924 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:09:01,243 [Epoch: 026 Step: 00004379] Batch Translation Loss:   5.863822 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:09:38,894 [Epoch: 026 Step: 00004380] Batch Translation Loss:   5.709421 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:10:12,377 [Epoch: 026 Step: 00004381] Batch Translation Loss:   5.593177 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:10:51,271 [Epoch: 026 Step: 00004382] Batch Translation Loss:   5.683486 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:11:29,167 [Epoch: 026 Step: 00004383] Batch Translation Loss:   5.577459 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:12:09,233 [Epoch: 026 Step: 00004384] Batch Translation Loss:   5.977639 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:12:46,344 [Epoch: 026 Step: 00004385] Batch Translation Loss:   5.543344 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:13:20,872 [Epoch: 026 Step: 00004386] Batch Translation Loss:   5.726925 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:14:03,900 [Epoch: 026 Step: 00004387] Batch Translation Loss:   6.129919 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:14:45,550 [Epoch: 026 Step: 00004388] Batch Translation Loss:   5.658710 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:15:26,845 [Epoch: 026 Step: 00004389] Batch Translation Loss:   5.701019 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:16:01,217 [Epoch: 026 Step: 00004390] Batch Translation Loss:   5.731484 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:16:37,460 [Epoch: 026 Step: 00004391] Batch Translation Loss:   5.850105 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:17:27,012 [Epoch: 026 Step: 00004392] Batch Translation Loss:   5.596634 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:18:14,307 [Epoch: 026 Step: 00004393] Batch Translation Loss:   5.328003 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:18:55,455 [Epoch: 026 Step: 00004394] Batch Translation Loss:   5.757831 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:19:36,381 [Epoch: 026 Step: 00004395] Batch Translation Loss:   5.751421 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:20:28,503 [Epoch: 026 Step: 00004396] Batch Translation Loss:   5.367889 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:21:23,837 [Epoch: 026 Step: 00004397] Batch Translation Loss:   5.416350 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:22:16,989 [Epoch: 026 Step: 00004398] Batch Translation Loss:   5.524462 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:23:10,261 [Epoch: 026 Step: 00004399] Batch Translation Loss:   5.718585 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:23:59,851 [Epoch: 026 Step: 00004400] Batch Translation Loss:   6.126807 => Txt Tokens per Sec:        1 || Lr: 0.000490
2022-01-05 00:32:41,900 Validation result at epoch  26, step     4400: duration: 522.0471s
	Recognition Beam Size: -1	Translation Beam Size: 9	Translation Beam Alpha: 1
	Recognition Loss: -1.00000	Translation Loss: 12969.85254	PPL: 22540.50781
	Eval Metric: WACC
	WAcc (Word Accuracy Rate) 1.00	(DEL: 25.50,	INS: 0.00,	SUB: 73.49)
	Sequence Accuracy 0.83
2022-01-05 00:32:47,343 Logging Recognition and Translation Outputs
2022-01-05 00:32:47,343 ========================================================================================================================
2022-01-05 00:32:47,343 Logging Sequence: deafvideo_4-tax_tips_by_irs_4953
2022-01-05 00:32:47,344 	Text Reference  :	co
2022-01-05 00:32:47,344 	Text Hypothesis :	if
2022-01-05 00:32:47,344 	Text Alignment  :	S 
2022-01-05 00:32:47,344 ========================================================================================================================
2022-01-05 00:32:47,344 Logging Sequence: aslized-suzanne_stecker_0260
2022-01-05 00:32:47,344 	Text Reference  :	lgbt cub
2022-01-05 00:32:47,344 	Text Hypothesis :	**** asl
2022-01-05 00:32:47,344 	Text Alignment  :	D    S  
2022-01-05 00:32:47,344 ========================================================================================================================
2022-01-05 00:32:47,344 Logging Sequence: deafvideo_3-geoalpha_4550
2022-01-05 00:32:47,345 	Text Reference  :	hurt
2022-01-05 00:32:47,345 	Text Hypothesis :	ok  
2022-01-05 00:32:47,345 	Text Alignment  :	S   
2022-01-05 00:32:47,345 ========================================================================================================================
2022-01-05 00:32:47,345 Logging Sequence: deafvideo_5-silentoneye_7326
2022-01-05 00:32:47,345 	Text Reference  :	asd  
2022-01-05 00:32:47,345 	Text Hypothesis :	micah
2022-01-05 00:32:47,345 	Text Alignment  :	S    
2022-01-05 00:32:47,345 ========================================================================================================================
2022-01-05 00:32:47,346 Logging Sequence: youtube_5-roberta_cordano_6127
2022-01-05 00:32:47,346 	Text Reference  :	camaspace
2022-01-05 00:32:47,346 	Text Hypothesis :	duality  
2022-01-05 00:32:47,346 	Text Alignment  :	S        
2022-01-05 00:32:47,346 ========================================================================================================================
2022-01-05 00:32:47,568 Training ended since there were no improvements inthe last learning rate step: 0.000490
2022-01-05 00:32:47,568 Best validation result at step     2600:   3.53 eval_metric.
2022-01-05 13:07:17,291 - ============================================================
2022-01-05 13:12:15,384 - [DEV] partition [Translation] results:
	New Best Translation Beam Size: 1 and Alpha: -1
	WAcc (Word Accuracy Rate) 2.83	(DEL: 23.72,	INS: 0.00,	SUB: 73.45)
	Sequence Accuracy 2.78
2022-01-05 13:12:15,384 - ------------------------------------------------------------
2022-01-05 13:17:43,610 - [DEV] partition [Translation] results:
	New Best Translation Beam Size: 1 and Alpha: 0
	WAcc (Word Accuracy Rate) 2.83	(DEL: 24.96,	INS: 0.00,	SUB: 72.20)
	Sequence Accuracy 3.25
2022-01-05 13:17:43,610 - ------------------------------------------------------------
2022-01-05 13:39:48,984 - [DEV] partition [Translation] results:
	New Best Translation Beam Size: 1 and Alpha: 4
	WAcc (Word Accuracy Rate) 2.98	(DEL: 24.76,	INS: 0.00,	SUB: 72.26)
	Sequence Accuracy 3.33
2022-01-05 13:39:48,984 - ------------------------------------------------------------
2022-01-05 13:51:03,142 - [DEV] partition [Translation] results:
	New Best Translation Beam Size: 2 and Alpha: -1
	WAcc (Word Accuracy Rate) 3.18	(DEL: 23.93,	INS: 0.00,	SUB: 72.89)
	Sequence Accuracy 3.03
2022-01-05 13:51:03,142 - ------------------------------------------------------------
2022-01-05 19:38:24,158 - ************************************************************
2022-01-05 19:38:24,159 - [DEV] partition [Recognition & Translation] results:
	Best CTC Decode Beam Size: -1
	Best Translation Beam Size: 2 and Alpha: -1
	WAcc (Word Accuracy Rate) 3.18	(DEL: 23.93,	INS: 0.00,	SUB: 72.89)
	Sequence Accuracy 3.03
2022-01-05 19:38:24,159 - ************************************************************
2022-01-05 19:43:15,873 - [TEST] partition [Recognition & Translation] results:
	Best CTC Decode Beam Size: -1
	Best Translation Beam Size: 2 and Alpha: -1
	WAcc (Word Accuracy Rate) 1.94	(DEL: 30.04,	INS: 0.00,	SUB: 68.02)
	Sequence Accuracy 2.66
2022-01-05 19:43:15,873 - ************************************************************

