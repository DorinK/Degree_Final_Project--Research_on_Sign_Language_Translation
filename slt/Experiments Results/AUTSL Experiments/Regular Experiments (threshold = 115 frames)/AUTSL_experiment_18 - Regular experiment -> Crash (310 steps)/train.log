2021-12-31 14:18:18,815 Hello! This is Joey-NMT.
2021-12-31 14:18:21,048 Total params: 12632045
2021-12-31 14:18:21,051 Trainable parameters: ['encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'gloss_output_layer.bias', 'gloss_output_layer.weight', 'image_encoder.classifier.0.bias', 'image_encoder.classifier.0.weight', 'image_encoder.classifier.3.bias', 'image_encoder.classifier.3.weight', 'image_encoder.features.0.0.weight', 'image_encoder.features.0.1.bias', 'image_encoder.features.0.1.weight', 'image_encoder.features.1.block.0.0.weight', 'image_encoder.features.1.block.0.1.bias', 'image_encoder.features.1.block.0.1.weight', 'image_encoder.features.1.block.1.fc1.bias', 'image_encoder.features.1.block.1.fc1.weight', 'image_encoder.features.1.block.1.fc2.bias', 'image_encoder.features.1.block.1.fc2.weight', 'image_encoder.features.1.block.2.0.weight', 'image_encoder.features.1.block.2.1.bias', 'image_encoder.features.1.block.2.1.weight', 'image_encoder.features.10.block.0.0.weight', 'image_encoder.features.10.block.0.1.bias', 'image_encoder.features.10.block.0.1.weight', 'image_encoder.features.10.block.1.0.weight', 'image_encoder.features.10.block.1.1.bias', 'image_encoder.features.10.block.1.1.weight', 'image_encoder.features.10.block.2.fc1.bias', 'image_encoder.features.10.block.2.fc1.weight', 'image_encoder.features.10.block.2.fc2.bias', 'image_encoder.features.10.block.2.fc2.weight', 'image_encoder.features.10.block.3.0.weight', 'image_encoder.features.10.block.3.1.bias', 'image_encoder.features.10.block.3.1.weight', 'image_encoder.features.11.block.0.0.weight', 'image_encoder.features.11.block.0.1.bias', 'image_encoder.features.11.block.0.1.weight', 'image_encoder.features.11.block.1.0.weight', 'image_encoder.features.11.block.1.1.bias', 'image_encoder.features.11.block.1.1.weight', 'image_encoder.features.11.block.2.fc1.bias', 'image_encoder.features.11.block.2.fc1.weight', 'image_encoder.features.11.block.2.fc2.bias', 'image_encoder.features.11.block.2.fc2.weight', 'image_encoder.features.11.block.3.0.weight', 'image_encoder.features.11.block.3.1.bias', 'image_encoder.features.11.block.3.1.weight', 'image_encoder.features.12.0.weight', 'image_encoder.features.12.1.bias', 'image_encoder.features.12.1.weight', 'image_encoder.features.2.block.0.0.weight', 'image_encoder.features.2.block.0.1.bias', 'image_encoder.features.2.block.0.1.weight', 'image_encoder.features.2.block.1.0.weight', 'image_encoder.features.2.block.1.1.bias', 'image_encoder.features.2.block.1.1.weight', 'image_encoder.features.2.block.2.0.weight', 'image_encoder.features.2.block.2.1.bias', 'image_encoder.features.2.block.2.1.weight', 'image_encoder.features.3.block.0.0.weight', 'image_encoder.features.3.block.0.1.bias', 'image_encoder.features.3.block.0.1.weight', 'image_encoder.features.3.block.1.0.weight', 'image_encoder.features.3.block.1.1.bias', 'image_encoder.features.3.block.1.1.weight', 'image_encoder.features.3.block.2.0.weight', 'image_encoder.features.3.block.2.1.bias', 'image_encoder.features.3.block.2.1.weight', 'image_encoder.features.4.block.0.0.weight', 'image_encoder.features.4.block.0.1.bias', 'image_encoder.features.4.block.0.1.weight', 'image_encoder.features.4.block.1.0.weight', 'image_encoder.features.4.block.1.1.bias', 'image_encoder.features.4.block.1.1.weight', 'image_encoder.features.4.block.2.fc1.bias', 'image_encoder.features.4.block.2.fc1.weight', 'image_encoder.features.4.block.2.fc2.bias', 'image_encoder.features.4.block.2.fc2.weight', 'image_encoder.features.4.block.3.0.weight', 'image_encoder.features.4.block.3.1.bias', 'image_encoder.features.4.block.3.1.weight', 'image_encoder.features.5.block.0.0.weight', 'image_encoder.features.5.block.0.1.bias', 'image_encoder.features.5.block.0.1.weight', 'image_encoder.features.5.block.1.0.weight', 'image_encoder.features.5.block.1.1.bias', 'image_encoder.features.5.block.1.1.weight', 'image_encoder.features.5.block.2.fc1.bias', 'image_encoder.features.5.block.2.fc1.weight', 'image_encoder.features.5.block.2.fc2.bias', 'image_encoder.features.5.block.2.fc2.weight', 'image_encoder.features.5.block.3.0.weight', 'image_encoder.features.5.block.3.1.bias', 'image_encoder.features.5.block.3.1.weight', 'image_encoder.features.6.block.0.0.weight', 'image_encoder.features.6.block.0.1.bias', 'image_encoder.features.6.block.0.1.weight', 'image_encoder.features.6.block.1.0.weight', 'image_encoder.features.6.block.1.1.bias', 'image_encoder.features.6.block.1.1.weight', 'image_encoder.features.6.block.2.fc1.bias', 'image_encoder.features.6.block.2.fc1.weight', 'image_encoder.features.6.block.2.fc2.bias', 'image_encoder.features.6.block.2.fc2.weight', 'image_encoder.features.6.block.3.0.weight', 'image_encoder.features.6.block.3.1.bias', 'image_encoder.features.6.block.3.1.weight', 'image_encoder.features.7.block.0.0.weight', 'image_encoder.features.7.block.0.1.bias', 'image_encoder.features.7.block.0.1.weight', 'image_encoder.features.7.block.1.0.weight', 'image_encoder.features.7.block.1.1.bias', 'image_encoder.features.7.block.1.1.weight', 'image_encoder.features.7.block.2.fc1.bias', 'image_encoder.features.7.block.2.fc1.weight', 'image_encoder.features.7.block.2.fc2.bias', 'image_encoder.features.7.block.2.fc2.weight', 'image_encoder.features.7.block.3.0.weight', 'image_encoder.features.7.block.3.1.bias', 'image_encoder.features.7.block.3.1.weight', 'image_encoder.features.8.block.0.0.weight', 'image_encoder.features.8.block.0.1.bias', 'image_encoder.features.8.block.0.1.weight', 'image_encoder.features.8.block.1.0.weight', 'image_encoder.features.8.block.1.1.bias', 'image_encoder.features.8.block.1.1.weight', 'image_encoder.features.8.block.2.fc1.bias', 'image_encoder.features.8.block.2.fc1.weight', 'image_encoder.features.8.block.2.fc2.bias', 'image_encoder.features.8.block.2.fc2.weight', 'image_encoder.features.8.block.3.0.weight', 'image_encoder.features.8.block.3.1.bias', 'image_encoder.features.8.block.3.1.weight', 'image_encoder.features.9.block.0.0.weight', 'image_encoder.features.9.block.0.1.bias', 'image_encoder.features.9.block.0.1.weight', 'image_encoder.features.9.block.1.0.weight', 'image_encoder.features.9.block.1.1.bias', 'image_encoder.features.9.block.1.1.weight', 'image_encoder.features.9.block.2.fc1.bias', 'image_encoder.features.9.block.2.fc1.weight', 'image_encoder.features.9.block.2.fc2.bias', 'image_encoder.features.9.block.2.fc2.weight', 'image_encoder.features.9.block.3.0.weight', 'image_encoder.features.9.block.3.1.bias', 'image_encoder.features.9.block.3.1.weight', 'sgn_embed.ln.bias', 'sgn_embed.ln.weight', 'sgn_embed.norm.norm.bias', 'sgn_embed.norm.norm.weight']
2021-12-31 14:18:43,536 cfg.name                           : AUTSL Experiment
2021-12-31 14:18:43,611 cfg.data.data_path                 : ./data/
2021-12-31 14:18:43,611 cfg.data.version                   : autsl
2021-12-31 14:18:43,612 cfg.data.sgn                       : sign
2021-12-31 14:18:43,612 cfg.data.gls                       : gloss
2021-12-31 14:18:43,612 cfg.data.feature_size              : 1000
2021-12-31 14:18:43,612 cfg.data.level                     : word
2021-12-31 14:18:43,612 cfg.data.max_sent_length           : 400
2021-12-31 14:18:43,613 cfg.data.random_train_subset       : -1
2021-12-31 14:18:43,613 cfg.data.random_dev_subset         : -1
2021-12-31 14:18:43,613 cfg.testing.recognition_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2021-12-31 14:18:43,613 cfg.testing.translation_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2021-12-31 14:18:43,613 cfg.testing.translation_beam_alphas : [-1, 0, 1, 2, 3, 4, 5]
2021-12-31 14:18:43,614 cfg.training.reset_best_ckpt       : False
2021-12-31 14:18:43,614 cfg.training.reset_scheduler       : False
2021-12-31 14:18:43,614 cfg.training.reset_optimizer       : False
2021-12-31 14:18:43,614 cfg.training.random_seed           : 42
2021-12-31 14:18:43,614 cfg.training.model_dir             : ./AUTSL Experiments/AUTSL_experiment_18
2021-12-31 14:18:43,615 cfg.training.recognition_loss_weight : 1.0
2021-12-31 14:18:43,615 cfg.training.translation_loss_weight : 0.0
2021-12-31 14:18:43,615 cfg.training.eval_metric           : wer
2021-12-31 14:18:43,615 cfg.training.optimizer             : adam
2021-12-31 14:18:43,615 cfg.training.learning_rate         : 0.001
2021-12-31 14:18:43,616 cfg.training.batch_size            : 32
2021-12-31 14:18:43,616 cfg.training.num_valid_log         : 5
2021-12-31 14:18:43,616 cfg.training.epochs                : 5000000
2021-12-31 14:18:43,616 cfg.training.early_stopping_metric : eval_metric
2021-12-31 14:18:43,617 cfg.training.batch_type            : sentence
2021-12-31 14:18:43,617 cfg.training.translation_normalization : batch
2021-12-31 14:18:43,617 cfg.training.eval_recognition_beam_size : 9
2021-12-31 14:18:43,617 cfg.training.eval_translation_beam_size : 9
2021-12-31 14:18:43,617 cfg.training.eval_translation_beam_alpha : 1
2021-12-31 14:18:43,618 cfg.training.overwrite             : True
2021-12-31 14:18:43,618 cfg.training.shuffle               : True
2021-12-31 14:18:43,618 cfg.training.use_cuda              : True
2021-12-31 14:18:43,618 cfg.training.translation_max_output_length : 1
2021-12-31 14:18:43,618 cfg.training.keep_last_ckpts       : 1
2021-12-31 14:18:43,618 cfg.training.batch_multiplier      : 1
2021-12-31 14:18:43,618 cfg.training.logging_freq          : 1
2021-12-31 14:18:43,618 cfg.training.validation_freq       : 400
2021-12-31 14:18:43,619 cfg.training.betas                 : [0.9, 0.998]
2021-12-31 14:18:43,619 cfg.training.scheduling            : plateau
2021-12-31 14:18:43,619 cfg.training.learning_rate_min     : 1e-06
2021-12-31 14:18:43,619 cfg.training.weight_decay          : 0.001
2021-12-31 14:18:43,619 cfg.training.patience              : 8
2021-12-31 14:18:43,619 cfg.training.decrease_factor       : 0.7
2021-12-31 14:18:43,619 cfg.training.label_smoothing       : 0.0
2021-12-31 14:18:43,620 cfg.model.initializer              : xavier
2021-12-31 14:18:43,620 cfg.model.bias_initializer         : zeros
2021-12-31 14:18:43,620 cfg.model.init_gain                : 1.0
2021-12-31 14:18:43,620 cfg.model.embed_initializer        : xavier
2021-12-31 14:18:43,620 cfg.model.embed_init_gain          : 1.0
2021-12-31 14:18:43,620 cfg.model.tied_softmax             : False
2021-12-31 14:18:43,620 cfg.model.encoder.type             : transformer
2021-12-31 14:18:43,620 cfg.model.encoder.num_layers       : 3
2021-12-31 14:18:43,621 cfg.model.encoder.num_heads        : 8
2021-12-31 14:18:43,622 cfg.model.encoder.embeddings.embedding_dim : 512
2021-12-31 14:18:43,622 cfg.model.encoder.embeddings.scale : False
2021-12-31 14:18:43,622 cfg.model.encoder.embeddings.dropout : 0.1
2021-12-31 14:18:43,622 cfg.model.encoder.embeddings.norm_type : batch
2021-12-31 14:18:43,622 cfg.model.encoder.embeddings.activation_type : softsign
2021-12-31 14:18:43,622 cfg.model.encoder.hidden_size      : 512
2021-12-31 14:18:43,622 cfg.model.encoder.ff_size          : 2048
2021-12-31 14:18:43,622 cfg.model.encoder.dropout          : 0.1
2021-12-31 14:18:43,622 cfg.model.decoder.type             : transformer
2021-12-31 14:18:43,623 cfg.model.decoder.num_layers       : 3
2021-12-31 14:18:43,623 cfg.model.decoder.num_heads        : 8
2021-12-31 14:18:43,623 cfg.model.decoder.embeddings.embedding_dim : 512
2021-12-31 14:18:43,623 cfg.model.decoder.embeddings.scale : False
2021-12-31 14:18:43,623 cfg.model.decoder.embeddings.dropout : 0.1
2021-12-31 14:18:43,623 cfg.model.decoder.embeddings.norm_type : batch
2021-12-31 14:18:43,623 cfg.model.decoder.embeddings.activation_type : softsign
2021-12-31 14:18:43,623 cfg.model.decoder.hidden_size      : 512
2021-12-31 14:18:43,623 cfg.model.decoder.ff_size          : 2048
2021-12-31 14:18:43,624 cfg.model.decoder.dropout          : 0.1
2021-12-31 14:18:43,625 SignModel(
	encoder=TransformerEncoder(num_layers=3, num_heads=8),
	decoder=None,
	sgn_embed=SpatialEmbeddings(embedding_dim=512, input_size=1000),
	txt_embed=None)
2021-12-31 14:18:44,011 EPOCH 1
2021-12-31 14:20:55,930 [Epoch: 001 Step: 00000001] Batch Recognition Loss: 328.732300 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:22:39,669 [Epoch: 001 Step: 00000002] Batch Recognition Loss:  15.316386 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:24:39,558 [Epoch: 001 Step: 00000003] Batch Recognition Loss:  15.341816 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:26:39,205 [Epoch: 001 Step: 00000004] Batch Recognition Loss:  14.801518 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:28:34,125 [Epoch: 001 Step: 00000005] Batch Recognition Loss:  13.648355 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:30:22,697 [Epoch: 001 Step: 00000006] Batch Recognition Loss:  12.232467 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:32:05,471 [Epoch: 001 Step: 00000007] Batch Recognition Loss:  10.353833 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:34:01,394 [Epoch: 001 Step: 00000008] Batch Recognition Loss:   8.902055 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:35:51,365 [Epoch: 001 Step: 00000009] Batch Recognition Loss:   6.845267 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:37:56,758 [Epoch: 001 Step: 00000010] Batch Recognition Loss:  10.678820 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:40:02,497 [Epoch: 001 Step: 00000011] Batch Recognition Loss:   6.930143 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:42:18,268 [Epoch: 001 Step: 00000012] Batch Recognition Loss:   7.276790 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:44:27,140 [Epoch: 001 Step: 00000013] Batch Recognition Loss:   7.454988 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:46:37,265 [Epoch: 001 Step: 00000014] Batch Recognition Loss:   7.801594 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:49:01,227 [Epoch: 001 Step: 00000015] Batch Recognition Loss:   8.236433 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:53:05,937 [Epoch: 001 Step: 00000016] Batch Recognition Loss:   8.241990 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:57:11,542 [Epoch: 001 Step: 00000017] Batch Recognition Loss:   7.773800 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 14:59:31,965 [Epoch: 001 Step: 00000018] Batch Recognition Loss:   7.641356 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:01:51,053 [Epoch: 001 Step: 00000019] Batch Recognition Loss:   7.606840 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:06:37,130 [Epoch: 001 Step: 00000020] Batch Recognition Loss:   6.904999 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:08:57,868 [Epoch: 001 Step: 00000021] Batch Recognition Loss:   6.684771 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:11:18,463 [Epoch: 001 Step: 00000022] Batch Recognition Loss:   6.847783 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:13:53,497 [Epoch: 001 Step: 00000023] Batch Recognition Loss:   7.066928 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:16:24,164 [Epoch: 001 Step: 00000024] Batch Recognition Loss:   7.730536 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:19:04,536 [Epoch: 001 Step: 00000025] Batch Recognition Loss:   7.079664 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:21:49,469 [Epoch: 001 Step: 00000026] Batch Recognition Loss:   7.054634 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:24:34,533 [Epoch: 001 Step: 00000027] Batch Recognition Loss:   6.679142 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:27:00,267 [Epoch: 001 Step: 00000028] Batch Recognition Loss:   6.737232 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:29:25,007 [Epoch: 001 Step: 00000029] Batch Recognition Loss:   6.645319 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:31:53,692 [Epoch: 001 Step: 00000030] Batch Recognition Loss:   6.830598 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:34:29,383 [Epoch: 001 Step: 00000031] Batch Recognition Loss:   6.867993 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:37:11,561 [Epoch: 001 Step: 00000032] Batch Recognition Loss:   6.923687 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:39:49,694 [Epoch: 001 Step: 00000033] Batch Recognition Loss:   6.747602 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:42:28,137 [Epoch: 001 Step: 00000034] Batch Recognition Loss:   6.744419 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:45:03,300 [Epoch: 001 Step: 00000035] Batch Recognition Loss:   6.735363 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:47:33,319 [Epoch: 001 Step: 00000036] Batch Recognition Loss:   6.729095 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:50:10,805 [Epoch: 001 Step: 00000037] Batch Recognition Loss:   6.765622 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:52:33,631 [Epoch: 001 Step: 00000038] Batch Recognition Loss:   6.630906 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:55:00,907 [Epoch: 001 Step: 00000039] Batch Recognition Loss:   6.758142 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:57:26,015 [Epoch: 001 Step: 00000040] Batch Recognition Loss:   6.803560 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 15:59:59,629 [Epoch: 001 Step: 00000041] Batch Recognition Loss:   6.657287 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:02:55,880 [Epoch: 001 Step: 00000042] Batch Recognition Loss:   6.518011 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:05:35,027 [Epoch: 001 Step: 00000043] Batch Recognition Loss:   6.404427 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:08:21,267 [Epoch: 001 Step: 00000044] Batch Recognition Loss:   6.741009 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:11:09,239 [Epoch: 001 Step: 00000045] Batch Recognition Loss:   6.621386 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:14:03,652 [Epoch: 001 Step: 00000046] Batch Recognition Loss:   6.674496 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:16:55,805 [Epoch: 001 Step: 00000047] Batch Recognition Loss:   6.597465 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:19:54,199 [Epoch: 001 Step: 00000048] Batch Recognition Loss:   6.660553 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:22:53,753 [Epoch: 001 Step: 00000049] Batch Recognition Loss:   6.477819 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:25:41,112 [Epoch: 001 Step: 00000050] Batch Recognition Loss:   6.618771 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:28:42,919 [Epoch: 001 Step: 00000051] Batch Recognition Loss:   6.714981 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:31:40,398 [Epoch: 001 Step: 00000052] Batch Recognition Loss:   6.497725 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:34:37,820 [Epoch: 001 Step: 00000053] Batch Recognition Loss:   6.662086 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:37:32,139 [Epoch: 001 Step: 00000054] Batch Recognition Loss:   6.590726 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:40:27,586 [Epoch: 001 Step: 00000055] Batch Recognition Loss:   6.725689 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:43:34,376 [Epoch: 001 Step: 00000056] Batch Recognition Loss:   6.751648 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:46:48,017 [Epoch: 001 Step: 00000057] Batch Recognition Loss:   6.702587 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:50:05,350 [Epoch: 001 Step: 00000058] Batch Recognition Loss:   6.536873 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:53:02,415 [Epoch: 001 Step: 00000059] Batch Recognition Loss:   6.637417 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:55:46,386 [Epoch: 001 Step: 00000060] Batch Recognition Loss:   6.588136 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 16:58:21,743 [Epoch: 001 Step: 00000061] Batch Recognition Loss:   6.666809 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 17:02:19,549 [Epoch: 001 Step: 00000062] Batch Recognition Loss:   6.546500 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 17:06:22,436 [Epoch: 001 Step: 00000063] Batch Recognition Loss:   6.789501 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 17:10:27,562 [Epoch: 001 Step: 00000064] Batch Recognition Loss:   6.719053 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 17:14:12,245 [Epoch: 001 Step: 00000065] Batch Recognition Loss:   6.511002 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 17:18:27,048 [Epoch: 001 Step: 00000066] Batch Recognition Loss:   6.632977 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 17:22:29,228 [Epoch: 001 Step: 00000067] Batch Recognition Loss:   6.380476 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 17:26:37,034 [Epoch: 001 Step: 00000068] Batch Recognition Loss:   6.544044 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 17:30:35,804 [Epoch: 001 Step: 00000069] Batch Recognition Loss:   6.562108 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 17:34:52,365 [Epoch: 001 Step: 00000070] Batch Recognition Loss:   6.844758 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 17:39:02,832 [Epoch: 001 Step: 00000071] Batch Recognition Loss:   6.754959 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 17:43:18,936 [Epoch: 001 Step: 00000072] Batch Recognition Loss:   6.544922 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 17:47:48,543 [Epoch: 001 Step: 00000073] Batch Recognition Loss:   6.699793 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 17:52:01,751 [Epoch: 001 Step: 00000074] Batch Recognition Loss:   6.673827 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 17:56:24,817 [Epoch: 001 Step: 00000075] Batch Recognition Loss:   6.686436 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:00:50,056 [Epoch: 001 Step: 00000076] Batch Recognition Loss:   6.843462 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:05:24,272 [Epoch: 001 Step: 00000077] Batch Recognition Loss:   6.643640 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:09:29,119 [Epoch: 001 Step: 00000078] Batch Recognition Loss:   6.848600 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:14:00,314 [Epoch: 001 Step: 00000079] Batch Recognition Loss:   6.549654 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:18:19,545 [Epoch: 001 Step: 00000080] Batch Recognition Loss:   6.435811 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:22:46,498 [Epoch: 001 Step: 00000081] Batch Recognition Loss:   6.684542 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:26:55,386 [Epoch: 001 Step: 00000082] Batch Recognition Loss:   6.398375 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:31:11,105 [Epoch: 001 Step: 00000083] Batch Recognition Loss:   6.563265 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:35:13,551 [Epoch: 001 Step: 00000084] Batch Recognition Loss:   6.624944 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:39:20,603 [Epoch: 001 Step: 00000085] Batch Recognition Loss:   6.636580 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:43:18,358 [Epoch: 001 Step: 00000086] Batch Recognition Loss:   6.542270 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:47:09,143 [Epoch: 001 Step: 00000087] Batch Recognition Loss:   6.490762 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:50:58,288 [Epoch: 001 Step: 00000088] Batch Recognition Loss:   6.584035 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:54:48,055 [Epoch: 001 Step: 00000089] Batch Recognition Loss:   6.496344 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 18:58:23,253 [Epoch: 001 Step: 00000090] Batch Recognition Loss:   6.429878 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:01:49,198 [Epoch: 001 Step: 00000091] Batch Recognition Loss:   6.584311 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:07:00,564 [Epoch: 001 Step: 00000092] Batch Recognition Loss:   6.736386 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:11:54,584 [Epoch: 001 Step: 00000093] Batch Recognition Loss:   6.635663 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:17:12,261 [Epoch: 001 Step: 00000094] Batch Recognition Loss:   6.780317 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:22:30,639 [Epoch: 001 Step: 00000095] Batch Recognition Loss:   6.628477 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:27:38,649 [Epoch: 001 Step: 00000096] Batch Recognition Loss:   6.686529 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:38:01,218 [Epoch: 001 Step: 00000097] Batch Recognition Loss:   6.632686 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:43:11,406 [Epoch: 001 Step: 00000098] Batch Recognition Loss:   6.753522 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:48:23,540 [Epoch: 001 Step: 00000099] Batch Recognition Loss:   6.545854 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:53:25,307 [Epoch: 001 Step: 00000100] Batch Recognition Loss:   6.848615 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 19:58:40,490 [Epoch: 001 Step: 00000101] Batch Recognition Loss:   6.589161 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 20:03:40,114 [Epoch: 001 Step: 00000102] Batch Recognition Loss:   6.651120 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 20:13:33,755 [Epoch: 001 Step: 00000103] Batch Recognition Loss:   6.590501 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 20:18:27,063 [Epoch: 001 Step: 00000104] Batch Recognition Loss:   6.548913 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 20:22:53,794 [Epoch: 001 Step: 00000105] Batch Recognition Loss:   6.551735 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 20:27:27,693 [Epoch: 001 Step: 00000106] Batch Recognition Loss:   6.673677 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 20:31:59,502 [Epoch: 001 Step: 00000107] Batch Recognition Loss:   6.677988 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 20:37:03,718 [Epoch: 001 Step: 00000108] Batch Recognition Loss:   6.605649 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 20:41:48,642 [Epoch: 001 Step: 00000109] Batch Recognition Loss:   6.780590 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 20:51:06,107 [Epoch: 001 Step: 00000110] Batch Recognition Loss:   6.789032 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 20:55:05,235 [Epoch: 001 Step: 00000111] Batch Recognition Loss:   6.824643 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 20:59:05,661 [Epoch: 001 Step: 00000112] Batch Recognition Loss:   6.718312 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 21:05:08,924 [Epoch: 001 Step: 00000113] Batch Recognition Loss:   6.459387 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 21:11:02,592 [Epoch: 001 Step: 00000114] Batch Recognition Loss:   6.698730 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 21:16:45,877 [Epoch: 001 Step: 00000115] Batch Recognition Loss:   6.557875 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 21:22:30,643 [Epoch: 001 Step: 00000116] Batch Recognition Loss:   6.501030 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 21:28:18,407 [Epoch: 001 Step: 00000117] Batch Recognition Loss:   6.560802 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 21:34:14,466 [Epoch: 001 Step: 00000118] Batch Recognition Loss:   6.536457 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 21:40:20,458 [Epoch: 001 Step: 00000119] Batch Recognition Loss:   6.620197 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 21:46:27,453 [Epoch: 001 Step: 00000120] Batch Recognition Loss:   6.574066 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 21:52:23,206 [Epoch: 001 Step: 00000121] Batch Recognition Loss:   6.508850 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 21:58:28,204 [Epoch: 001 Step: 00000122] Batch Recognition Loss:   6.721087 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:04:27,236 [Epoch: 001 Step: 00000123] Batch Recognition Loss:   6.582764 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:10:27,359 [Epoch: 001 Step: 00000124] Batch Recognition Loss:   6.653076 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:16:27,509 [Epoch: 001 Step: 00000125] Batch Recognition Loss:   6.851212 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:22:22,426 [Epoch: 001 Step: 00000126] Batch Recognition Loss:   6.728021 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:28:12,997 [Epoch: 001 Step: 00000127] Batch Recognition Loss:   6.682916 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:33:59,282 [Epoch: 001 Step: 00000128] Batch Recognition Loss:   6.420304 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:39:32,574 [Epoch: 001 Step: 00000129] Batch Recognition Loss:   6.815939 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:45:05,546 [Epoch: 001 Step: 00000130] Batch Recognition Loss:   6.612379 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:50:10,281 [Epoch: 001 Step: 00000131] Batch Recognition Loss:   6.722773 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 22:55:21,399 [Epoch: 001 Step: 00000132] Batch Recognition Loss:   6.643398 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 23:00:30,682 [Epoch: 001 Step: 00000133] Batch Recognition Loss:   6.839049 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 23:05:19,122 [Epoch: 001 Step: 00000134] Batch Recognition Loss:   6.636141 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 23:10:51,449 [Epoch: 001 Step: 00000135] Batch Recognition Loss:   6.635056 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 23:17:29,929 [Epoch: 001 Step: 00000136] Batch Recognition Loss:   6.681742 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 23:24:22,280 [Epoch: 001 Step: 00000137] Batch Recognition Loss:   6.938483 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 23:30:21,604 [Epoch: 001 Step: 00000138] Batch Recognition Loss:   6.623148 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 23:36:53,004 [Epoch: 001 Step: 00000139] Batch Recognition Loss:   6.747798 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 23:43:14,995 [Epoch: 001 Step: 00000140] Batch Recognition Loss:   6.477986 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 23:49:37,873 [Epoch: 001 Step: 00000141] Batch Recognition Loss:   6.492651 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-31 23:56:10,359 [Epoch: 001 Step: 00000142] Batch Recognition Loss:   6.714725 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 00:02:41,094 [Epoch: 001 Step: 00000143] Batch Recognition Loss:   6.475343 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 00:09:24,067 [Epoch: 001 Step: 00000144] Batch Recognition Loss:   6.574136 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 00:16:01,178 [Epoch: 001 Step: 00000145] Batch Recognition Loss:   6.907740 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 00:22:40,732 [Epoch: 001 Step: 00000146] Batch Recognition Loss:   6.848147 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 00:27:23,509 [Epoch: 001 Step: 00000147] Batch Recognition Loss:   6.825012 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 00:34:07,132 [Epoch: 001 Step: 00000148] Batch Recognition Loss:   6.671726 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 00:41:23,557 [Epoch: 001 Step: 00000149] Batch Recognition Loss:   6.658830 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 00:48:16,943 [Epoch: 001 Step: 00000150] Batch Recognition Loss:   6.911856 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 00:55:38,174 [Epoch: 001 Step: 00000151] Batch Recognition Loss:   6.742843 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 01:02:53,797 [Epoch: 001 Step: 00000152] Batch Recognition Loss:   6.605072 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 01:10:25,079 [Epoch: 001 Step: 00000153] Batch Recognition Loss:   6.618933 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 01:17:27,930 [Epoch: 001 Step: 00000154] Batch Recognition Loss:   6.859040 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 01:24:47,537 [Epoch: 001 Step: 00000155] Batch Recognition Loss:   6.510791 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 01:32:20,696 [Epoch: 001 Step: 00000156] Batch Recognition Loss:   6.427854 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 01:40:02,385 [Epoch: 001 Step: 00000157] Batch Recognition Loss:   6.607623 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 01:47:24,322 [Epoch: 001 Step: 00000158] Batch Recognition Loss:   6.367210 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 01:54:47,818 [Epoch: 001 Step: 00000159] Batch Recognition Loss:   6.755509 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 02:01:56,911 [Epoch: 001 Step: 00000160] Batch Recognition Loss:   6.651373 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 02:08:56,771 [Epoch: 001 Step: 00000161] Batch Recognition Loss:   6.496999 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 02:15:27,380 [Epoch: 001 Step: 00000162] Batch Recognition Loss:   6.550968 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 02:22:01,622 [Epoch: 001 Step: 00000163] Batch Recognition Loss:   6.547368 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 02:27:16,902 [Epoch: 001 Step: 00000164] Batch Recognition Loss:   6.549327 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 02:34:02,374 [Epoch: 001 Step: 00000165] Batch Recognition Loss:   6.465980 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 02:41:08,259 [Epoch: 001 Step: 00000166] Batch Recognition Loss:   6.791948 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 02:48:18,890 [Epoch: 001 Step: 00000167] Batch Recognition Loss:   6.675948 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 02:55:43,617 [Epoch: 001 Step: 00000168] Batch Recognition Loss:   6.862294 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 03:03:37,744 [Epoch: 001 Step: 00000169] Batch Recognition Loss:   6.656527 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 03:10:52,693 [Epoch: 001 Step: 00000170] Batch Recognition Loss:   6.577969 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 03:18:38,361 [Epoch: 001 Step: 00000171] Batch Recognition Loss:   6.875748 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 03:26:48,822 [Epoch: 001 Step: 00000172] Batch Recognition Loss:   6.393854 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 03:34:29,573 [Epoch: 001 Step: 00000173] Batch Recognition Loss:   6.744477 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 03:41:52,597 [Epoch: 001 Step: 00000174] Batch Recognition Loss:   6.464681 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 03:47:24,627 [Epoch: 001 Step: 00000175] Batch Recognition Loss:   6.748793 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 03:55:07,504 [Epoch: 001 Step: 00000176] Batch Recognition Loss:   6.622046 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 04:03:49,452 [Epoch: 001 Step: 00000177] Batch Recognition Loss:   6.445596 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 04:12:47,518 [Epoch: 001 Step: 00000178] Batch Recognition Loss:   6.791109 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 04:21:11,305 [Epoch: 001 Step: 00000179] Batch Recognition Loss:   6.821563 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 04:30:02,479 [Epoch: 001 Step: 00000180] Batch Recognition Loss:   6.684710 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 04:39:01,692 [Epoch: 001 Step: 00000181] Batch Recognition Loss:   6.868021 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 04:48:11,282 [Epoch: 001 Step: 00000182] Batch Recognition Loss:   6.594058 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 04:56:53,721 [Epoch: 001 Step: 00000183] Batch Recognition Loss:   6.646509 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 05:05:23,311 [Epoch: 001 Step: 00000184] Batch Recognition Loss:   6.640995 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 05:13:48,523 [Epoch: 001 Step: 00000185] Batch Recognition Loss:   6.715475 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 05:22:08,259 [Epoch: 001 Step: 00000186] Batch Recognition Loss:   6.452291 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 05:28:19,773 [Epoch: 001 Step: 00000187] Batch Recognition Loss:   6.571557 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 05:37:14,437 [Epoch: 001 Step: 00000188] Batch Recognition Loss:   6.561787 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 05:45:54,123 [Epoch: 001 Step: 00000189] Batch Recognition Loss:   6.940316 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 05:54:51,889 [Epoch: 001 Step: 00000190] Batch Recognition Loss:   6.716421 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 06:03:48,543 [Epoch: 001 Step: 00000191] Batch Recognition Loss:   6.657407 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 06:12:37,861 [Epoch: 001 Step: 00000192] Batch Recognition Loss:   6.697698 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 06:21:46,572 [Epoch: 001 Step: 00000193] Batch Recognition Loss:   6.458072 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 06:30:49,896 [Epoch: 001 Step: 00000194] Batch Recognition Loss:   6.607710 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 06:40:23,362 [Epoch: 001 Step: 00000195] Batch Recognition Loss:   7.142688 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 06:49:38,838 [Epoch: 001 Step: 00000196] Batch Recognition Loss:   6.736803 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 06:56:15,570 [Epoch: 001 Step: 00000197] Batch Recognition Loss:   6.508390 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 07:05:59,336 [Epoch: 001 Step: 00000198] Batch Recognition Loss:   6.896260 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 07:15:13,023 [Epoch: 001 Step: 00000199] Batch Recognition Loss:   6.671914 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 07:24:43,173 [Epoch: 001 Step: 00000200] Batch Recognition Loss:   6.713227 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 07:33:49,155 [Epoch: 001 Step: 00000201] Batch Recognition Loss:   6.464727 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 07:42:46,487 [Epoch: 001 Step: 00000202] Batch Recognition Loss:   6.674992 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 07:51:46,336 [Epoch: 001 Step: 00000203] Batch Recognition Loss:   6.490196 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 08:00:49,574 [Epoch: 001 Step: 00000204] Batch Recognition Loss:   6.576972 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 08:09:07,867 [Epoch: 001 Step: 00000205] Batch Recognition Loss:   6.603486 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 08:16:57,674 [Epoch: 001 Step: 00000206] Batch Recognition Loss:   6.826483 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 08:26:30,278 [Epoch: 001 Step: 00000207] Batch Recognition Loss:   6.989349 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 08:36:13,319 [Epoch: 001 Step: 00000208] Batch Recognition Loss:   6.699218 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 08:45:48,795 [Epoch: 001 Step: 00000209] Batch Recognition Loss:   6.771474 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 08:55:39,823 [Epoch: 001 Step: 00000210] Batch Recognition Loss:   6.786578 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 09:04:58,001 [Epoch: 001 Step: 00000211] Batch Recognition Loss:   6.693156 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 09:14:29,542 [Epoch: 001 Step: 00000212] Batch Recognition Loss:   6.793400 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 09:23:48,714 [Epoch: 001 Step: 00000213] Batch Recognition Loss:   6.476467 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 09:33:23,879 [Epoch: 001 Step: 00000214] Batch Recognition Loss:   6.611909 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 09:42:47,547 [Epoch: 001 Step: 00000215] Batch Recognition Loss:   6.695772 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 09:51:35,787 [Epoch: 001 Step: 00000216] Batch Recognition Loss:   6.591299 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 09:59:13,286 [Epoch: 001 Step: 00000217] Batch Recognition Loss:   6.739317 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 10:08:49,285 [Epoch: 001 Step: 00000218] Batch Recognition Loss:   6.759650 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 10:18:19,774 [Epoch: 001 Step: 00000219] Batch Recognition Loss:   6.609069 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 10:27:52,338 [Epoch: 001 Step: 00000220] Batch Recognition Loss:   6.892080 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 10:37:33,837 [Epoch: 001 Step: 00000221] Batch Recognition Loss:   6.761861 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 10:47:34,954 [Epoch: 001 Step: 00000222] Batch Recognition Loss:   6.587399 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 10:56:17,752 [Epoch: 001 Step: 00000223] Batch Recognition Loss:   6.623778 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 11:06:36,216 [Epoch: 001 Step: 00000224] Batch Recognition Loss:   6.418043 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 11:26:29,106 [Epoch: 001 Step: 00000225] Batch Recognition Loss:   6.511707 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 11:36:53,047 [Epoch: 001 Step: 00000226] Batch Recognition Loss:   6.540268 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 11:47:10,504 [Epoch: 001 Step: 00000227] Batch Recognition Loss:   6.609507 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 11:57:21,182 [Epoch: 001 Step: 00000228] Batch Recognition Loss:   6.351462 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 12:08:03,053 [Epoch: 001 Step: 00000229] Batch Recognition Loss:   6.738078 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 12:18:46,468 [Epoch: 001 Step: 00000230] Batch Recognition Loss:   6.812773 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 12:28:50,644 [Epoch: 001 Step: 00000231] Batch Recognition Loss:   6.779747 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 12:38:30,237 [Epoch: 001 Step: 00000232] Batch Recognition Loss:   6.767605 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 12:46:56,238 [Epoch: 001 Step: 00000233] Batch Recognition Loss:   6.709546 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 12:57:05,518 [Epoch: 001 Step: 00000234] Batch Recognition Loss:   6.619316 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 13:07:19,463 [Epoch: 001 Step: 00000235] Batch Recognition Loss:   6.617203 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 13:17:44,305 [Epoch: 001 Step: 00000236] Batch Recognition Loss:   7.045348 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 13:29:33,993 [Epoch: 001 Step: 00000237] Batch Recognition Loss:   6.484341 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 13:40:12,653 [Epoch: 001 Step: 00000238] Batch Recognition Loss:   6.551951 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 14:00:53,002 [Epoch: 001 Step: 00000239] Batch Recognition Loss:   6.550550 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 14:11:02,795 [Epoch: 001 Step: 00000240] Batch Recognition Loss:   6.718444 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 14:20:26,442 [Epoch: 001 Step: 00000241] Batch Recognition Loss:   6.812779 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 14:40:35,854 [Epoch: 001 Step: 00000242] Batch Recognition Loss:   6.684287 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 14:50:54,974 [Epoch: 001 Step: 00000243] Batch Recognition Loss:   6.611038 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 15:01:21,439 [Epoch: 001 Step: 00000244] Batch Recognition Loss:   6.798020 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 15:11:14,265 [Epoch: 001 Step: 00000245] Batch Recognition Loss:   6.427038 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 15:32:10,184 [Epoch: 001 Step: 00000246] Batch Recognition Loss:   6.469200 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 15:41:59,615 [Epoch: 001 Step: 00000247] Batch Recognition Loss:   6.468234 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 15:51:45,489 [Epoch: 001 Step: 00000248] Batch Recognition Loss:   6.725188 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 15:59:23,926 [Epoch: 001 Step: 00000249] Batch Recognition Loss:   6.527905 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 16:11:16,841 [Epoch: 001 Step: 00000250] Batch Recognition Loss:   6.481331 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 16:22:46,349 [Epoch: 001 Step: 00000251] Batch Recognition Loss:   6.633790 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 16:34:54,639 [Epoch: 001 Step: 00000252] Batch Recognition Loss:   6.624902 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 16:47:04,357 [Epoch: 001 Step: 00000253] Batch Recognition Loss:   6.547021 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 16:59:08,489 [Epoch: 001 Step: 00000254] Batch Recognition Loss:   6.759937 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:10:54,695 [Epoch: 001 Step: 00000255] Batch Recognition Loss:   6.715059 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:21:47,143 [Epoch: 001 Step: 00000256] Batch Recognition Loss:   6.743566 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:31:49,307 [Epoch: 001 Step: 00000257] Batch Recognition Loss:   6.663934 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:40:48,585 [Epoch: 001 Step: 00000258] Batch Recognition Loss:   6.763566 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:49:49,247 [Epoch: 001 Step: 00000259] Batch Recognition Loss:   6.736634 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 17:58:31,664 [Epoch: 001 Step: 00000260] Batch Recognition Loss:   6.776992 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 18:07:17,766 [Epoch: 001 Step: 00000261] Batch Recognition Loss:   6.735983 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 18:16:09,130 [Epoch: 001 Step: 00000262] Batch Recognition Loss:   6.733011 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 18:24:40,388 [Epoch: 001 Step: 00000263] Batch Recognition Loss:   6.749197 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 18:33:08,826 [Epoch: 001 Step: 00000264] Batch Recognition Loss:   6.630825 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 18:41:41,403 [Epoch: 001 Step: 00000265] Batch Recognition Loss:   6.544973 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 18:51:19,711 [Epoch: 001 Step: 00000266] Batch Recognition Loss:   6.531296 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 19:02:44,268 [Epoch: 001 Step: 00000267] Batch Recognition Loss:   6.655956 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 19:14:12,856 [Epoch: 001 Step: 00000268] Batch Recognition Loss:   6.523638 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 19:26:00,375 [Epoch: 001 Step: 00000269] Batch Recognition Loss:   6.416604 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 19:37:53,631 [Epoch: 001 Step: 00000270] Batch Recognition Loss:   6.797124 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 19:49:33,015 [Epoch: 001 Step: 00000271] Batch Recognition Loss:   6.656821 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 20:00:59,048 [Epoch: 001 Step: 00000272] Batch Recognition Loss:   6.667126 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 20:11:35,693 [Epoch: 001 Step: 00000273] Batch Recognition Loss:   6.631090 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 20:20:42,943 [Epoch: 001 Step: 00000274] Batch Recognition Loss:   6.530551 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 20:33:06,064 [Epoch: 001 Step: 00000275] Batch Recognition Loss:   6.711078 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 20:45:23,282 [Epoch: 001 Step: 00000276] Batch Recognition Loss:   6.574583 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 20:57:44,350 [Epoch: 001 Step: 00000277] Batch Recognition Loss:   6.903072 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 21:09:20,500 [Epoch: 001 Step: 00000278] Batch Recognition Loss:   6.751901 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 21:22:01,555 [Epoch: 001 Step: 00000279] Batch Recognition Loss:   6.785127 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 21:34:41,179 [Epoch: 001 Step: 00000280] Batch Recognition Loss:   6.739708 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 21:46:43,175 [Epoch: 001 Step: 00000281] Batch Recognition Loss:   6.669011 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 21:58:10,577 [Epoch: 001 Step: 00000282] Batch Recognition Loss:   6.474961 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 22:08:33,843 [Epoch: 001 Step: 00000283] Batch Recognition Loss:   6.475946 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 22:18:14,622 [Epoch: 001 Step: 00000284] Batch Recognition Loss:   6.826702 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 22:27:33,048 [Epoch: 001 Step: 00000285] Batch Recognition Loss:   6.644573 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 22:36:24,088 [Epoch: 001 Step: 00000286] Batch Recognition Loss:   6.638052 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 22:45:48,087 [Epoch: 001 Step: 00000287] Batch Recognition Loss:   6.582186 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 22:55:19,870 [Epoch: 001 Step: 00000288] Batch Recognition Loss:   6.995574 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 23:07:55,111 [Epoch: 001 Step: 00000289] Batch Recognition Loss:   6.647789 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 23:19:54,773 [Epoch: 001 Step: 00000290] Batch Recognition Loss:   6.771812 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 23:31:42,134 [Epoch: 001 Step: 00000291] Batch Recognition Loss:   6.637112 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 23:43:04,384 [Epoch: 001 Step: 00000292] Batch Recognition Loss:   6.755418 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-01 23:54:28,866 [Epoch: 001 Step: 00000293] Batch Recognition Loss:   6.614859 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 00:05:02,539 [Epoch: 001 Step: 00000294] Batch Recognition Loss:   6.679409 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 00:28:57,057 [Epoch: 001 Step: 00000295] Batch Recognition Loss:   6.455338 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 00:41:17,517 [Epoch: 001 Step: 00000296] Batch Recognition Loss:   6.893633 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 00:53:23,229 [Epoch: 001 Step: 00000297] Batch Recognition Loss:   6.489849 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 01:05:08,504 [Epoch: 001 Step: 00000298] Batch Recognition Loss:   6.892781 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 01:16:21,872 [Epoch: 001 Step: 00000299] Batch Recognition Loss:   6.509422 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 01:27:50,516 [Epoch: 001 Step: 00000300] Batch Recognition Loss:   6.658552 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 01:37:48,604 [Epoch: 001 Step: 00000301] Batch Recognition Loss:   6.491872 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 01:50:22,804 [Epoch: 001 Step: 00000302] Batch Recognition Loss:   6.644470 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 02:02:50,724 [Epoch: 001 Step: 00000303] Batch Recognition Loss:   6.506663 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 02:15:43,431 [Epoch: 001 Step: 00000304] Batch Recognition Loss:   6.800692 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 02:28:25,543 [Epoch: 001 Step: 00000305] Batch Recognition Loss:   6.756321 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 02:40:23,210 [Epoch: 001 Step: 00000306] Batch Recognition Loss:   6.710760 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 02:51:52,393 [Epoch: 001 Step: 00000307] Batch Recognition Loss:   6.392730 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 03:02:46,772 [Epoch: 001 Step: 00000308] Batch Recognition Loss:   6.745671 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 03:15:00,428 [Epoch: 001 Step: 00000309] Batch Recognition Loss:   6.834622 => Gls Tokens per Sec:        0 || Lr: 0.001000
2022-01-02 03:27:05,343 [Epoch: 001 Step: 00000310] Batch Recognition Loss:   6.631996 => Gls Tokens per Sec:        0 || Lr: 0.001000
