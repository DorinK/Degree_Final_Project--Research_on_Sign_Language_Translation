2021-12-24 01:21:55,197 Hello! This is Joey-NMT.
2021-12-24 01:21:56,210 Total params: 12632045
2021-12-24 01:21:56,211 Trainable parameters: ['encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'gloss_output_layer.bias', 'gloss_output_layer.weight', 'image_encoder.classifier.0.bias', 'image_encoder.classifier.0.weight', 'image_encoder.classifier.3.bias', 'image_encoder.classifier.3.weight', 'image_encoder.features.0.0.weight', 'image_encoder.features.0.1.bias', 'image_encoder.features.0.1.weight', 'image_encoder.features.1.block.0.0.weight', 'image_encoder.features.1.block.0.1.bias', 'image_encoder.features.1.block.0.1.weight', 'image_encoder.features.1.block.1.fc1.bias', 'image_encoder.features.1.block.1.fc1.weight', 'image_encoder.features.1.block.1.fc2.bias', 'image_encoder.features.1.block.1.fc2.weight', 'image_encoder.features.1.block.2.0.weight', 'image_encoder.features.1.block.2.1.bias', 'image_encoder.features.1.block.2.1.weight', 'image_encoder.features.10.block.0.0.weight', 'image_encoder.features.10.block.0.1.bias', 'image_encoder.features.10.block.0.1.weight', 'image_encoder.features.10.block.1.0.weight', 'image_encoder.features.10.block.1.1.bias', 'image_encoder.features.10.block.1.1.weight', 'image_encoder.features.10.block.2.fc1.bias', 'image_encoder.features.10.block.2.fc1.weight', 'image_encoder.features.10.block.2.fc2.bias', 'image_encoder.features.10.block.2.fc2.weight', 'image_encoder.features.10.block.3.0.weight', 'image_encoder.features.10.block.3.1.bias', 'image_encoder.features.10.block.3.1.weight', 'image_encoder.features.11.block.0.0.weight', 'image_encoder.features.11.block.0.1.bias', 'image_encoder.features.11.block.0.1.weight', 'image_encoder.features.11.block.1.0.weight', 'image_encoder.features.11.block.1.1.bias', 'image_encoder.features.11.block.1.1.weight', 'image_encoder.features.11.block.2.fc1.bias', 'image_encoder.features.11.block.2.fc1.weight', 'image_encoder.features.11.block.2.fc2.bias', 'image_encoder.features.11.block.2.fc2.weight', 'image_encoder.features.11.block.3.0.weight', 'image_encoder.features.11.block.3.1.bias', 'image_encoder.features.11.block.3.1.weight', 'image_encoder.features.12.0.weight', 'image_encoder.features.12.1.bias', 'image_encoder.features.12.1.weight', 'image_encoder.features.2.block.0.0.weight', 'image_encoder.features.2.block.0.1.bias', 'image_encoder.features.2.block.0.1.weight', 'image_encoder.features.2.block.1.0.weight', 'image_encoder.features.2.block.1.1.bias', 'image_encoder.features.2.block.1.1.weight', 'image_encoder.features.2.block.2.0.weight', 'image_encoder.features.2.block.2.1.bias', 'image_encoder.features.2.block.2.1.weight', 'image_encoder.features.3.block.0.0.weight', 'image_encoder.features.3.block.0.1.bias', 'image_encoder.features.3.block.0.1.weight', 'image_encoder.features.3.block.1.0.weight', 'image_encoder.features.3.block.1.1.bias', 'image_encoder.features.3.block.1.1.weight', 'image_encoder.features.3.block.2.0.weight', 'image_encoder.features.3.block.2.1.bias', 'image_encoder.features.3.block.2.1.weight', 'image_encoder.features.4.block.0.0.weight', 'image_encoder.features.4.block.0.1.bias', 'image_encoder.features.4.block.0.1.weight', 'image_encoder.features.4.block.1.0.weight', 'image_encoder.features.4.block.1.1.bias', 'image_encoder.features.4.block.1.1.weight', 'image_encoder.features.4.block.2.fc1.bias', 'image_encoder.features.4.block.2.fc1.weight', 'image_encoder.features.4.block.2.fc2.bias', 'image_encoder.features.4.block.2.fc2.weight', 'image_encoder.features.4.block.3.0.weight', 'image_encoder.features.4.block.3.1.bias', 'image_encoder.features.4.block.3.1.weight', 'image_encoder.features.5.block.0.0.weight', 'image_encoder.features.5.block.0.1.bias', 'image_encoder.features.5.block.0.1.weight', 'image_encoder.features.5.block.1.0.weight', 'image_encoder.features.5.block.1.1.bias', 'image_encoder.features.5.block.1.1.weight', 'image_encoder.features.5.block.2.fc1.bias', 'image_encoder.features.5.block.2.fc1.weight', 'image_encoder.features.5.block.2.fc2.bias', 'image_encoder.features.5.block.2.fc2.weight', 'image_encoder.features.5.block.3.0.weight', 'image_encoder.features.5.block.3.1.bias', 'image_encoder.features.5.block.3.1.weight', 'image_encoder.features.6.block.0.0.weight', 'image_encoder.features.6.block.0.1.bias', 'image_encoder.features.6.block.0.1.weight', 'image_encoder.features.6.block.1.0.weight', 'image_encoder.features.6.block.1.1.bias', 'image_encoder.features.6.block.1.1.weight', 'image_encoder.features.6.block.2.fc1.bias', 'image_encoder.features.6.block.2.fc1.weight', 'image_encoder.features.6.block.2.fc2.bias', 'image_encoder.features.6.block.2.fc2.weight', 'image_encoder.features.6.block.3.0.weight', 'image_encoder.features.6.block.3.1.bias', 'image_encoder.features.6.block.3.1.weight', 'image_encoder.features.7.block.0.0.weight', 'image_encoder.features.7.block.0.1.bias', 'image_encoder.features.7.block.0.1.weight', 'image_encoder.features.7.block.1.0.weight', 'image_encoder.features.7.block.1.1.bias', 'image_encoder.features.7.block.1.1.weight', 'image_encoder.features.7.block.2.fc1.bias', 'image_encoder.features.7.block.2.fc1.weight', 'image_encoder.features.7.block.2.fc2.bias', 'image_encoder.features.7.block.2.fc2.weight', 'image_encoder.features.7.block.3.0.weight', 'image_encoder.features.7.block.3.1.bias', 'image_encoder.features.7.block.3.1.weight', 'image_encoder.features.8.block.0.0.weight', 'image_encoder.features.8.block.0.1.bias', 'image_encoder.features.8.block.0.1.weight', 'image_encoder.features.8.block.1.0.weight', 'image_encoder.features.8.block.1.1.bias', 'image_encoder.features.8.block.1.1.weight', 'image_encoder.features.8.block.2.fc1.bias', 'image_encoder.features.8.block.2.fc1.weight', 'image_encoder.features.8.block.2.fc2.bias', 'image_encoder.features.8.block.2.fc2.weight', 'image_encoder.features.8.block.3.0.weight', 'image_encoder.features.8.block.3.1.bias', 'image_encoder.features.8.block.3.1.weight', 'image_encoder.features.9.block.0.0.weight', 'image_encoder.features.9.block.0.1.bias', 'image_encoder.features.9.block.0.1.weight', 'image_encoder.features.9.block.1.0.weight', 'image_encoder.features.9.block.1.1.bias', 'image_encoder.features.9.block.1.1.weight', 'image_encoder.features.9.block.2.fc1.bias', 'image_encoder.features.9.block.2.fc1.weight', 'image_encoder.features.9.block.2.fc2.bias', 'image_encoder.features.9.block.2.fc2.weight', 'image_encoder.features.9.block.3.0.weight', 'image_encoder.features.9.block.3.1.bias', 'image_encoder.features.9.block.3.1.weight', 'sgn_embed.ln.bias', 'sgn_embed.ln.weight', 'sgn_embed.norm.norm.bias', 'sgn_embed.norm.norm.weight']
2021-12-24 01:22:14,081 cfg.name                           : AUTSL Experiment
2021-12-24 01:22:14,081 cfg.data.data_path                 : ./data/
2021-12-24 01:22:14,081 cfg.data.version                   : autsl
2021-12-24 01:22:14,081 cfg.data.sgn                       : sign
2021-12-24 01:22:14,082 cfg.data.gls                       : gloss
2021-12-24 01:22:14,082 cfg.data.feature_size              : 1000
2021-12-24 01:22:14,082 cfg.data.level                     : word
2021-12-24 01:22:14,082 cfg.data.max_sent_length           : 400
2021-12-24 01:22:14,082 cfg.data.random_train_subset       : -1
2021-12-24 01:22:14,082 cfg.data.random_dev_subset         : -1
2021-12-24 01:22:14,082 cfg.testing.recognition_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2021-12-24 01:22:14,082 cfg.testing.translation_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2021-12-24 01:22:14,082 cfg.testing.translation_beam_alphas : [-1, 0, 1, 2, 3, 4, 5]
2021-12-24 01:22:14,082 cfg.training.reset_best_ckpt       : False
2021-12-24 01:22:14,082 cfg.training.reset_scheduler       : False
2021-12-24 01:22:14,082 cfg.training.reset_optimizer       : False
2021-12-24 01:22:14,082 cfg.training.random_seed           : 42
2021-12-24 01:22:14,082 cfg.training.model_dir             : ./AUTSL Experiments/AUTSL_experiment_11
2021-12-24 01:22:14,082 cfg.training.recognition_loss_weight : 1.0
2021-12-24 01:22:14,082 cfg.training.translation_loss_weight : 0.0
2021-12-24 01:22:14,082 cfg.training.eval_metric           : wer
2021-12-24 01:22:14,083 cfg.training.optimizer             : adam
2021-12-24 01:22:14,083 cfg.training.learning_rate         : 0.001
2021-12-24 01:22:14,083 cfg.training.batch_size            : 32
2021-12-24 01:22:14,083 cfg.training.num_valid_log         : 5
2021-12-24 01:22:14,083 cfg.training.epochs                : 5000000
2021-12-24 01:22:14,083 cfg.training.early_stopping_metric : eval_metric
2021-12-24 01:22:14,083 cfg.training.batch_type            : sentence
2021-12-24 01:22:14,083 cfg.training.translation_normalization : batch
2021-12-24 01:22:14,083 cfg.training.eval_recognition_beam_size : 9
2021-12-24 01:22:14,083 cfg.training.eval_translation_beam_size : 9
2021-12-24 01:22:14,083 cfg.training.eval_translation_beam_alpha : 1
2021-12-24 01:22:14,083 cfg.training.overwrite             : True
2021-12-24 01:22:14,083 cfg.training.shuffle               : True
2021-12-24 01:22:14,083 cfg.training.use_cuda              : True
2021-12-24 01:22:14,083 cfg.training.translation_max_output_length : 30
2021-12-24 01:22:14,083 cfg.training.keep_last_ckpts       : 1
2021-12-24 01:22:14,083 cfg.training.batch_multiplier      : 1
2021-12-24 01:22:14,083 cfg.training.logging_freq          : 1
2021-12-24 01:22:14,084 cfg.training.validation_freq       : 400
2021-12-24 01:22:14,084 cfg.training.betas                 : [0.9, 0.998]
2021-12-24 01:22:14,084 cfg.training.scheduling            : plateau
2021-12-24 01:22:14,084 cfg.training.learning_rate_min     : 1e-06
2021-12-24 01:22:14,084 cfg.training.weight_decay          : 0.001
2021-12-24 01:22:14,084 cfg.training.patience              : 8
2021-12-24 01:22:14,084 cfg.training.decrease_factor       : 0.7
2021-12-24 01:22:14,084 cfg.training.label_smoothing       : 0.0
2021-12-24 01:22:14,084 cfg.model.initializer              : xavier
2021-12-24 01:22:14,084 cfg.model.bias_initializer         : zeros
2021-12-24 01:22:14,084 cfg.model.init_gain                : 1.0
2021-12-24 01:22:14,084 cfg.model.embed_initializer        : xavier
2021-12-24 01:22:14,084 cfg.model.embed_init_gain          : 1.0
2021-12-24 01:22:14,084 cfg.model.tied_softmax             : False
2021-12-24 01:22:14,084 cfg.model.encoder.type             : transformer
2021-12-24 01:22:14,084 cfg.model.encoder.num_layers       : 3
2021-12-24 01:22:14,084 cfg.model.encoder.num_heads        : 8
2021-12-24 01:22:14,084 cfg.model.encoder.embeddings.embedding_dim : 512
2021-12-24 01:22:14,085 cfg.model.encoder.embeddings.scale : False
2021-12-24 01:22:14,085 cfg.model.encoder.embeddings.dropout : 0.1
2021-12-24 01:22:14,085 cfg.model.encoder.embeddings.norm_type : batch
2021-12-24 01:22:14,085 cfg.model.encoder.embeddings.activation_type : softsign
2021-12-24 01:22:14,085 cfg.model.encoder.hidden_size      : 512
2021-12-24 01:22:14,085 cfg.model.encoder.ff_size          : 2048
2021-12-24 01:22:14,085 cfg.model.encoder.dropout          : 0.1
2021-12-24 01:22:14,085 cfg.model.decoder.type             : transformer
2021-12-24 01:22:14,085 cfg.model.decoder.num_layers       : 3
2021-12-24 01:22:14,085 cfg.model.decoder.num_heads        : 8
2021-12-24 01:22:14,085 cfg.model.decoder.embeddings.embedding_dim : 512
2021-12-24 01:22:14,085 cfg.model.decoder.embeddings.scale : False
2021-12-24 01:22:14,085 cfg.model.decoder.embeddings.dropout : 0.1
2021-12-24 01:22:14,085 cfg.model.decoder.embeddings.norm_type : batch
2021-12-24 01:22:14,085 cfg.model.decoder.embeddings.activation_type : softsign
2021-12-24 01:22:14,085 cfg.model.decoder.hidden_size      : 512
2021-12-24 01:22:14,085 cfg.model.decoder.ff_size          : 2048
2021-12-24 01:22:14,085 cfg.model.decoder.dropout          : 0.1
2021-12-24 01:22:14,086 SignModel(
	encoder=TransformerEncoder(num_layers=3, num_heads=8),
	decoder=None,
	sgn_embed=SpatialEmbeddings(embedding_dim=512, input_size=1000),
	txt_embed=None)
2021-12-24 01:22:14,089 EPOCH 1
2021-12-24 01:23:25,088 [Epoch: 001 Step: 00000001] Batch Recognition Loss: 311.301697 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 01:24:40,559 [Epoch: 001 Step: 00000002] Batch Recognition Loss:  15.485285 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 01:25:48,807 [Epoch: 001 Step: 00000003] Batch Recognition Loss:  15.036830 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 01:26:53,230 [Epoch: 001 Step: 00000004] Batch Recognition Loss:  14.257447 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 01:27:59,181 [Epoch: 001 Step: 00000005] Batch Recognition Loss:  13.318907 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 01:29:07,160 [Epoch: 001 Step: 00000006] Batch Recognition Loss:  11.297660 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 01:30:10,576 [Epoch: 001 Step: 00000007] Batch Recognition Loss:   9.049158 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 01:31:18,415 [Epoch: 001 Step: 00000008] Batch Recognition Loss:   7.247276 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 01:32:24,925 [Epoch: 001 Step: 00000009] Batch Recognition Loss:   8.780413 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 01:33:36,306 [Epoch: 001 Step: 00000010] Batch Recognition Loss:   7.986113 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 01:34:47,396 [Epoch: 001 Step: 00000011] Batch Recognition Loss:   7.041810 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 01:36:01,132 [Epoch: 001 Step: 00000012] Batch Recognition Loss:   7.077955 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 01:37:12,313 [Epoch: 001 Step: 00000013] Batch Recognition Loss:   7.545291 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 01:38:27,650 [Epoch: 001 Step: 00000014] Batch Recognition Loss:   7.445946 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 01:39:42,331 [Epoch: 001 Step: 00000015] Batch Recognition Loss:   7.455477 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 01:41:00,185 [Epoch: 001 Step: 00000016] Batch Recognition Loss:   7.092296 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 01:42:38,390 [Epoch: 001 Step: 00000017] Batch Recognition Loss:   6.831951 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 01:44:09,755 [Epoch: 001 Step: 00000018] Batch Recognition Loss:   6.934962 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 01:45:26,567 [Epoch: 001 Step: 00000019] Batch Recognition Loss:   7.088645 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 01:46:56,592 [Epoch: 001 Step: 00000020] Batch Recognition Loss:   6.880610 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 01:48:16,861 [Epoch: 001 Step: 00000021] Batch Recognition Loss:   6.585016 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 01:49:44,680 [Epoch: 001 Step: 00000022] Batch Recognition Loss:   6.657121 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 01:51:20,361 [Epoch: 001 Step: 00000023] Batch Recognition Loss:   7.040485 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 01:52:59,441 [Epoch: 001 Step: 00000024] Batch Recognition Loss:   6.647822 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 01:54:32,892 [Epoch: 001 Step: 00000025] Batch Recognition Loss:   6.790874 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 01:56:19,177 [Epoch: 001 Step: 00000026] Batch Recognition Loss:   6.742159 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 01:57:57,161 [Epoch: 001 Step: 00000027] Batch Recognition Loss:   6.581465 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 01:59:50,804 [Epoch: 001 Step: 00000028] Batch Recognition Loss:   6.662453 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 02:01:36,662 [Epoch: 001 Step: 00000029] Batch Recognition Loss:   6.494390 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 02:03:23,203 [Epoch: 001 Step: 00000030] Batch Recognition Loss:   6.460484 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 02:05:22,997 [Epoch: 001 Step: 00000031] Batch Recognition Loss:   6.682807 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 02:07:23,863 [Epoch: 001 Step: 00000032] Batch Recognition Loss:   6.588143 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 02:09:21,625 [Epoch: 001 Step: 00000033] Batch Recognition Loss:   6.861055 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 02:11:19,001 [Epoch: 001 Step: 00000034] Batch Recognition Loss:   6.632917 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 02:13:11,888 [Epoch: 001 Step: 00000035] Batch Recognition Loss:   6.846085 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 02:15:03,118 [Epoch: 001 Step: 00000036] Batch Recognition Loss:   6.448907 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 02:17:07,232 [Epoch: 001 Step: 00000037] Batch Recognition Loss:   6.653614 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 02:19:09,570 [Epoch: 001 Step: 00000038] Batch Recognition Loss:   6.300668 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 02:21:08,280 [Epoch: 001 Step: 00000039] Batch Recognition Loss:   6.746320 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 02:23:14,904 [Epoch: 001 Step: 00000040] Batch Recognition Loss:   6.875437 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 02:25:22,254 [Epoch: 001 Step: 00000041] Batch Recognition Loss:   6.678681 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 02:27:38,709 [Epoch: 001 Step: 00000042] Batch Recognition Loss:   6.813383 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 02:29:55,125 [Epoch: 001 Step: 00000043] Batch Recognition Loss:   6.491438 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 02:32:09,250 [Epoch: 001 Step: 00000044] Batch Recognition Loss:   6.598393 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 02:34:23,114 [Epoch: 001 Step: 00000045] Batch Recognition Loss:   6.787090 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 02:36:38,821 [Epoch: 001 Step: 00000046] Batch Recognition Loss:   6.698809 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 02:39:00,357 [Epoch: 001 Step: 00000047] Batch Recognition Loss:   6.437122 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 02:41:21,419 [Epoch: 001 Step: 00000048] Batch Recognition Loss:   6.335740 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 02:43:42,876 [Epoch: 001 Step: 00000049] Batch Recognition Loss:   6.585653 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 02:46:15,249 [Epoch: 001 Step: 00000050] Batch Recognition Loss:   6.625643 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 02:48:39,999 [Epoch: 001 Step: 00000051] Batch Recognition Loss:   6.577085 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 02:51:01,888 [Epoch: 001 Step: 00000052] Batch Recognition Loss:   6.629338 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 02:53:41,791 [Epoch: 001 Step: 00000053] Batch Recognition Loss:   6.454179 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 02:55:59,387 [Epoch: 001 Step: 00000054] Batch Recognition Loss:   6.584487 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 02:58:28,844 [Epoch: 001 Step: 00000055] Batch Recognition Loss:   6.625133 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 03:00:52,943 [Epoch: 001 Step: 00000056] Batch Recognition Loss:   6.748417 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 03:03:26,011 [Epoch: 001 Step: 00000057] Batch Recognition Loss:   6.695590 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 03:05:54,101 [Epoch: 001 Step: 00000058] Batch Recognition Loss:   6.843255 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 03:08:30,810 [Epoch: 001 Step: 00000059] Batch Recognition Loss:   6.719614 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 03:11:16,473 [Epoch: 001 Step: 00000060] Batch Recognition Loss:   6.790147 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 03:13:53,168 [Epoch: 001 Step: 00000061] Batch Recognition Loss:   6.829058 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 03:16:52,085 [Epoch: 001 Step: 00000062] Batch Recognition Loss:   6.777333 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 03:19:40,281 [Epoch: 001 Step: 00000063] Batch Recognition Loss:   6.585867 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 03:22:24,340 [Epoch: 001 Step: 00000064] Batch Recognition Loss:   6.608592 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 03:25:16,704 [Epoch: 001 Step: 00000065] Batch Recognition Loss:   6.710962 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 03:28:07,543 [Epoch: 001 Step: 00000066] Batch Recognition Loss:   6.330992 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 03:30:55,503 [Epoch: 001 Step: 00000067] Batch Recognition Loss:   6.582106 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 03:33:55,676 [Epoch: 001 Step: 00000068] Batch Recognition Loss:   6.907551 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 03:36:48,626 [Epoch: 001 Step: 00000069] Batch Recognition Loss:   6.481911 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 03:39:49,046 [Epoch: 001 Step: 00000070] Batch Recognition Loss:   6.683273 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 03:43:03,783 [Epoch: 001 Step: 00000071] Batch Recognition Loss:   6.698974 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 03:46:05,748 [Epoch: 001 Step: 00000072] Batch Recognition Loss:   6.650852 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 03:49:15,609 [Epoch: 001 Step: 00000073] Batch Recognition Loss:   6.637716 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 03:52:25,519 [Epoch: 001 Step: 00000074] Batch Recognition Loss:   6.725271 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 03:55:41,429 [Epoch: 001 Step: 00000075] Batch Recognition Loss:   6.607680 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 03:58:52,371 [Epoch: 001 Step: 00000076] Batch Recognition Loss:   6.473741 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 04:02:00,444 [Epoch: 001 Step: 00000077] Batch Recognition Loss:   6.729172 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 04:05:10,030 [Epoch: 001 Step: 00000078] Batch Recognition Loss:   6.703238 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 04:08:32,316 [Epoch: 001 Step: 00000079] Batch Recognition Loss:   6.740022 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 04:11:37,571 [Epoch: 001 Step: 00000080] Batch Recognition Loss:   6.587289 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 04:15:14,151 [Epoch: 001 Step: 00000081] Batch Recognition Loss:   6.835467 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 04:18:32,597 [Epoch: 001 Step: 00000082] Batch Recognition Loss:   6.712491 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 04:21:53,713 [Epoch: 001 Step: 00000083] Batch Recognition Loss:   6.655354 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 04:25:17,019 [Epoch: 001 Step: 00000084] Batch Recognition Loss:   6.642607 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 04:28:52,134 [Epoch: 001 Step: 00000085] Batch Recognition Loss:   6.534441 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 04:32:10,887 [Epoch: 001 Step: 00000086] Batch Recognition Loss:   6.737109 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 04:35:50,227 [Epoch: 001 Step: 00000087] Batch Recognition Loss:   6.940843 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 04:39:27,901 [Epoch: 001 Step: 00000088] Batch Recognition Loss:   6.659801 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 04:42:56,969 [Epoch: 001 Step: 00000089] Batch Recognition Loss:   6.344896 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 04:46:36,377 [Epoch: 001 Step: 00000090] Batch Recognition Loss:   6.782281 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 04:50:20,757 [Epoch: 001 Step: 00000091] Batch Recognition Loss:   6.777798 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 04:53:49,121 [Epoch: 001 Step: 00000092] Batch Recognition Loss:   6.750585 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 04:57:27,801 [Epoch: 001 Step: 00000093] Batch Recognition Loss:   6.779289 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 05:01:08,992 [Epoch: 001 Step: 00000094] Batch Recognition Loss:   6.610536 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 05:04:45,969 [Epoch: 001 Step: 00000095] Batch Recognition Loss:   6.667912 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 05:08:34,025 [Epoch: 001 Step: 00000096] Batch Recognition Loss:   6.510151 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 05:13:15,532 [Epoch: 001 Step: 00000097] Batch Recognition Loss:   6.463675 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 05:16:46,251 [Epoch: 001 Step: 00000098] Batch Recognition Loss:   6.611813 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 05:20:37,278 [Epoch: 001 Step: 00000099] Batch Recognition Loss:   6.631858 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 05:24:22,341 [Epoch: 001 Step: 00000100] Batch Recognition Loss:   6.512644 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 05:28:17,190 [Epoch: 001 Step: 00000101] Batch Recognition Loss:   6.387845 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 05:32:02,016 [Epoch: 001 Step: 00000102] Batch Recognition Loss:   6.580215 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 05:35:50,428 [Epoch: 001 Step: 00000103] Batch Recognition Loss:   6.621807 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 05:39:43,520 [Epoch: 001 Step: 00000104] Batch Recognition Loss:   6.811484 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 05:43:41,077 [Epoch: 001 Step: 00000105] Batch Recognition Loss:   6.792373 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 05:47:30,348 [Epoch: 001 Step: 00000106] Batch Recognition Loss:   6.806860 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 05:51:32,271 [Epoch: 001 Step: 00000107] Batch Recognition Loss:   6.800516 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 05:55:34,892 [Epoch: 001 Step: 00000108] Batch Recognition Loss:   6.628938 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 05:59:43,763 [Epoch: 001 Step: 00000109] Batch Recognition Loss:   6.732297 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 06:03:47,460 [Epoch: 001 Step: 00000110] Batch Recognition Loss:   6.393817 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 06:08:02,196 [Epoch: 001 Step: 00000111] Batch Recognition Loss:   6.796412 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 06:12:15,022 [Epoch: 001 Step: 00000112] Batch Recognition Loss:   6.695186 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 06:16:27,153 [Epoch: 001 Step: 00000113] Batch Recognition Loss:   6.683764 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 06:20:37,358 [Epoch: 001 Step: 00000114] Batch Recognition Loss:   6.561373 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 06:24:57,996 [Epoch: 001 Step: 00000115] Batch Recognition Loss:   6.627185 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 06:29:34,122 [Epoch: 001 Step: 00000116] Batch Recognition Loss:   6.511310 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 06:33:49,178 [Epoch: 001 Step: 00000117] Batch Recognition Loss:   6.622162 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 06:38:11,964 [Epoch: 001 Step: 00000118] Batch Recognition Loss:   6.673409 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 06:42:36,374 [Epoch: 001 Step: 00000119] Batch Recognition Loss:   6.694767 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 06:46:51,676 [Epoch: 001 Step: 00000120] Batch Recognition Loss:   6.262443 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 06:51:23,382 [Epoch: 001 Step: 00000121] Batch Recognition Loss:   6.666307 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 06:55:52,105 [Epoch: 001 Step: 00000122] Batch Recognition Loss:   6.712551 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 07:00:23,337 [Epoch: 001 Step: 00000123] Batch Recognition Loss:   6.585445 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 07:05:05,435 [Epoch: 001 Step: 00000124] Batch Recognition Loss:   6.666374 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 07:09:36,216 [Epoch: 001 Step: 00000125] Batch Recognition Loss:   6.798352 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 07:14:01,737 [Epoch: 001 Step: 00000126] Batch Recognition Loss:   6.591759 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 07:18:43,028 [Epoch: 001 Step: 00000127] Batch Recognition Loss:   6.536436 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 07:23:24,444 [Epoch: 001 Step: 00000128] Batch Recognition Loss:   6.900692 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 07:28:08,239 [Epoch: 001 Step: 00000129] Batch Recognition Loss:   6.663978 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 07:32:51,521 [Epoch: 001 Step: 00000130] Batch Recognition Loss:   6.722330 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 07:37:43,296 [Epoch: 001 Step: 00000131] Batch Recognition Loss:   6.689897 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 07:42:22,748 [Epoch: 001 Step: 00000132] Batch Recognition Loss:   6.596193 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 07:47:10,583 [Epoch: 001 Step: 00000133] Batch Recognition Loss:   6.470518 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 07:52:00,205 [Epoch: 001 Step: 00000134] Batch Recognition Loss:   6.488889 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 07:56:51,983 [Epoch: 001 Step: 00000135] Batch Recognition Loss:   6.547373 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 08:01:58,513 [Epoch: 001 Step: 00000136] Batch Recognition Loss:   6.433941 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 08:06:41,169 [Epoch: 001 Step: 00000137] Batch Recognition Loss:   6.496154 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 08:11:38,803 [Epoch: 001 Step: 00000138] Batch Recognition Loss:   6.737325 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 08:16:35,584 [Epoch: 001 Step: 00000139] Batch Recognition Loss:   6.693949 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 08:21:29,195 [Epoch: 001 Step: 00000140] Batch Recognition Loss:   6.625169 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 08:26:34,278 [Epoch: 001 Step: 00000141] Batch Recognition Loss:   6.533564 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 08:31:43,030 [Epoch: 001 Step: 00000142] Batch Recognition Loss:   6.804819 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 08:36:49,615 [Epoch: 001 Step: 00000143] Batch Recognition Loss:   6.707705 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 08:42:06,154 [Epoch: 001 Step: 00000144] Batch Recognition Loss:   6.778700 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 08:47:03,979 [Epoch: 001 Step: 00000145] Batch Recognition Loss:   6.659245 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 08:52:25,086 [Epoch: 001 Step: 00000146] Batch Recognition Loss:   6.595634 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 08:57:41,019 [Epoch: 001 Step: 00000147] Batch Recognition Loss:   6.535608 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 09:08:35,229 [Epoch: 001 Step: 00000148] Batch Recognition Loss:   6.632077 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 09:14:06,067 [Epoch: 001 Step: 00000149] Batch Recognition Loss:   6.690156 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 09:19:33,976 [Epoch: 001 Step: 00000150] Batch Recognition Loss:   6.797860 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 09:25:02,795 [Epoch: 001 Step: 00000151] Batch Recognition Loss:   6.774726 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 09:30:29,607 [Epoch: 001 Step: 00000152] Batch Recognition Loss:   6.758079 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 09:35:58,092 [Epoch: 001 Step: 00000153] Batch Recognition Loss:   6.312711 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 09:41:26,070 [Epoch: 001 Step: 00000154] Batch Recognition Loss:   6.485112 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 09:46:36,464 [Epoch: 001 Step: 00000155] Batch Recognition Loss:   6.673797 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 09:52:04,903 [Epoch: 001 Step: 00000156] Batch Recognition Loss:   6.484259 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 09:57:24,557 [Epoch: 001 Step: 00000157] Batch Recognition Loss:   6.907524 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 10:02:59,545 [Epoch: 001 Step: 00000158] Batch Recognition Loss:   6.648423 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 10:08:30,593 [Epoch: 001 Step: 00000159] Batch Recognition Loss:   6.523283 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 10:14:00,235 [Epoch: 001 Step: 00000160] Batch Recognition Loss:   6.594151 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 10:19:27,700 [Epoch: 001 Step: 00000161] Batch Recognition Loss:   6.525106 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 10:25:02,247 [Epoch: 001 Step: 00000162] Batch Recognition Loss:   6.748308 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 10:30:24,333 [Epoch: 001 Step: 00000163] Batch Recognition Loss:   6.591591 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 10:35:57,223 [Epoch: 001 Step: 00000164] Batch Recognition Loss:   6.733443 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 10:41:37,530 [Epoch: 001 Step: 00000165] Batch Recognition Loss:   6.786862 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 10:47:13,411 [Epoch: 001 Step: 00000166] Batch Recognition Loss:   6.575372 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 10:53:02,728 [Epoch: 001 Step: 00000167] Batch Recognition Loss:   6.849786 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 10:58:34,293 [Epoch: 001 Step: 00000168] Batch Recognition Loss:   6.695620 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 11:04:14,251 [Epoch: 001 Step: 00000169] Batch Recognition Loss:   6.269764 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 11:10:00,149 [Epoch: 001 Step: 00000170] Batch Recognition Loss:   6.321911 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 11:15:57,253 [Epoch: 001 Step: 00000171] Batch Recognition Loss:   6.640752 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 11:21:39,009 [Epoch: 001 Step: 00000172] Batch Recognition Loss:   6.416247 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 11:27:32,726 [Epoch: 001 Step: 00000173] Batch Recognition Loss:   6.481876 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 11:33:20,286 [Epoch: 001 Step: 00000174] Batch Recognition Loss:   6.514541 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 11:39:06,563 [Epoch: 001 Step: 00000175] Batch Recognition Loss:   6.598250 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 11:44:56,460 [Epoch: 001 Step: 00000176] Batch Recognition Loss:   6.676091 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 11:50:54,991 [Epoch: 001 Step: 00000177] Batch Recognition Loss:   6.631857 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 11:56:51,632 [Epoch: 001 Step: 00000178] Batch Recognition Loss:   6.766588 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 12:02:48,966 [Epoch: 001 Step: 00000179] Batch Recognition Loss:   6.813576 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 12:08:49,642 [Epoch: 001 Step: 00000180] Batch Recognition Loss:   6.756515 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 12:14:55,284 [Epoch: 001 Step: 00000181] Batch Recognition Loss:   6.567053 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 12:20:56,381 [Epoch: 001 Step: 00000182] Batch Recognition Loss:   6.946213 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 12:27:45,633 [Epoch: 001 Step: 00000183] Batch Recognition Loss:   6.858534 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 12:34:24,623 [Epoch: 001 Step: 00000184] Batch Recognition Loss:   6.638736 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 12:40:48,682 [Epoch: 001 Step: 00000185] Batch Recognition Loss:   6.556255 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 12:47:10,617 [Epoch: 001 Step: 00000186] Batch Recognition Loss:   6.900841 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 12:53:29,098 [Epoch: 001 Step: 00000187] Batch Recognition Loss:   6.536110 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 12:59:46,616 [Epoch: 001 Step: 00000188] Batch Recognition Loss:   6.733232 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 13:06:03,982 [Epoch: 001 Step: 00000189] Batch Recognition Loss:   6.546314 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 13:12:22,422 [Epoch: 001 Step: 00000190] Batch Recognition Loss:   6.414841 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 13:18:59,329 [Epoch: 001 Step: 00000191] Batch Recognition Loss:   6.699054 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 13:25:30,652 [Epoch: 001 Step: 00000192] Batch Recognition Loss:   6.680192 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 13:32:05,775 [Epoch: 001 Step: 00000193] Batch Recognition Loss:   6.746930 => Gls Tokens per Sec:        0 || Lr: 0.001000
