2021-12-23 11:20:35,908 Hello! This is Joey-NMT.
2021-12-23 11:20:36,224 Total params: 12632045
2021-12-23 11:20:36,227 Trainable parameters: ['encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'gloss_output_layer.bias', 'gloss_output_layer.weight', 'image_encoder.classifier.0.bias', 'image_encoder.classifier.0.weight', 'image_encoder.classifier.3.bias', 'image_encoder.classifier.3.weight', 'image_encoder.features.0.0.weight', 'image_encoder.features.0.1.bias', 'image_encoder.features.0.1.weight', 'image_encoder.features.1.block.0.0.weight', 'image_encoder.features.1.block.0.1.bias', 'image_encoder.features.1.block.0.1.weight', 'image_encoder.features.1.block.1.fc1.bias', 'image_encoder.features.1.block.1.fc1.weight', 'image_encoder.features.1.block.1.fc2.bias', 'image_encoder.features.1.block.1.fc2.weight', 'image_encoder.features.1.block.2.0.weight', 'image_encoder.features.1.block.2.1.bias', 'image_encoder.features.1.block.2.1.weight', 'image_encoder.features.10.block.0.0.weight', 'image_encoder.features.10.block.0.1.bias', 'image_encoder.features.10.block.0.1.weight', 'image_encoder.features.10.block.1.0.weight', 'image_encoder.features.10.block.1.1.bias', 'image_encoder.features.10.block.1.1.weight', 'image_encoder.features.10.block.2.fc1.bias', 'image_encoder.features.10.block.2.fc1.weight', 'image_encoder.features.10.block.2.fc2.bias', 'image_encoder.features.10.block.2.fc2.weight', 'image_encoder.features.10.block.3.0.weight', 'image_encoder.features.10.block.3.1.bias', 'image_encoder.features.10.block.3.1.weight', 'image_encoder.features.11.block.0.0.weight', 'image_encoder.features.11.block.0.1.bias', 'image_encoder.features.11.block.0.1.weight', 'image_encoder.features.11.block.1.0.weight', 'image_encoder.features.11.block.1.1.bias', 'image_encoder.features.11.block.1.1.weight', 'image_encoder.features.11.block.2.fc1.bias', 'image_encoder.features.11.block.2.fc1.weight', 'image_encoder.features.11.block.2.fc2.bias', 'image_encoder.features.11.block.2.fc2.weight', 'image_encoder.features.11.block.3.0.weight', 'image_encoder.features.11.block.3.1.bias', 'image_encoder.features.11.block.3.1.weight', 'image_encoder.features.12.0.weight', 'image_encoder.features.12.1.bias', 'image_encoder.features.12.1.weight', 'image_encoder.features.2.block.0.0.weight', 'image_encoder.features.2.block.0.1.bias', 'image_encoder.features.2.block.0.1.weight', 'image_encoder.features.2.block.1.0.weight', 'image_encoder.features.2.block.1.1.bias', 'image_encoder.features.2.block.1.1.weight', 'image_encoder.features.2.block.2.0.weight', 'image_encoder.features.2.block.2.1.bias', 'image_encoder.features.2.block.2.1.weight', 'image_encoder.features.3.block.0.0.weight', 'image_encoder.features.3.block.0.1.bias', 'image_encoder.features.3.block.0.1.weight', 'image_encoder.features.3.block.1.0.weight', 'image_encoder.features.3.block.1.1.bias', 'image_encoder.features.3.block.1.1.weight', 'image_encoder.features.3.block.2.0.weight', 'image_encoder.features.3.block.2.1.bias', 'image_encoder.features.3.block.2.1.weight', 'image_encoder.features.4.block.0.0.weight', 'image_encoder.features.4.block.0.1.bias', 'image_encoder.features.4.block.0.1.weight', 'image_encoder.features.4.block.1.0.weight', 'image_encoder.features.4.block.1.1.bias', 'image_encoder.features.4.block.1.1.weight', 'image_encoder.features.4.block.2.fc1.bias', 'image_encoder.features.4.block.2.fc1.weight', 'image_encoder.features.4.block.2.fc2.bias', 'image_encoder.features.4.block.2.fc2.weight', 'image_encoder.features.4.block.3.0.weight', 'image_encoder.features.4.block.3.1.bias', 'image_encoder.features.4.block.3.1.weight', 'image_encoder.features.5.block.0.0.weight', 'image_encoder.features.5.block.0.1.bias', 'image_encoder.features.5.block.0.1.weight', 'image_encoder.features.5.block.1.0.weight', 'image_encoder.features.5.block.1.1.bias', 'image_encoder.features.5.block.1.1.weight', 'image_encoder.features.5.block.2.fc1.bias', 'image_encoder.features.5.block.2.fc1.weight', 'image_encoder.features.5.block.2.fc2.bias', 'image_encoder.features.5.block.2.fc2.weight', 'image_encoder.features.5.block.3.0.weight', 'image_encoder.features.5.block.3.1.bias', 'image_encoder.features.5.block.3.1.weight', 'image_encoder.features.6.block.0.0.weight', 'image_encoder.features.6.block.0.1.bias', 'image_encoder.features.6.block.0.1.weight', 'image_encoder.features.6.block.1.0.weight', 'image_encoder.features.6.block.1.1.bias', 'image_encoder.features.6.block.1.1.weight', 'image_encoder.features.6.block.2.fc1.bias', 'image_encoder.features.6.block.2.fc1.weight', 'image_encoder.features.6.block.2.fc2.bias', 'image_encoder.features.6.block.2.fc2.weight', 'image_encoder.features.6.block.3.0.weight', 'image_encoder.features.6.block.3.1.bias', 'image_encoder.features.6.block.3.1.weight', 'image_encoder.features.7.block.0.0.weight', 'image_encoder.features.7.block.0.1.bias', 'image_encoder.features.7.block.0.1.weight', 'image_encoder.features.7.block.1.0.weight', 'image_encoder.features.7.block.1.1.bias', 'image_encoder.features.7.block.1.1.weight', 'image_encoder.features.7.block.2.fc1.bias', 'image_encoder.features.7.block.2.fc1.weight', 'image_encoder.features.7.block.2.fc2.bias', 'image_encoder.features.7.block.2.fc2.weight', 'image_encoder.features.7.block.3.0.weight', 'image_encoder.features.7.block.3.1.bias', 'image_encoder.features.7.block.3.1.weight', 'image_encoder.features.8.block.0.0.weight', 'image_encoder.features.8.block.0.1.bias', 'image_encoder.features.8.block.0.1.weight', 'image_encoder.features.8.block.1.0.weight', 'image_encoder.features.8.block.1.1.bias', 'image_encoder.features.8.block.1.1.weight', 'image_encoder.features.8.block.2.fc1.bias', 'image_encoder.features.8.block.2.fc1.weight', 'image_encoder.features.8.block.2.fc2.bias', 'image_encoder.features.8.block.2.fc2.weight', 'image_encoder.features.8.block.3.0.weight', 'image_encoder.features.8.block.3.1.bias', 'image_encoder.features.8.block.3.1.weight', 'image_encoder.features.9.block.0.0.weight', 'image_encoder.features.9.block.0.1.bias', 'image_encoder.features.9.block.0.1.weight', 'image_encoder.features.9.block.1.0.weight', 'image_encoder.features.9.block.1.1.bias', 'image_encoder.features.9.block.1.1.weight', 'image_encoder.features.9.block.2.fc1.bias', 'image_encoder.features.9.block.2.fc1.weight', 'image_encoder.features.9.block.2.fc2.bias', 'image_encoder.features.9.block.2.fc2.weight', 'image_encoder.features.9.block.3.0.weight', 'image_encoder.features.9.block.3.1.bias', 'image_encoder.features.9.block.3.1.weight', 'sgn_embed.ln.bias', 'sgn_embed.ln.weight', 'sgn_embed.norm.norm.bias', 'sgn_embed.norm.norm.weight']
2021-12-23 11:20:50,835 cfg.name                           : AUTSL Experiment
2021-12-23 11:20:50,836 cfg.data.data_path                 : ./data/
2021-12-23 11:20:50,836 cfg.data.version                   : autsl
2021-12-23 11:20:50,836 cfg.data.sgn                       : sign
2021-12-23 11:20:50,836 cfg.data.gls                       : gloss
2021-12-23 11:20:50,836 cfg.data.feature_size              : 1000
2021-12-23 11:20:50,836 cfg.data.level                     : word
2021-12-23 11:20:50,836 cfg.data.max_sent_length           : 400
2021-12-23 11:20:50,836 cfg.data.random_train_subset       : -1
2021-12-23 11:20:50,837 cfg.data.random_dev_subset         : -1
2021-12-23 11:20:50,837 cfg.testing.recognition_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2021-12-23 11:20:50,837 cfg.testing.translation_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2021-12-23 11:20:50,837 cfg.testing.translation_beam_alphas : [-1, 0, 1, 2, 3, 4, 5]
2021-12-23 11:20:50,837 cfg.training.reset_best_ckpt       : False
2021-12-23 11:20:50,837 cfg.training.reset_scheduler       : False
2021-12-23 11:20:50,837 cfg.training.reset_optimizer       : False
2021-12-23 11:20:50,837 cfg.training.random_seed           : 42
2021-12-23 11:20:50,837 cfg.training.model_dir             : ./AUTSL Experiments/AUTSL_experiment_08
2021-12-23 11:20:50,837 cfg.training.recognition_loss_weight : 1.0
2021-12-23 11:20:50,837 cfg.training.translation_loss_weight : 0.0
2021-12-23 11:20:50,838 cfg.training.eval_metric           : wer
2021-12-23 11:20:50,838 cfg.training.optimizer             : adam
2021-12-23 11:20:50,838 cfg.training.learning_rate         : 0.001
2021-12-23 11:20:50,838 cfg.training.batch_size            : 32
2021-12-23 11:20:50,838 cfg.training.num_valid_log         : 5
2021-12-23 11:20:50,838 cfg.training.epochs                : 5000000
2021-12-23 11:20:50,838 cfg.training.early_stopping_metric : eval_metric
2021-12-23 11:20:50,838 cfg.training.batch_type            : batch
2021-12-23 11:20:50,838 cfg.training.translation_normalization : batch
2021-12-23 11:20:50,838 cfg.training.eval_recognition_beam_size : 9
2021-12-23 11:20:50,838 cfg.training.eval_translation_beam_size : 9
2021-12-23 11:20:50,838 cfg.training.eval_translation_beam_alpha : 1
2021-12-23 11:20:50,838 cfg.training.overwrite             : True
2021-12-23 11:20:50,839 cfg.training.shuffle               : True
2021-12-23 11:20:50,839 cfg.training.use_cuda              : True
2021-12-23 11:20:50,839 cfg.training.translation_max_output_length : 30
2021-12-23 11:20:50,839 cfg.training.keep_last_ckpts       : 1
2021-12-23 11:20:50,839 cfg.training.batch_multiplier      : 1
2021-12-23 11:20:50,839 cfg.training.logging_freq          : 1
2021-12-23 11:20:50,839 cfg.training.validation_freq       : 400
2021-12-23 11:20:50,839 cfg.training.betas                 : [0.9, 0.998]
2021-12-23 11:20:50,839 cfg.training.scheduling            : plateau
2021-12-23 11:20:50,839 cfg.training.learning_rate_min     : 1e-06
2021-12-23 11:20:50,839 cfg.training.weight_decay          : 0.001
2021-12-23 11:20:50,839 cfg.training.patience              : 8
2021-12-23 11:20:50,839 cfg.training.decrease_factor       : 0.7
2021-12-23 11:20:50,840 cfg.training.label_smoothing       : 0.0
2021-12-23 11:20:50,840 cfg.model.initializer              : xavier
2021-12-23 11:20:50,840 cfg.model.bias_initializer         : zeros
2021-12-23 11:20:50,840 cfg.model.init_gain                : 1.0
2021-12-23 11:20:50,840 cfg.model.embed_initializer        : xavier
2021-12-23 11:20:50,840 cfg.model.embed_init_gain          : 1.0
2021-12-23 11:20:50,840 cfg.model.tied_softmax             : False
2021-12-23 11:20:50,840 cfg.model.encoder.type             : transformer
2021-12-23 11:20:50,840 cfg.model.encoder.num_layers       : 3
2021-12-23 11:20:50,840 cfg.model.encoder.num_heads        : 8
2021-12-23 11:20:50,840 cfg.model.encoder.embeddings.embedding_dim : 512
2021-12-23 11:20:50,840 cfg.model.encoder.embeddings.scale : False
2021-12-23 11:20:50,841 cfg.model.encoder.embeddings.dropout : 0.1
2021-12-23 11:20:50,841 cfg.model.encoder.embeddings.norm_type : batch
2021-12-23 11:20:50,841 cfg.model.encoder.embeddings.activation_type : softsign
2021-12-23 11:20:50,841 cfg.model.encoder.hidden_size      : 512
2021-12-23 11:20:50,841 cfg.model.encoder.ff_size          : 2048
2021-12-23 11:20:50,841 cfg.model.encoder.dropout          : 0.1
2021-12-23 11:20:50,841 cfg.model.decoder.type             : transformer
2021-12-23 11:20:50,841 cfg.model.decoder.num_layers       : 3
2021-12-23 11:20:50,841 cfg.model.decoder.num_heads        : 8
2021-12-23 11:20:50,841 cfg.model.decoder.embeddings.embedding_dim : 512
2021-12-23 11:20:50,841 cfg.model.decoder.embeddings.scale : False
2021-12-23 11:20:50,841 cfg.model.decoder.embeddings.dropout : 0.1
2021-12-23 11:20:50,841 cfg.model.decoder.embeddings.norm_type : batch
2021-12-23 11:20:50,842 cfg.model.decoder.embeddings.activation_type : softsign
2021-12-23 11:20:50,842 cfg.model.decoder.hidden_size      : 512
2021-12-23 11:20:50,842 cfg.model.decoder.ff_size          : 2048
2021-12-23 11:20:50,842 cfg.model.decoder.dropout          : 0.1
2021-12-23 11:20:50,842 SignModel(
	encoder=TransformerEncoder(num_layers=3, num_heads=8),
	decoder=None,
	sgn_embed=SpatialEmbeddings(embedding_dim=512, input_size=1000),
	txt_embed=None)
2021-12-23 11:20:50,846 EPOCH 1
2021-12-23 11:21:57,515 [Epoch: 001 Step: 00000001] Batch Recognition Loss: 329.171448 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 11:22:59,022 [Epoch: 001 Step: 00000002] Batch Recognition Loss:  15.353312 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 11:23:52,754 [Epoch: 001 Step: 00000003] Batch Recognition Loss:  15.615439 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 11:24:49,130 [Epoch: 001 Step: 00000004] Batch Recognition Loss:  14.591053 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 11:25:50,198 [Epoch: 001 Step: 00000005] Batch Recognition Loss:  13.303015 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 11:26:54,652 [Epoch: 001 Step: 00000006] Batch Recognition Loss:  12.058334 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 11:27:49,741 [Epoch: 001 Step: 00000007] Batch Recognition Loss:   9.851410 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 11:28:44,187 [Epoch: 001 Step: 00000008] Batch Recognition Loss:   8.094025 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 11:29:46,610 [Epoch: 001 Step: 00000009] Batch Recognition Loss:   7.355111 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 11:30:41,369 [Epoch: 001 Step: 00000010] Batch Recognition Loss:  10.070093 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 11:31:37,988 [Epoch: 001 Step: 00000011] Batch Recognition Loss:   6.935046 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 11:32:39,258 [Epoch: 001 Step: 00000012] Batch Recognition Loss:   7.113143 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 11:33:31,341 [Epoch: 001 Step: 00000013] Batch Recognition Loss:   7.386980 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 11:34:29,923 [Epoch: 001 Step: 00000014] Batch Recognition Loss:   8.043898 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 11:35:35,760 [Epoch: 001 Step: 00000015] Batch Recognition Loss:   8.250898 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 11:37:35,857 [Epoch: 001 Step: 00000016] Batch Recognition Loss:   8.232155 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 11:38:42,901 [Epoch: 001 Step: 00000017] Batch Recognition Loss:   7.741101 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 11:39:41,576 [Epoch: 001 Step: 00000018] Batch Recognition Loss:   7.546402 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-23 11:40:48,571 [Epoch: 001 Step: 00000019] Batch Recognition Loss:   7.149868 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 11:41:56,618 [Epoch: 001 Step: 00000020] Batch Recognition Loss:   6.831254 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 11:43:09,435 [Epoch: 001 Step: 00000021] Batch Recognition Loss:   6.768627 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 11:44:15,368 [Epoch: 001 Step: 00000022] Batch Recognition Loss:   7.019660 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 11:45:23,773 [Epoch: 001 Step: 00000023] Batch Recognition Loss:   7.199106 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 11:47:57,995 [Epoch: 001 Step: 00000024] Batch Recognition Loss:   7.313118 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 11:49:22,428 [Epoch: 001 Step: 00000025] Batch Recognition Loss:   7.240496 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 11:50:38,459 [Epoch: 001 Step: 00000026] Batch Recognition Loss:   6.582343 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 11:52:07,665 [Epoch: 001 Step: 00000027] Batch Recognition Loss:   6.643814 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 11:53:47,354 [Epoch: 001 Step: 00000028] Batch Recognition Loss:   6.781222 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 11:55:17,135 [Epoch: 001 Step: 00000029] Batch Recognition Loss:   6.956972 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 11:58:16,995 [Epoch: 001 Step: 00000030] Batch Recognition Loss:   6.996526 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 11:59:56,894 [Epoch: 001 Step: 00000031] Batch Recognition Loss:   6.890027 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:01:42,938 [Epoch: 001 Step: 00000032] Batch Recognition Loss:   7.058925 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:03:17,151 [Epoch: 001 Step: 00000033] Batch Recognition Loss:   6.724020 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:04:57,726 [Epoch: 001 Step: 00000034] Batch Recognition Loss:   6.829363 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:06:46,400 [Epoch: 001 Step: 00000035] Batch Recognition Loss:   6.407557 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:08:29,398 [Epoch: 001 Step: 00000036] Batch Recognition Loss:   6.572009 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:10:11,367 [Epoch: 001 Step: 00000037] Batch Recognition Loss:   6.764832 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:11:54,408 [Epoch: 001 Step: 00000038] Batch Recognition Loss:   6.899477 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:13:42,276 [Epoch: 001 Step: 00000039] Batch Recognition Loss:   6.816635 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:15:34,302 [Epoch: 001 Step: 00000040] Batch Recognition Loss:   6.739940 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:17:23,905 [Epoch: 001 Step: 00000041] Batch Recognition Loss:   6.688249 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:19:20,349 [Epoch: 001 Step: 00000042] Batch Recognition Loss:   6.715131 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:21:17,815 [Epoch: 001 Step: 00000043] Batch Recognition Loss:   6.553776 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:23:22,910 [Epoch: 001 Step: 00000044] Batch Recognition Loss:   6.731259 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:25:21,160 [Epoch: 001 Step: 00000045] Batch Recognition Loss:   6.762692 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:27:22,880 [Epoch: 001 Step: 00000046] Batch Recognition Loss:   6.570094 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:29:15,658 [Epoch: 001 Step: 00000047] Batch Recognition Loss:   6.716934 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:31:13,870 [Epoch: 001 Step: 00000048] Batch Recognition Loss:   6.501323 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:33:10,287 [Epoch: 001 Step: 00000049] Batch Recognition Loss:   6.527025 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:35:05,264 [Epoch: 001 Step: 00000050] Batch Recognition Loss:   6.515058 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:36:57,361 [Epoch: 001 Step: 00000051] Batch Recognition Loss:   6.600694 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:38:48,555 [Epoch: 001 Step: 00000052] Batch Recognition Loss:   6.691831 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:40:45,861 [Epoch: 001 Step: 00000053] Batch Recognition Loss:   6.640250 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:42:51,385 [Epoch: 001 Step: 00000054] Batch Recognition Loss:   6.702043 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:44:46,894 [Epoch: 001 Step: 00000055] Batch Recognition Loss:   6.667799 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:46:47,456 [Epoch: 001 Step: 00000056] Batch Recognition Loss:   6.561574 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:48:41,482 [Epoch: 001 Step: 00000057] Batch Recognition Loss:   6.607924 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:50:39,626 [Epoch: 001 Step: 00000058] Batch Recognition Loss:   6.683764 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:54:49,598 [Epoch: 001 Step: 00000059] Batch Recognition Loss:   6.459802 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:56:25,884 [Epoch: 001 Step: 00000060] Batch Recognition Loss:   6.588275 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 12:58:20,164 [Epoch: 001 Step: 00000061] Batch Recognition Loss:   6.555019 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 13:00:20,193 [Epoch: 001 Step: 00000062] Batch Recognition Loss:   6.587327 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 13:02:17,183 [Epoch: 001 Step: 00000063] Batch Recognition Loss:   6.472089 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 13:04:13,463 [Epoch: 001 Step: 00000064] Batch Recognition Loss:   6.770109 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 13:06:13,183 [Epoch: 001 Step: 00000065] Batch Recognition Loss:   6.749723 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 13:08:11,182 [Epoch: 001 Step: 00000066] Batch Recognition Loss:   6.572989 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 13:10:00,637 [Epoch: 001 Step: 00000067] Batch Recognition Loss:   6.709230 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 13:11:57,751 [Epoch: 001 Step: 00000068] Batch Recognition Loss:   6.828862 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 13:13:52,443 [Epoch: 001 Step: 00000069] Batch Recognition Loss:   6.616351 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 13:15:52,064 [Epoch: 001 Step: 00000070] Batch Recognition Loss:   6.642497 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 13:18:11,335 [Epoch: 001 Step: 00000071] Batch Recognition Loss:   6.677073 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 13:22:27,692 [Epoch: 001 Step: 00000072] Batch Recognition Loss:   6.634921 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 13:26:44,104 [Epoch: 001 Step: 00000073] Batch Recognition Loss:   6.479493 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 13:31:03,343 [Epoch: 001 Step: 00000074] Batch Recognition Loss:   6.537110 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 13:35:20,885 [Epoch: 001 Step: 00000075] Batch Recognition Loss:   6.510971 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 13:39:23,592 [Epoch: 001 Step: 00000076] Batch Recognition Loss:   6.719829 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 13:48:36,850 [Epoch: 001 Step: 00000077] Batch Recognition Loss:   6.614615 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 13:52:59,185 [Epoch: 001 Step: 00000078] Batch Recognition Loss:   6.841892 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 13:57:06,022 [Epoch: 001 Step: 00000079] Batch Recognition Loss:   6.801796 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:01:29,187 [Epoch: 001 Step: 00000080] Batch Recognition Loss:   6.565461 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:05:47,194 [Epoch: 001 Step: 00000081] Batch Recognition Loss:   6.700316 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:10:15,030 [Epoch: 001 Step: 00000082] Batch Recognition Loss:   6.924912 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:15:05,708 [Epoch: 001 Step: 00000083] Batch Recognition Loss:   6.742675 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:19:46,585 [Epoch: 001 Step: 00000084] Batch Recognition Loss:   6.576694 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:24:24,174 [Epoch: 001 Step: 00000085] Batch Recognition Loss:   6.547658 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:29:20,011 [Epoch: 001 Step: 00000086] Batch Recognition Loss:   6.794973 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:33:52,796 [Epoch: 001 Step: 00000087] Batch Recognition Loss:   6.812187 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:38:45,815 [Epoch: 001 Step: 00000088] Batch Recognition Loss:   6.710304 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:43:46,567 [Epoch: 001 Step: 00000089] Batch Recognition Loss:   6.418104 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:48:31,708 [Epoch: 001 Step: 00000090] Batch Recognition Loss:   6.654431 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:53:37,697 [Epoch: 001 Step: 00000091] Batch Recognition Loss:   6.631837 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:59:04,124 [Epoch: 001 Step: 00000092] Batch Recognition Loss:   6.580539 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 15:04:21,693 [Epoch: 001 Step: 00000093] Batch Recognition Loss:   6.561817 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 15:08:21,876 [Epoch: 001 Step: 00000094] Batch Recognition Loss:   6.636776 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 15:12:55,602 [Epoch: 001 Step: 00000095] Batch Recognition Loss:   6.679553 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 15:17:00,472 [Epoch: 001 Step: 00000096] Batch Recognition Loss:   6.491055 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 15:21:29,117 [Epoch: 001 Step: 00000097] Batch Recognition Loss:   6.580564 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 15:25:39,726 [Epoch: 001 Step: 00000098] Batch Recognition Loss:   6.668978 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 15:30:30,636 [Epoch: 001 Step: 00000099] Batch Recognition Loss:   6.599964 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 15:34:46,491 [Epoch: 001 Step: 00000100] Batch Recognition Loss:   6.605013 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 15:40:12,486 [Epoch: 001 Step: 00000101] Batch Recognition Loss:   6.688350 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 15:47:52,552 [Epoch: 001 Step: 00000102] Batch Recognition Loss:   6.676397 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 15:56:13,211 [Epoch: 001 Step: 00000103] Batch Recognition Loss:   6.573947 => Gls Tokens per Sec:        0 || Lr: 0.001000
