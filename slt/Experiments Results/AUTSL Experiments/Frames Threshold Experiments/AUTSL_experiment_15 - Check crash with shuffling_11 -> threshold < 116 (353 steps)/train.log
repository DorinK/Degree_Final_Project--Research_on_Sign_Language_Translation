2021-12-27 13:15:50,390 Hello! This is Joey-NMT.
2021-12-27 13:15:50,521 Total params: 12632045
2021-12-27 13:15:50,523 Trainable parameters: ['encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'gloss_output_layer.bias', 'gloss_output_layer.weight', 'image_encoder.classifier.0.bias', 'image_encoder.classifier.0.weight', 'image_encoder.classifier.3.bias', 'image_encoder.classifier.3.weight', 'image_encoder.features.0.0.weight', 'image_encoder.features.0.1.bias', 'image_encoder.features.0.1.weight', 'image_encoder.features.1.block.0.0.weight', 'image_encoder.features.1.block.0.1.bias', 'image_encoder.features.1.block.0.1.weight', 'image_encoder.features.1.block.1.fc1.bias', 'image_encoder.features.1.block.1.fc1.weight', 'image_encoder.features.1.block.1.fc2.bias', 'image_encoder.features.1.block.1.fc2.weight', 'image_encoder.features.1.block.2.0.weight', 'image_encoder.features.1.block.2.1.bias', 'image_encoder.features.1.block.2.1.weight', 'image_encoder.features.10.block.0.0.weight', 'image_encoder.features.10.block.0.1.bias', 'image_encoder.features.10.block.0.1.weight', 'image_encoder.features.10.block.1.0.weight', 'image_encoder.features.10.block.1.1.bias', 'image_encoder.features.10.block.1.1.weight', 'image_encoder.features.10.block.2.fc1.bias', 'image_encoder.features.10.block.2.fc1.weight', 'image_encoder.features.10.block.2.fc2.bias', 'image_encoder.features.10.block.2.fc2.weight', 'image_encoder.features.10.block.3.0.weight', 'image_encoder.features.10.block.3.1.bias', 'image_encoder.features.10.block.3.1.weight', 'image_encoder.features.11.block.0.0.weight', 'image_encoder.features.11.block.0.1.bias', 'image_encoder.features.11.block.0.1.weight', 'image_encoder.features.11.block.1.0.weight', 'image_encoder.features.11.block.1.1.bias', 'image_encoder.features.11.block.1.1.weight', 'image_encoder.features.11.block.2.fc1.bias', 'image_encoder.features.11.block.2.fc1.weight', 'image_encoder.features.11.block.2.fc2.bias', 'image_encoder.features.11.block.2.fc2.weight', 'image_encoder.features.11.block.3.0.weight', 'image_encoder.features.11.block.3.1.bias', 'image_encoder.features.11.block.3.1.weight', 'image_encoder.features.12.0.weight', 'image_encoder.features.12.1.bias', 'image_encoder.features.12.1.weight', 'image_encoder.features.2.block.0.0.weight', 'image_encoder.features.2.block.0.1.bias', 'image_encoder.features.2.block.0.1.weight', 'image_encoder.features.2.block.1.0.weight', 'image_encoder.features.2.block.1.1.bias', 'image_encoder.features.2.block.1.1.weight', 'image_encoder.features.2.block.2.0.weight', 'image_encoder.features.2.block.2.1.bias', 'image_encoder.features.2.block.2.1.weight', 'image_encoder.features.3.block.0.0.weight', 'image_encoder.features.3.block.0.1.bias', 'image_encoder.features.3.block.0.1.weight', 'image_encoder.features.3.block.1.0.weight', 'image_encoder.features.3.block.1.1.bias', 'image_encoder.features.3.block.1.1.weight', 'image_encoder.features.3.block.2.0.weight', 'image_encoder.features.3.block.2.1.bias', 'image_encoder.features.3.block.2.1.weight', 'image_encoder.features.4.block.0.0.weight', 'image_encoder.features.4.block.0.1.bias', 'image_encoder.features.4.block.0.1.weight', 'image_encoder.features.4.block.1.0.weight', 'image_encoder.features.4.block.1.1.bias', 'image_encoder.features.4.block.1.1.weight', 'image_encoder.features.4.block.2.fc1.bias', 'image_encoder.features.4.block.2.fc1.weight', 'image_encoder.features.4.block.2.fc2.bias', 'image_encoder.features.4.block.2.fc2.weight', 'image_encoder.features.4.block.3.0.weight', 'image_encoder.features.4.block.3.1.bias', 'image_encoder.features.4.block.3.1.weight', 'image_encoder.features.5.block.0.0.weight', 'image_encoder.features.5.block.0.1.bias', 'image_encoder.features.5.block.0.1.weight', 'image_encoder.features.5.block.1.0.weight', 'image_encoder.features.5.block.1.1.bias', 'image_encoder.features.5.block.1.1.weight', 'image_encoder.features.5.block.2.fc1.bias', 'image_encoder.features.5.block.2.fc1.weight', 'image_encoder.features.5.block.2.fc2.bias', 'image_encoder.features.5.block.2.fc2.weight', 'image_encoder.features.5.block.3.0.weight', 'image_encoder.features.5.block.3.1.bias', 'image_encoder.features.5.block.3.1.weight', 'image_encoder.features.6.block.0.0.weight', 'image_encoder.features.6.block.0.1.bias', 'image_encoder.features.6.block.0.1.weight', 'image_encoder.features.6.block.1.0.weight', 'image_encoder.features.6.block.1.1.bias', 'image_encoder.features.6.block.1.1.weight', 'image_encoder.features.6.block.2.fc1.bias', 'image_encoder.features.6.block.2.fc1.weight', 'image_encoder.features.6.block.2.fc2.bias', 'image_encoder.features.6.block.2.fc2.weight', 'image_encoder.features.6.block.3.0.weight', 'image_encoder.features.6.block.3.1.bias', 'image_encoder.features.6.block.3.1.weight', 'image_encoder.features.7.block.0.0.weight', 'image_encoder.features.7.block.0.1.bias', 'image_encoder.features.7.block.0.1.weight', 'image_encoder.features.7.block.1.0.weight', 'image_encoder.features.7.block.1.1.bias', 'image_encoder.features.7.block.1.1.weight', 'image_encoder.features.7.block.2.fc1.bias', 'image_encoder.features.7.block.2.fc1.weight', 'image_encoder.features.7.block.2.fc2.bias', 'image_encoder.features.7.block.2.fc2.weight', 'image_encoder.features.7.block.3.0.weight', 'image_encoder.features.7.block.3.1.bias', 'image_encoder.features.7.block.3.1.weight', 'image_encoder.features.8.block.0.0.weight', 'image_encoder.features.8.block.0.1.bias', 'image_encoder.features.8.block.0.1.weight', 'image_encoder.features.8.block.1.0.weight', 'image_encoder.features.8.block.1.1.bias', 'image_encoder.features.8.block.1.1.weight', 'image_encoder.features.8.block.2.fc1.bias', 'image_encoder.features.8.block.2.fc1.weight', 'image_encoder.features.8.block.2.fc2.bias', 'image_encoder.features.8.block.2.fc2.weight', 'image_encoder.features.8.block.3.0.weight', 'image_encoder.features.8.block.3.1.bias', 'image_encoder.features.8.block.3.1.weight', 'image_encoder.features.9.block.0.0.weight', 'image_encoder.features.9.block.0.1.bias', 'image_encoder.features.9.block.0.1.weight', 'image_encoder.features.9.block.1.0.weight', 'image_encoder.features.9.block.1.1.bias', 'image_encoder.features.9.block.1.1.weight', 'image_encoder.features.9.block.2.fc1.bias', 'image_encoder.features.9.block.2.fc1.weight', 'image_encoder.features.9.block.2.fc2.bias', 'image_encoder.features.9.block.2.fc2.weight', 'image_encoder.features.9.block.3.0.weight', 'image_encoder.features.9.block.3.1.bias', 'image_encoder.features.9.block.3.1.weight', 'sgn_embed.ln.bias', 'sgn_embed.ln.weight', 'sgn_embed.norm.norm.bias', 'sgn_embed.norm.norm.weight']
2021-12-27 13:15:55,076 cfg.name                           : AUTSL Experiment
2021-12-27 13:15:55,077 cfg.data.data_path                 : ./data/
2021-12-27 13:15:55,077 cfg.data.version                   : autsl
2021-12-27 13:15:55,077 cfg.data.sgn                       : sign
2021-12-27 13:15:55,077 cfg.data.gls                       : gloss
2021-12-27 13:15:55,077 cfg.data.feature_size              : 1000
2021-12-27 13:15:55,077 cfg.data.level                     : word
2021-12-27 13:15:55,077 cfg.data.max_sent_length           : 400
2021-12-27 13:15:55,077 cfg.data.random_train_subset       : -1
2021-12-27 13:15:55,077 cfg.data.random_dev_subset         : -1
2021-12-27 13:15:55,077 cfg.testing.recognition_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2021-12-27 13:15:55,077 cfg.testing.translation_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2021-12-27 13:15:55,077 cfg.testing.translation_beam_alphas : [-1, 0, 1, 2, 3, 4, 5]
2021-12-27 13:15:55,077 cfg.training.reset_best_ckpt       : False
2021-12-27 13:15:55,077 cfg.training.reset_scheduler       : False
2021-12-27 13:15:55,077 cfg.training.reset_optimizer       : False
2021-12-27 13:15:55,077 cfg.training.random_seed           : 42
2021-12-27 13:15:55,077 cfg.training.model_dir             : ./AUTSL Experiments/AUTSL_experiment_15
2021-12-27 13:15:55,077 cfg.training.recognition_loss_weight : 1.0
2021-12-27 13:15:55,078 cfg.training.translation_loss_weight : 0.0
2021-12-27 13:15:55,078 cfg.training.eval_metric           : wer
2021-12-27 13:15:55,078 cfg.training.optimizer             : adam
2021-12-27 13:15:55,078 cfg.training.learning_rate         : 0.001
2021-12-27 13:15:55,078 cfg.training.batch_size            : 32
2021-12-27 13:15:55,078 cfg.training.num_valid_log         : 5
2021-12-27 13:15:55,078 cfg.training.epochs                : 5000000
2021-12-27 13:15:55,078 cfg.training.early_stopping_metric : eval_metric
2021-12-27 13:15:55,078 cfg.training.batch_type            : sentence
2021-12-27 13:15:55,078 cfg.training.translation_normalization : batch
2021-12-27 13:15:55,078 cfg.training.eval_recognition_beam_size : 9
2021-12-27 13:15:55,078 cfg.training.eval_translation_beam_size : 9
2021-12-27 13:15:55,078 cfg.training.eval_translation_beam_alpha : 1
2021-12-27 13:15:55,078 cfg.training.overwrite             : True
2021-12-27 13:15:55,078 cfg.training.shuffle               : True
2021-12-27 13:15:55,078 cfg.training.use_cuda              : True
2021-12-27 13:15:55,078 cfg.training.translation_max_output_length : 30
2021-12-27 13:15:55,078 cfg.training.keep_last_ckpts       : 1
2021-12-27 13:15:55,078 cfg.training.batch_multiplier      : 1
2021-12-27 13:15:55,078 cfg.training.logging_freq          : 1
2021-12-27 13:15:55,078 cfg.training.validation_freq       : 400
2021-12-27 13:15:55,079 cfg.training.betas                 : [0.9, 0.998]
2021-12-27 13:15:55,079 cfg.training.scheduling            : plateau
2021-12-27 13:15:55,079 cfg.training.learning_rate_min     : 1e-06
2021-12-27 13:15:55,079 cfg.training.weight_decay          : 0.001
2021-12-27 13:15:55,079 cfg.training.patience              : 8
2021-12-27 13:15:55,079 cfg.training.decrease_factor       : 0.7
2021-12-27 13:15:55,079 cfg.training.label_smoothing       : 0.0
2021-12-27 13:15:55,079 cfg.model.initializer              : xavier
2021-12-27 13:15:55,079 cfg.model.bias_initializer         : zeros
2021-12-27 13:15:55,079 cfg.model.init_gain                : 1.0
2021-12-27 13:15:55,079 cfg.model.embed_initializer        : xavier
2021-12-27 13:15:55,079 cfg.model.embed_init_gain          : 1.0
2021-12-27 13:15:55,079 cfg.model.tied_softmax             : False
2021-12-27 13:15:55,079 cfg.model.encoder.type             : transformer
2021-12-27 13:15:55,079 cfg.model.encoder.num_layers       : 3
2021-12-27 13:15:55,079 cfg.model.encoder.num_heads        : 8
2021-12-27 13:15:55,079 cfg.model.encoder.embeddings.embedding_dim : 512
2021-12-27 13:15:55,079 cfg.model.encoder.embeddings.scale : False
2021-12-27 13:15:55,079 cfg.model.encoder.embeddings.dropout : 0.1
2021-12-27 13:15:55,079 cfg.model.encoder.embeddings.norm_type : batch
2021-12-27 13:15:55,079 cfg.model.encoder.embeddings.activation_type : softsign
2021-12-27 13:15:55,079 cfg.model.encoder.hidden_size      : 512
2021-12-27 13:15:55,080 cfg.model.encoder.ff_size          : 2048
2021-12-27 13:15:55,080 cfg.model.encoder.dropout          : 0.1
2021-12-27 13:15:55,080 cfg.model.decoder.type             : transformer
2021-12-27 13:15:55,080 cfg.model.decoder.num_layers       : 3
2021-12-27 13:15:55,080 cfg.model.decoder.num_heads        : 8
2021-12-27 13:15:55,080 cfg.model.decoder.embeddings.embedding_dim : 512
2021-12-27 13:15:55,080 cfg.model.decoder.embeddings.scale : False
2021-12-27 13:15:55,080 cfg.model.decoder.embeddings.dropout : 0.1
2021-12-27 13:15:55,080 cfg.model.decoder.embeddings.norm_type : batch
2021-12-27 13:15:55,080 cfg.model.decoder.embeddings.activation_type : softsign
2021-12-27 13:15:55,080 cfg.model.decoder.hidden_size      : 512
2021-12-27 13:15:55,080 cfg.model.decoder.ff_size          : 2048
2021-12-27 13:15:55,080 cfg.model.decoder.dropout          : 0.1
2021-12-27 13:15:55,080 SignModel(
	encoder=TransformerEncoder(num_layers=3, num_heads=8),
	decoder=None,
	sgn_embed=SpatialEmbeddings(embedding_dim=512, input_size=1000),
	txt_embed=None)
2021-12-27 13:15:55,083 EPOCH 1
2021-12-27 13:16:58,758 [Epoch: 001 Step: 00000001] Batch Recognition Loss: 321.998291 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 13:18:03,193 [Epoch: 001 Step: 00000002] Batch Recognition Loss:  15.482931 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 13:18:59,409 [Epoch: 001 Step: 00000003] Batch Recognition Loss:  15.784336 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 13:20:06,456 [Epoch: 001 Step: 00000004] Batch Recognition Loss:  14.541039 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 13:21:05,297 [Epoch: 001 Step: 00000005] Batch Recognition Loss:  13.253828 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 13:22:03,468 [Epoch: 001 Step: 00000006] Batch Recognition Loss:  11.572985 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 13:23:03,770 [Epoch: 001 Step: 00000007] Batch Recognition Loss:   9.517660 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 13:23:53,882 [Epoch: 001 Step: 00000008] Batch Recognition Loss:   8.055635 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 13:24:48,604 [Epoch: 001 Step: 00000009] Batch Recognition Loss:   7.385048 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 13:25:47,023 [Epoch: 001 Step: 00000010] Batch Recognition Loss:   8.295465 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 13:26:40,605 [Epoch: 001 Step: 00000011] Batch Recognition Loss:   6.962437 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 13:27:40,825 [Epoch: 001 Step: 00000012] Batch Recognition Loss:   7.134864 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 13:28:39,236 [Epoch: 001 Step: 00000013] Batch Recognition Loss:   7.717060 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 13:29:38,183 [Epoch: 001 Step: 00000014] Batch Recognition Loss:   7.780471 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 13:31:28,873 [Epoch: 001 Step: 00000015] Batch Recognition Loss:   7.881020 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 13:32:36,189 [Epoch: 001 Step: 00000016] Batch Recognition Loss:   7.145322 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 13:33:40,670 [Epoch: 001 Step: 00000017] Batch Recognition Loss:   7.011211 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 13:34:45,999 [Epoch: 001 Step: 00000018] Batch Recognition Loss:   6.619387 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 13:35:48,903 [Epoch: 001 Step: 00000019] Batch Recognition Loss:   7.116870 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 13:36:59,388 [Epoch: 001 Step: 00000020] Batch Recognition Loss:   7.473782 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 13:38:01,312 [Epoch: 001 Step: 00000021] Batch Recognition Loss:   7.217234 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 13:39:04,556 [Epoch: 001 Step: 00000022] Batch Recognition Loss:   6.763765 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-27 13:40:13,340 [Epoch: 001 Step: 00000023] Batch Recognition Loss:   6.608847 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 13:41:26,954 [Epoch: 001 Step: 00000024] Batch Recognition Loss:   6.609352 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 13:44:22,566 [Epoch: 001 Step: 00000025] Batch Recognition Loss:   6.834606 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 13:45:57,042 [Epoch: 001 Step: 00000026] Batch Recognition Loss:   6.820215 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 13:47:20,211 [Epoch: 001 Step: 00000027] Batch Recognition Loss:   6.915508 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 13:48:46,362 [Epoch: 001 Step: 00000028] Batch Recognition Loss:   6.505854 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 13:50:18,406 [Epoch: 001 Step: 00000029] Batch Recognition Loss:   6.748329 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 13:51:41,192 [Epoch: 001 Step: 00000030] Batch Recognition Loss:   6.735648 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 13:53:00,378 [Epoch: 001 Step: 00000031] Batch Recognition Loss:   6.709592 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 13:54:12,523 [Epoch: 001 Step: 00000032] Batch Recognition Loss:   6.970423 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 13:55:34,084 [Epoch: 001 Step: 00000033] Batch Recognition Loss:   6.680275 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 13:56:55,475 [Epoch: 001 Step: 00000034] Batch Recognition Loss:   6.814299 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 13:58:19,644 [Epoch: 001 Step: 00000035] Batch Recognition Loss:   6.712235 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 13:59:38,439 [Epoch: 001 Step: 00000036] Batch Recognition Loss:   6.626531 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:00:50,566 [Epoch: 001 Step: 00000037] Batch Recognition Loss:   6.653179 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:02:15,745 [Epoch: 001 Step: 00000038] Batch Recognition Loss:   6.664872 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:03:28,647 [Epoch: 001 Step: 00000039] Batch Recognition Loss:   6.579674 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:04:47,451 [Epoch: 001 Step: 00000040] Batch Recognition Loss:   6.822686 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:06:29,890 [Epoch: 001 Step: 00000041] Batch Recognition Loss:   6.583159 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:08:10,182 [Epoch: 001 Step: 00000042] Batch Recognition Loss:   6.465638 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:09:48,664 [Epoch: 001 Step: 00000043] Batch Recognition Loss:   6.663095 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:11:38,283 [Epoch: 001 Step: 00000044] Batch Recognition Loss:   6.518384 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:13:25,635 [Epoch: 001 Step: 00000045] Batch Recognition Loss:   6.696145 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:15:07,368 [Epoch: 001 Step: 00000046] Batch Recognition Loss:   6.557459 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:16:40,673 [Epoch: 001 Step: 00000047] Batch Recognition Loss:   6.643673 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:18:22,183 [Epoch: 001 Step: 00000048] Batch Recognition Loss:   6.919584 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:20:10,936 [Epoch: 001 Step: 00000049] Batch Recognition Loss:   6.731354 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:21:51,132 [Epoch: 001 Step: 00000050] Batch Recognition Loss:   6.806588 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:23:36,633 [Epoch: 001 Step: 00000051] Batch Recognition Loss:   6.747892 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:25:25,955 [Epoch: 001 Step: 00000052] Batch Recognition Loss:   6.742497 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:27:20,380 [Epoch: 001 Step: 00000053] Batch Recognition Loss:   6.645441 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:29:08,080 [Epoch: 001 Step: 00000054] Batch Recognition Loss:   6.561926 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:31:02,988 [Epoch: 001 Step: 00000055] Batch Recognition Loss:   6.528806 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:32:52,540 [Epoch: 001 Step: 00000056] Batch Recognition Loss:   6.538125 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:34:43,732 [Epoch: 001 Step: 00000057] Batch Recognition Loss:   6.541316 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:36:35,758 [Epoch: 001 Step: 00000058] Batch Recognition Loss:   6.450949 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:38:41,667 [Epoch: 001 Step: 00000059] Batch Recognition Loss:   6.523929 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:40:38,900 [Epoch: 001 Step: 00000060] Batch Recognition Loss:   6.669024 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:42:41,667 [Epoch: 001 Step: 00000061] Batch Recognition Loss:   6.729916 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:45:11,255 [Epoch: 001 Step: 00000062] Batch Recognition Loss:   6.522817 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:47:13,603 [Epoch: 001 Step: 00000063] Batch Recognition Loss:   6.592821 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:49:16,182 [Epoch: 001 Step: 00000064] Batch Recognition Loss:   6.813968 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:51:23,336 [Epoch: 001 Step: 00000065] Batch Recognition Loss:   6.927940 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:53:24,632 [Epoch: 001 Step: 00000066] Batch Recognition Loss:   6.480556 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:55:26,810 [Epoch: 001 Step: 00000067] Batch Recognition Loss:   6.433607 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:57:29,023 [Epoch: 001 Step: 00000068] Batch Recognition Loss:   6.669024 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 14:59:39,059 [Epoch: 001 Step: 00000069] Batch Recognition Loss:   6.582219 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 15:01:55,167 [Epoch: 001 Step: 00000070] Batch Recognition Loss:   6.600305 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 15:04:06,027 [Epoch: 001 Step: 00000071] Batch Recognition Loss:   6.712122 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 15:06:18,981 [Epoch: 001 Step: 00000072] Batch Recognition Loss:   6.733541 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 15:08:39,441 [Epoch: 001 Step: 00000073] Batch Recognition Loss:   6.641557 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 15:10:54,111 [Epoch: 001 Step: 00000074] Batch Recognition Loss:   6.688166 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 15:13:18,593 [Epoch: 001 Step: 00000075] Batch Recognition Loss:   6.790124 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 15:15:41,071 [Epoch: 001 Step: 00000076] Batch Recognition Loss:   6.777499 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 15:18:04,550 [Epoch: 001 Step: 00000077] Batch Recognition Loss:   6.423792 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 15:20:20,051 [Epoch: 001 Step: 00000078] Batch Recognition Loss:   6.672103 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 15:22:42,407 [Epoch: 001 Step: 00000079] Batch Recognition Loss:   6.693813 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 15:24:37,393 [Epoch: 001 Step: 00000080] Batch Recognition Loss:   6.681439 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 15:26:38,955 [Epoch: 001 Step: 00000081] Batch Recognition Loss:   6.503121 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 15:28:44,013 [Epoch: 001 Step: 00000082] Batch Recognition Loss:   6.622540 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 15:30:48,445 [Epoch: 001 Step: 00000083] Batch Recognition Loss:   6.601607 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 15:32:53,614 [Epoch: 001 Step: 00000084] Batch Recognition Loss:   6.579006 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 15:35:05,552 [Epoch: 001 Step: 00000085] Batch Recognition Loss:   6.663411 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 15:37:17,103 [Epoch: 001 Step: 00000086] Batch Recognition Loss:   6.682588 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 15:39:59,414 [Epoch: 001 Step: 00000087] Batch Recognition Loss:   6.559773 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 15:43:45,470 [Epoch: 001 Step: 00000088] Batch Recognition Loss:   6.743153 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 15:46:21,210 [Epoch: 001 Step: 00000089] Batch Recognition Loss:   6.640152 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 15:51:29,008 [Epoch: 001 Step: 00000090] Batch Recognition Loss:   6.570703 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 15:53:38,084 [Epoch: 001 Step: 00000091] Batch Recognition Loss:   6.554085 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 15:55:48,103 [Epoch: 001 Step: 00000092] Batch Recognition Loss:   6.622803 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 15:58:06,517 [Epoch: 001 Step: 00000093] Batch Recognition Loss:   6.506891 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 16:00:36,579 [Epoch: 001 Step: 00000094] Batch Recognition Loss:   6.660937 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 16:02:57,266 [Epoch: 001 Step: 00000095] Batch Recognition Loss:   6.864128 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 16:05:20,906 [Epoch: 001 Step: 00000096] Batch Recognition Loss:   6.595126 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 16:08:03,531 [Epoch: 001 Step: 00000097] Batch Recognition Loss:   6.438429 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 16:10:51,089 [Epoch: 001 Step: 00000098] Batch Recognition Loss:   6.668863 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 16:16:28,119 [Epoch: 001 Step: 00000099] Batch Recognition Loss:   6.608384 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 16:19:02,240 [Epoch: 001 Step: 00000100] Batch Recognition Loss:   6.694018 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 16:21:23,461 [Epoch: 001 Step: 00000101] Batch Recognition Loss:   6.742487 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 16:23:38,067 [Epoch: 001 Step: 00000102] Batch Recognition Loss:   6.633478 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 16:26:06,635 [Epoch: 001 Step: 00000103] Batch Recognition Loss:   6.605698 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 16:28:37,191 [Epoch: 001 Step: 00000104] Batch Recognition Loss:   6.765366 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 16:30:59,788 [Epoch: 001 Step: 00000105] Batch Recognition Loss:   6.673354 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 16:33:38,299 [Epoch: 001 Step: 00000106] Batch Recognition Loss:   6.308845 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 16:36:15,825 [Epoch: 001 Step: 00000107] Batch Recognition Loss:   6.472705 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 16:41:17,161 [Epoch: 001 Step: 00000108] Batch Recognition Loss:   6.622134 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 16:44:17,450 [Epoch: 001 Step: 00000109] Batch Recognition Loss:   6.814127 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 16:47:17,656 [Epoch: 001 Step: 00000110] Batch Recognition Loss:   6.641507 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 16:50:11,877 [Epoch: 001 Step: 00000111] Batch Recognition Loss:   6.616749 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 16:53:18,974 [Epoch: 001 Step: 00000112] Batch Recognition Loss:   6.510045 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 16:56:24,413 [Epoch: 001 Step: 00000113] Batch Recognition Loss:   6.688455 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 16:59:43,518 [Epoch: 001 Step: 00000114] Batch Recognition Loss:   6.693572 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 17:02:58,108 [Epoch: 001 Step: 00000115] Batch Recognition Loss:   6.668781 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 17:05:36,044 [Epoch: 001 Step: 00000116] Batch Recognition Loss:   6.626622 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 17:08:44,481 [Epoch: 001 Step: 00000117] Batch Recognition Loss:   6.835019 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 17:11:45,972 [Epoch: 001 Step: 00000118] Batch Recognition Loss:   6.556586 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 17:14:58,842 [Epoch: 001 Step: 00000119] Batch Recognition Loss:   6.689267 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 17:17:45,111 [Epoch: 001 Step: 00000120] Batch Recognition Loss:   6.401175 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 17:20:53,817 [Epoch: 001 Step: 00000121] Batch Recognition Loss:   6.580264 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 17:27:28,475 [Epoch: 001 Step: 00000122] Batch Recognition Loss:   6.643871 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 17:30:43,512 [Epoch: 001 Step: 00000123] Batch Recognition Loss:   6.650268 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 17:34:09,153 [Epoch: 001 Step: 00000124] Batch Recognition Loss:   6.592720 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 17:37:01,962 [Epoch: 001 Step: 00000125] Batch Recognition Loss:   6.638408 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 17:40:03,288 [Epoch: 001 Step: 00000126] Batch Recognition Loss:   6.639063 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 17:43:08,031 [Epoch: 001 Step: 00000127] Batch Recognition Loss:   6.726264 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 17:46:06,795 [Epoch: 001 Step: 00000128] Batch Recognition Loss:   6.449957 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 17:49:35,065 [Epoch: 001 Step: 00000129] Batch Recognition Loss:   6.567025 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 17:54:21,056 [Epoch: 001 Step: 00000130] Batch Recognition Loss:   6.740501 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 17:57:43,061 [Epoch: 001 Step: 00000131] Batch Recognition Loss:   6.654449 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 18:00:42,780 [Epoch: 001 Step: 00000132] Batch Recognition Loss:   6.726316 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 18:04:05,068 [Epoch: 001 Step: 00000133] Batch Recognition Loss:   6.706606 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 18:07:49,490 [Epoch: 001 Step: 00000134] Batch Recognition Loss:   6.687453 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 18:11:20,573 [Epoch: 001 Step: 00000135] Batch Recognition Loss:   6.406229 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 18:14:51,173 [Epoch: 001 Step: 00000136] Batch Recognition Loss:   6.634528 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 18:18:37,857 [Epoch: 001 Step: 00000137] Batch Recognition Loss:   6.419646 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 18:22:12,673 [Epoch: 001 Step: 00000138] Batch Recognition Loss:   6.838023 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 18:25:31,248 [Epoch: 001 Step: 00000139] Batch Recognition Loss:   6.592024 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 18:29:08,251 [Epoch: 001 Step: 00000140] Batch Recognition Loss:   6.502312 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 18:32:58,182 [Epoch: 001 Step: 00000141] Batch Recognition Loss:   6.739370 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 18:36:46,686 [Epoch: 001 Step: 00000142] Batch Recognition Loss:   6.611933 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 18:40:44,209 [Epoch: 001 Step: 00000143] Batch Recognition Loss:   6.720076 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 18:44:37,032 [Epoch: 001 Step: 00000144] Batch Recognition Loss:   6.743721 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 18:48:30,713 [Epoch: 001 Step: 00000145] Batch Recognition Loss:   6.722415 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 18:52:33,426 [Epoch: 001 Step: 00000146] Batch Recognition Loss:   6.450128 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 18:56:44,703 [Epoch: 001 Step: 00000147] Batch Recognition Loss:   6.566378 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 19:00:40,887 [Epoch: 001 Step: 00000148] Batch Recognition Loss:   6.632376 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 19:03:59,508 [Epoch: 001 Step: 00000149] Batch Recognition Loss:   6.532353 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 19:07:19,799 [Epoch: 001 Step: 00000150] Batch Recognition Loss:   6.816132 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 19:10:41,871 [Epoch: 001 Step: 00000151] Batch Recognition Loss:   6.793937 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 19:14:03,717 [Epoch: 001 Step: 00000152] Batch Recognition Loss:   6.798785 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 19:19:13,232 [Epoch: 001 Step: 00000153] Batch Recognition Loss:   6.462927 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 19:23:24,268 [Epoch: 001 Step: 00000154] Batch Recognition Loss:   6.696769 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 19:27:05,721 [Epoch: 001 Step: 00000155] Batch Recognition Loss:   6.737579 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 19:31:00,025 [Epoch: 001 Step: 00000156] Batch Recognition Loss:   6.622624 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 19:34:27,803 [Epoch: 001 Step: 00000157] Batch Recognition Loss:   6.599279 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 19:38:15,340 [Epoch: 001 Step: 00000158] Batch Recognition Loss:   6.780470 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 19:41:57,233 [Epoch: 001 Step: 00000159] Batch Recognition Loss:   6.640653 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 19:46:08,384 [Epoch: 001 Step: 00000160] Batch Recognition Loss:   6.568363 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 19:50:20,261 [Epoch: 001 Step: 00000161] Batch Recognition Loss:   6.662792 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 19:54:09,918 [Epoch: 001 Step: 00000162] Batch Recognition Loss:   6.711168 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 19:58:33,332 [Epoch: 001 Step: 00000163] Batch Recognition Loss:   6.634905 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 20:02:42,874 [Epoch: 001 Step: 00000164] Batch Recognition Loss:   6.681802 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 20:07:04,275 [Epoch: 001 Step: 00000165] Batch Recognition Loss:   6.665364 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 20:11:27,091 [Epoch: 001 Step: 00000166] Batch Recognition Loss:   6.571113 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 20:15:00,090 [Epoch: 001 Step: 00000167] Batch Recognition Loss:   6.664584 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 20:18:39,706 [Epoch: 001 Step: 00000168] Batch Recognition Loss:   6.530888 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 20:22:17,988 [Epoch: 001 Step: 00000169] Batch Recognition Loss:   6.788191 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 20:26:13,468 [Epoch: 001 Step: 00000170] Batch Recognition Loss:   6.570129 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 20:29:57,349 [Epoch: 001 Step: 00000171] Batch Recognition Loss:   6.742590 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 20:33:45,246 [Epoch: 001 Step: 00000172] Batch Recognition Loss:   6.388245 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 20:37:40,824 [Epoch: 001 Step: 00000173] Batch Recognition Loss:   6.602076 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 20:41:25,530 [Epoch: 001 Step: 00000174] Batch Recognition Loss:   6.595047 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 20:45:17,779 [Epoch: 001 Step: 00000175] Batch Recognition Loss:   6.643800 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 20:49:06,998 [Epoch: 001 Step: 00000176] Batch Recognition Loss:   6.587484 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 20:53:02,894 [Epoch: 001 Step: 00000177] Batch Recognition Loss:   6.663743 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 20:59:02,769 [Epoch: 001 Step: 00000178] Batch Recognition Loss:   6.466942 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 21:03:26,465 [Epoch: 001 Step: 00000179] Batch Recognition Loss:   6.589374 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 21:07:43,475 [Epoch: 001 Step: 00000180] Batch Recognition Loss:   6.908686 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 21:11:50,629 [Epoch: 001 Step: 00000181] Batch Recognition Loss:   6.771353 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 21:16:01,953 [Epoch: 001 Step: 00000182] Batch Recognition Loss:   6.869255 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 21:19:53,459 [Epoch: 001 Step: 00000183] Batch Recognition Loss:   6.895806 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 21:24:22,669 [Epoch: 001 Step: 00000184] Batch Recognition Loss:   6.582761 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 21:29:00,567 [Epoch: 001 Step: 00000185] Batch Recognition Loss:   6.772104 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 21:33:02,109 [Epoch: 001 Step: 00000186] Batch Recognition Loss:   6.662102 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 21:37:03,056 [Epoch: 001 Step: 00000187] Batch Recognition Loss:   6.840725 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 21:41:04,082 [Epoch: 001 Step: 00000188] Batch Recognition Loss:   6.740568 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 21:45:04,443 [Epoch: 001 Step: 00000189] Batch Recognition Loss:   6.559488 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 21:49:29,131 [Epoch: 001 Step: 00000190] Batch Recognition Loss:   6.707034 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 21:53:38,829 [Epoch: 001 Step: 00000191] Batch Recognition Loss:   6.378642 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 21:57:41,577 [Epoch: 001 Step: 00000192] Batch Recognition Loss:   6.716512 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 22:01:43,893 [Epoch: 001 Step: 00000193] Batch Recognition Loss:   6.648943 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 22:05:44,061 [Epoch: 001 Step: 00000194] Batch Recognition Loss:   6.640091 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 22:09:55,541 [Epoch: 001 Step: 00000195] Batch Recognition Loss:   6.659468 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 22:16:31,594 [Epoch: 001 Step: 00000196] Batch Recognition Loss:   6.648384 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 22:21:17,793 [Epoch: 001 Step: 00000197] Batch Recognition Loss:   6.762917 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 22:26:06,235 [Epoch: 001 Step: 00000198] Batch Recognition Loss:   6.704834 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 22:30:52,519 [Epoch: 001 Step: 00000199] Batch Recognition Loss:   6.870110 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 22:36:16,735 [Epoch: 001 Step: 00000200] Batch Recognition Loss:   6.810923 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 22:41:42,470 [Epoch: 001 Step: 00000201] Batch Recognition Loss:   6.551813 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 22:46:50,712 [Epoch: 001 Step: 00000202] Batch Recognition Loss:   6.415612 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 22:52:39,681 [Epoch: 001 Step: 00000203] Batch Recognition Loss:   6.458801 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 22:56:56,097 [Epoch: 001 Step: 00000204] Batch Recognition Loss:   6.564554 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 23:01:59,420 [Epoch: 001 Step: 00000205] Batch Recognition Loss:   6.723116 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 23:06:28,238 [Epoch: 001 Step: 00000206] Batch Recognition Loss:   6.634249 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 23:10:44,273 [Epoch: 001 Step: 00000207] Batch Recognition Loss:   6.616791 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 23:15:09,626 [Epoch: 001 Step: 00000208] Batch Recognition Loss:   6.744658 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 23:19:35,172 [Epoch: 001 Step: 00000209] Batch Recognition Loss:   6.683417 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 23:24:53,515 [Epoch: 001 Step: 00000210] Batch Recognition Loss:   6.683818 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 23:31:26,433 [Epoch: 001 Step: 00000211] Batch Recognition Loss:   6.646314 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 23:36:58,313 [Epoch: 001 Step: 00000212] Batch Recognition Loss:   6.545608 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 23:43:24,865 [Epoch: 001 Step: 00000213] Batch Recognition Loss:   6.492043 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 23:49:22,391 [Epoch: 001 Step: 00000214] Batch Recognition Loss:   6.612717 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-27 23:56:19,290 [Epoch: 001 Step: 00000215] Batch Recognition Loss:   6.728706 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 00:03:13,291 [Epoch: 001 Step: 00000216] Batch Recognition Loss:   6.683640 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 00:08:47,927 [Epoch: 001 Step: 00000217] Batch Recognition Loss:   6.810040 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 00:23:34,294 [Epoch: 001 Step: 00000218] Batch Recognition Loss:   6.778267 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 00:30:25,947 [Epoch: 001 Step: 00000219] Batch Recognition Loss:   6.571112 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 00:37:37,618 [Epoch: 001 Step: 00000220] Batch Recognition Loss:   6.430092 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 00:43:59,760 [Epoch: 001 Step: 00000221] Batch Recognition Loss:   6.609609 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 00:51:07,892 [Epoch: 001 Step: 00000222] Batch Recognition Loss:   6.560061 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 00:57:20,788 [Epoch: 001 Step: 00000223] Batch Recognition Loss:   6.649912 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 01:04:23,361 [Epoch: 001 Step: 00000224] Batch Recognition Loss:   6.760126 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 01:11:15,000 [Epoch: 001 Step: 00000225] Batch Recognition Loss:   6.564573 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 01:18:16,951 [Epoch: 001 Step: 00000226] Batch Recognition Loss:   6.800822 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 01:25:33,370 [Epoch: 001 Step: 00000227] Batch Recognition Loss:   6.553888 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 01:31:54,181 [Epoch: 001 Step: 00000228] Batch Recognition Loss:   6.623231 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 01:39:14,646 [Epoch: 001 Step: 00000229] Batch Recognition Loss:   6.604594 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 01:46:53,167 [Epoch: 001 Step: 00000230] Batch Recognition Loss:   6.628161 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 01:54:05,038 [Epoch: 001 Step: 00000231] Batch Recognition Loss:   6.415677 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 02:01:43,700 [Epoch: 001 Step: 00000232] Batch Recognition Loss:   6.490168 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 02:08:21,004 [Epoch: 001 Step: 00000233] Batch Recognition Loss:   6.797721 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 02:15:46,339 [Epoch: 001 Step: 00000234] Batch Recognition Loss:   6.821981 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 02:22:48,389 [Epoch: 001 Step: 00000235] Batch Recognition Loss:   6.676050 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 02:30:08,823 [Epoch: 001 Step: 00000236] Batch Recognition Loss:   6.731581 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 02:37:34,324 [Epoch: 001 Step: 00000237] Batch Recognition Loss:   6.655475 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 02:44:54,162 [Epoch: 001 Step: 00000238] Batch Recognition Loss:   6.550289 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 02:52:38,891 [Epoch: 001 Step: 00000239] Batch Recognition Loss:   6.588233 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 03:00:22,475 [Epoch: 001 Step: 00000240] Batch Recognition Loss:   6.766932 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 03:07:47,670 [Epoch: 001 Step: 00000241] Batch Recognition Loss:   6.677920 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 03:15:52,488 [Epoch: 001 Step: 00000242] Batch Recognition Loss:   6.553199 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 03:23:45,733 [Epoch: 001 Step: 00000243] Batch Recognition Loss:   6.696715 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 03:31:51,167 [Epoch: 001 Step: 00000244] Batch Recognition Loss:   6.486249 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 03:39:47,206 [Epoch: 001 Step: 00000245] Batch Recognition Loss:   6.734687 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 03:47:54,237 [Epoch: 001 Step: 00000246] Batch Recognition Loss:   6.757930 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 03:57:01,526 [Epoch: 001 Step: 00000247] Batch Recognition Loss:   6.786096 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 04:05:22,370 [Epoch: 001 Step: 00000248] Batch Recognition Loss:   6.544826 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 04:13:21,939 [Epoch: 001 Step: 00000249] Batch Recognition Loss:   6.815171 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 04:21:51,832 [Epoch: 001 Step: 00000250] Batch Recognition Loss:   6.769769 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 04:30:12,727 [Epoch: 001 Step: 00000251] Batch Recognition Loss:   6.822524 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 04:39:26,840 [Epoch: 001 Step: 00000252] Batch Recognition Loss:   6.737079 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 04:47:40,117 [Epoch: 001 Step: 00000253] Batch Recognition Loss:   6.816037 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 05:03:43,472 [Epoch: 001 Step: 00000254] Batch Recognition Loss:   6.592737 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 05:11:30,126 [Epoch: 001 Step: 00000255] Batch Recognition Loss:   6.668517 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 05:28:06,011 [Epoch: 001 Step: 00000256] Batch Recognition Loss:   6.611607 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 05:37:14,542 [Epoch: 001 Step: 00000257] Batch Recognition Loss:   6.558043 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 05:45:31,123 [Epoch: 001 Step: 00000258] Batch Recognition Loss:   6.442981 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 05:53:51,416 [Epoch: 001 Step: 00000259] Batch Recognition Loss:   6.420497 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 06:02:24,730 [Epoch: 001 Step: 00000260] Batch Recognition Loss:   6.401239 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 06:10:37,376 [Epoch: 001 Step: 00000261] Batch Recognition Loss:   6.639702 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 06:19:10,597 [Epoch: 001 Step: 00000262] Batch Recognition Loss:   6.882924 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 06:28:20,651 [Epoch: 001 Step: 00000263] Batch Recognition Loss:   6.455650 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 06:35:25,396 [Epoch: 001 Step: 00000264] Batch Recognition Loss:   6.762211 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 06:44:08,078 [Epoch: 001 Step: 00000265] Batch Recognition Loss:   6.633598 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 06:51:44,105 [Epoch: 001 Step: 00000266] Batch Recognition Loss:   6.746943 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 07:00:00,607 [Epoch: 001 Step: 00000267] Batch Recognition Loss:   6.802918 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 07:08:23,262 [Epoch: 001 Step: 00000268] Batch Recognition Loss:   6.769303 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 07:15:55,941 [Epoch: 001 Step: 00000269] Batch Recognition Loss:   6.717031 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 07:25:11,100 [Epoch: 001 Step: 00000270] Batch Recognition Loss:   6.853405 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 07:33:17,999 [Epoch: 001 Step: 00000271] Batch Recognition Loss:   6.419614 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 07:41:55,279 [Epoch: 001 Step: 00000272] Batch Recognition Loss:   6.497756 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 07:50:36,193 [Epoch: 001 Step: 00000273] Batch Recognition Loss:   6.671772 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 07:59:33,156 [Epoch: 001 Step: 00000274] Batch Recognition Loss:   6.719732 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 08:07:52,061 [Epoch: 001 Step: 00000275] Batch Recognition Loss:   6.447062 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 08:16:42,245 [Epoch: 001 Step: 00000276] Batch Recognition Loss:   6.748639 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 08:25:43,491 [Epoch: 001 Step: 00000277] Batch Recognition Loss:   6.568882 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 08:34:38,522 [Epoch: 001 Step: 00000278] Batch Recognition Loss:   6.620682 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 08:43:02,568 [Epoch: 001 Step: 00000279] Batch Recognition Loss:   6.704088 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 08:52:11,850 [Epoch: 001 Step: 00000280] Batch Recognition Loss:   6.700448 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 09:00:46,118 [Epoch: 001 Step: 00000281] Batch Recognition Loss:   6.386253 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 09:10:47,832 [Epoch: 001 Step: 00000282] Batch Recognition Loss:   6.624859 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 09:19:29,142 [Epoch: 001 Step: 00000283] Batch Recognition Loss:   6.617772 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 09:28:47,051 [Epoch: 001 Step: 00000284] Batch Recognition Loss:   6.595646 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 09:37:04,575 [Epoch: 001 Step: 00000285] Batch Recognition Loss:   6.586713 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 09:46:32,122 [Epoch: 001 Step: 00000286] Batch Recognition Loss:   6.782505 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 09:55:04,022 [Epoch: 001 Step: 00000287] Batch Recognition Loss:   6.626794 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 10:04:23,187 [Epoch: 001 Step: 00000288] Batch Recognition Loss:   6.753363 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 10:12:39,859 [Epoch: 001 Step: 00000289] Batch Recognition Loss:   6.485484 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 10:22:25,118 [Epoch: 001 Step: 00000290] Batch Recognition Loss:   6.552410 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 10:31:06,398 [Epoch: 001 Step: 00000291] Batch Recognition Loss:   6.515373 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 10:40:48,739 [Epoch: 001 Step: 00000292] Batch Recognition Loss:   7.054866 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 10:49:31,668 [Epoch: 001 Step: 00000293] Batch Recognition Loss:   6.655711 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 10:59:32,093 [Epoch: 001 Step: 00000294] Batch Recognition Loss:   6.607485 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 11:08:24,178 [Epoch: 001 Step: 00000295] Batch Recognition Loss:   6.644632 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 11:17:25,651 [Epoch: 001 Step: 00000296] Batch Recognition Loss:   6.863798 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 11:27:25,250 [Epoch: 001 Step: 00000297] Batch Recognition Loss:   6.520752 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 11:37:11,091 [Epoch: 001 Step: 00000298] Batch Recognition Loss:   6.709838 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 11:46:41,971 [Epoch: 001 Step: 00000299] Batch Recognition Loss:   6.752658 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 11:55:30,226 [Epoch: 001 Step: 00000300] Batch Recognition Loss:   6.884758 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 12:06:18,038 [Epoch: 001 Step: 00000301] Batch Recognition Loss:   6.637916 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 12:15:01,576 [Epoch: 001 Step: 00000302] Batch Recognition Loss:   6.513816 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 12:24:43,486 [Epoch: 001 Step: 00000303] Batch Recognition Loss:   6.740334 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 12:33:48,687 [Epoch: 001 Step: 00000304] Batch Recognition Loss:   6.521592 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 12:43:41,087 [Epoch: 001 Step: 00000305] Batch Recognition Loss:   6.653529 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 12:52:17,601 [Epoch: 001 Step: 00000306] Batch Recognition Loss:   6.753251 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 13:02:39,837 [Epoch: 001 Step: 00000307] Batch Recognition Loss:   6.529881 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 13:12:38,627 [Epoch: 001 Step: 00000308] Batch Recognition Loss:   6.848949 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 13:22:35,087 [Epoch: 001 Step: 00000309] Batch Recognition Loss:   6.418147 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 13:32:35,703 [Epoch: 001 Step: 00000310] Batch Recognition Loss:   6.808221 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 13:43:22,913 [Epoch: 001 Step: 00000311] Batch Recognition Loss:   6.524313 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 13:53:11,312 [Epoch: 001 Step: 00000312] Batch Recognition Loss:   6.475902 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 14:02:50,463 [Epoch: 001 Step: 00000313] Batch Recognition Loss:   6.570432 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 14:13:29,165 [Epoch: 001 Step: 00000314] Batch Recognition Loss:   6.493407 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 14:23:37,083 [Epoch: 001 Step: 00000315] Batch Recognition Loss:   6.839424 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 14:33:47,865 [Epoch: 001 Step: 00000316] Batch Recognition Loss:   6.497345 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 14:43:26,362 [Epoch: 001 Step: 00000317] Batch Recognition Loss:   6.499519 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 14:54:36,971 [Epoch: 001 Step: 00000318] Batch Recognition Loss:   6.585591 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 15:03:11,773 [Epoch: 001 Step: 00000319] Batch Recognition Loss:   6.640191 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 15:11:41,714 [Epoch: 001 Step: 00000320] Batch Recognition Loss:   6.883264 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 15:20:20,995 [Epoch: 001 Step: 00000321] Batch Recognition Loss:   6.687883 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 15:28:54,565 [Epoch: 001 Step: 00000322] Batch Recognition Loss:   6.754315 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 15:39:19,683 [Epoch: 001 Step: 00000323] Batch Recognition Loss:   6.609663 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 15:48:54,064 [Epoch: 001 Step: 00000324] Batch Recognition Loss:   6.864240 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 15:58:10,782 [Epoch: 001 Step: 00000325] Batch Recognition Loss:   6.708350 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 16:08:18,598 [Epoch: 001 Step: 00000326] Batch Recognition Loss:   6.608614 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 16:18:35,559 [Epoch: 001 Step: 00000327] Batch Recognition Loss:   6.575360 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 16:28:24,319 [Epoch: 001 Step: 00000328] Batch Recognition Loss:   6.592277 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 16:37:06,278 [Epoch: 001 Step: 00000329] Batch Recognition Loss:   6.563568 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 16:46:03,690 [Epoch: 001 Step: 00000330] Batch Recognition Loss:   6.489424 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 16:55:18,384 [Epoch: 001 Step: 00000331] Batch Recognition Loss:   6.608397 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 17:03:53,412 [Epoch: 001 Step: 00000332] Batch Recognition Loss:   6.840134 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 17:12:45,974 [Epoch: 001 Step: 00000333] Batch Recognition Loss:   6.508975 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 17:20:57,475 [Epoch: 001 Step: 00000334] Batch Recognition Loss:   6.720531 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 17:29:14,167 [Epoch: 001 Step: 00000335] Batch Recognition Loss:   6.496780 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 17:36:27,827 [Epoch: 001 Step: 00000336] Batch Recognition Loss:   6.676065 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 17:44:39,232 [Epoch: 001 Step: 00000337] Batch Recognition Loss:   6.461801 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 17:52:33,663 [Epoch: 001 Step: 00000338] Batch Recognition Loss:   6.631971 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 18:00:48,503 [Epoch: 001 Step: 00000339] Batch Recognition Loss:   6.638771 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 18:09:05,238 [Epoch: 001 Step: 00000340] Batch Recognition Loss:   6.668051 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 18:17:21,667 [Epoch: 001 Step: 00000341] Batch Recognition Loss:   6.692417 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 18:25:34,341 [Epoch: 001 Step: 00000342] Batch Recognition Loss:   6.633332 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 18:33:51,286 [Epoch: 001 Step: 00000343] Batch Recognition Loss:   6.705322 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 18:42:11,198 [Epoch: 001 Step: 00000344] Batch Recognition Loss:   6.636646 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 18:50:29,078 [Epoch: 001 Step: 00000345] Batch Recognition Loss:   6.688390 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 18:58:59,018 [Epoch: 001 Step: 00000346] Batch Recognition Loss:   6.739611 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 19:07:25,751 [Epoch: 001 Step: 00000347] Batch Recognition Loss:   6.547150 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 19:15:52,224 [Epoch: 001 Step: 00000348] Batch Recognition Loss:   6.711742 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 19:24:30,135 [Epoch: 001 Step: 00000349] Batch Recognition Loss:   6.413512 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 19:33:06,176 [Epoch: 001 Step: 00000350] Batch Recognition Loss:   6.663091 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 19:41:31,755 [Epoch: 001 Step: 00000351] Batch Recognition Loss:   6.514555 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 19:50:00,866 [Epoch: 001 Step: 00000352] Batch Recognition Loss:   6.795149 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-28 19:58:34,502 [Epoch: 001 Step: 00000353] Batch Recognition Loss:   6.523082 => Gls Tokens per Sec:        0 || Lr: 0.001000
