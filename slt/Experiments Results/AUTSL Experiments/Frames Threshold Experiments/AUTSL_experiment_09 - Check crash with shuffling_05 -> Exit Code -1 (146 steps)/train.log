2021-12-23 13:52:18,224 Hello! This is Joey-NMT.
2021-12-23 13:52:25,424 Total params: 12632045
2021-12-23 13:52:25,427 Trainable parameters: ['encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'gloss_output_layer.bias', 'gloss_output_layer.weight', 'image_encoder.classifier.0.bias', 'image_encoder.classifier.0.weight', 'image_encoder.classifier.3.bias', 'image_encoder.classifier.3.weight', 'image_encoder.features.0.0.weight', 'image_encoder.features.0.1.bias', 'image_encoder.features.0.1.weight', 'image_encoder.features.1.block.0.0.weight', 'image_encoder.features.1.block.0.1.bias', 'image_encoder.features.1.block.0.1.weight', 'image_encoder.features.1.block.1.fc1.bias', 'image_encoder.features.1.block.1.fc1.weight', 'image_encoder.features.1.block.1.fc2.bias', 'image_encoder.features.1.block.1.fc2.weight', 'image_encoder.features.1.block.2.0.weight', 'image_encoder.features.1.block.2.1.bias', 'image_encoder.features.1.block.2.1.weight', 'image_encoder.features.10.block.0.0.weight', 'image_encoder.features.10.block.0.1.bias', 'image_encoder.features.10.block.0.1.weight', 'image_encoder.features.10.block.1.0.weight', 'image_encoder.features.10.block.1.1.bias', 'image_encoder.features.10.block.1.1.weight', 'image_encoder.features.10.block.2.fc1.bias', 'image_encoder.features.10.block.2.fc1.weight', 'image_encoder.features.10.block.2.fc2.bias', 'image_encoder.features.10.block.2.fc2.weight', 'image_encoder.features.10.block.3.0.weight', 'image_encoder.features.10.block.3.1.bias', 'image_encoder.features.10.block.3.1.weight', 'image_encoder.features.11.block.0.0.weight', 'image_encoder.features.11.block.0.1.bias', 'image_encoder.features.11.block.0.1.weight', 'image_encoder.features.11.block.1.0.weight', 'image_encoder.features.11.block.1.1.bias', 'image_encoder.features.11.block.1.1.weight', 'image_encoder.features.11.block.2.fc1.bias', 'image_encoder.features.11.block.2.fc1.weight', 'image_encoder.features.11.block.2.fc2.bias', 'image_encoder.features.11.block.2.fc2.weight', 'image_encoder.features.11.block.3.0.weight', 'image_encoder.features.11.block.3.1.bias', 'image_encoder.features.11.block.3.1.weight', 'image_encoder.features.12.0.weight', 'image_encoder.features.12.1.bias', 'image_encoder.features.12.1.weight', 'image_encoder.features.2.block.0.0.weight', 'image_encoder.features.2.block.0.1.bias', 'image_encoder.features.2.block.0.1.weight', 'image_encoder.features.2.block.1.0.weight', 'image_encoder.features.2.block.1.1.bias', 'image_encoder.features.2.block.1.1.weight', 'image_encoder.features.2.block.2.0.weight', 'image_encoder.features.2.block.2.1.bias', 'image_encoder.features.2.block.2.1.weight', 'image_encoder.features.3.block.0.0.weight', 'image_encoder.features.3.block.0.1.bias', 'image_encoder.features.3.block.0.1.weight', 'image_encoder.features.3.block.1.0.weight', 'image_encoder.features.3.block.1.1.bias', 'image_encoder.features.3.block.1.1.weight', 'image_encoder.features.3.block.2.0.weight', 'image_encoder.features.3.block.2.1.bias', 'image_encoder.features.3.block.2.1.weight', 'image_encoder.features.4.block.0.0.weight', 'image_encoder.features.4.block.0.1.bias', 'image_encoder.features.4.block.0.1.weight', 'image_encoder.features.4.block.1.0.weight', 'image_encoder.features.4.block.1.1.bias', 'image_encoder.features.4.block.1.1.weight', 'image_encoder.features.4.block.2.fc1.bias', 'image_encoder.features.4.block.2.fc1.weight', 'image_encoder.features.4.block.2.fc2.bias', 'image_encoder.features.4.block.2.fc2.weight', 'image_encoder.features.4.block.3.0.weight', 'image_encoder.features.4.block.3.1.bias', 'image_encoder.features.4.block.3.1.weight', 'image_encoder.features.5.block.0.0.weight', 'image_encoder.features.5.block.0.1.bias', 'image_encoder.features.5.block.0.1.weight', 'image_encoder.features.5.block.1.0.weight', 'image_encoder.features.5.block.1.1.bias', 'image_encoder.features.5.block.1.1.weight', 'image_encoder.features.5.block.2.fc1.bias', 'image_encoder.features.5.block.2.fc1.weight', 'image_encoder.features.5.block.2.fc2.bias', 'image_encoder.features.5.block.2.fc2.weight', 'image_encoder.features.5.block.3.0.weight', 'image_encoder.features.5.block.3.1.bias', 'image_encoder.features.5.block.3.1.weight', 'image_encoder.features.6.block.0.0.weight', 'image_encoder.features.6.block.0.1.bias', 'image_encoder.features.6.block.0.1.weight', 'image_encoder.features.6.block.1.0.weight', 'image_encoder.features.6.block.1.1.bias', 'image_encoder.features.6.block.1.1.weight', 'image_encoder.features.6.block.2.fc1.bias', 'image_encoder.features.6.block.2.fc1.weight', 'image_encoder.features.6.block.2.fc2.bias', 'image_encoder.features.6.block.2.fc2.weight', 'image_encoder.features.6.block.3.0.weight', 'image_encoder.features.6.block.3.1.bias', 'image_encoder.features.6.block.3.1.weight', 'image_encoder.features.7.block.0.0.weight', 'image_encoder.features.7.block.0.1.bias', 'image_encoder.features.7.block.0.1.weight', 'image_encoder.features.7.block.1.0.weight', 'image_encoder.features.7.block.1.1.bias', 'image_encoder.features.7.block.1.1.weight', 'image_encoder.features.7.block.2.fc1.bias', 'image_encoder.features.7.block.2.fc1.weight', 'image_encoder.features.7.block.2.fc2.bias', 'image_encoder.features.7.block.2.fc2.weight', 'image_encoder.features.7.block.3.0.weight', 'image_encoder.features.7.block.3.1.bias', 'image_encoder.features.7.block.3.1.weight', 'image_encoder.features.8.block.0.0.weight', 'image_encoder.features.8.block.0.1.bias', 'image_encoder.features.8.block.0.1.weight', 'image_encoder.features.8.block.1.0.weight', 'image_encoder.features.8.block.1.1.bias', 'image_encoder.features.8.block.1.1.weight', 'image_encoder.features.8.block.2.fc1.bias', 'image_encoder.features.8.block.2.fc1.weight', 'image_encoder.features.8.block.2.fc2.bias', 'image_encoder.features.8.block.2.fc2.weight', 'image_encoder.features.8.block.3.0.weight', 'image_encoder.features.8.block.3.1.bias', 'image_encoder.features.8.block.3.1.weight', 'image_encoder.features.9.block.0.0.weight', 'image_encoder.features.9.block.0.1.bias', 'image_encoder.features.9.block.0.1.weight', 'image_encoder.features.9.block.1.0.weight', 'image_encoder.features.9.block.1.1.bias', 'image_encoder.features.9.block.1.1.weight', 'image_encoder.features.9.block.2.fc1.bias', 'image_encoder.features.9.block.2.fc1.weight', 'image_encoder.features.9.block.2.fc2.bias', 'image_encoder.features.9.block.2.fc2.weight', 'image_encoder.features.9.block.3.0.weight', 'image_encoder.features.9.block.3.1.bias', 'image_encoder.features.9.block.3.1.weight', 'sgn_embed.ln.bias', 'sgn_embed.ln.weight', 'sgn_embed.norm.norm.bias', 'sgn_embed.norm.norm.weight']
2021-12-23 13:52:50,476 cfg.name                           : AUTSL Experiment
2021-12-23 13:52:50,477 cfg.data.data_path                 : ./data/
2021-12-23 13:52:50,477 cfg.data.version                   : autsl
2021-12-23 13:52:50,477 cfg.data.sgn                       : sign
2021-12-23 13:52:50,477 cfg.data.gls                       : gloss
2021-12-23 13:52:50,477 cfg.data.feature_size              : 1000
2021-12-23 13:52:50,477 cfg.data.level                     : word
2021-12-23 13:52:50,478 cfg.data.max_sent_length           : 400
2021-12-23 13:52:50,478 cfg.data.random_train_subset       : -1
2021-12-23 13:52:50,478 cfg.data.random_dev_subset         : -1
2021-12-23 13:52:50,478 cfg.testing.recognition_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2021-12-23 13:52:50,478 cfg.testing.translation_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2021-12-23 13:52:50,478 cfg.testing.translation_beam_alphas : [-1, 0, 1, 2, 3, 4, 5]
2021-12-23 13:52:50,478 cfg.training.reset_best_ckpt       : False
2021-12-23 13:52:50,479 cfg.training.reset_scheduler       : False
2021-12-23 13:52:50,479 cfg.training.reset_optimizer       : False
2021-12-23 13:52:50,479 cfg.training.random_seed           : 42
2021-12-23 13:52:50,479 cfg.training.model_dir             : ./AUTSL Experiments/AUTSL_experiment_09
2021-12-23 13:52:50,479 cfg.training.recognition_loss_weight : 1.0
2021-12-23 13:52:50,479 cfg.training.translation_loss_weight : 0.0
2021-12-23 13:52:50,479 cfg.training.eval_metric           : wer
2021-12-23 13:52:50,480 cfg.training.optimizer             : adam
2021-12-23 13:52:50,480 cfg.training.learning_rate         : 0.001
2021-12-23 13:52:50,480 cfg.training.batch_size            : 32
2021-12-23 13:52:50,480 cfg.training.num_valid_log         : 5
2021-12-23 13:52:50,480 cfg.training.epochs                : 5000000
2021-12-23 13:52:50,480 cfg.training.early_stopping_metric : eval_metric
2021-12-23 13:52:50,480 cfg.training.batch_type            : batch
2021-12-23 13:52:50,481 cfg.training.translation_normalization : batch
2021-12-23 13:52:50,481 cfg.training.eval_recognition_beam_size : 9
2021-12-23 13:52:50,481 cfg.training.eval_translation_beam_size : 9
2021-12-23 13:52:50,481 cfg.training.eval_translation_beam_alpha : 1
2021-12-23 13:52:50,481 cfg.training.overwrite             : True
2021-12-23 13:52:50,481 cfg.training.shuffle               : True
2021-12-23 13:52:50,481 cfg.training.use_cuda              : True
2021-12-23 13:52:50,481 cfg.training.translation_max_output_length : 30
2021-12-23 13:52:50,482 cfg.training.keep_last_ckpts       : 1
2021-12-23 13:52:50,482 cfg.training.batch_multiplier      : 1
2021-12-23 13:52:50,482 cfg.training.logging_freq          : 1
2021-12-23 13:52:50,482 cfg.training.validation_freq       : 400
2021-12-23 13:52:50,482 cfg.training.betas                 : [0.9, 0.998]
2021-12-23 13:52:50,482 cfg.training.scheduling            : plateau
2021-12-23 13:52:50,482 cfg.training.learning_rate_min     : 1e-06
2021-12-23 13:52:50,483 cfg.training.weight_decay          : 0.001
2021-12-23 13:52:50,483 cfg.training.patience              : 8
2021-12-23 13:52:50,483 cfg.training.decrease_factor       : 0.7
2021-12-23 13:52:50,483 cfg.training.label_smoothing       : 0.0
2021-12-23 13:52:50,483 cfg.model.initializer              : xavier
2021-12-23 13:52:50,483 cfg.model.bias_initializer         : zeros
2021-12-23 13:52:50,483 cfg.model.init_gain                : 1.0
2021-12-23 13:52:50,484 cfg.model.embed_initializer        : xavier
2021-12-23 13:52:50,484 cfg.model.embed_init_gain          : 1.0
2021-12-23 13:52:50,484 cfg.model.tied_softmax             : False
2021-12-23 13:52:50,484 cfg.model.encoder.type             : transformer
2021-12-23 13:52:50,484 cfg.model.encoder.num_layers       : 3
2021-12-23 13:52:50,484 cfg.model.encoder.num_heads        : 8
2021-12-23 13:52:50,484 cfg.model.encoder.embeddings.embedding_dim : 512
2021-12-23 13:52:50,485 cfg.model.encoder.embeddings.scale : False
2021-12-23 13:52:50,485 cfg.model.encoder.embeddings.dropout : 0.1
2021-12-23 13:52:50,485 cfg.model.encoder.embeddings.norm_type : batch
2021-12-23 13:52:50,485 cfg.model.encoder.embeddings.activation_type : softsign
2021-12-23 13:52:50,485 cfg.model.encoder.hidden_size      : 512
2021-12-23 13:52:50,485 cfg.model.encoder.ff_size          : 2048
2021-12-23 13:52:50,485 cfg.model.encoder.dropout          : 0.1
2021-12-23 13:52:50,485 cfg.model.decoder.type             : transformer
2021-12-23 13:52:50,486 cfg.model.decoder.num_layers       : 3
2021-12-23 13:52:50,486 cfg.model.decoder.num_heads        : 8
2021-12-23 13:52:50,486 cfg.model.decoder.embeddings.embedding_dim : 512
2021-12-23 13:52:50,486 cfg.model.decoder.embeddings.scale : False
2021-12-23 13:52:50,486 cfg.model.decoder.embeddings.dropout : 0.1
2021-12-23 13:52:50,486 cfg.model.decoder.embeddings.norm_type : batch
2021-12-23 13:52:50,486 cfg.model.decoder.embeddings.activation_type : softsign
2021-12-23 13:52:50,486 cfg.model.decoder.hidden_size      : 512
2021-12-23 13:52:50,487 cfg.model.decoder.ff_size          : 2048
2021-12-23 13:52:50,487 cfg.model.decoder.dropout          : 0.1
2021-12-23 13:52:50,487 SignModel(
	encoder=TransformerEncoder(num_layers=3, num_heads=8),
	decoder=None,
	sgn_embed=SpatialEmbeddings(embedding_dim=512, input_size=1000),
	txt_embed=None)
2021-12-23 13:52:50,495 EPOCH 1
2021-12-23 13:54:52,340 [Epoch: 001 Step: 00000001] Batch Recognition Loss: 309.619019 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 13:56:43,867 [Epoch: 001 Step: 00000002] Batch Recognition Loss:  15.210443 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 13:58:26,749 [Epoch: 001 Step: 00000003] Batch Recognition Loss:  15.397160 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:00:21,185 [Epoch: 001 Step: 00000004] Batch Recognition Loss:  14.368635 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:02:11,910 [Epoch: 001 Step: 00000005] Batch Recognition Loss:  13.267244 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:04:14,113 [Epoch: 001 Step: 00000006] Batch Recognition Loss:  11.510480 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:06:06,487 [Epoch: 001 Step: 00000007] Batch Recognition Loss:   9.819073 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:10:12,015 [Epoch: 001 Step: 00000008] Batch Recognition Loss:   6.970625 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:12:03,142 [Epoch: 001 Step: 00000009] Batch Recognition Loss:   8.957212 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:14:06,432 [Epoch: 001 Step: 00000010] Batch Recognition Loss:   7.318908 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:15:57,272 [Epoch: 001 Step: 00000011] Batch Recognition Loss:   7.128017 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:17:54,925 [Epoch: 001 Step: 00000012] Batch Recognition Loss:   7.233631 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:19:49,118 [Epoch: 001 Step: 00000013] Batch Recognition Loss:   7.632712 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:22:11,239 [Epoch: 001 Step: 00000014] Batch Recognition Loss:   7.780232 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:24:21,699 [Epoch: 001 Step: 00000015] Batch Recognition Loss:   7.025711 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:26:32,909 [Epoch: 001 Step: 00000016] Batch Recognition Loss:   7.374721 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:28:35,746 [Epoch: 001 Step: 00000017] Batch Recognition Loss:   6.840113 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:30:41,000 [Epoch: 001 Step: 00000018] Batch Recognition Loss:   6.743980 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:33:17,948 [Epoch: 001 Step: 00000019] Batch Recognition Loss:   6.732233 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:35:34,549 [Epoch: 001 Step: 00000020] Batch Recognition Loss:   7.121201 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:37:56,922 [Epoch: 001 Step: 00000021] Batch Recognition Loss:   6.875640 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:40:18,900 [Epoch: 001 Step: 00000022] Batch Recognition Loss:   7.035127 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:45:23,427 [Epoch: 001 Step: 00000023] Batch Recognition Loss:   6.811477 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:48:01,011 [Epoch: 001 Step: 00000024] Batch Recognition Loss:   6.868110 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:50:35,941 [Epoch: 001 Step: 00000025] Batch Recognition Loss:   6.997440 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:53:29,186 [Epoch: 001 Step: 00000026] Batch Recognition Loss:   6.996956 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:56:15,361 [Epoch: 001 Step: 00000027] Batch Recognition Loss:   6.716881 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 14:58:59,002 [Epoch: 001 Step: 00000028] Batch Recognition Loss:   6.857086 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 15:02:14,249 [Epoch: 001 Step: 00000029] Batch Recognition Loss:   6.654897 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 15:04:34,733 [Epoch: 001 Step: 00000030] Batch Recognition Loss:   6.787368 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 15:07:24,799 [Epoch: 001 Step: 00000031] Batch Recognition Loss:   6.786879 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 15:10:04,647 [Epoch: 001 Step: 00000032] Batch Recognition Loss:   6.538520 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 15:13:04,689 [Epoch: 001 Step: 00000033] Batch Recognition Loss:   6.775523 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 15:16:11,955 [Epoch: 001 Step: 00000034] Batch Recognition Loss:   6.578885 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 15:18:47,917 [Epoch: 001 Step: 00000035] Batch Recognition Loss:   6.856676 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 15:21:42,888 [Epoch: 001 Step: 00000036] Batch Recognition Loss:   6.537008 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 15:24:46,667 [Epoch: 001 Step: 00000037] Batch Recognition Loss:   6.682471 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 15:27:31,395 [Epoch: 001 Step: 00000038] Batch Recognition Loss:   6.881595 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 15:30:41,457 [Epoch: 001 Step: 00000039] Batch Recognition Loss:   6.664600 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 15:33:49,443 [Epoch: 001 Step: 00000040] Batch Recognition Loss:   6.904999 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 15:36:47,132 [Epoch: 001 Step: 00000041] Batch Recognition Loss:   6.916086 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 15:40:15,958 [Epoch: 001 Step: 00000042] Batch Recognition Loss:   6.898774 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 15:49:50,324 [Epoch: 001 Step: 00000043] Batch Recognition Loss:   6.507462 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 15:55:03,350 [Epoch: 001 Step: 00000044] Batch Recognition Loss:   6.728112 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 16:00:07,305 [Epoch: 001 Step: 00000045] Batch Recognition Loss:   6.702723 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 16:06:18,422 [Epoch: 001 Step: 00000046] Batch Recognition Loss:   6.465034 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 16:08:55,038 [Epoch: 001 Step: 00000047] Batch Recognition Loss:   6.786318 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 16:12:17,677 [Epoch: 001 Step: 00000048] Batch Recognition Loss:   6.547088 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 16:15:45,979 [Epoch: 001 Step: 00000049] Batch Recognition Loss:   6.503636 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 16:19:19,188 [Epoch: 001 Step: 00000050] Batch Recognition Loss:   6.509789 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 16:22:33,088 [Epoch: 001 Step: 00000051] Batch Recognition Loss:   6.699503 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 16:25:22,884 [Epoch: 001 Step: 00000052] Batch Recognition Loss:   6.824458 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 16:28:36,348 [Epoch: 001 Step: 00000053] Batch Recognition Loss:   6.782596 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 16:31:57,811 [Epoch: 001 Step: 00000054] Batch Recognition Loss:   6.667868 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 16:35:13,253 [Epoch: 001 Step: 00000055] Batch Recognition Loss:   6.736955 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 16:38:23,482 [Epoch: 001 Step: 00000056] Batch Recognition Loss:   6.613651 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 16:41:38,185 [Epoch: 001 Step: 00000057] Batch Recognition Loss:   6.541635 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 16:44:47,529 [Epoch: 001 Step: 00000058] Batch Recognition Loss:   6.272864 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 16:47:49,630 [Epoch: 001 Step: 00000059] Batch Recognition Loss:   6.653243 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 16:51:22,304 [Epoch: 001 Step: 00000060] Batch Recognition Loss:   6.659233 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 16:54:37,019 [Epoch: 001 Step: 00000061] Batch Recognition Loss:   6.793662 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 16:58:19,146 [Epoch: 001 Step: 00000062] Batch Recognition Loss:   6.687763 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 17:02:02,997 [Epoch: 001 Step: 00000063] Batch Recognition Loss:   6.606546 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 17:05:05,200 [Epoch: 001 Step: 00000064] Batch Recognition Loss:   6.496459 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 17:08:49,557 [Epoch: 001 Step: 00000065] Batch Recognition Loss:   6.872598 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 17:11:51,495 [Epoch: 001 Step: 00000066] Batch Recognition Loss:   6.718768 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 17:15:51,996 [Epoch: 001 Step: 00000067] Batch Recognition Loss:   6.830890 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 17:19:18,307 [Epoch: 001 Step: 00000068] Batch Recognition Loss:   6.720192 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 17:22:55,344 [Epoch: 001 Step: 00000069] Batch Recognition Loss:   6.549368 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 17:26:40,745 [Epoch: 001 Step: 00000070] Batch Recognition Loss:   6.611681 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 17:29:50,747 [Epoch: 001 Step: 00000071] Batch Recognition Loss:   6.603457 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 17:33:39,446 [Epoch: 001 Step: 00000072] Batch Recognition Loss:   6.639838 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 17:40:06,260 [Epoch: 001 Step: 00000073] Batch Recognition Loss:   6.555308 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 17:44:00,342 [Epoch: 001 Step: 00000074] Batch Recognition Loss:   6.545694 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 17:47:22,288 [Epoch: 001 Step: 00000075] Batch Recognition Loss:   6.632555 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 17:51:03,984 [Epoch: 001 Step: 00000076] Batch Recognition Loss:   6.665894 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 17:55:08,369 [Epoch: 001 Step: 00000077] Batch Recognition Loss:   6.690145 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 17:59:35,325 [Epoch: 001 Step: 00000078] Batch Recognition Loss:   6.762403 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 18:03:52,399 [Epoch: 001 Step: 00000079] Batch Recognition Loss:   6.616669 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 18:08:33,607 [Epoch: 001 Step: 00000080] Batch Recognition Loss:   6.825343 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 18:13:18,987 [Epoch: 001 Step: 00000081] Batch Recognition Loss:   6.560682 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 18:17:35,781 [Epoch: 001 Step: 00000082] Batch Recognition Loss:   6.479733 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 18:22:06,805 [Epoch: 001 Step: 00000083] Batch Recognition Loss:   6.778739 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 18:27:00,195 [Epoch: 001 Step: 00000084] Batch Recognition Loss:   6.777130 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 18:31:41,354 [Epoch: 001 Step: 00000085] Batch Recognition Loss:   6.609059 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 18:41:37,693 [Epoch: 001 Step: 00000086] Batch Recognition Loss:   6.765332 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 18:46:09,716 [Epoch: 001 Step: 00000087] Batch Recognition Loss:   6.675336 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 18:50:39,945 [Epoch: 001 Step: 00000088] Batch Recognition Loss:   6.444173 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 18:54:46,092 [Epoch: 001 Step: 00000089] Batch Recognition Loss:   6.589073 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 18:58:57,437 [Epoch: 001 Step: 00000090] Batch Recognition Loss:   6.574256 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 19:03:04,652 [Epoch: 001 Step: 00000091] Batch Recognition Loss:   6.629757 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 19:07:28,352 [Epoch: 001 Step: 00000092] Batch Recognition Loss:   6.961360 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 19:11:47,327 [Epoch: 001 Step: 00000093] Batch Recognition Loss:   6.719894 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 19:21:33,191 [Epoch: 001 Step: 00000094] Batch Recognition Loss:   6.429414 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 19:26:10,298 [Epoch: 001 Step: 00000095] Batch Recognition Loss:   6.412454 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 19:30:48,382 [Epoch: 001 Step: 00000096] Batch Recognition Loss:   6.835665 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 19:35:25,619 [Epoch: 001 Step: 00000097] Batch Recognition Loss:   6.699001 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 19:38:26,486 [Epoch: 001 Step: 00000098] Batch Recognition Loss:   6.671618 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 19:41:23,985 [Epoch: 001 Step: 00000099] Batch Recognition Loss:   6.766628 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 19:44:12,640 [Epoch: 001 Step: 00000100] Batch Recognition Loss:   6.766498 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 19:46:54,327 [Epoch: 001 Step: 00000101] Batch Recognition Loss:   6.663253 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 19:49:42,234 [Epoch: 001 Step: 00000102] Batch Recognition Loss:   6.556648 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 19:52:26,757 [Epoch: 001 Step: 00000103] Batch Recognition Loss:   6.535954 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 19:55:08,948 [Epoch: 001 Step: 00000104] Batch Recognition Loss:   6.698297 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 20:00:47,699 [Epoch: 001 Step: 00000105] Batch Recognition Loss:   6.567701 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 20:03:37,647 [Epoch: 001 Step: 00000106] Batch Recognition Loss:   6.792305 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 20:06:26,221 [Epoch: 001 Step: 00000107] Batch Recognition Loss:   6.752703 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 20:09:27,076 [Epoch: 001 Step: 00000108] Batch Recognition Loss:   6.778770 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 20:12:29,595 [Epoch: 001 Step: 00000109] Batch Recognition Loss:   6.748987 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 20:15:29,414 [Epoch: 001 Step: 00000110] Batch Recognition Loss:   6.710721 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 20:18:24,581 [Epoch: 001 Step: 00000111] Batch Recognition Loss:   6.709951 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 20:21:33,075 [Epoch: 001 Step: 00000112] Batch Recognition Loss:   6.672874 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 20:24:16,604 [Epoch: 001 Step: 00000113] Batch Recognition Loss:   6.518091 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 20:26:51,274 [Epoch: 001 Step: 00000114] Batch Recognition Loss:   6.699126 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 20:29:17,525 [Epoch: 001 Step: 00000115] Batch Recognition Loss:   6.512061 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 20:31:45,787 [Epoch: 001 Step: 00000116] Batch Recognition Loss:   6.504934 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 20:34:28,698 [Epoch: 001 Step: 00000117] Batch Recognition Loss:   6.774727 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 20:41:34,324 [Epoch: 001 Step: 00000118] Batch Recognition Loss:   6.687727 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 20:44:23,118 [Epoch: 001 Step: 00000119] Batch Recognition Loss:   6.593610 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 20:47:05,774 [Epoch: 001 Step: 00000120] Batch Recognition Loss:   6.422211 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 20:50:00,563 [Epoch: 001 Step: 00000121] Batch Recognition Loss:   6.394105 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 20:53:10,839 [Epoch: 001 Step: 00000122] Batch Recognition Loss:   6.719057 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 20:56:23,122 [Epoch: 001 Step: 00000123] Batch Recognition Loss:   6.645759 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 20:58:57,394 [Epoch: 001 Step: 00000124] Batch Recognition Loss:   6.659288 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 21:02:06,409 [Epoch: 001 Step: 00000125] Batch Recognition Loss:   6.499339 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 21:05:17,452 [Epoch: 001 Step: 00000126] Batch Recognition Loss:   6.826719 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 21:08:42,500 [Epoch: 001 Step: 00000127] Batch Recognition Loss:   6.698093 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 21:14:55,539 [Epoch: 001 Step: 00000128] Batch Recognition Loss:   6.760668 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 21:17:46,881 [Epoch: 001 Step: 00000129] Batch Recognition Loss:   6.627473 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 21:21:06,960 [Epoch: 001 Step: 00000130] Batch Recognition Loss:   6.824587 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 21:24:40,946 [Epoch: 001 Step: 00000131] Batch Recognition Loss:   6.813511 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 21:27:41,162 [Epoch: 001 Step: 00000132] Batch Recognition Loss:   6.965228 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 21:30:28,911 [Epoch: 001 Step: 00000133] Batch Recognition Loss:   6.807295 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 21:33:22,665 [Epoch: 001 Step: 00000134] Batch Recognition Loss:   6.738855 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 21:36:06,456 [Epoch: 001 Step: 00000135] Batch Recognition Loss:   6.569225 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 21:38:57,964 [Epoch: 001 Step: 00000136] Batch Recognition Loss:   6.596504 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 21:41:58,776 [Epoch: 001 Step: 00000137] Batch Recognition Loss:   6.580914 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 21:45:13,685 [Epoch: 001 Step: 00000138] Batch Recognition Loss:   6.513481 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 21:48:23,106 [Epoch: 001 Step: 00000139] Batch Recognition Loss:   6.727292 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 21:51:25,903 [Epoch: 001 Step: 00000140] Batch Recognition Loss:   6.667051 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 21:56:23,214 [Epoch: 001 Step: 00000141] Batch Recognition Loss:   6.449977 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 22:00:07,507 [Epoch: 001 Step: 00000142] Batch Recognition Loss:   6.326486 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 22:04:07,844 [Epoch: 001 Step: 00000143] Batch Recognition Loss:   6.884572 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 22:08:32,775 [Epoch: 001 Step: 00000144] Batch Recognition Loss:   6.786911 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 22:12:40,563 [Epoch: 001 Step: 00000145] Batch Recognition Loss:   6.728035 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-23 22:16:46,221 [Epoch: 001 Step: 00000146] Batch Recognition Loss:   6.883142 => Gls Tokens per Sec:        0 || Lr: 0.001000
