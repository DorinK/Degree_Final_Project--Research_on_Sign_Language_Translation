2021-12-24 16:34:41,115 Hello! This is Joey-NMT.
2021-12-24 16:34:41,470 Total params: 12632045
2021-12-24 16:34:41,473 Trainable parameters: ['encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'gloss_output_layer.bias', 'gloss_output_layer.weight', 'image_encoder.classifier.0.bias', 'image_encoder.classifier.0.weight', 'image_encoder.classifier.3.bias', 'image_encoder.classifier.3.weight', 'image_encoder.features.0.0.weight', 'image_encoder.features.0.1.bias', 'image_encoder.features.0.1.weight', 'image_encoder.features.1.block.0.0.weight', 'image_encoder.features.1.block.0.1.bias', 'image_encoder.features.1.block.0.1.weight', 'image_encoder.features.1.block.1.fc1.bias', 'image_encoder.features.1.block.1.fc1.weight', 'image_encoder.features.1.block.1.fc2.bias', 'image_encoder.features.1.block.1.fc2.weight', 'image_encoder.features.1.block.2.0.weight', 'image_encoder.features.1.block.2.1.bias', 'image_encoder.features.1.block.2.1.weight', 'image_encoder.features.10.block.0.0.weight', 'image_encoder.features.10.block.0.1.bias', 'image_encoder.features.10.block.0.1.weight', 'image_encoder.features.10.block.1.0.weight', 'image_encoder.features.10.block.1.1.bias', 'image_encoder.features.10.block.1.1.weight', 'image_encoder.features.10.block.2.fc1.bias', 'image_encoder.features.10.block.2.fc1.weight', 'image_encoder.features.10.block.2.fc2.bias', 'image_encoder.features.10.block.2.fc2.weight', 'image_encoder.features.10.block.3.0.weight', 'image_encoder.features.10.block.3.1.bias', 'image_encoder.features.10.block.3.1.weight', 'image_encoder.features.11.block.0.0.weight', 'image_encoder.features.11.block.0.1.bias', 'image_encoder.features.11.block.0.1.weight', 'image_encoder.features.11.block.1.0.weight', 'image_encoder.features.11.block.1.1.bias', 'image_encoder.features.11.block.1.1.weight', 'image_encoder.features.11.block.2.fc1.bias', 'image_encoder.features.11.block.2.fc1.weight', 'image_encoder.features.11.block.2.fc2.bias', 'image_encoder.features.11.block.2.fc2.weight', 'image_encoder.features.11.block.3.0.weight', 'image_encoder.features.11.block.3.1.bias', 'image_encoder.features.11.block.3.1.weight', 'image_encoder.features.12.0.weight', 'image_encoder.features.12.1.bias', 'image_encoder.features.12.1.weight', 'image_encoder.features.2.block.0.0.weight', 'image_encoder.features.2.block.0.1.bias', 'image_encoder.features.2.block.0.1.weight', 'image_encoder.features.2.block.1.0.weight', 'image_encoder.features.2.block.1.1.bias', 'image_encoder.features.2.block.1.1.weight', 'image_encoder.features.2.block.2.0.weight', 'image_encoder.features.2.block.2.1.bias', 'image_encoder.features.2.block.2.1.weight', 'image_encoder.features.3.block.0.0.weight', 'image_encoder.features.3.block.0.1.bias', 'image_encoder.features.3.block.0.1.weight', 'image_encoder.features.3.block.1.0.weight', 'image_encoder.features.3.block.1.1.bias', 'image_encoder.features.3.block.1.1.weight', 'image_encoder.features.3.block.2.0.weight', 'image_encoder.features.3.block.2.1.bias', 'image_encoder.features.3.block.2.1.weight', 'image_encoder.features.4.block.0.0.weight', 'image_encoder.features.4.block.0.1.bias', 'image_encoder.features.4.block.0.1.weight', 'image_encoder.features.4.block.1.0.weight', 'image_encoder.features.4.block.1.1.bias', 'image_encoder.features.4.block.1.1.weight', 'image_encoder.features.4.block.2.fc1.bias', 'image_encoder.features.4.block.2.fc1.weight', 'image_encoder.features.4.block.2.fc2.bias', 'image_encoder.features.4.block.2.fc2.weight', 'image_encoder.features.4.block.3.0.weight', 'image_encoder.features.4.block.3.1.bias', 'image_encoder.features.4.block.3.1.weight', 'image_encoder.features.5.block.0.0.weight', 'image_encoder.features.5.block.0.1.bias', 'image_encoder.features.5.block.0.1.weight', 'image_encoder.features.5.block.1.0.weight', 'image_encoder.features.5.block.1.1.bias', 'image_encoder.features.5.block.1.1.weight', 'image_encoder.features.5.block.2.fc1.bias', 'image_encoder.features.5.block.2.fc1.weight', 'image_encoder.features.5.block.2.fc2.bias', 'image_encoder.features.5.block.2.fc2.weight', 'image_encoder.features.5.block.3.0.weight', 'image_encoder.features.5.block.3.1.bias', 'image_encoder.features.5.block.3.1.weight', 'image_encoder.features.6.block.0.0.weight', 'image_encoder.features.6.block.0.1.bias', 'image_encoder.features.6.block.0.1.weight', 'image_encoder.features.6.block.1.0.weight', 'image_encoder.features.6.block.1.1.bias', 'image_encoder.features.6.block.1.1.weight', 'image_encoder.features.6.block.2.fc1.bias', 'image_encoder.features.6.block.2.fc1.weight', 'image_encoder.features.6.block.2.fc2.bias', 'image_encoder.features.6.block.2.fc2.weight', 'image_encoder.features.6.block.3.0.weight', 'image_encoder.features.6.block.3.1.bias', 'image_encoder.features.6.block.3.1.weight', 'image_encoder.features.7.block.0.0.weight', 'image_encoder.features.7.block.0.1.bias', 'image_encoder.features.7.block.0.1.weight', 'image_encoder.features.7.block.1.0.weight', 'image_encoder.features.7.block.1.1.bias', 'image_encoder.features.7.block.1.1.weight', 'image_encoder.features.7.block.2.fc1.bias', 'image_encoder.features.7.block.2.fc1.weight', 'image_encoder.features.7.block.2.fc2.bias', 'image_encoder.features.7.block.2.fc2.weight', 'image_encoder.features.7.block.3.0.weight', 'image_encoder.features.7.block.3.1.bias', 'image_encoder.features.7.block.3.1.weight', 'image_encoder.features.8.block.0.0.weight', 'image_encoder.features.8.block.0.1.bias', 'image_encoder.features.8.block.0.1.weight', 'image_encoder.features.8.block.1.0.weight', 'image_encoder.features.8.block.1.1.bias', 'image_encoder.features.8.block.1.1.weight', 'image_encoder.features.8.block.2.fc1.bias', 'image_encoder.features.8.block.2.fc1.weight', 'image_encoder.features.8.block.2.fc2.bias', 'image_encoder.features.8.block.2.fc2.weight', 'image_encoder.features.8.block.3.0.weight', 'image_encoder.features.8.block.3.1.bias', 'image_encoder.features.8.block.3.1.weight', 'image_encoder.features.9.block.0.0.weight', 'image_encoder.features.9.block.0.1.bias', 'image_encoder.features.9.block.0.1.weight', 'image_encoder.features.9.block.1.0.weight', 'image_encoder.features.9.block.1.1.bias', 'image_encoder.features.9.block.1.1.weight', 'image_encoder.features.9.block.2.fc1.bias', 'image_encoder.features.9.block.2.fc1.weight', 'image_encoder.features.9.block.2.fc2.bias', 'image_encoder.features.9.block.2.fc2.weight', 'image_encoder.features.9.block.3.0.weight', 'image_encoder.features.9.block.3.1.bias', 'image_encoder.features.9.block.3.1.weight', 'sgn_embed.ln.bias', 'sgn_embed.ln.weight', 'sgn_embed.norm.norm.bias', 'sgn_embed.norm.norm.weight']
2021-12-24 16:34:56,520 cfg.name                           : AUTSL Experiment
2021-12-24 16:34:56,521 cfg.data.data_path                 : ./data/
2021-12-24 16:34:56,521 cfg.data.version                   : autsl
2021-12-24 16:34:56,521 cfg.data.sgn                       : sign
2021-12-24 16:34:56,521 cfg.data.gls                       : gloss
2021-12-24 16:34:56,521 cfg.data.feature_size              : 1000
2021-12-24 16:34:56,522 cfg.data.level                     : word
2021-12-24 16:34:56,522 cfg.data.max_sent_length           : 400
2021-12-24 16:34:56,522 cfg.data.random_train_subset       : -1
2021-12-24 16:34:56,522 cfg.data.random_dev_subset         : -1
2021-12-24 16:34:56,522 cfg.testing.recognition_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2021-12-24 16:34:56,522 cfg.testing.translation_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2021-12-24 16:34:56,522 cfg.testing.translation_beam_alphas : [-1, 0, 1, 2, 3, 4, 5]
2021-12-24 16:34:56,522 cfg.training.reset_best_ckpt       : False
2021-12-24 16:34:56,522 cfg.training.reset_scheduler       : False
2021-12-24 16:34:56,523 cfg.training.reset_optimizer       : False
2021-12-24 16:34:56,523 cfg.training.random_seed           : 42
2021-12-24 16:34:56,523 cfg.training.model_dir             : ./AUTSL Experiments/AUTSL_experiment_12
2021-12-24 16:34:56,523 cfg.training.recognition_loss_weight : 1.0
2021-12-24 16:34:56,523 cfg.training.translation_loss_weight : 0.0
2021-12-24 16:34:56,523 cfg.training.eval_metric           : wer
2021-12-24 16:34:56,523 cfg.training.optimizer             : adam
2021-12-24 16:34:56,523 cfg.training.learning_rate         : 0.001
2021-12-24 16:34:56,523 cfg.training.batch_size            : 32
2021-12-24 16:34:56,523 cfg.training.num_valid_log         : 5
2021-12-24 16:34:56,524 cfg.training.epochs                : 5000000
2021-12-24 16:34:56,524 cfg.training.early_stopping_metric : eval_metric
2021-12-24 16:34:56,524 cfg.training.batch_type            : sentence
2021-12-24 16:34:56,524 cfg.training.translation_normalization : batch
2021-12-24 16:34:56,524 cfg.training.eval_recognition_beam_size : 9
2021-12-24 16:34:56,524 cfg.training.eval_translation_beam_size : 9
2021-12-24 16:34:56,524 cfg.training.eval_translation_beam_alpha : 1
2021-12-24 16:34:56,524 cfg.training.overwrite             : True
2021-12-24 16:34:56,524 cfg.training.shuffle               : True
2021-12-24 16:34:56,524 cfg.training.use_cuda              : True
2021-12-24 16:34:56,525 cfg.training.translation_max_output_length : 30
2021-12-24 16:34:56,525 cfg.training.keep_last_ckpts       : 1
2021-12-24 16:34:56,525 cfg.training.batch_multiplier      : 1
2021-12-24 16:34:56,525 cfg.training.logging_freq          : 1
2021-12-24 16:34:56,525 cfg.training.validation_freq       : 400
2021-12-24 16:34:56,525 cfg.training.betas                 : [0.9, 0.998]
2021-12-24 16:34:56,525 cfg.training.scheduling            : plateau
2021-12-24 16:34:56,525 cfg.training.learning_rate_min     : 1e-06
2021-12-24 16:34:56,525 cfg.training.weight_decay          : 0.001
2021-12-24 16:34:56,526 cfg.training.patience              : 8
2021-12-24 16:34:56,526 cfg.training.decrease_factor       : 0.7
2021-12-24 16:34:56,526 cfg.training.label_smoothing       : 0.0
2021-12-24 16:34:56,526 cfg.model.initializer              : xavier
2021-12-24 16:34:56,526 cfg.model.bias_initializer         : zeros
2021-12-24 16:34:56,526 cfg.model.init_gain                : 1.0
2021-12-24 16:34:56,526 cfg.model.embed_initializer        : xavier
2021-12-24 16:34:56,526 cfg.model.embed_init_gain          : 1.0
2021-12-24 16:34:56,526 cfg.model.tied_softmax             : False
2021-12-24 16:34:56,526 cfg.model.encoder.type             : transformer
2021-12-24 16:34:56,527 cfg.model.encoder.num_layers       : 3
2021-12-24 16:34:56,527 cfg.model.encoder.num_heads        : 8
2021-12-24 16:34:56,527 cfg.model.encoder.embeddings.embedding_dim : 512
2021-12-24 16:34:56,527 cfg.model.encoder.embeddings.scale : False
2021-12-24 16:34:56,527 cfg.model.encoder.embeddings.dropout : 0.1
2021-12-24 16:34:56,527 cfg.model.encoder.embeddings.norm_type : batch
2021-12-24 16:34:56,527 cfg.model.encoder.embeddings.activation_type : softsign
2021-12-24 16:34:56,527 cfg.model.encoder.hidden_size      : 512
2021-12-24 16:34:56,527 cfg.model.encoder.ff_size          : 2048
2021-12-24 16:34:56,527 cfg.model.encoder.dropout          : 0.1
2021-12-24 16:34:56,528 cfg.model.decoder.type             : transformer
2021-12-24 16:34:56,528 cfg.model.decoder.num_layers       : 3
2021-12-24 16:34:56,528 cfg.model.decoder.num_heads        : 8
2021-12-24 16:34:56,528 cfg.model.decoder.embeddings.embedding_dim : 512
2021-12-24 16:34:56,528 cfg.model.decoder.embeddings.scale : False
2021-12-24 16:34:56,528 cfg.model.decoder.embeddings.dropout : 0.1
2021-12-24 16:34:56,528 cfg.model.decoder.embeddings.norm_type : batch
2021-12-24 16:34:56,528 cfg.model.decoder.embeddings.activation_type : softsign
2021-12-24 16:34:56,528 cfg.model.decoder.hidden_size      : 512
2021-12-24 16:34:56,529 cfg.model.decoder.ff_size          : 2048
2021-12-24 16:34:56,529 cfg.model.decoder.dropout          : 0.1
2021-12-24 16:34:56,529 SignModel(
	encoder=TransformerEncoder(num_layers=3, num_heads=8),
	decoder=None,
	sgn_embed=SpatialEmbeddings(embedding_dim=512, input_size=1000),
	txt_embed=None)
2021-12-24 16:34:56,533 EPOCH 1
2021-12-24 16:35:56,114 [Epoch: 001 Step: 00000001] Batch Recognition Loss: 331.626373 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 16:36:47,975 [Epoch: 001 Step: 00000002] Batch Recognition Loss:  15.212700 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 16:37:39,043 [Epoch: 001 Step: 00000003] Batch Recognition Loss:  15.447153 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 16:38:36,452 [Epoch: 001 Step: 00000004] Batch Recognition Loss:  14.845661 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 16:39:26,534 [Epoch: 001 Step: 00000005] Batch Recognition Loss:  13.061631 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 16:40:15,029 [Epoch: 001 Step: 00000006] Batch Recognition Loss:  11.722843 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 16:41:07,689 [Epoch: 001 Step: 00000007] Batch Recognition Loss:   9.502829 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 16:42:09,248 [Epoch: 001 Step: 00000008] Batch Recognition Loss:   8.077069 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 16:43:06,979 [Epoch: 001 Step: 00000009] Batch Recognition Loss:   7.342940 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 16:44:01,479 [Epoch: 001 Step: 00000010] Batch Recognition Loss:   8.968698 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 16:45:04,603 [Epoch: 001 Step: 00000011] Batch Recognition Loss:   7.280187 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 16:45:56,048 [Epoch: 001 Step: 00000012] Batch Recognition Loss:   7.126068 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 16:46:44,658 [Epoch: 001 Step: 00000013] Batch Recognition Loss:   7.635421 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 16:47:47,300 [Epoch: 001 Step: 00000014] Batch Recognition Loss:   7.886333 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 16:48:42,770 [Epoch: 001 Step: 00000015] Batch Recognition Loss:   8.083994 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 16:49:39,987 [Epoch: 001 Step: 00000016] Batch Recognition Loss:   7.514650 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 16:50:36,768 [Epoch: 001 Step: 00000017] Batch Recognition Loss:   7.141973 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 16:51:32,413 [Epoch: 001 Step: 00000018] Batch Recognition Loss:   6.916709 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 16:52:28,586 [Epoch: 001 Step: 00000019] Batch Recognition Loss:   6.443252 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 16:53:31,983 [Epoch: 001 Step: 00000020] Batch Recognition Loss:   6.531296 => Gls Tokens per Sec:        1 || Lr: 0.001000
2021-12-24 16:54:41,390 [Epoch: 001 Step: 00000021] Batch Recognition Loss:   7.325680 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 16:55:49,460 [Epoch: 001 Step: 00000022] Batch Recognition Loss:   7.088523 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 16:57:02,484 [Epoch: 001 Step: 00000023] Batch Recognition Loss:   7.129069 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 16:58:14,200 [Epoch: 001 Step: 00000024] Batch Recognition Loss:   6.796729 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:00:28,983 [Epoch: 001 Step: 00000025] Batch Recognition Loss:   6.470945 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:01:38,575 [Epoch: 001 Step: 00000026] Batch Recognition Loss:   6.526409 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:02:52,775 [Epoch: 001 Step: 00000027] Batch Recognition Loss:   7.091303 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:04:07,381 [Epoch: 001 Step: 00000028] Batch Recognition Loss:   6.947853 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:05:34,895 [Epoch: 001 Step: 00000029] Batch Recognition Loss:   6.766934 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:07:03,759 [Epoch: 001 Step: 00000030] Batch Recognition Loss:   6.818649 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:08:16,970 [Epoch: 001 Step: 00000031] Batch Recognition Loss:   6.789102 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:11:04,283 [Epoch: 001 Step: 00000032] Batch Recognition Loss:   6.917588 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:12:36,345 [Epoch: 001 Step: 00000033] Batch Recognition Loss:   6.637297 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:14:01,608 [Epoch: 001 Step: 00000034] Batch Recognition Loss:   6.811693 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:15:31,687 [Epoch: 001 Step: 00000035] Batch Recognition Loss:   6.646605 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:17:07,949 [Epoch: 001 Step: 00000036] Batch Recognition Loss:   6.837689 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:18:47,476 [Epoch: 001 Step: 00000037] Batch Recognition Loss:   6.877223 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:20:22,760 [Epoch: 001 Step: 00000038] Batch Recognition Loss:   6.374960 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:22:02,085 [Epoch: 001 Step: 00000039] Batch Recognition Loss:   6.661604 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:25:18,748 [Epoch: 001 Step: 00000040] Batch Recognition Loss:   6.501655 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:26:56,067 [Epoch: 001 Step: 00000041] Batch Recognition Loss:   6.590907 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:28:37,621 [Epoch: 001 Step: 00000042] Batch Recognition Loss:   6.694228 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:30:24,957 [Epoch: 001 Step: 00000043] Batch Recognition Loss:   6.890666 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:32:04,296 [Epoch: 001 Step: 00000044] Batch Recognition Loss:   6.600240 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:33:49,054 [Epoch: 001 Step: 00000045] Batch Recognition Loss:   6.872275 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:35:38,600 [Epoch: 001 Step: 00000046] Batch Recognition Loss:   6.696733 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:37:31,198 [Epoch: 001 Step: 00000047] Batch Recognition Loss:   6.877104 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:39:11,974 [Epoch: 001 Step: 00000048] Batch Recognition Loss:   6.801319 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:41:02,010 [Epoch: 001 Step: 00000049] Batch Recognition Loss:   6.342098 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:42:49,636 [Epoch: 001 Step: 00000050] Batch Recognition Loss:   6.645688 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:44:40,917 [Epoch: 001 Step: 00000051] Batch Recognition Loss:   6.665909 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:46:29,342 [Epoch: 001 Step: 00000052] Batch Recognition Loss:   6.514029 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:48:12,467 [Epoch: 001 Step: 00000053] Batch Recognition Loss:   6.711866 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:50:05,805 [Epoch: 001 Step: 00000054] Batch Recognition Loss:   6.774549 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:51:47,817 [Epoch: 001 Step: 00000055] Batch Recognition Loss:   6.608777 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:53:36,248 [Epoch: 001 Step: 00000056] Batch Recognition Loss:   6.408754 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:55:19,839 [Epoch: 001 Step: 00000057] Batch Recognition Loss:   6.705512 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:57:10,061 [Epoch: 001 Step: 00000058] Batch Recognition Loss:   6.701485 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 17:59:02,165 [Epoch: 001 Step: 00000059] Batch Recognition Loss:   6.568654 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 18:00:57,805 [Epoch: 001 Step: 00000060] Batch Recognition Loss:   6.428942 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 18:02:57,535 [Epoch: 001 Step: 00000061] Batch Recognition Loss:   6.603092 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 18:04:48,042 [Epoch: 001 Step: 00000062] Batch Recognition Loss:   6.489419 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 18:06:40,110 [Epoch: 001 Step: 00000063] Batch Recognition Loss:   6.600274 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 18:08:35,706 [Epoch: 001 Step: 00000064] Batch Recognition Loss:   6.600961 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 18:10:34,328 [Epoch: 001 Step: 00000065] Batch Recognition Loss:   6.641279 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 18:12:36,161 [Epoch: 001 Step: 00000066] Batch Recognition Loss:   6.758648 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 18:14:32,110 [Epoch: 001 Step: 00000067] Batch Recognition Loss:   6.749059 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 18:16:37,384 [Epoch: 001 Step: 00000068] Batch Recognition Loss:   6.575168 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 18:18:35,678 [Epoch: 001 Step: 00000069] Batch Recognition Loss:   6.589280 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 18:20:42,016 [Epoch: 001 Step: 00000070] Batch Recognition Loss:   6.710414 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 18:22:49,820 [Epoch: 001 Step: 00000071] Batch Recognition Loss:   6.715822 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 18:25:01,404 [Epoch: 001 Step: 00000072] Batch Recognition Loss:   6.836435 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 18:27:16,735 [Epoch: 001 Step: 00000073] Batch Recognition Loss:   6.592440 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 18:29:38,423 [Epoch: 001 Step: 00000074] Batch Recognition Loss:   6.808124 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 18:32:11,238 [Epoch: 001 Step: 00000075] Batch Recognition Loss:   6.917988 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 18:34:48,596 [Epoch: 001 Step: 00000076] Batch Recognition Loss:   6.631883 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 18:36:54,799 [Epoch: 001 Step: 00000077] Batch Recognition Loss:   6.449824 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 18:38:59,919 [Epoch: 001 Step: 00000078] Batch Recognition Loss:   6.681463 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 18:41:13,423 [Epoch: 001 Step: 00000079] Batch Recognition Loss:   6.643338 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 18:43:33,699 [Epoch: 001 Step: 00000080] Batch Recognition Loss:   6.594313 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 18:46:03,980 [Epoch: 001 Step: 00000081] Batch Recognition Loss:   6.463273 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 18:48:28,795 [Epoch: 001 Step: 00000082] Batch Recognition Loss:   6.596921 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 18:50:52,614 [Epoch: 001 Step: 00000083] Batch Recognition Loss:   6.692822 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 18:53:30,980 [Epoch: 001 Step: 00000084] Batch Recognition Loss:   6.664768 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 18:56:03,292 [Epoch: 001 Step: 00000085] Batch Recognition Loss:   6.380852 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 18:58:42,865 [Epoch: 001 Step: 00000086] Batch Recognition Loss:   6.653228 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 19:01:12,052 [Epoch: 001 Step: 00000087] Batch Recognition Loss:   6.858895 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 19:03:43,695 [Epoch: 001 Step: 00000088] Batch Recognition Loss:   6.712041 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 19:06:21,955 [Epoch: 001 Step: 00000089] Batch Recognition Loss:   6.776379 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 19:08:57,905 [Epoch: 001 Step: 00000090] Batch Recognition Loss:   6.680383 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 19:11:32,600 [Epoch: 001 Step: 00000091] Batch Recognition Loss:   6.474995 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 19:14:17,456 [Epoch: 001 Step: 00000092] Batch Recognition Loss:   6.596385 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 19:17:01,466 [Epoch: 001 Step: 00000093] Batch Recognition Loss:   6.778997 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 19:19:39,113 [Epoch: 001 Step: 00000094] Batch Recognition Loss:   6.513289 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 19:22:18,553 [Epoch: 001 Step: 00000095] Batch Recognition Loss:   6.527596 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 19:25:11,848 [Epoch: 001 Step: 00000096] Batch Recognition Loss:   6.573826 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 19:28:12,487 [Epoch: 001 Step: 00000097] Batch Recognition Loss:   6.715204 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 19:31:05,010 [Epoch: 001 Step: 00000098] Batch Recognition Loss:   6.631966 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 19:33:59,193 [Epoch: 001 Step: 00000099] Batch Recognition Loss:   6.939064 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 19:36:44,371 [Epoch: 001 Step: 00000100] Batch Recognition Loss:   6.663382 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 19:39:42,822 [Epoch: 001 Step: 00000101] Batch Recognition Loss:   6.668216 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 19:42:35,667 [Epoch: 001 Step: 00000102] Batch Recognition Loss:   6.582295 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 19:45:40,355 [Epoch: 001 Step: 00000103] Batch Recognition Loss:   6.748977 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 19:48:39,877 [Epoch: 001 Step: 00000104] Batch Recognition Loss:   6.632689 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 19:51:29,767 [Epoch: 001 Step: 00000105] Batch Recognition Loss:   6.736241 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 19:54:28,738 [Epoch: 001 Step: 00000106] Batch Recognition Loss:   6.508617 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 20:00:50,797 [Epoch: 001 Step: 00000107] Batch Recognition Loss:   6.690825 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 20:04:00,086 [Epoch: 001 Step: 00000108] Batch Recognition Loss:   6.390494 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 20:07:00,089 [Epoch: 001 Step: 00000109] Batch Recognition Loss:   6.781535 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 20:10:16,035 [Epoch: 001 Step: 00000110] Batch Recognition Loss:   6.586390 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 20:13:15,316 [Epoch: 001 Step: 00000111] Batch Recognition Loss:   6.610743 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 20:16:14,268 [Epoch: 001 Step: 00000112] Batch Recognition Loss:   6.623082 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 20:19:23,169 [Epoch: 001 Step: 00000113] Batch Recognition Loss:   6.568910 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 20:22:37,525 [Epoch: 001 Step: 00000114] Batch Recognition Loss:   6.536426 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 20:25:41,009 [Epoch: 001 Step: 00000115] Batch Recognition Loss:   6.686522 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 20:28:57,590 [Epoch: 001 Step: 00000116] Batch Recognition Loss:   6.571920 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 20:32:27,674 [Epoch: 001 Step: 00000117] Batch Recognition Loss:   6.496739 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 20:35:38,531 [Epoch: 001 Step: 00000118] Batch Recognition Loss:   6.484149 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 20:38:50,831 [Epoch: 001 Step: 00000119] Batch Recognition Loss:   6.486666 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 20:42:15,582 [Epoch: 001 Step: 00000120] Batch Recognition Loss:   6.655595 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 20:45:46,856 [Epoch: 001 Step: 00000121] Batch Recognition Loss:   6.793162 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 20:49:10,887 [Epoch: 001 Step: 00000122] Batch Recognition Loss:   6.544168 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 20:52:42,229 [Epoch: 001 Step: 00000123] Batch Recognition Loss:   6.675719 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 20:56:13,838 [Epoch: 001 Step: 00000124] Batch Recognition Loss:   6.470210 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 20:59:37,034 [Epoch: 001 Step: 00000125] Batch Recognition Loss:   6.622573 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 21:03:01,370 [Epoch: 001 Step: 00000126] Batch Recognition Loss:   6.429860 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 21:06:24,098 [Epoch: 001 Step: 00000127] Batch Recognition Loss:   6.518279 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 21:09:51,456 [Epoch: 001 Step: 00000128] Batch Recognition Loss:   6.832972 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 21:13:22,087 [Epoch: 001 Step: 00000129] Batch Recognition Loss:   6.755532 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 21:16:54,565 [Epoch: 001 Step: 00000130] Batch Recognition Loss:   6.604539 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 21:20:31,347 [Epoch: 001 Step: 00000131] Batch Recognition Loss:   6.610786 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 21:24:05,768 [Epoch: 001 Step: 00000132] Batch Recognition Loss:   6.658650 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 21:27:34,149 [Epoch: 001 Step: 00000133] Batch Recognition Loss:   6.579440 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 21:30:49,890 [Epoch: 001 Step: 00000134] Batch Recognition Loss:   6.684576 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 21:34:24,488 [Epoch: 001 Step: 00000135] Batch Recognition Loss:   6.801800 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 21:37:54,478 [Epoch: 001 Step: 00000136] Batch Recognition Loss:   6.934309 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 21:41:26,962 [Epoch: 001 Step: 00000137] Batch Recognition Loss:   6.447850 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 21:45:05,845 [Epoch: 001 Step: 00000138] Batch Recognition Loss:   6.644332 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 21:48:38,513 [Epoch: 001 Step: 00000139] Batch Recognition Loss:   6.693581 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 21:52:18,320 [Epoch: 001 Step: 00000140] Batch Recognition Loss:   6.614954 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 21:55:53,588 [Epoch: 001 Step: 00000141] Batch Recognition Loss:   6.468692 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 21:59:37,341 [Epoch: 001 Step: 00000142] Batch Recognition Loss:   6.792632 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 22:03:21,090 [Epoch: 001 Step: 00000143] Batch Recognition Loss:   6.637901 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 22:06:59,262 [Epoch: 001 Step: 00000144] Batch Recognition Loss:   6.618147 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 22:10:41,993 [Epoch: 001 Step: 00000145] Batch Recognition Loss:   6.504115 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 22:14:40,026 [Epoch: 001 Step: 00000146] Batch Recognition Loss:   6.681690 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 22:18:26,474 [Epoch: 001 Step: 00000147] Batch Recognition Loss:   6.520495 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 22:22:11,911 [Epoch: 001 Step: 00000148] Batch Recognition Loss:   6.641721 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 22:26:11,034 [Epoch: 001 Step: 00000149] Batch Recognition Loss:   6.765725 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 22:29:59,479 [Epoch: 001 Step: 00000150] Batch Recognition Loss:   6.528121 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 22:33:50,721 [Epoch: 001 Step: 00000151] Batch Recognition Loss:   6.619376 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 22:37:48,218 [Epoch: 001 Step: 00000152] Batch Recognition Loss:   6.620532 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 22:41:43,549 [Epoch: 001 Step: 00000153] Batch Recognition Loss:   6.734784 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 22:45:33,663 [Epoch: 001 Step: 00000154] Batch Recognition Loss:   6.513607 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 22:53:13,664 [Epoch: 001 Step: 00000155] Batch Recognition Loss:   6.684151 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 22:57:15,948 [Epoch: 001 Step: 00000156] Batch Recognition Loss:   6.749089 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 23:01:27,526 [Epoch: 001 Step: 00000157] Batch Recognition Loss:   6.636494 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 23:05:29,271 [Epoch: 001 Step: 00000158] Batch Recognition Loss:   6.538998 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 23:09:38,235 [Epoch: 001 Step: 00000159] Batch Recognition Loss:   6.540386 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 23:13:46,934 [Epoch: 001 Step: 00000160] Batch Recognition Loss:   6.719099 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 23:18:00,723 [Epoch: 001 Step: 00000161] Batch Recognition Loss:   6.563068 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 23:22:10,643 [Epoch: 001 Step: 00000162] Batch Recognition Loss:   6.658966 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 23:26:22,586 [Epoch: 001 Step: 00000163] Batch Recognition Loss:   6.751055 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 23:30:43,982 [Epoch: 001 Step: 00000164] Batch Recognition Loss:   6.702942 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 23:34:51,342 [Epoch: 001 Step: 00000165] Batch Recognition Loss:   6.624951 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 23:39:05,429 [Epoch: 001 Step: 00000166] Batch Recognition Loss:   6.840659 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 23:43:24,320 [Epoch: 001 Step: 00000167] Batch Recognition Loss:   6.718885 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 23:47:44,637 [Epoch: 001 Step: 00000168] Batch Recognition Loss:   6.502999 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 23:52:08,225 [Epoch: 001 Step: 00000169] Batch Recognition Loss:   6.671487 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-24 23:56:37,167 [Epoch: 001 Step: 00000170] Batch Recognition Loss:   6.783732 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 00:01:03,043 [Epoch: 001 Step: 00000171] Batch Recognition Loss:   6.870109 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 00:05:30,488 [Epoch: 001 Step: 00000172] Batch Recognition Loss:   6.634604 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 00:09:47,740 [Epoch: 001 Step: 00000173] Batch Recognition Loss:   6.667075 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 00:14:06,374 [Epoch: 001 Step: 00000174] Batch Recognition Loss:   6.673531 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 00:18:26,291 [Epoch: 001 Step: 00000175] Batch Recognition Loss:   6.515275 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 00:22:47,744 [Epoch: 001 Step: 00000176] Batch Recognition Loss:   6.266733 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 00:27:07,528 [Epoch: 001 Step: 00000177] Batch Recognition Loss:   6.680359 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 00:31:29,853 [Epoch: 001 Step: 00000178] Batch Recognition Loss:   6.427588 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 00:35:58,328 [Epoch: 001 Step: 00000179] Batch Recognition Loss:   6.872500 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 00:40:25,967 [Epoch: 001 Step: 00000180] Batch Recognition Loss:   6.460382 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 00:45:03,773 [Epoch: 001 Step: 00000181] Batch Recognition Loss:   6.679440 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 00:49:43,579 [Epoch: 001 Step: 00000182] Batch Recognition Loss:   6.764208 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 00:54:18,659 [Epoch: 001 Step: 00000183] Batch Recognition Loss:   6.808558 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 00:58:42,398 [Epoch: 001 Step: 00000184] Batch Recognition Loss:   6.685869 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 01:03:29,827 [Epoch: 001 Step: 00000185] Batch Recognition Loss:   6.536617 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 01:08:05,354 [Epoch: 001 Step: 00000186] Batch Recognition Loss:   6.748812 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 01:12:41,278 [Epoch: 001 Step: 00000187] Batch Recognition Loss:   6.713872 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 01:17:10,352 [Epoch: 001 Step: 00000188] Batch Recognition Loss:   6.729940 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 01:21:39,402 [Epoch: 001 Step: 00000189] Batch Recognition Loss:   6.684861 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 01:26:14,877 [Epoch: 001 Step: 00000190] Batch Recognition Loss:   6.590891 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 01:30:55,508 [Epoch: 001 Step: 00000191] Batch Recognition Loss:   6.668814 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 01:35:38,447 [Epoch: 001 Step: 00000192] Batch Recognition Loss:   6.481668 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 01:40:30,709 [Epoch: 001 Step: 00000193] Batch Recognition Loss:   6.542184 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 01:45:21,749 [Epoch: 001 Step: 00000194] Batch Recognition Loss:   6.475447 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 01:50:10,934 [Epoch: 001 Step: 00000195] Batch Recognition Loss:   6.506983 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 01:54:59,322 [Epoch: 001 Step: 00000196] Batch Recognition Loss:   6.492929 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 01:59:52,229 [Epoch: 001 Step: 00000197] Batch Recognition Loss:   6.591187 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 02:04:43,106 [Epoch: 001 Step: 00000198] Batch Recognition Loss:   6.765075 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 02:09:41,374 [Epoch: 001 Step: 00000199] Batch Recognition Loss:   6.755784 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 02:14:26,989 [Epoch: 001 Step: 00000200] Batch Recognition Loss:   6.776815 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 02:19:18,680 [Epoch: 001 Step: 00000201] Batch Recognition Loss:   6.732736 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 02:24:22,967 [Epoch: 001 Step: 00000202] Batch Recognition Loss:   6.705306 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 02:29:01,921 [Epoch: 001 Step: 00000203] Batch Recognition Loss:   6.694796 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 02:34:04,314 [Epoch: 001 Step: 00000204] Batch Recognition Loss:   6.645618 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 02:39:20,957 [Epoch: 001 Step: 00000205] Batch Recognition Loss:   6.610225 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 02:44:19,445 [Epoch: 001 Step: 00000206] Batch Recognition Loss:   6.741945 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 02:49:17,822 [Epoch: 001 Step: 00000207] Batch Recognition Loss:   6.629791 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 02:54:26,939 [Epoch: 001 Step: 00000208] Batch Recognition Loss:   6.679397 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 02:59:42,233 [Epoch: 001 Step: 00000209] Batch Recognition Loss:   6.648407 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 03:04:57,748 [Epoch: 001 Step: 00000210] Batch Recognition Loss:   6.544743 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 03:10:03,961 [Epoch: 001 Step: 00000211] Batch Recognition Loss:   6.450045 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 03:15:28,065 [Epoch: 001 Step: 00000212] Batch Recognition Loss:   6.672864 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 03:20:41,732 [Epoch: 001 Step: 00000213] Batch Recognition Loss:   6.516675 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 03:25:52,613 [Epoch: 001 Step: 00000214] Batch Recognition Loss:   6.792170 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 03:31:17,290 [Epoch: 001 Step: 00000215] Batch Recognition Loss:   6.544152 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 03:36:18,934 [Epoch: 001 Step: 00000216] Batch Recognition Loss:   6.644361 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 03:41:30,758 [Epoch: 001 Step: 00000217] Batch Recognition Loss:   6.643365 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 03:47:24,328 [Epoch: 001 Step: 00000218] Batch Recognition Loss:   6.450461 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 03:53:21,214 [Epoch: 001 Step: 00000219] Batch Recognition Loss:   6.768127 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 03:59:12,576 [Epoch: 001 Step: 00000220] Batch Recognition Loss:   6.628753 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 04:05:08,702 [Epoch: 001 Step: 00000221] Batch Recognition Loss:   6.693905 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 04:10:50,937 [Epoch: 001 Step: 00000222] Batch Recognition Loss:   6.593144 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 04:16:44,040 [Epoch: 001 Step: 00000223] Batch Recognition Loss:   6.897830 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 04:22:32,121 [Epoch: 001 Step: 00000224] Batch Recognition Loss:   6.560596 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 04:28:32,283 [Epoch: 001 Step: 00000225] Batch Recognition Loss:   6.592337 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 04:34:35,105 [Epoch: 001 Step: 00000226] Batch Recognition Loss:   6.545328 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 04:40:39,496 [Epoch: 001 Step: 00000227] Batch Recognition Loss:   6.534621 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 04:47:04,866 [Epoch: 001 Step: 00000228] Batch Recognition Loss:   6.661665 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 04:53:15,246 [Epoch: 001 Step: 00000229] Batch Recognition Loss:   6.871071 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 04:59:23,153 [Epoch: 001 Step: 00000230] Batch Recognition Loss:   6.458529 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 05:05:29,195 [Epoch: 001 Step: 00000231] Batch Recognition Loss:   6.828698 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 05:11:42,808 [Epoch: 001 Step: 00000232] Batch Recognition Loss:   6.678404 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 05:17:50,156 [Epoch: 001 Step: 00000233] Batch Recognition Loss:   6.659938 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 05:24:07,372 [Epoch: 001 Step: 00000234] Batch Recognition Loss:   6.592725 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 05:30:24,413 [Epoch: 001 Step: 00000235] Batch Recognition Loss:   6.549992 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 05:36:43,554 [Epoch: 001 Step: 00000236] Batch Recognition Loss:   6.643332 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 05:43:07,332 [Epoch: 001 Step: 00000237] Batch Recognition Loss:   6.564664 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 05:49:24,769 [Epoch: 001 Step: 00000238] Batch Recognition Loss:   6.606450 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 05:55:45,172 [Epoch: 001 Step: 00000239] Batch Recognition Loss:   6.501353 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 06:02:10,408 [Epoch: 001 Step: 00000240] Batch Recognition Loss:   6.707841 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 06:08:38,590 [Epoch: 001 Step: 00000241] Batch Recognition Loss:   6.667550 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 06:15:11,795 [Epoch: 001 Step: 00000242] Batch Recognition Loss:   6.629539 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 06:21:31,784 [Epoch: 001 Step: 00000243] Batch Recognition Loss:   6.735167 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 06:28:08,643 [Epoch: 001 Step: 00000244] Batch Recognition Loss:   6.792068 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 06:34:46,389 [Epoch: 001 Step: 00000245] Batch Recognition Loss:   6.746350 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 06:41:24,726 [Epoch: 001 Step: 00000246] Batch Recognition Loss:   6.800920 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 06:48:10,576 [Epoch: 001 Step: 00000247] Batch Recognition Loss:   6.827912 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 06:54:48,833 [Epoch: 001 Step: 00000248] Batch Recognition Loss:   6.575294 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 07:01:12,605 [Epoch: 001 Step: 00000249] Batch Recognition Loss:   6.527788 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 07:07:49,325 [Epoch: 001 Step: 00000250] Batch Recognition Loss:   6.662457 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 07:14:24,987 [Epoch: 001 Step: 00000251] Batch Recognition Loss:   6.641293 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 07:21:06,520 [Epoch: 001 Step: 00000252] Batch Recognition Loss:   6.541285 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 07:27:48,430 [Epoch: 001 Step: 00000253] Batch Recognition Loss:   6.785037 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 07:34:28,618 [Epoch: 001 Step: 00000254] Batch Recognition Loss:   6.560226 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 07:41:11,876 [Epoch: 001 Step: 00000255] Batch Recognition Loss:   6.598382 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 07:47:59,277 [Epoch: 001 Step: 00000256] Batch Recognition Loss:   6.714687 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 07:54:40,520 [Epoch: 001 Step: 00000257] Batch Recognition Loss:   6.528369 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 08:01:33,592 [Epoch: 001 Step: 00000258] Batch Recognition Loss:   6.730221 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 08:08:24,377 [Epoch: 001 Step: 00000259] Batch Recognition Loss:   6.852230 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 08:15:14,980 [Epoch: 001 Step: 00000260] Batch Recognition Loss:   6.624925 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 08:21:52,955 [Epoch: 001 Step: 00000261] Batch Recognition Loss:   6.700431 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 08:28:35,189 [Epoch: 001 Step: 00000262] Batch Recognition Loss:   6.657983 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 08:35:27,353 [Epoch: 001 Step: 00000263] Batch Recognition Loss:   6.750885 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 08:42:14,095 [Epoch: 001 Step: 00000264] Batch Recognition Loss:   6.705174 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 08:49:07,213 [Epoch: 001 Step: 00000265] Batch Recognition Loss:   6.477187 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 08:56:11,038 [Epoch: 001 Step: 00000266] Batch Recognition Loss:   6.584538 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 09:03:11,460 [Epoch: 001 Step: 00000267] Batch Recognition Loss:   6.681291 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 09:17:07,187 [Epoch: 001 Step: 00000268] Batch Recognition Loss:   6.468501 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 09:24:00,711 [Epoch: 001 Step: 00000269] Batch Recognition Loss:   6.658487 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 09:30:46,935 [Epoch: 001 Step: 00000270] Batch Recognition Loss:   6.464394 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 09:37:55,521 [Epoch: 001 Step: 00000271] Batch Recognition Loss:   6.556906 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 09:44:52,702 [Epoch: 001 Step: 00000272] Batch Recognition Loss:   6.566031 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 09:52:01,529 [Epoch: 001 Step: 00000273] Batch Recognition Loss:   6.586915 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 09:59:05,166 [Epoch: 001 Step: 00000274] Batch Recognition Loss:   6.782709 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 10:06:27,635 [Epoch: 001 Step: 00000275] Batch Recognition Loss:   6.393987 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 10:13:43,897 [Epoch: 001 Step: 00000276] Batch Recognition Loss:   6.932698 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 10:20:48,601 [Epoch: 001 Step: 00000277] Batch Recognition Loss:   6.874420 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 10:28:08,573 [Epoch: 001 Step: 00000278] Batch Recognition Loss:   6.591594 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 10:35:16,254 [Epoch: 001 Step: 00000279] Batch Recognition Loss:   6.648047 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 10:42:28,270 [Epoch: 001 Step: 00000280] Batch Recognition Loss:   7.029644 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 10:49:56,715 [Epoch: 001 Step: 00000281] Batch Recognition Loss:   6.610065 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 10:57:19,995 [Epoch: 001 Step: 00000282] Batch Recognition Loss:   6.662008 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 11:04:52,682 [Epoch: 001 Step: 00000283] Batch Recognition Loss:   6.670879 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 11:12:12,520 [Epoch: 001 Step: 00000284] Batch Recognition Loss:   6.592095 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 11:19:44,441 [Epoch: 001 Step: 00000285] Batch Recognition Loss:   6.516693 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 11:27:10,778 [Epoch: 001 Step: 00000286] Batch Recognition Loss:   6.424155 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 11:34:57,838 [Epoch: 001 Step: 00000287] Batch Recognition Loss:   6.584978 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 11:42:10,128 [Epoch: 001 Step: 00000288] Batch Recognition Loss:   6.439542 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 11:49:33,507 [Epoch: 001 Step: 00000289] Batch Recognition Loss:   6.920369 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 11:57:07,827 [Epoch: 001 Step: 00000290] Batch Recognition Loss:   6.709182 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 12:04:34,440 [Epoch: 001 Step: 00000291] Batch Recognition Loss:   6.526988 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 12:12:42,604 [Epoch: 001 Step: 00000292] Batch Recognition Loss:   6.564804 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 12:20:26,439 [Epoch: 001 Step: 00000293] Batch Recognition Loss:   6.920629 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 12:28:05,174 [Epoch: 001 Step: 00000294] Batch Recognition Loss:   6.782937 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 12:35:31,521 [Epoch: 001 Step: 00000295] Batch Recognition Loss:   6.762645 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 12:43:26,012 [Epoch: 001 Step: 00000296] Batch Recognition Loss:   6.924889 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 12:51:12,713 [Epoch: 001 Step: 00000297] Batch Recognition Loss:   6.629783 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 12:58:58,781 [Epoch: 001 Step: 00000298] Batch Recognition Loss:   6.306412 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 13:07:17,277 [Epoch: 001 Step: 00000299] Batch Recognition Loss:   6.605473 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 13:14:59,513 [Epoch: 001 Step: 00000300] Batch Recognition Loss:   6.634160 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 13:22:48,405 [Epoch: 001 Step: 00000301] Batch Recognition Loss:   6.526620 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 13:30:34,423 [Epoch: 001 Step: 00000302] Batch Recognition Loss:   6.395272 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 13:38:33,731 [Epoch: 001 Step: 00000303] Batch Recognition Loss:   6.436619 => Gls Tokens per Sec:        0 || Lr: 0.001000
2021-12-25 13:46:27,789 [Epoch: 001 Step: 00000304] Batch Recognition Loss:   6.649708 => Gls Tokens per Sec:        0 || Lr: 0.001000
